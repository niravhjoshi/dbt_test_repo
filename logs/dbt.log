2022-01-14 12:54:26.270128 (MainThread): Running with dbt=0.21.1
2022-01-14 12:54:26.347718 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2022-01-14 12:54:26.349427 (MainThread): Tracking: tracking
2022-01-14 12:54:26.368973 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d1c92b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d904bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d904400>]}
2022-01-14 12:54:26.371854 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d8d6fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d8d6820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d8d6940>]}
2022-01-14 12:54:26.372256 (MainThread): Flushing usage events
2022-01-14 12:54:28.000392 (MainThread): Encountered an error:
2022-01-14 12:54:28.000760 (MainThread): Compilation Error
  dbt found 1 package(s) specified in packages.yml, but only 0 package(s) installed in dbt_modules. Run "dbt deps" to install package dependencies.
2022-01-14 12:54:28.007303 (MainThread): Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/dbt/main.py", line 127, in main
    results, succeeded = handle_and_check(args)
  File "/usr/local/lib/python3.9/site-packages/dbt/main.py", line 205, in handle_and_check
    task, res = run_from_args(parsed)
  File "/usr/local/lib/python3.9/site-packages/dbt/main.py", line 258, in run_from_args
    results = task.run()
  File "/usr/local/lib/python3.9/site-packages/dbt/task/runnable.py", line 438, in run
    self._runtime_initialize()
  File "/usr/local/lib/python3.9/site-packages/dbt/task/runnable.py", line 154, in _runtime_initialize
    super()._runtime_initialize()
  File "/usr/local/lib/python3.9/site-packages/dbt/task/runnable.py", line 92, in _runtime_initialize
    self.load_manifest()
  File "/usr/local/lib/python3.9/site-packages/dbt/task/runnable.py", line 79, in load_manifest
    self.manifest = ManifestLoader.get_full_manifest(self.config)
  File "/usr/local/lib/python3.9/site-packages/dbt/parser/manifest.py", line 179, in get_full_manifest
    projects = config.load_dependencies()
  File "/usr/local/lib/python3.9/site-packages/dbt/config/runtime.py", line 336, in load_dependencies
    raise_compiler_error(
  File "/usr/local/lib/python3.9/site-packages/dbt/exceptions.py", line 447, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error
  dbt found 1 package(s) specified in packages.yml, but only 0 package(s) installed in dbt_modules. Run "dbt deps" to install package dependencies.

2022-01-14 12:54:41.908275 (MainThread): Running with dbt=0.21.1
2022-01-14 12:54:41.986608 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, defer=None, state=None, cls=<class 'dbt.task.deps.DepsTask'>, which='deps', rpc_method='deps')
2022-01-14 12:54:41.987168 (MainThread): Tracking: tracking
2022-01-14 12:54:42.005160 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1099634f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109f807f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109f70a30>]}
2022-01-14 12:54:42.008081 (MainThread): Set downloads directory='/var/folders/ht/55m1kf9529v8n85gyrn0hzcc0000gp/T/dbt-downloads-t5a6htjv'
2022-01-14 12:54:42.009066 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/index.json
2022-01-14 12:54:42.608056 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/index.json 200
2022-01-14 12:54:42.623498 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
2022-01-14 12:54:43.086803 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
2022-01-14 12:54:43.108856 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils/0.7.1.json
2022-01-14 12:54:43.722966 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils/0.7.1.json 200
2022-01-14 12:54:43.723593 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
2022-01-14 12:54:44.194162 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
2022-01-14 12:54:44.215623 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils/0.7.1.json
2022-01-14 12:54:44.877243 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils/0.7.1.json 200
2022-01-14 12:54:44.877643 (MainThread): Installing dbt-labs/dbt_utils@0.7.1
2022-01-14 12:54:45.810316 (MainThread):   Installed from version 0.7.1
2022-01-14 12:54:45.810705 (MainThread):   Updated version available: 0.8.0
2022-01-14 12:54:45.811103 (MainThread): Sending event: {'category': 'dbt', 'action': 'package', 'label': '9c724d62-b2e9-4b62-9a61-863c048b62f5', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109963bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109f80100>]}
2022-01-14 12:54:45.811496 (MainThread): 
Updates available for packages: ['dbt-labs/dbt_utils']                 
Update your versions in packages.yml, then run dbt deps
2022-01-14 12:54:45.813137 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109963190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109963bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109f807f0>]}
2022-01-14 12:54:45.813609 (MainThread): Flushing usage events
2022-01-14 12:54:55.326081 (MainThread): Running with dbt=0.21.1
2022-01-14 12:54:55.406421 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2022-01-14 12:54:55.408257 (MainThread): Tracking: tracking
2022-01-14 12:54:55.427465 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b891820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10be94bb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10be94400>]}
2022-01-14 12:54:55.449756 (MainThread): Partial parsing not enabled
2022-01-14 12:54:55.494895 (MainThread): Parsing macros/catalog.sql
2022-01-14 12:54:55.499034 (MainThread): Parsing macros/relations.sql
2022-01-14 12:54:55.500393 (MainThread): Parsing macros/adapters.sql
2022-01-14 12:54:55.523682 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2022-01-14 12:54:55.525339 (MainThread): Parsing macros/core.sql
2022-01-14 12:54:55.528841 (MainThread): Parsing macros/materializations/test.sql
2022-01-14 12:54:55.535194 (MainThread): Parsing macros/materializations/helpers.sql
2022-01-14 12:54:55.544927 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2022-01-14 12:54:55.546548 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2022-01-14 12:54:55.562863 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2022-01-14 12:54:55.592851 (MainThread): Parsing macros/materializations/seed/seed.sql
2022-01-14 12:54:55.614326 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2022-01-14 12:54:55.615967 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2022-01-14 12:54:55.625798 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2022-01-14 12:54:55.644328 (MainThread): Parsing macros/materializations/common/merge.sql
2022-01-14 12:54:55.657164 (MainThread): Parsing macros/materializations/table/table.sql
2022-01-14 12:54:55.664452 (MainThread): Parsing macros/materializations/view/view.sql
2022-01-14 12:54:55.670949 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2022-01-14 12:54:55.674727 (MainThread): Parsing macros/etc/get_custom_alias.sql
2022-01-14 12:54:55.676084 (MainThread): Parsing macros/etc/query.sql
2022-01-14 12:54:55.676957 (MainThread): Parsing macros/etc/is_incremental.sql
2022-01-14 12:54:55.678320 (MainThread): Parsing macros/etc/datetime.sql
2022-01-14 12:54:55.686206 (MainThread): Parsing macros/etc/where_subquery.sql
2022-01-14 12:54:55.687919 (MainThread): Parsing macros/etc/get_custom_schema.sql
2022-01-14 12:54:55.690315 (MainThread): Parsing macros/etc/get_custom_database.sql
2022-01-14 12:54:55.691750 (MainThread): Parsing macros/adapters/common.sql
2022-01-14 12:54:55.743102 (MainThread): Parsing macros/schema_tests/relationships.sql
2022-01-14 12:54:55.744754 (MainThread): Parsing macros/schema_tests/not_null.sql
2022-01-14 12:54:55.745849 (MainThread): Parsing macros/schema_tests/unique.sql
2022-01-14 12:54:55.747075 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2022-01-14 12:54:55.749088 (MainThread): Parsing macros/cross_db_utils/except.sql
2022-01-14 12:54:55.750067 (MainThread): Parsing macros/cross_db_utils/replace.sql
2022-01-14 12:54:55.751220 (MainThread): Parsing macros/cross_db_utils/concat.sql
2022-01-14 12:54:55.752255 (MainThread): Parsing macros/cross_db_utils/datatypes.sql
2022-01-14 12:54:55.758032 (MainThread): Parsing macros/cross_db_utils/_is_relation.sql
2022-01-14 12:54:55.759077 (MainThread): Parsing macros/cross_db_utils/length.sql
2022-01-14 12:54:55.760327 (MainThread): Parsing macros/cross_db_utils/dateadd.sql
2022-01-14 12:54:55.763144 (MainThread): Parsing macros/cross_db_utils/intersect.sql
2022-01-14 12:54:55.764143 (MainThread): Parsing macros/cross_db_utils/right.sql
2022-01-14 12:54:55.766234 (MainThread): Parsing macros/cross_db_utils/datediff.sql
2022-01-14 12:54:55.775698 (MainThread): Parsing macros/cross_db_utils/safe_cast.sql
2022-01-14 12:54:55.777463 (MainThread): Parsing macros/cross_db_utils/hash.sql
2022-01-14 12:54:55.778761 (MainThread): Parsing macros/cross_db_utils/cast_bool_to_text.sql
2022-01-14 12:54:55.780132 (MainThread): Parsing macros/cross_db_utils/identifier.sql
2022-01-14 12:54:55.781662 (MainThread): Parsing macros/cross_db_utils/position.sql
2022-01-14 12:54:55.783176 (MainThread): Parsing macros/cross_db_utils/literal.sql
2022-01-14 12:54:55.784055 (MainThread): Parsing macros/cross_db_utils/current_timestamp.sql
2022-01-14 12:54:55.787343 (MainThread): Parsing macros/cross_db_utils/width_bucket.sql
2022-01-14 12:54:55.792268 (MainThread): Parsing macros/cross_db_utils/last_day.sql
2022-01-14 12:54:55.795489 (MainThread): Parsing macros/cross_db_utils/split_part.sql
2022-01-14 12:54:55.797169 (MainThread): Parsing macros/cross_db_utils/date_trunc.sql
2022-01-14 12:54:55.798639 (MainThread): Parsing macros/cross_db_utils/_is_ephemeral.sql
2022-01-14 12:54:55.800470 (MainThread): Parsing macros/materializations/insert_by_period_materialization.sql
2022-01-14 12:54:55.824044 (MainThread): Parsing macros/web/get_url_host.sql
2022-01-14 12:54:55.825765 (MainThread): Parsing macros/web/get_url_path.sql
2022-01-14 12:54:55.828113 (MainThread): Parsing macros/web/get_url_parameter.sql
2022-01-14 12:54:55.829554 (MainThread): Parsing macros/jinja_helpers/pretty_log_format.sql
2022-01-14 12:54:55.830574 (MainThread): Parsing macros/jinja_helpers/pretty_time.sql
2022-01-14 12:54:55.831680 (MainThread): Parsing macros/jinja_helpers/log_info.sql
2022-01-14 12:54:55.832704 (MainThread): Parsing macros/jinja_helpers/slugify.sql
2022-01-14 12:54:55.833787 (MainThread): Parsing macros/schema_tests/fewer_rows_than.sql
2022-01-14 12:54:55.835339 (MainThread): Parsing macros/schema_tests/equal_rowcount.sql
2022-01-14 12:54:55.836890 (MainThread): Parsing macros/schema_tests/relationships_where.sql
2022-01-14 12:54:55.839195 (MainThread): Parsing macros/schema_tests/recency.sql
2022-01-14 12:54:55.840822 (MainThread): Parsing macros/schema_tests/not_constant.sql
2022-01-14 12:54:55.841961 (MainThread): Parsing macros/schema_tests/accepted_range.sql
2022-01-14 12:54:55.844309 (MainThread): Parsing macros/schema_tests/not_accepted_values.sql
2022-01-14 12:54:55.846227 (MainThread): Parsing macros/schema_tests/test_unique_where.sql
2022-01-14 12:54:55.847535 (MainThread): Parsing macros/schema_tests/at_least_one.sql
2022-01-14 12:54:55.848685 (MainThread): Parsing macros/schema_tests/unique_combination_of_columns.sql
2022-01-14 12:54:55.851229 (MainThread): Parsing macros/schema_tests/cardinality_equality.sql
2022-01-14 12:54:55.853025 (MainThread): Parsing macros/schema_tests/expression_is_true.sql
2022-01-14 12:54:55.854659 (MainThread): Parsing macros/schema_tests/sequential_values.sql
2022-01-14 12:54:55.857578 (MainThread): Parsing macros/schema_tests/test_not_null_where.sql
2022-01-14 12:54:55.858911 (MainThread): Parsing macros/schema_tests/equality.sql
2022-01-14 12:54:55.862091 (MainThread): Parsing macros/schema_tests/mutually_exclusive_ranges.sql
2022-01-14 12:54:55.870544 (MainThread): Parsing macros/sql/date_spine.sql
2022-01-14 12:54:55.875171 (MainThread): Parsing macros/sql/nullcheck_table.sql
2022-01-14 12:54:55.876680 (MainThread): Parsing macros/sql/get_relations_by_pattern.sql
2022-01-14 12:54:55.879797 (MainThread): Parsing macros/sql/generate_series.sql
2022-01-14 12:54:55.908296 (MainThread): Parsing macros/sql/get_relations_by_prefix.sql
2022-01-14 12:54:55.912642 (MainThread): Parsing macros/sql/get_tables_by_prefix_sql.sql
2022-01-14 12:54:55.914762 (MainThread): Parsing macros/sql/star.sql
2022-01-14 12:54:55.918924 (MainThread): Parsing macros/sql/unpivot.sql
2022-01-14 12:54:55.928927 (MainThread): Parsing macros/sql/union.sql
2022-01-14 12:54:55.938217 (MainThread): Parsing macros/sql/groupby.sql
2022-01-14 12:54:55.939831 (MainThread): Parsing macros/sql/surrogate_key.sql
2022-01-14 12:54:55.943634 (MainThread): Parsing macros/sql/safe_add.sql
2022-01-14 12:54:55.945433 (MainThread): Parsing macros/sql/nullcheck.sql
2022-01-14 12:54:55.947349 (MainThread): Parsing macros/sql/get_tables_by_pattern_sql.sql
2022-01-14 12:54:55.954247 (MainThread): Parsing macros/sql/get_column_values.sql
2022-01-14 12:54:55.959564 (MainThread): Parsing macros/sql/pivot.sql
2022-01-14 12:54:55.963829 (MainThread): Parsing macros/sql/get_query_results_as_dict.sql
2022-01-14 12:54:55.966022 (MainThread): Parsing macros/sql/haversine_distance.sql
2022-01-14 12:54:56.266232 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-14 12:54:56.277777 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-14 12:54:56.281170 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-14 12:54:56.284175 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-14 12:54:56.288050 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 12:54:56.289891 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-14 12:54:56.297489 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 12:54:56.299010 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_film".
2022-01-14 12:54:56.303539 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 12:54:56.305231 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-14 12:54:56.307332 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 12:54:56.308403 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_store".
2022-01-14 12:54:56.312430 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 12:54:56.320657 (MainThread): Acquiring new postgres connection "operation.sakila_dbt_project.sakila_dbt_project-on-run-start-0".
2022-01-14 12:54:56.324382 (MainThread): Acquiring new postgres connection "operation.sakila_dbt_project.sakila_dbt_project-on-run-end-0".
2022-01-14 12:54:56.354823 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 12:54:56.364183 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 12:54:56.365857 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 12:54:56.367439 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 12:54:56.369175 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 12:54:56.370960 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 12:54:56.387919 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 12:54:56.389785 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 12:54:56.391548 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 12:54:56.393168 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 12:54:56.394736 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 12:54:56.396332 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 12:54:56.398546 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 12:54:56.400107 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 12:54:56.401673 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 12:54:56.403478 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 12:54:56.427806 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '60679a6b-7853-43f5-ad40-0bb536a6cf39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c06c0d0>]}
2022-01-14 12:54:56.437343 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-01-14 12:54:56.437897 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '60679a6b-7853-43f5-ad40-0bb536a6cf39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c06c1c0>]}
2022-01-14 12:54:56.438137 (MainThread): Found 8 models, 16 tests, 0 snapshots, 0 analyses, 347 macros, 2 operations, 0 seed files, 12 sources, 0 exposures
2022-01-14 12:54:56.440295 (MainThread): 
2022-01-14 12:54:56.440651 (MainThread): Acquiring new postgres connection "master".
2022-01-14 12:54:56.441620 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_sakila_wh".
2022-01-14 12:54:56.450817 (ThreadPoolExecutor-0_0): Using postgres connection "list_sakila_wh".
2022-01-14 12:54:56.450988 (ThreadPoolExecutor-0_0): On list_sakila_wh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh"} */

    select distinct nspname from pg_namespace
  
2022-01-14 12:54:56.451142 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2022-01-14 12:54:56.818275 (ThreadPoolExecutor-0_0): SQL status: SELECT 8 in 0.37 seconds
2022-01-14 12:54:56.820806 (ThreadPoolExecutor-0_0): On list_sakila_wh: Close
2022-01-14 12:54:56.821651 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_sakila_wh".
2022-01-14 12:54:56.823700 (ThreadPoolExecutor-0_0): Using postgres connection "list_sakila_wh".
2022-01-14 12:54:56.823908 (ThreadPoolExecutor-0_0): On list_sakila_wh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh"} */

    select distinct nspname from pg_namespace
  
2022-01-14 12:54:56.824080 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2022-01-14 12:54:57.159029 (ThreadPoolExecutor-0_0): SQL status: SELECT 8 in 0.33 seconds
2022-01-14 12:54:57.160855 (ThreadPoolExecutor-0_0): On list_sakila_wh: Close
2022-01-14 12:54:57.161619 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "create_sakila_wh_stg_dwh".
2022-01-14 12:54:57.161943 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "create_sakila_wh_stg_dwh".
2022-01-14 12:54:57.162165 (ThreadPoolExecutor-0_0): Creating schema ""sakila_wh"."stg_dwh""
2022-01-14 12:54:57.168403 (ThreadPoolExecutor-0_0): Using postgres connection "create_sakila_wh_stg_dwh".
2022-01-14 12:54:57.168587 (ThreadPoolExecutor-0_0): On create_sakila_wh_stg_dwh: BEGIN
2022-01-14 12:54:57.168754 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2022-01-14 12:54:57.513195 (ThreadPoolExecutor-0_0): SQL status: BEGIN in 0.34 seconds
2022-01-14 12:54:57.513854 (ThreadPoolExecutor-0_0): Using postgres connection "create_sakila_wh_stg_dwh".
2022-01-14 12:54:57.514224 (ThreadPoolExecutor-0_0): On create_sakila_wh_stg_dwh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "create_sakila_wh_stg_dwh"} */
create schema if not exists "stg_dwh"
2022-01-14 12:54:57.570533 (ThreadPoolExecutor-0_0): SQL status: CREATE SCHEMA in 0.06 seconds
2022-01-14 12:54:57.572293 (ThreadPoolExecutor-0_0): On create_sakila_wh_stg_dwh: COMMIT
2022-01-14 12:54:57.572607 (ThreadPoolExecutor-0_0): Using postgres connection "create_sakila_wh_stg_dwh".
2022-01-14 12:54:57.572854 (ThreadPoolExecutor-0_0): On create_sakila_wh_stg_dwh: COMMIT
2022-01-14 12:54:57.629469 (ThreadPoolExecutor-0_0): SQL status: COMMIT in 0.06 seconds
2022-01-14 12:54:57.630075 (ThreadPoolExecutor-0_0): On create_sakila_wh_stg_dwh: Close
2022-01-14 12:54:57.632243 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_stg_dwh".
2022-01-14 12:54:57.639326 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_stg_dwh".
2022-01-14 12:54:57.639594 (ThreadPoolExecutor-1_0): On list_sakila_wh_stg_dwh: BEGIN
2022-01-14 12:54:57.639772 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2022-01-14 12:54:57.984022 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.34 seconds
2022-01-14 12:54:57.984394 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_stg_dwh".
2022-01-14 12:54:57.984638 (ThreadPoolExecutor-1_0): On list_sakila_wh_stg_dwh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_stg_dwh"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'stg_dwh'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'stg_dwh'
  
2022-01-14 12:54:58.045731 (ThreadPoolExecutor-1_0): SQL status: SELECT 0 in 0.06 seconds
2022-01-14 12:54:58.047492 (ThreadPoolExecutor-1_0): On list_sakila_wh_stg_dwh: ROLLBACK
2022-01-14 12:54:58.101542 (ThreadPoolExecutor-1_0): On list_sakila_wh_stg_dwh: Close
2022-01-14 12:54:58.102646 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_stg".
2022-01-14 12:54:58.104872 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_stg".
2022-01-14 12:54:58.105106 (ThreadPoolExecutor-1_0): On list_sakila_wh_stg: BEGIN
2022-01-14 12:54:58.105284 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2022-01-14 12:54:58.440509 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.34 seconds
2022-01-14 12:54:58.440815 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_stg".
2022-01-14 12:54:58.441011 (ThreadPoolExecutor-1_0): On list_sakila_wh_stg: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_stg"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'stg'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'stg'
  
2022-01-14 12:54:58.505298 (ThreadPoolExecutor-1_0): SQL status: SELECT 28 in 0.06 seconds
2022-01-14 12:54:58.507787 (ThreadPoolExecutor-1_0): On list_sakila_wh_stg: ROLLBACK
2022-01-14 12:54:58.561954 (ThreadPoolExecutor-1_0): On list_sakila_wh_stg: Close
2022-01-14 12:54:58.568608 (MainThread): Using postgres connection "master".
2022-01-14 12:54:58.568834 (MainThread): On master: BEGIN
2022-01-14 12:54:58.569005 (MainThread): Opening a new connection, currently in state init
2022-01-14 12:54:58.908208 (MainThread): SQL status: BEGIN in 0.34 seconds
2022-01-14 12:54:58.908544 (MainThread): Using postgres connection "master".
2022-01-14 12:54:58.908756 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-14 12:54:58.982111 (MainThread): SQL status: SELECT 43 in 0.07 seconds
2022-01-14 12:54:58.985916 (MainThread): On master: ROLLBACK
2022-01-14 12:54:59.040531 (MainThread): Using postgres connection "master".
2022-01-14 12:54:59.040881 (MainThread): On master: BEGIN
2022-01-14 12:54:59.151252 (MainThread): SQL status: BEGIN in 0.11 seconds
2022-01-14 12:54:59.151604 (MainThread): On master: COMMIT
2022-01-14 12:54:59.151820 (MainThread): Using postgres connection "master".
2022-01-14 12:54:59.152018 (MainThread): On master: COMMIT
2022-01-14 12:54:59.206898 (MainThread): SQL status: COMMIT in 0.05 seconds
2022-01-14 12:54:59.207248 (MainThread): 18:24:59 | 
2022-01-14 12:54:59.207512 (MainThread): 18:24:59 | Running 1 on-run-start hook
2022-01-14 12:54:59.207757 (MainThread): Compiling operation.sakila_dbt_project.sakila_dbt_project-on-run-start-0
2022-01-14 12:54:59.209719 (MainThread): Writing injected SQL for node "operation.sakila_dbt_project.sakila_dbt_project-on-run-start-0"
2022-01-14 12:54:59.212050 (MainThread): 18:24:59 | 1 of 1 START hook: sakila_dbt_project.on-run-start.0................. [RUN]
2022-01-14 12:54:59.212303 (MainThread): Using postgres connection "master".
2022-01-14 12:54:59.212473 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "master"} */
create table if not exists dwh.dbt_log  (dbt_id varchar,start_at timestamp,end_at timestamp,status varchar,dbt_total_sec int)
2022-01-14 12:54:59.278166 (MainThread): SQL status: CREATE TABLE in 0.07 seconds
2022-01-14 12:54:59.279866 (MainThread): 18:24:59 | 1 of 1 OK hook: sakila_dbt_project.on-run-start.0.................... [CREATE TABLE in 0.07s]
2022-01-14 12:54:59.280221 (MainThread): 18:24:59 | 
2022-01-14 12:54:59.280492 (MainThread): On master: Close
2022-01-14 12:54:59.281127 (MainThread): 18:24:59 | Concurrency: 1 threads (target='dev')
2022-01-14 12:54:59.281395 (MainThread): 18:24:59 | 
2022-01-14 12:54:59.284877 (Thread-1): Began running node model.sakila_dbt_project.dim_customer
2022-01-14 12:54:59.285252 (Thread-1): 18:24:59 | 1 of 8 START incremental model stg_dwh.dim_customer.................. [RUN]
2022-01-14 12:54:59.285670 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-14 12:54:59.285883 (Thread-1): Compiling model.sakila_dbt_project.dim_customer
2022-01-14 12:54:59.291774 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_customer"
2022-01-14 12:54:59.292901 (Thread-1): finished collecting timing info
2022-01-14 12:54:59.342852 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_customer"
2022-01-14 12:54:59.344010 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-14 12:54:59.344197 (Thread-1): On model.sakila_dbt_project.dim_customer: BEGIN
2022-01-14 12:54:59.344354 (Thread-1): Opening a new connection, currently in state closed
2022-01-14 12:54:59.680880 (Thread-1): SQL status: BEGIN in 0.34 seconds
2022-01-14 12:54:59.681258 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-14 12:54:59.681510 (Thread-1): On model.sakila_dbt_project.dim_customer: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_customer"} */

      

  create  table "sakila_wh"."stg_dwh"."dim_customer"
  as (
    

with customer_base as (

select
 *,
	concat(customer.first_name,' ',customer.last_name) as full_name,
	substring(email from POSITION('@' in email)+1 for char_length(email)-POSITION('@' in email)) as domain,
	customer.active::int as active_int,
	(case when customer.active = 0 then 'no' else 'yes' end)::varchar(100) as "active_desc",
  '2022-01-14 12:54:55'::timestamp as dbt_time
from
	"sakila_wh"."stg"."customer" as customer),

  address as (
    select * from "sakila_wh"."stg"."address"
  ),

  city as (
    select * from "sakila_wh"."stg"."city"
  ),

  country as (
    select * from "sakila_wh"."stg"."country"
  )

  select
  customer_base.customer_id,
  customer_base.store_id,
  customer_base.first_name,
  customer_base.last_name,
  customer_base.full_name,
  customer_base.domain,
  customer_base.email,
  customer_base.active_int as active,
  customer_base.active_desc,

  address.address_id,
  address.address,
  city.city_id,
  city.city,
  country.country_id,
  country.country,

  customer_base.create_date,
  customer_base.last_update,
  customer_base.dbt_time

  from
  customer_base

	left join address on 1=1
	and customer_base.address_id =address.address_id

	left join city on 1=1
	and address.city_id = city.city_id

  left join country on 1=1
  and country.country_id = city.country_id

  where 1=1

  
  );
  
2022-01-14 12:54:59.761590 (Thread-1): SQL status: SELECT 599 in 0.08 seconds
2022-01-14 12:54:59.774912 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 12:54:59.775279 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-14 12:54:59.775455 (Thread-1): On model.sakila_dbt_project.dim_customer: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_customer"} */

        insert into "sakila_wh"."stg_dwh"."dim_customer"(customer_id) VALUES (-1)
      
2022-01-14 12:54:59.829873 (Thread-1): SQL status: INSERT 0 1 in 0.05 seconds
2022-01-14 12:54:59.831061 (Thread-1): On model.sakila_dbt_project.dim_customer: COMMIT
2022-01-14 12:54:59.831294 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-14 12:54:59.831492 (Thread-1): On model.sakila_dbt_project.dim_customer: COMMIT
2022-01-14 12:54:59.886282 (Thread-1): SQL status: COMMIT in 0.05 seconds
2022-01-14 12:54:59.887207 (Thread-1): finished collecting timing info
2022-01-14 12:54:59.887543 (Thread-1): On model.sakila_dbt_project.dim_customer: Close
2022-01-14 12:54:59.888182 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '60679a6b-7853-43f5-ad40-0bb536a6cf39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c2172b0>]}
2022-01-14 12:54:59.888638 (Thread-1): 18:24:59 | 1 of 8 OK created incremental model stg_dwh.dim_customer............. [SELECT 599 in 0.60s]
2022-01-14 12:54:59.888933 (Thread-1): Finished running node model.sakila_dbt_project.dim_customer
2022-01-14 12:54:59.889224 (Thread-1): Began running node model.sakila_dbt_project.dim_date
2022-01-14 12:54:59.889684 (Thread-1): 18:24:59 | 2 of 8 START table model stg_dwh.dim_date............................ [RUN]
2022-01-14 12:54:59.890087 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-14 12:54:59.890283 (Thread-1): Compiling model.sakila_dbt_project.dim_date
2022-01-14 12:54:59.892312 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_date"
2022-01-14 12:54:59.892903 (Thread-1): finished collecting timing info
2022-01-14 12:54:59.908941 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_date"
2022-01-14 12:54:59.909661 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-14 12:54:59.909836 (Thread-1): On model.sakila_dbt_project.dim_date: BEGIN
2022-01-14 12:54:59.909999 (Thread-1): Opening a new connection, currently in state closed
2022-01-14 12:55:00.246441 (Thread-1): SQL status: BEGIN in 0.34 seconds
2022-01-14 12:55:00.246838 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-14 12:55:00.247097 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */


  create  table "sakila_wh"."stg_dwh"."dim_date__dbt_tmp"
  as (
    with dates as (
SELECT
       TO_CHAR(datum, 'yyyymmdd')::INT AS date_dim_id,
       datum AS date_key,
       EXTRACT(EPOCH FROM datum) AS epoch,
       TO_CHAR(datum, 'TMDay') AS day_name,
       EXTRACT(ISODOW FROM datum) AS day_of_week,
       EXTRACT(DAY FROM datum) AS day_of_month,
       datum - DATE_TRUNC('quarter', datum)::DATE + 1 AS day_of_quarter,
       EXTRACT(DOY FROM datum) AS day_of_year,
       TO_CHAR(datum, 'W')::INT AS week_of_month,
       EXTRACT(WEEK FROM datum) AS week_of_year,
       EXTRACT(MONTH FROM datum) AS month_actual,
       TO_CHAR(datum, 'TMMonth') AS month_name,
       TO_CHAR(datum, 'Mon') AS month_name_abbreviated,
       EXTRACT(QUARTER FROM datum) AS quarter_actual,
       CASE
           WHEN EXTRACT(QUARTER FROM datum) = 1 THEN 'First'
           WHEN EXTRACT(QUARTER FROM datum) = 2 THEN 'Second'
           WHEN EXTRACT(QUARTER FROM datum) = 3 THEN 'Third'
           WHEN EXTRACT(QUARTER FROM datum) = 4 THEN 'Fourth'
           END AS quarter_name,
       EXTRACT(YEAR FROM datum) AS year_actual,
       datum + (1 - EXTRACT(ISODOW FROM datum))::INT AS first_day_of_week,
       datum + (7 - EXTRACT(ISODOW FROM datum))::INT AS last_day_of_week,
       datum + (1 - EXTRACT(DAY FROM datum))::INT AS first_day_of_month,
       (DATE_TRUNC('MONTH', datum) + INTERVAL '1 MONTH - 1 day')::DATE AS last_day_of_month,
       DATE_TRUNC('quarter', datum)::DATE AS first_day_of_quarter,
       (DATE_TRUNC('quarter', datum) + INTERVAL '3 MONTH - 1 day')::DATE AS last_day_of_quarter,
       TO_DATE(EXTRACT(YEAR FROM datum) || '-01-01', 'YYYY-MM-DD') AS first_day_of_year,
       TO_DATE(EXTRACT(YEAR FROM datum) || '-12-31', 'YYYY-MM-DD') AS last_day_of_year,
       TO_CHAR(datum, 'yyyymm') AS yyyymm,
       CASE
           WHEN EXTRACT(ISODOW FROM datum) IN (6, 7) THEN TRUE
           ELSE FALSE
           END AS weekend_indr
FROM (SELECT '2000-01-01'::DATE + SEQUENCE.DAY AS datum
      FROM GENERATE_SERIES(0, 29219) AS SEQUENCE (DAY)
      GROUP BY SEQUENCE.DAY) DQ
)
select
*
from
dates
where
date_key <= CURRENT_DATE
order by date_dim_id asc
  );
2022-01-14 12:55:01.137340 (Thread-1): SQL status: SELECT 8050 in 0.89 seconds
2022-01-14 12:55:01.145708 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-14 12:55:01.145955 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
alter table "sakila_wh"."stg_dwh"."dim_date__dbt_tmp" rename to "dim_date"
2022-01-14 12:55:01.202292 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-14 12:55:01.203716 (Thread-1): On model.sakila_dbt_project.dim_date: COMMIT
2022-01-14 12:55:01.203908 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-14 12:55:01.204053 (Thread-1): On model.sakila_dbt_project.dim_date: COMMIT
2022-01-14 12:55:01.264698 (Thread-1): SQL status: COMMIT in 0.06 seconds
2022-01-14 12:55:01.271620 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-14 12:55:01.271902 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
drop table if exists "sakila_wh"."stg_dwh"."dim_date__dbt_backup" cascade
2022-01-14 12:55:01.329914 (Thread-1): SQL status: DROP TABLE in 0.06 seconds
2022-01-14 12:55:01.332022 (Thread-1): finished collecting timing info
2022-01-14 12:55:01.332364 (Thread-1): On model.sakila_dbt_project.dim_date: Close
2022-01-14 12:55:01.333062 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '60679a6b-7853-43f5-ad40-0bb536a6cf39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c217f70>]}
2022-01-14 12:55:01.333510 (Thread-1): 18:25:01 | 2 of 8 OK created table model stg_dwh.dim_date....................... [SELECT 8050 in 1.44s]
2022-01-14 12:55:01.333790 (Thread-1): Finished running node model.sakila_dbt_project.dim_date
2022-01-14 12:55:01.334004 (Thread-1): Began running node model.sakila_dbt_project.dim_film
2022-01-14 12:55:01.334276 (Thread-1): 18:25:01 | 3 of 8 START incremental model stg_dwh.dim_film...................... [RUN]
2022-01-14 12:55:01.334710 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_film".
2022-01-14 12:55:01.334904 (Thread-1): Compiling model.sakila_dbt_project.dim_film
2022-01-14 12:55:01.340528 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_film"
2022-01-14 12:55:01.341181 (Thread-1): finished collecting timing info
2022-01-14 12:55:01.344491 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_film"
2022-01-14 12:55:01.345112 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_film".
2022-01-14 12:55:01.345289 (Thread-1): On model.sakila_dbt_project.dim_film: BEGIN
2022-01-14 12:55:01.345455 (Thread-1): Opening a new connection, currently in state closed
2022-01-14 12:55:01.680351 (Thread-1): SQL status: BEGIN in 0.33 seconds
2022-01-14 12:55:01.680736 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_film".
2022-01-14 12:55:01.680986 (Thread-1): On model.sakila_dbt_project.dim_film: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_film"} */

      

  create  table "sakila_wh"."stg_dwh"."dim_film"
  as (
    

with stg_film as (
	select
	*,
	(case
	when length<=75 then 'short'
	when (length>75 and length<=120) then 'medium'
	when length>120 then 'long'
	else 'na' end) as length_desc,
	COALESCE(original_language_id,0) as original_language_id_zero,
	case when POSITION('Trailers' in special_features::varchar)>0 then 1 else 0 end  as has_trailers,
	case when POSITION('Commentaries' in special_features::varchar)>0 then 1 else 0 end  as has_commentaries,
	case when POSITION('Deleted Scenes' in special_features::varchar)>0 then 1 else 0 end  as has_deleted_scenes,
	case when POSITION('Behind the Scenes' in special_features::varchar)>0 then 1 else 0 end  as has_behind_the_scenes,
	'2022-01-14 12:54:55'::timestamp as dbt_time
	from
	"sakila_wh"."stg"."film"
),

language as (
	select * from "sakila_wh"."stg"."language"
),

category as (
	select * from "sakila_wh"."stg"."category"
),

film_category as (
	select * from "sakila_wh"."stg"."film_category"
),

stg_film_1 as (
	select
	stg_film.*,
	language.name as lang_name
	from
	stg_film
	left join language on 1=1
	and stg_film.language_id = language.language_id
),

stg_film_2 as (
	select
		stg_film_1.*,
		category.category_id,
		category.name as category_desc
	from
	stg_film_1

	left join film_category on 1=1
	and stg_film_1.film_id = film_category.film_id

	left join category on 1=1
	and film_category.category_id  = category.category_id
)


select
  film_id,
  title,
  description,
  release_year,
  language_id,
  lang_name,
  original_language_id_zero as original_language_id,
  rental_duration,
  rental_rate,
  length,
  length_desc,
  replacement_cost,
  rating,
  category_id,
  category_desc,
  special_features,
  has_trailers,
  has_commentaries,
  has_behind_the_scenes,
  has_deleted_scenes,
  last_update,
	dbt_time
from
stg_film_2

where 1=1


  );
  
2022-01-14 12:55:01.776172 (Thread-1): SQL status: SELECT 1000 in 0.09 seconds
2022-01-14 12:55:01.779337 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 12:55:01.779753 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_film".
2022-01-14 12:55:01.779934 (Thread-1): On model.sakila_dbt_project.dim_film: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_film"} */

        insert into "sakila_wh"."stg_dwh"."dim_film"(film_id) VALUES (-1)
      
2022-01-14 12:55:01.836225 (Thread-1): SQL status: INSERT 0 1 in 0.06 seconds
2022-01-14 12:55:01.837911 (Thread-1): On model.sakila_dbt_project.dim_film: COMMIT
2022-01-14 12:55:01.838192 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_film".
2022-01-14 12:55:01.838438 (Thread-1): On model.sakila_dbt_project.dim_film: COMMIT
2022-01-14 12:55:01.894865 (Thread-1): SQL status: COMMIT in 0.06 seconds
2022-01-14 12:55:01.895786 (Thread-1): finished collecting timing info
2022-01-14 12:55:01.896130 (Thread-1): On model.sakila_dbt_project.dim_film: Close
2022-01-14 12:55:01.896811 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '60679a6b-7853-43f5-ad40-0bb536a6cf39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c1777c0>]}
2022-01-14 12:55:01.897371 (Thread-1): 18:25:01 | 3 of 8 OK created incremental model stg_dwh.dim_film................. [SELECT 1000 in 0.56s]
2022-01-14 12:55:01.897632 (Thread-1): Finished running node model.sakila_dbt_project.dim_film
2022-01-14 12:55:01.897886 (Thread-1): Began running node model.sakila_dbt_project.dim_staff
2022-01-14 12:55:01.898223 (Thread-1): 18:25:01 | 4 of 8 START table model stg_dwh.dim_staff........................... [RUN]
2022-01-14 12:55:01.898783 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-14 12:55:01.899070 (Thread-1): Compiling model.sakila_dbt_project.dim_staff
2022-01-14 12:55:01.902562 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_staff"
2022-01-14 12:55:01.903185 (Thread-1): finished collecting timing info
2022-01-14 12:55:01.907231 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_staff"
2022-01-14 12:55:01.907908 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-14 12:55:01.908093 (Thread-1): On model.sakila_dbt_project.dim_staff: BEGIN
2022-01-14 12:55:01.908266 (Thread-1): Opening a new connection, currently in state closed
2022-01-14 12:55:02.240858 (Thread-1): SQL status: BEGIN in 0.33 seconds
2022-01-14 12:55:02.241237 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-14 12:55:02.241487 (Thread-1): On model.sakila_dbt_project.dim_staff: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_staff"} */


  create  table "sakila_wh"."stg_dwh"."dim_staff__dbt_tmp"
  as (
    

with staff_base as (
select
*,
(case when active::int = 1 then 1 else 0 end) as "active_int",
(case when active::int = 1 then 'yes' else 'no' end) as "active_desc",
'2022-01-14 12:54:55'::timestamp as dbt_time
from
"sakila_wh"."stg"."staff"
)

select
	staff_id,
	first_name,
	last_name,
	email,
  active_int as active,
  active_desc,
	last_update,
  dbt_time
from
	staff_base
  );
2022-01-14 12:55:02.310697 (Thread-1): SQL status: SELECT 2 in 0.07 seconds
2022-01-14 12:55:02.314273 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-14 12:55:02.314508 (Thread-1): On model.sakila_dbt_project.dim_staff: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_staff"} */
alter table "sakila_wh"."stg_dwh"."dim_staff__dbt_tmp" rename to "dim_staff"
2022-01-14 12:55:02.369949 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-14 12:55:02.373128 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 12:55:02.373524 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-14 12:55:02.373732 (Thread-1): On model.sakila_dbt_project.dim_staff: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_staff"} */

        insert into "sakila_wh"."stg_dwh"."dim_staff"(staff_id) VALUES (-1)
      
2022-01-14 12:55:02.428593 (Thread-1): SQL status: INSERT 0 1 in 0.05 seconds
2022-01-14 12:55:02.430685 (Thread-1): On model.sakila_dbt_project.dim_staff: COMMIT
2022-01-14 12:55:02.430971 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-14 12:55:02.431217 (Thread-1): On model.sakila_dbt_project.dim_staff: COMMIT
2022-01-14 12:55:02.486191 (Thread-1): SQL status: COMMIT in 0.05 seconds
2022-01-14 12:55:02.489371 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-14 12:55:02.489594 (Thread-1): On model.sakila_dbt_project.dim_staff: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_staff"} */
drop table if exists "sakila_wh"."stg_dwh"."dim_staff__dbt_backup" cascade
2022-01-14 12:55:02.544060 (Thread-1): SQL status: DROP TABLE in 0.05 seconds
2022-01-14 12:55:02.545614 (Thread-1): finished collecting timing info
2022-01-14 12:55:02.545887 (Thread-1): On model.sakila_dbt_project.dim_staff: Close
2022-01-14 12:55:02.546429 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '60679a6b-7853-43f5-ad40-0bb536a6cf39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c260070>]}
2022-01-14 12:55:02.546887 (Thread-1): 18:25:02 | 4 of 8 OK created table model stg_dwh.dim_staff...................... [SELECT 2 in 0.65s]
2022-01-14 12:55:02.547158 (Thread-1): Finished running node model.sakila_dbt_project.dim_staff
2022-01-14 12:55:02.547434 (Thread-1): Began running node model.sakila_dbt_project.hello_world
2022-01-14 12:55:02.547879 (Thread-1): 18:25:02 | 5 of 8 START view model stg.hello_world.............................. [RUN]
2022-01-14 12:55:02.548246 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-14 12:55:02.548439 (Thread-1): Compiling model.sakila_dbt_project.hello_world
2022-01-14 12:55:02.550193 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.hello_world"
2022-01-14 12:55:02.550989 (Thread-1): finished collecting timing info
2022-01-14 12:55:02.570698 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.hello_world"
2022-01-14 12:55:02.571651 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-14 12:55:02.571844 (Thread-1): On model.sakila_dbt_project.hello_world: BEGIN
2022-01-14 12:55:02.572055 (Thread-1): Opening a new connection, currently in state closed
2022-01-14 12:55:02.909518 (Thread-1): SQL status: BEGIN in 0.34 seconds
2022-01-14 12:55:02.909841 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-14 12:55:02.910047 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */

  create view "sakila_wh"."stg"."hello_world__dbt_tmp" as (
    select
	customer.customer_id::int,
	customer.store_id::int,
	customer.first_name,
	customer.last_name,
	concat(customer.first_name,' ',customer.last_name) as full_name,
	substring(email from POSITION('@' in email)+1 for char_length(email)-POSITION('@' in email)) as domain,
	customer.email,
	customer.active::int,
	customer.address_id::int,
	address.address,
	city.city_id::int,
	city.city,
	(case when customer.active = 0 then 'no' else 'yes' end)::varchar(100) as "active_desc",
	customer.create_date::timestamp,
	customer.last_update::timestamp
from
	stg.customer as customer

	left join stg.address on 1=1
	and customer.address_id =address.address_id

	left join stg.city on 1=1
	and address.city_id = city.city_id
  );

2022-01-14 12:55:02.978214 (Thread-1): SQL status: CREATE VIEW in 0.07 seconds
2022-01-14 12:55:02.982050 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-14 12:55:02.982277 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
alter table "sakila_wh"."stg"."hello_world__dbt_tmp" rename to "hello_world"
2022-01-14 12:55:03.037411 (Thread-1): SQL status: ALTER TABLE in 0.05 seconds
2022-01-14 12:55:03.039600 (Thread-1): On model.sakila_dbt_project.hello_world: COMMIT
2022-01-14 12:55:03.039896 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-14 12:55:03.040144 (Thread-1): On model.sakila_dbt_project.hello_world: COMMIT
2022-01-14 12:55:03.095088 (Thread-1): SQL status: COMMIT in 0.05 seconds
2022-01-14 12:55:03.098397 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-14 12:55:03.098618 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
drop view if exists "sakila_wh"."stg"."hello_world__dbt_backup" cascade
2022-01-14 12:55:03.153627 (Thread-1): SQL status: DROP VIEW in 0.05 seconds
2022-01-14 12:55:03.155678 (Thread-1): finished collecting timing info
2022-01-14 12:55:03.156023 (Thread-1): On model.sakila_dbt_project.hello_world: Close
2022-01-14 12:55:03.156735 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '60679a6b-7853-43f5-ad40-0bb536a6cf39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c0f5880>]}
2022-01-14 12:55:03.157202 (Thread-1): 18:25:03 | 5 of 8 OK created view model stg.hello_world......................... [CREATE VIEW in 0.61s]
2022-01-14 12:55:03.157497 (Thread-1): Finished running node model.sakila_dbt_project.hello_world
2022-01-14 12:55:03.157720 (Thread-1): Began running node model.sakila_dbt_project.my_first_dbt_model
2022-01-14 12:55:03.158004 (Thread-1): 18:25:03 | 6 of 8 START table model stg.my_first_dbt_model...................... [RUN]
2022-01-14 12:55:03.158462 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-14 12:55:03.158673 (Thread-1): Compiling model.sakila_dbt_project.my_first_dbt_model
2022-01-14 12:55:03.161444 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.my_first_dbt_model"
2022-01-14 12:55:03.162055 (Thread-1): finished collecting timing info
2022-01-14 12:55:03.165306 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.my_first_dbt_model"
2022-01-14 12:55:03.165889 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-14 12:55:03.166069 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: BEGIN
2022-01-14 12:55:03.166246 (Thread-1): Opening a new connection, currently in state closed
2022-01-14 12:55:03.499546 (Thread-1): SQL status: BEGIN in 0.33 seconds
2022-01-14 12:55:03.500058 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-14 12:55:03.500327 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */


  create  table "sakila_wh"."stg"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-14 12:55:03.560546 (Thread-1): SQL status: SELECT 2 in 0.06 seconds
2022-01-14 12:55:03.566044 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-14 12:55:03.566322 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
alter table "sakila_wh"."stg"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-14 12:55:03.631779 (Thread-1): SQL status: ALTER TABLE in 0.07 seconds
2022-01-14 12:55:03.660920 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: COMMIT
2022-01-14 12:55:03.661180 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-14 12:55:03.661355 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: COMMIT
2022-01-14 12:55:03.716853 (Thread-1): SQL status: COMMIT in 0.06 seconds
2022-01-14 12:55:03.720178 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-14 12:55:03.720496 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
drop table if exists "sakila_wh"."stg"."my_first_dbt_model__dbt_backup" cascade
2022-01-14 12:55:03.775319 (Thread-1): SQL status: DROP TABLE in 0.05 seconds
2022-01-14 12:55:03.777036 (Thread-1): finished collecting timing info
2022-01-14 12:55:03.777317 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: Close
2022-01-14 12:55:03.777867 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '60679a6b-7853-43f5-ad40-0bb536a6cf39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c2a0430>]}
2022-01-14 12:55:03.778322 (Thread-1): 18:25:03 | 6 of 8 OK created table model stg.my_first_dbt_model................. [SELECT 2 in 0.62s]
2022-01-14 12:55:03.778591 (Thread-1): Finished running node model.sakila_dbt_project.my_first_dbt_model
2022-01-14 12:55:03.778876 (Thread-1): Began running node model.sakila_dbt_project.dim_store
2022-01-14 12:55:03.779438 (Thread-1): 18:25:03 | 7 of 8 START table model stg_dwh.dim_store........................... [RUN]
2022-01-14 12:55:03.779860 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_store".
2022-01-14 12:55:03.780054 (Thread-1): Compiling model.sakila_dbt_project.dim_store
2022-01-14 12:55:03.784897 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_store"
2022-01-14 12:55:03.785533 (Thread-1): finished collecting timing info
2022-01-14 12:55:03.788241 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_store"
2022-01-14 12:55:03.788887 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_store".
2022-01-14 12:55:03.789074 (Thread-1): On model.sakila_dbt_project.dim_store: BEGIN
2022-01-14 12:55:03.789286 (Thread-1): Opening a new connection, currently in state closed
2022-01-14 12:55:04.122413 (Thread-1): SQL status: BEGIN in 0.33 seconds
2022-01-14 12:55:04.122745 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_store".
2022-01-14 12:55:04.123021 (Thread-1): On model.sakila_dbt_project.dim_store: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_store"} */


  create  table "sakila_wh"."stg_dwh"."dim_store__dbt_tmp"
  as (
    

with stg_store as (
		select
    *,
    '2022-01-14 12:54:55'::timestamp as dbt_time
     from "sakila_wh"."stg"."store"
),

staff as (
 select * from "sakila_wh"."stg_dwh"."dim_staff"
),

address as (
  select * from "sakila_wh"."stg"."address"
),

city as (
  select * from "sakila_wh"."stg"."city"
),

country as (
  select * from "sakila_wh"."stg"."country"
),
stg_store_1 as (-- add staff
		select
		stg_store.*,
		staff.first_name as staff_first_name,
		staff.last_name as staff_last_name
		from
		stg_store
		left join staff  on 1=1
		and stg_store.manager_staff_id = staff.staff_id
),
stg_store_2 as (-- add adress
		select
		stg_store_1.*,
		address.address,
		city.city_id,
		city.city,
		country.country_id,
		country.country
		from
		stg_store_1

		left join address on 1=1
		and stg_store_1.address_id =address.address_id

		left join city on 1=1
		and address.city_id = city.city_id

		left join country on  1=1
		and city.country_id = country.country_id
)

select
  store_id,
  manager_staff_id,
  staff_first_name,
  staff_last_name,
  address_id,
  address,
  city_id,
  city,
  country_id,
  country,
  last_update,
  dbt_time
from stg_store_2
  );
2022-01-14 12:55:04.188790 (Thread-1): SQL status: SELECT 2 in 0.07 seconds
2022-01-14 12:55:04.192354 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_store".
2022-01-14 12:55:04.192590 (Thread-1): On model.sakila_dbt_project.dim_store: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_store"} */
alter table "sakila_wh"."stg_dwh"."dim_store__dbt_tmp" rename to "dim_store"
2022-01-14 12:55:04.249902 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-14 12:55:04.252496 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 12:55:04.252895 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_store".
2022-01-14 12:55:04.253102 (Thread-1): On model.sakila_dbt_project.dim_store: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_store"} */

        insert into "sakila_wh"."stg_dwh"."dim_store"(store_id) VALUES (-1)
      
2022-01-14 12:55:04.307173 (Thread-1): SQL status: INSERT 0 1 in 0.05 seconds
2022-01-14 12:55:04.308648 (Thread-1): On model.sakila_dbt_project.dim_store: COMMIT
2022-01-14 12:55:04.308842 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_store".
2022-01-14 12:55:04.309002 (Thread-1): On model.sakila_dbt_project.dim_store: COMMIT
2022-01-14 12:55:04.364408 (Thread-1): SQL status: COMMIT in 0.06 seconds
2022-01-14 12:55:04.367310 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_store".
2022-01-14 12:55:04.367540 (Thread-1): On model.sakila_dbt_project.dim_store: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_store"} */
drop table if exists "sakila_wh"."stg_dwh"."dim_store__dbt_backup" cascade
2022-01-14 12:55:04.421886 (Thread-1): SQL status: DROP TABLE in 0.05 seconds
2022-01-14 12:55:04.423383 (Thread-1): finished collecting timing info
2022-01-14 12:55:04.423626 (Thread-1): On model.sakila_dbt_project.dim_store: Close
2022-01-14 12:55:04.424090 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '60679a6b-7853-43f5-ad40-0bb536a6cf39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c2a0a30>]}
2022-01-14 12:55:04.424463 (Thread-1): 18:25:04 | 7 of 8 OK created table model stg_dwh.dim_store...................... [SELECT 2 in 0.64s]
2022-01-14 12:55:04.424681 (Thread-1): Finished running node model.sakila_dbt_project.dim_store
2022-01-14 12:55:04.424892 (Thread-1): Began running node model.sakila_dbt_project.my_second_dbt_model
2022-01-14 12:55:04.425236 (Thread-1): 18:25:04 | 8 of 8 START view model stg.my_second_dbt_model...................... [RUN]
2022-01-14 12:55:04.425600 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-14 12:55:04.425797 (Thread-1): Compiling model.sakila_dbt_project.my_second_dbt_model
2022-01-14 12:55:04.428441 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.my_second_dbt_model"
2022-01-14 12:55:04.429035 (Thread-1): finished collecting timing info
2022-01-14 12:55:04.432180 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.my_second_dbt_model"
2022-01-14 12:55:04.432761 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-14 12:55:04.432943 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: BEGIN
2022-01-14 12:55:04.433112 (Thread-1): Opening a new connection, currently in state closed
2022-01-14 12:55:04.763642 (Thread-1): SQL status: BEGIN in 0.33 seconds
2022-01-14 12:55:04.763970 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-14 12:55:04.764172 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */

  create view "sakila_wh"."stg"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "sakila_wh"."stg"."my_first_dbt_model"
where id = 1
  );

2022-01-14 12:55:04.822868 (Thread-1): SQL status: CREATE VIEW in 0.06 seconds
2022-01-14 12:55:04.825685 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-14 12:55:04.825877 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
alter table "sakila_wh"."stg"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-14 12:55:04.880443 (Thread-1): SQL status: ALTER TABLE in 0.05 seconds
2022-01-14 12:55:04.881766 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: COMMIT
2022-01-14 12:55:04.881967 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-14 12:55:04.882114 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: COMMIT
2022-01-14 12:55:04.936597 (Thread-1): SQL status: COMMIT in 0.05 seconds
2022-01-14 12:55:04.940006 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-14 12:55:04.940215 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
drop view if exists "sakila_wh"."stg"."my_second_dbt_model__dbt_backup" cascade
2022-01-14 12:55:04.994394 (Thread-1): SQL status: DROP VIEW in 0.05 seconds
2022-01-14 12:55:04.995532 (Thread-1): finished collecting timing info
2022-01-14 12:55:04.995732 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: Close
2022-01-14 12:55:04.996130 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '60679a6b-7853-43f5-ad40-0bb536a6cf39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c0e8d90>]}
2022-01-14 12:55:04.996458 (Thread-1): 18:25:04 | 8 of 8 OK created view model stg.my_second_dbt_model................. [CREATE VIEW in 0.57s]
2022-01-14 12:55:04.996645 (Thread-1): Finished running node model.sakila_dbt_project.my_second_dbt_model
2022-01-14 12:55:04.997573 (MainThread): Acquiring new postgres connection "master".
2022-01-14 12:55:04.997799 (MainThread): Using postgres connection "master".
2022-01-14 12:55:04.997946 (MainThread): On master: BEGIN
2022-01-14 12:55:04.998092 (MainThread): Opening a new connection, currently in state closed
2022-01-14 12:55:05.328861 (MainThread): SQL status: BEGIN in 0.33 seconds
2022-01-14 12:55:05.329125 (MainThread): On master: COMMIT
2022-01-14 12:55:05.329332 (MainThread): Using postgres connection "master".
2022-01-14 12:55:05.329562 (MainThread): On master: COMMIT
2022-01-14 12:55:05.383281 (MainThread): SQL status: COMMIT in 0.05 seconds
2022-01-14 12:55:05.383574 (MainThread): 18:25:05 | 
2022-01-14 12:55:05.383778 (MainThread): 18:25:05 | Running 1 on-run-end hook
2022-01-14 12:55:05.383954 (MainThread): Compiling operation.sakila_dbt_project.sakila_dbt_project-on-run-end-0
2022-01-14 12:55:05.387214 (MainThread): Database error while running on-run-end
2022-01-14 12:55:05.387445 (MainThread): On master: Close
2022-01-14 12:55:05.387816 (MainThread): Connection 'master' was properly closed.
2022-01-14 12:55:05.387972 (MainThread): Connection 'model.sakila_dbt_project.my_second_dbt_model' was properly closed.
2022-01-14 12:55:05.388189 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c063af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c25dca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c25d910>]}
2022-01-14 12:55:05.388431 (MainThread): Flushing usage events
2022-01-14 12:55:07.099674 (MainThread): Encountered an error:
2022-01-14 12:55:07.100039 (MainThread): Compilation Error in operation sakila_dbt_project-on-run-end-0 (./dbt_project.yml)
  'delete_from_table' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
2022-01-14 12:55:07.108988 (MainThread): Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/dbt/clients/jinja.py", line 517, in catch_jinja
    yield
  File "/usr/local/lib/python3.9/site-packages/dbt/clients/jinja.py", line 549, in render_template
    return template.render(ctx)
  File "/usr/local/lib/python3.9/site-packages/jinja2/environment.py", line 1090, in render
    self.environment.handle_exception()
  File "/usr/local/lib/python3.9/site-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.9/site-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 1, in top-level template code
  File "/usr/local/lib/python3.9/site-packages/jinja2/sandbox.py", line 460, in call
    if not __self.is_safe_callable(__obj):
  File "/usr/local/lib/python3.9/site-packages/jinja2/sandbox.py", line 360, in is_safe_callable
    getattr(obj, "unsafe_callable", False) or getattr(obj, "alters_data", False)
jinja2.exceptions.UndefinedError: 'delete_from_table' is undefined

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/dbt/main.py", line 127, in main
    results, succeeded = handle_and_check(args)
  File "/usr/local/lib/python3.9/site-packages/dbt/main.py", line 205, in handle_and_check
    task, res = run_from_args(parsed)
  File "/usr/local/lib/python3.9/site-packages/dbt/main.py", line 258, in run_from_args
    results = task.run()
  File "/usr/local/lib/python3.9/site-packages/dbt/task/runnable.py", line 457, in run
    result = self.execute_with_hooks(selected_uids)
  File "/usr/local/lib/python3.9/site-packages/dbt/task/runnable.py", line 417, in execute_with_hooks
    self.after_run(adapter, res)
  File "/usr/local/lib/python3.9/site-packages/dbt/task/run.py", line 438, in after_run
    self.safe_run_hooks(adapter, RunHookType.End, extras)
  File "/usr/local/lib/python3.9/site-packages/dbt/task/run.py", line 353, in safe_run_hooks
    self.run_hooks(adapter, hook_type, extra_context)
  File "/usr/local/lib/python3.9/site-packages/dbt/task/run.py", line 321, in run_hooks
    sql = self.get_hook_sql(adapter, hook, idx, num_hooks,
  File "/usr/local/lib/python3.9/site-packages/dbt/task/run.py", line 273, in get_hook_sql
    compiled = compiler.compile_node(hook, self.manifest, extra_context)
  File "/usr/local/lib/python3.9/site-packages/dbt/compilation.py", line 544, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.9/site-packages/dbt/compilation.py", line 384, in _compile_node
    compiled_node.compiled_sql = jinja.get_rendered(
  File "/usr/local/lib/python3.9/site-packages/dbt/clients/jinja.py", line 598, in get_rendered
    return render_template(template, ctx, node)
  File "/usr/local/lib/python3.9/site-packages/dbt/clients/jinja.py", line 549, in render_template
    return template.render(ctx)
  File "/usr/local/Cellar/python@3.9/3.9.9/Frameworks/Python.framework/Versions/3.9/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/usr/local/lib/python3.9/site-packages/dbt/clients/jinja.py", line 522, in catch_jinja
    raise UndefinedMacroException(str(e), node) from e
dbt.exceptions.UndefinedMacroException: Compilation Error in operation sakila_dbt_project-on-run-end-0 (./dbt_project.yml)
  'delete_from_table' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".

2022-01-14 12:58:36.789301 (MainThread): Running with dbt=0.21.1
2022-01-14 12:58:36.877396 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2022-01-14 12:58:36.879411 (MainThread): Tracking: tracking
2022-01-14 12:58:36.898157 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10859faf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1085ae850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1085aee80>]}
2022-01-14 12:58:36.919616 (MainThread): Partial parsing not enabled
2022-01-14 12:58:36.963293 (MainThread): Parsing macros/catalog.sql
2022-01-14 12:58:36.966610 (MainThread): Parsing macros/relations.sql
2022-01-14 12:58:36.967862 (MainThread): Parsing macros/adapters.sql
2022-01-14 12:58:36.989142 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2022-01-14 12:58:36.990859 (MainThread): Parsing macros/core.sql
2022-01-14 12:58:36.994374 (MainThread): Parsing macros/materializations/test.sql
2022-01-14 12:58:37.000817 (MainThread): Parsing macros/materializations/helpers.sql
2022-01-14 12:58:37.011113 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2022-01-14 12:58:37.012960 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2022-01-14 12:58:37.029604 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2022-01-14 12:58:37.059838 (MainThread): Parsing macros/materializations/seed/seed.sql
2022-01-14 12:58:37.081043 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2022-01-14 12:58:37.082750 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2022-01-14 12:58:37.092470 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2022-01-14 12:58:37.110911 (MainThread): Parsing macros/materializations/common/merge.sql
2022-01-14 12:58:37.123990 (MainThread): Parsing macros/materializations/table/table.sql
2022-01-14 12:58:37.131358 (MainThread): Parsing macros/materializations/view/view.sql
2022-01-14 12:58:37.138191 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2022-01-14 12:58:37.141715 (MainThread): Parsing macros/etc/get_custom_alias.sql
2022-01-14 12:58:37.143054 (MainThread): Parsing macros/etc/query.sql
2022-01-14 12:58:37.143955 (MainThread): Parsing macros/etc/is_incremental.sql
2022-01-14 12:58:37.145316 (MainThread): Parsing macros/etc/datetime.sql
2022-01-14 12:58:37.153507 (MainThread): Parsing macros/etc/where_subquery.sql
2022-01-14 12:58:37.155245 (MainThread): Parsing macros/etc/get_custom_schema.sql
2022-01-14 12:58:37.157434 (MainThread): Parsing macros/etc/get_custom_database.sql
2022-01-14 12:58:37.158864 (MainThread): Parsing macros/adapters/common.sql
2022-01-14 12:58:37.210182 (MainThread): Parsing macros/schema_tests/relationships.sql
2022-01-14 12:58:37.211855 (MainThread): Parsing macros/schema_tests/not_null.sql
2022-01-14 12:58:37.213095 (MainThread): Parsing macros/schema_tests/unique.sql
2022-01-14 12:58:37.214428 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2022-01-14 12:58:37.216422 (MainThread): Parsing macros/cross_db_utils/except.sql
2022-01-14 12:58:37.217385 (MainThread): Parsing macros/cross_db_utils/replace.sql
2022-01-14 12:58:37.218646 (MainThread): Parsing macros/cross_db_utils/concat.sql
2022-01-14 12:58:37.219641 (MainThread): Parsing macros/cross_db_utils/datatypes.sql
2022-01-14 12:58:37.225253 (MainThread): Parsing macros/cross_db_utils/_is_relation.sql
2022-01-14 12:58:37.226427 (MainThread): Parsing macros/cross_db_utils/length.sql
2022-01-14 12:58:37.227616 (MainThread): Parsing macros/cross_db_utils/dateadd.sql
2022-01-14 12:58:37.230598 (MainThread): Parsing macros/cross_db_utils/intersect.sql
2022-01-14 12:58:37.231591 (MainThread): Parsing macros/cross_db_utils/right.sql
2022-01-14 12:58:37.233924 (MainThread): Parsing macros/cross_db_utils/datediff.sql
2022-01-14 12:58:37.243345 (MainThread): Parsing macros/cross_db_utils/safe_cast.sql
2022-01-14 12:58:37.245073 (MainThread): Parsing macros/cross_db_utils/hash.sql
2022-01-14 12:58:37.246386 (MainThread): Parsing macros/cross_db_utils/cast_bool_to_text.sql
2022-01-14 12:58:37.247713 (MainThread): Parsing macros/cross_db_utils/identifier.sql
2022-01-14 12:58:37.249231 (MainThread): Parsing macros/cross_db_utils/position.sql
2022-01-14 12:58:37.250710 (MainThread): Parsing macros/cross_db_utils/literal.sql
2022-01-14 12:58:37.251672 (MainThread): Parsing macros/cross_db_utils/current_timestamp.sql
2022-01-14 12:58:37.255300 (MainThread): Parsing macros/cross_db_utils/width_bucket.sql
2022-01-14 12:58:37.260101 (MainThread): Parsing macros/cross_db_utils/last_day.sql
2022-01-14 12:58:37.263340 (MainThread): Parsing macros/cross_db_utils/split_part.sql
2022-01-14 12:58:37.265029 (MainThread): Parsing macros/cross_db_utils/date_trunc.sql
2022-01-14 12:58:37.266503 (MainThread): Parsing macros/cross_db_utils/_is_ephemeral.sql
2022-01-14 12:58:37.268300 (MainThread): Parsing macros/materializations/insert_by_period_materialization.sql
2022-01-14 12:58:37.291249 (MainThread): Parsing macros/web/get_url_host.sql
2022-01-14 12:58:37.292965 (MainThread): Parsing macros/web/get_url_path.sql
2022-01-14 12:58:37.295486 (MainThread): Parsing macros/web/get_url_parameter.sql
2022-01-14 12:58:37.296934 (MainThread): Parsing macros/jinja_helpers/pretty_log_format.sql
2022-01-14 12:58:37.297959 (MainThread): Parsing macros/jinja_helpers/pretty_time.sql
2022-01-14 12:58:37.299126 (MainThread): Parsing macros/jinja_helpers/log_info.sql
2022-01-14 12:58:37.300158 (MainThread): Parsing macros/jinja_helpers/slugify.sql
2022-01-14 12:58:37.301253 (MainThread): Parsing macros/schema_tests/fewer_rows_than.sql
2022-01-14 12:58:37.302913 (MainThread): Parsing macros/schema_tests/equal_rowcount.sql
2022-01-14 12:58:37.304512 (MainThread): Parsing macros/schema_tests/relationships_where.sql
2022-01-14 12:58:37.306620 (MainThread): Parsing macros/schema_tests/recency.sql
2022-01-14 12:58:37.308246 (MainThread): Parsing macros/schema_tests/not_constant.sql
2022-01-14 12:58:37.309370 (MainThread): Parsing macros/schema_tests/accepted_range.sql
2022-01-14 12:58:37.311708 (MainThread): Parsing macros/schema_tests/not_accepted_values.sql
2022-01-14 12:58:37.313682 (MainThread): Parsing macros/schema_tests/test_unique_where.sql
2022-01-14 12:58:37.315041 (MainThread): Parsing macros/schema_tests/at_least_one.sql
2022-01-14 12:58:37.316195 (MainThread): Parsing macros/schema_tests/unique_combination_of_columns.sql
2022-01-14 12:58:37.318773 (MainThread): Parsing macros/schema_tests/cardinality_equality.sql
2022-01-14 12:58:37.320797 (MainThread): Parsing macros/schema_tests/expression_is_true.sql
2022-01-14 12:58:37.322449 (MainThread): Parsing macros/schema_tests/sequential_values.sql
2022-01-14 12:58:37.325216 (MainThread): Parsing macros/schema_tests/test_not_null_where.sql
2022-01-14 12:58:37.326573 (MainThread): Parsing macros/schema_tests/equality.sql
2022-01-14 12:58:37.330023 (MainThread): Parsing macros/schema_tests/mutually_exclusive_ranges.sql
2022-01-14 12:58:37.340139 (MainThread): Parsing macros/sql/date_spine.sql
2022-01-14 12:58:37.344623 (MainThread): Parsing macros/sql/nullcheck_table.sql
2022-01-14 12:58:37.346136 (MainThread): Parsing macros/sql/get_relations_by_pattern.sql
2022-01-14 12:58:37.349304 (MainThread): Parsing macros/sql/generate_series.sql
2022-01-14 12:58:37.379387 (MainThread): Parsing macros/sql/get_relations_by_prefix.sql
2022-01-14 12:58:37.384009 (MainThread): Parsing macros/sql/get_tables_by_prefix_sql.sql
2022-01-14 12:58:37.386124 (MainThread): Parsing macros/sql/star.sql
2022-01-14 12:58:37.390476 (MainThread): Parsing macros/sql/unpivot.sql
2022-01-14 12:58:37.400514 (MainThread): Parsing macros/sql/union.sql
2022-01-14 12:58:37.410513 (MainThread): Parsing macros/sql/groupby.sql
2022-01-14 12:58:37.412136 (MainThread): Parsing macros/sql/surrogate_key.sql
2022-01-14 12:58:37.416034 (MainThread): Parsing macros/sql/safe_add.sql
2022-01-14 12:58:37.417842 (MainThread): Parsing macros/sql/nullcheck.sql
2022-01-14 12:58:37.419903 (MainThread): Parsing macros/sql/get_tables_by_pattern_sql.sql
2022-01-14 12:58:37.426954 (MainThread): Parsing macros/sql/get_column_values.sql
2022-01-14 12:58:37.432437 (MainThread): Parsing macros/sql/pivot.sql
2022-01-14 12:58:37.437071 (MainThread): Parsing macros/sql/get_query_results_as_dict.sql
2022-01-14 12:58:37.439608 (MainThread): Parsing macros/sql/haversine_distance.sql
2022-01-14 12:58:37.738812 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-14 12:58:37.750193 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-14 12:58:37.753878 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-14 12:58:37.756784 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-14 12:58:37.760498 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 12:58:37.762059 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-14 12:58:37.769691 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 12:58:37.771401 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_film".
2022-01-14 12:58:37.776004 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 12:58:37.777559 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-14 12:58:37.779535 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 12:58:37.780639 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_store".
2022-01-14 12:58:37.784666 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 12:58:37.817023 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 12:58:37.826432 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 12:58:37.828237 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 12:58:37.829861 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 12:58:37.831824 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 12:58:37.833672 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 12:58:37.851114 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 12:58:37.852989 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 12:58:37.855005 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 12:58:37.856607 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 12:58:37.858198 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 12:58:37.859988 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 12:58:37.861788 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 12:58:37.863392 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 12:58:37.864991 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 12:58:37.866949 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 12:58:37.890390 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2d6dc256-0dfd-4627-9d51-9818b334abaf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1087fe0d0>]}
2022-01-14 12:58:37.899367 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-01-14 12:58:37.899959 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2d6dc256-0dfd-4627-9d51-9818b334abaf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1085fad30>]}
2022-01-14 12:58:37.900197 (MainThread): Found 8 models, 16 tests, 0 snapshots, 0 analyses, 347 macros, 0 operations, 0 seed files, 12 sources, 0 exposures
2022-01-14 12:58:37.901856 (MainThread): 
2022-01-14 12:58:37.902173 (MainThread): Acquiring new postgres connection "master".
2022-01-14 12:58:37.903193 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_sakila_wh".
2022-01-14 12:58:37.912155 (ThreadPoolExecutor-0_0): Using postgres connection "list_sakila_wh".
2022-01-14 12:58:37.912319 (ThreadPoolExecutor-0_0): On list_sakila_wh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh"} */

    select distinct nspname from pg_namespace
  
2022-01-14 12:58:37.912462 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2022-01-14 12:58:38.274628 (ThreadPoolExecutor-0_0): SQL status: SELECT 9 in 0.36 seconds
2022-01-14 12:58:38.276424 (ThreadPoolExecutor-0_0): On list_sakila_wh: Close
2022-01-14 12:58:38.277105 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_sakila_wh".
2022-01-14 12:58:38.279133 (ThreadPoolExecutor-0_0): Using postgres connection "list_sakila_wh".
2022-01-14 12:58:38.279319 (ThreadPoolExecutor-0_0): On list_sakila_wh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh"} */

    select distinct nspname from pg_namespace
  
2022-01-14 12:58:38.279492 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2022-01-14 12:58:38.616772 (ThreadPoolExecutor-0_0): SQL status: SELECT 9 in 0.34 seconds
2022-01-14 12:58:38.618826 (ThreadPoolExecutor-0_0): On list_sakila_wh: Close
2022-01-14 12:58:38.620899 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_stg_dwh".
2022-01-14 12:58:38.627867 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_stg_dwh".
2022-01-14 12:58:38.628073 (ThreadPoolExecutor-1_0): On list_sakila_wh_stg_dwh: BEGIN
2022-01-14 12:58:38.628254 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2022-01-14 12:58:38.962409 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.33 seconds
2022-01-14 12:58:38.962887 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_stg_dwh".
2022-01-14 12:58:38.963179 (ThreadPoolExecutor-1_0): On list_sakila_wh_stg_dwh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_stg_dwh"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'stg_dwh'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'stg_dwh'
  
2022-01-14 12:58:39.022412 (ThreadPoolExecutor-1_0): SQL status: SELECT 5 in 0.06 seconds
2022-01-14 12:58:39.024304 (ThreadPoolExecutor-1_0): On list_sakila_wh_stg_dwh: ROLLBACK
2022-01-14 12:58:39.079171 (ThreadPoolExecutor-1_0): On list_sakila_wh_stg_dwh: Close
2022-01-14 12:58:39.080181 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_stg".
2022-01-14 12:58:39.082772 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_stg".
2022-01-14 12:58:39.083002 (ThreadPoolExecutor-1_0): On list_sakila_wh_stg: BEGIN
2022-01-14 12:58:39.083209 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2022-01-14 12:58:39.422588 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.34 seconds
2022-01-14 12:58:39.423000 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_stg".
2022-01-14 12:58:39.423272 (ThreadPoolExecutor-1_0): On list_sakila_wh_stg: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_stg"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'stg'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'stg'
  
2022-01-14 12:58:39.484308 (ThreadPoolExecutor-1_0): SQL status: SELECT 31 in 0.06 seconds
2022-01-14 12:58:39.487268 (ThreadPoolExecutor-1_0): On list_sakila_wh_stg: ROLLBACK
2022-01-14 12:58:39.541944 (ThreadPoolExecutor-1_0): On list_sakila_wh_stg: Close
2022-01-14 12:58:39.550277 (MainThread): Using postgres connection "master".
2022-01-14 12:58:39.550518 (MainThread): On master: BEGIN
2022-01-14 12:58:39.550724 (MainThread): Opening a new connection, currently in state init
2022-01-14 12:58:39.895935 (MainThread): SQL status: BEGIN in 0.35 seconds
2022-01-14 12:58:39.896318 (MainThread): Using postgres connection "master".
2022-01-14 12:58:39.896546 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-14 12:58:39.971912 (MainThread): SQL status: SELECT 47 in 0.08 seconds
2022-01-14 12:58:39.975742 (MainThread): On master: ROLLBACK
2022-01-14 12:58:40.031296 (MainThread): Using postgres connection "master".
2022-01-14 12:58:40.031685 (MainThread): On master: BEGIN
2022-01-14 12:58:40.142588 (MainThread): SQL status: BEGIN in 0.11 seconds
2022-01-14 12:58:40.143184 (MainThread): On master: COMMIT
2022-01-14 12:58:40.143500 (MainThread): Using postgres connection "master".
2022-01-14 12:58:40.143745 (MainThread): On master: COMMIT
2022-01-14 12:58:40.198375 (MainThread): SQL status: COMMIT in 0.05 seconds
2022-01-14 12:58:40.198823 (MainThread): On master: Close
2022-01-14 12:58:40.199564 (MainThread): 18:28:40 | Concurrency: 1 threads (target='dev')
2022-01-14 12:58:40.199961 (MainThread): 18:28:40 | 
2022-01-14 12:58:40.203263 (Thread-1): Began running node model.sakila_dbt_project.dim_customer
2022-01-14 12:58:40.203702 (Thread-1): 18:28:40 | 1 of 8 START incremental model stg_dwh.dim_customer.................. [RUN]
2022-01-14 12:58:40.204172 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-14 12:58:40.204429 (Thread-1): Compiling model.sakila_dbt_project.dim_customer
2022-01-14 12:58:40.212401 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_customer"
2022-01-14 12:58:40.213085 (Thread-1): finished collecting timing info
2022-01-14 12:58:40.261943 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-14 12:58:40.262198 (Thread-1): On model.sakila_dbt_project.dim_customer: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_customer"} */

    

  create temporary table "dim_customer__dbt_tmp182840245933"
  as (
    

with customer_base as (

select
 *,
	concat(customer.first_name,' ',customer.last_name) as full_name,
	substring(email from POSITION('@' in email)+1 for char_length(email)-POSITION('@' in email)) as domain,
	customer.active::int as active_int,
	(case when customer.active = 0 then 'no' else 'yes' end)::varchar(100) as "active_desc",
  '2022-01-14 12:58:36'::timestamp as dbt_time
from
	"sakila_wh"."stg"."customer" as customer),

  address as (
    select * from "sakila_wh"."stg"."address"
  ),

  city as (
    select * from "sakila_wh"."stg"."city"
  ),

  country as (
    select * from "sakila_wh"."stg"."country"
  )

  select
  customer_base.customer_id,
  customer_base.store_id,
  customer_base.first_name,
  customer_base.last_name,
  customer_base.full_name,
  customer_base.domain,
  customer_base.email,
  customer_base.active_int as active,
  customer_base.active_desc,

  address.address_id,
  address.address,
  city.city_id,
  city.city,
  country.country_id,
  country.country,

  customer_base.create_date,
  customer_base.last_update,
  customer_base.dbt_time

  from
  customer_base

	left join address on 1=1
	and customer_base.address_id =address.address_id

	left join city on 1=1
	and address.city_id = city.city_id

  left join country on 1=1
  and country.country_id = city.country_id

  where 1=1

  
  and customer_base.last_update::timestamp > (select max(last_update) from "sakila_wh"."stg_dwh"."dim_customer")
  
  );
  
2022-01-14 12:58:40.262377 (Thread-1): Opening a new connection, currently in state closed
2022-01-14 12:58:40.619920 (Thread-1): SQL status: SELECT 0 in 0.36 seconds
2022-01-14 12:58:40.628180 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-14 12:58:40.628390 (Thread-1): On model.sakila_dbt_project.dim_customer: BEGIN
2022-01-14 12:58:40.683422 (Thread-1): SQL status: BEGIN in 0.05 seconds
2022-01-14 12:58:40.683941 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-14 12:58:40.684199 (Thread-1): On model.sakila_dbt_project.dim_customer: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_customer"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dim_customer__dbt_tmp182840245933'
        
      order by ordinal_position

  
2022-01-14 12:58:40.755269 (Thread-1): SQL status: SELECT 18 in 0.07 seconds
2022-01-14 12:58:40.761909 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-14 12:58:40.762122 (Thread-1): On model.sakila_dbt_project.dim_customer: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_customer"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "sakila_wh".INFORMATION_SCHEMA.columns
      where table_name = 'dim_customer'
        
        and table_schema = 'stg_dwh'
        
      order by ordinal_position

  
2022-01-14 12:58:40.821915 (Thread-1): SQL status: SELECT 18 in 0.06 seconds
2022-01-14 12:58:40.834250 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-14 12:58:40.834502 (Thread-1): On model.sakila_dbt_project.dim_customer: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_customer"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "sakila_wh".INFORMATION_SCHEMA.columns
      where table_name = 'dim_customer'
        
        and table_schema = 'stg_dwh'
        
      order by ordinal_position

  
2022-01-14 12:58:40.895192 (Thread-1): SQL status: SELECT 18 in 0.06 seconds
2022-01-14 12:58:40.898014 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_customer"
2022-01-14 12:58:40.898789 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-14 12:58:40.899011 (Thread-1): On model.sakila_dbt_project.dim_customer: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_customer"} */

      delete
    from "sakila_wh"."stg_dwh"."dim_customer"
    where (customer_id) in (
        select (customer_id)
        from "dim_customer__dbt_tmp182840245933"
    );

    insert into "sakila_wh"."stg_dwh"."dim_customer" ("customer_id", "store_id", "first_name", "last_name", "full_name", "domain", "email", "active", "active_desc", "address_id", "address", "city_id", "city", "country_id", "country", "create_date", "last_update", "dbt_time")
    (
       select "customer_id", "store_id", "first_name", "last_name", "full_name", "domain", "email", "active", "active_desc", "address_id", "address", "city_id", "city", "country_id", "country", "create_date", "last_update", "dbt_time"
       from "dim_customer__dbt_tmp182840245933"
    );
  
2022-01-14 12:58:40.953900 (Thread-1): SQL status: INSERT 0 0 in 0.05 seconds
2022-01-14 12:58:40.961804 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 12:58:40.962155 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-14 12:58:40.962331 (Thread-1): On model.sakila_dbt_project.dim_customer: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_customer"} */

        insert into "sakila_wh"."stg_dwh"."dim_customer"(customer_id) VALUES (-1)
      
2022-01-14 12:58:41.017983 (Thread-1): SQL status: INSERT 0 1 in 0.06 seconds
2022-01-14 12:58:41.019349 (Thread-1): On model.sakila_dbt_project.dim_customer: COMMIT
2022-01-14 12:58:41.019582 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-14 12:58:41.019780 (Thread-1): On model.sakila_dbt_project.dim_customer: COMMIT
2022-01-14 12:58:41.074999 (Thread-1): SQL status: COMMIT in 0.05 seconds
2022-01-14 12:58:41.075741 (Thread-1): finished collecting timing info
2022-01-14 12:58:41.076009 (Thread-1): On model.sakila_dbt_project.dim_customer: Close
2022-01-14 12:58:41.076490 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2d6dc256-0dfd-4627-9d51-9818b334abaf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1086f6310>]}
2022-01-14 12:58:41.076866 (Thread-1): 18:28:41 | 1 of 8 OK created incremental model stg_dwh.dim_customer............. [INSERT 0 0 in 0.87s]
2022-01-14 12:58:41.077088 (Thread-1): Finished running node model.sakila_dbt_project.dim_customer
2022-01-14 12:58:41.077301 (Thread-1): Began running node model.sakila_dbt_project.dim_date
2022-01-14 12:58:41.077680 (Thread-1): 18:28:41 | 2 of 8 START table model stg_dwh.dim_date............................ [RUN]
2022-01-14 12:58:41.078047 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-14 12:58:41.078242 (Thread-1): Compiling model.sakila_dbt_project.dim_date
2022-01-14 12:58:41.081251 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_date"
2022-01-14 12:58:41.081856 (Thread-1): finished collecting timing info
2022-01-14 12:58:41.097986 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_date"
2022-01-14 12:58:41.098752 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-14 12:58:41.098952 (Thread-1): On model.sakila_dbt_project.dim_date: BEGIN
2022-01-14 12:58:41.099130 (Thread-1): Opening a new connection, currently in state closed
2022-01-14 12:58:41.442521 (Thread-1): SQL status: BEGIN in 0.34 seconds
2022-01-14 12:58:41.443084 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-14 12:58:41.443425 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */


  create  table "sakila_wh"."stg_dwh"."dim_date__dbt_tmp"
  as (
    with dates as (
SELECT
       TO_CHAR(datum, 'yyyymmdd')::INT AS date_dim_id,
       datum AS date_key,
       EXTRACT(EPOCH FROM datum) AS epoch,
       TO_CHAR(datum, 'TMDay') AS day_name,
       EXTRACT(ISODOW FROM datum) AS day_of_week,
       EXTRACT(DAY FROM datum) AS day_of_month,
       datum - DATE_TRUNC('quarter', datum)::DATE + 1 AS day_of_quarter,
       EXTRACT(DOY FROM datum) AS day_of_year,
       TO_CHAR(datum, 'W')::INT AS week_of_month,
       EXTRACT(WEEK FROM datum) AS week_of_year,
       EXTRACT(MONTH FROM datum) AS month_actual,
       TO_CHAR(datum, 'TMMonth') AS month_name,
       TO_CHAR(datum, 'Mon') AS month_name_abbreviated,
       EXTRACT(QUARTER FROM datum) AS quarter_actual,
       CASE
           WHEN EXTRACT(QUARTER FROM datum) = 1 THEN 'First'
           WHEN EXTRACT(QUARTER FROM datum) = 2 THEN 'Second'
           WHEN EXTRACT(QUARTER FROM datum) = 3 THEN 'Third'
           WHEN EXTRACT(QUARTER FROM datum) = 4 THEN 'Fourth'
           END AS quarter_name,
       EXTRACT(YEAR FROM datum) AS year_actual,
       datum + (1 - EXTRACT(ISODOW FROM datum))::INT AS first_day_of_week,
       datum + (7 - EXTRACT(ISODOW FROM datum))::INT AS last_day_of_week,
       datum + (1 - EXTRACT(DAY FROM datum))::INT AS first_day_of_month,
       (DATE_TRUNC('MONTH', datum) + INTERVAL '1 MONTH - 1 day')::DATE AS last_day_of_month,
       DATE_TRUNC('quarter', datum)::DATE AS first_day_of_quarter,
       (DATE_TRUNC('quarter', datum) + INTERVAL '3 MONTH - 1 day')::DATE AS last_day_of_quarter,
       TO_DATE(EXTRACT(YEAR FROM datum) || '-01-01', 'YYYY-MM-DD') AS first_day_of_year,
       TO_DATE(EXTRACT(YEAR FROM datum) || '-12-31', 'YYYY-MM-DD') AS last_day_of_year,
       TO_CHAR(datum, 'yyyymm') AS yyyymm,
       CASE
           WHEN EXTRACT(ISODOW FROM datum) IN (6, 7) THEN TRUE
           ELSE FALSE
           END AS weekend_indr
FROM (SELECT '2000-01-01'::DATE + SEQUENCE.DAY AS datum
      FROM GENERATE_SERIES(0, 29219) AS SEQUENCE (DAY)
      GROUP BY SEQUENCE.DAY) DQ
)
select
*
from
dates
where
date_key <= CURRENT_DATE
order by date_dim_id asc
  );
2022-01-14 12:58:42.333454 (Thread-1): SQL status: SELECT 8050 in 0.89 seconds
2022-01-14 12:58:42.340373 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-14 12:58:42.340608 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
alter table "sakila_wh"."stg_dwh"."dim_date" rename to "dim_date__dbt_backup"
2022-01-14 12:58:42.395192 (Thread-1): SQL status: ALTER TABLE in 0.05 seconds
2022-01-14 12:58:42.397872 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-14 12:58:42.398069 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
alter table "sakila_wh"."stg_dwh"."dim_date__dbt_tmp" rename to "dim_date"
2022-01-14 12:58:42.454328 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-14 12:58:42.460315 (Thread-1): On model.sakila_dbt_project.dim_date: COMMIT
2022-01-14 12:58:42.460529 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-14 12:58:42.460696 (Thread-1): On model.sakila_dbt_project.dim_date: COMMIT
2022-01-14 12:58:42.517418 (Thread-1): SQL status: COMMIT in 0.06 seconds
2022-01-14 12:58:42.523891 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-14 12:58:42.524102 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
drop table if exists "sakila_wh"."stg_dwh"."dim_date__dbt_backup" cascade
2022-01-14 12:58:42.582570 (Thread-1): SQL status: DROP TABLE in 0.06 seconds
2022-01-14 12:58:42.584720 (Thread-1): finished collecting timing info
2022-01-14 12:58:42.585076 (Thread-1): On model.sakila_dbt_project.dim_date: Close
2022-01-14 12:58:42.585767 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2d6dc256-0dfd-4627-9d51-9818b334abaf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108932eb0>]}
2022-01-14 12:58:42.586222 (Thread-1): 18:28:42 | 2 of 8 OK created table model stg_dwh.dim_date....................... [SELECT 8050 in 1.51s]
2022-01-14 12:58:42.586494 (Thread-1): Finished running node model.sakila_dbt_project.dim_date
2022-01-14 12:58:42.586758 (Thread-1): Began running node model.sakila_dbt_project.dim_film
2022-01-14 12:58:42.587300 (Thread-1): 18:28:42 | 3 of 8 START incremental model stg_dwh.dim_film...................... [RUN]
2022-01-14 12:58:42.587742 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_film".
2022-01-14 12:58:42.587975 (Thread-1): Compiling model.sakila_dbt_project.dim_film
2022-01-14 12:58:42.594063 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_film"
2022-01-14 12:58:42.594710 (Thread-1): finished collecting timing info
2022-01-14 12:58:42.598099 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_film".
2022-01-14 12:58:42.598289 (Thread-1): On model.sakila_dbt_project.dim_film: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_film"} */

    

  create temporary table "dim_film__dbt_tmp182842596887"
  as (
    

with stg_film as (
	select
	*,
	(case
	when length<=75 then 'short'
	when (length>75 and length<=120) then 'medium'
	when length>120 then 'long'
	else 'na' end) as length_desc,
	COALESCE(original_language_id,0) as original_language_id_zero,
	case when POSITION('Trailers' in special_features::varchar)>0 then 1 else 0 end  as has_trailers,
	case when POSITION('Commentaries' in special_features::varchar)>0 then 1 else 0 end  as has_commentaries,
	case when POSITION('Deleted Scenes' in special_features::varchar)>0 then 1 else 0 end  as has_deleted_scenes,
	case when POSITION('Behind the Scenes' in special_features::varchar)>0 then 1 else 0 end  as has_behind_the_scenes,
	'2022-01-14 12:58:36'::timestamp as dbt_time
	from
	"sakila_wh"."stg"."film"
),

language as (
	select * from "sakila_wh"."stg"."language"
),

category as (
	select * from "sakila_wh"."stg"."category"
),

film_category as (
	select * from "sakila_wh"."stg"."film_category"
),

stg_film_1 as (
	select
	stg_film.*,
	language.name as lang_name
	from
	stg_film
	left join language on 1=1
	and stg_film.language_id = language.language_id
),

stg_film_2 as (
	select
		stg_film_1.*,
		category.category_id,
		category.name as category_desc
	from
	stg_film_1

	left join film_category on 1=1
	and stg_film_1.film_id = film_category.film_id

	left join category on 1=1
	and film_category.category_id  = category.category_id
)


select
  film_id,
  title,
  description,
  release_year,
  language_id,
  lang_name,
  original_language_id_zero as original_language_id,
  rental_duration,
  rental_rate,
  length,
  length_desc,
  replacement_cost,
  rating,
  category_id,
  category_desc,
  special_features,
  has_trailers,
  has_commentaries,
  has_behind_the_scenes,
  has_deleted_scenes,
  last_update,
	dbt_time
from
stg_film_2

where 1=1


and last_update::timestamp > (select max(last_update) from "sakila_wh"."stg_dwh"."dim_film")

  );
  
2022-01-14 12:58:42.598471 (Thread-1): Opening a new connection, currently in state closed
2022-01-14 12:58:42.969390 (Thread-1): SQL status: SELECT 0 in 0.37 seconds
2022-01-14 12:58:42.973610 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_film".
2022-01-14 12:58:42.973872 (Thread-1): On model.sakila_dbt_project.dim_film: BEGIN
2022-01-14 12:58:43.028524 (Thread-1): SQL status: BEGIN in 0.05 seconds
2022-01-14 12:58:43.029105 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_film".
2022-01-14 12:58:43.029473 (Thread-1): On model.sakila_dbt_project.dim_film: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_film"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'dim_film__dbt_tmp182842596887'
        
      order by ordinal_position

  
2022-01-14 12:58:43.096543 (Thread-1): SQL status: SELECT 22 in 0.07 seconds
2022-01-14 12:58:43.102573 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_film".
2022-01-14 12:58:43.102797 (Thread-1): On model.sakila_dbt_project.dim_film: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_film"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "sakila_wh".INFORMATION_SCHEMA.columns
      where table_name = 'dim_film'
        
        and table_schema = 'stg_dwh'
        
      order by ordinal_position

  
2022-01-14 12:58:43.163406 (Thread-1): SQL status: SELECT 22 in 0.06 seconds
2022-01-14 12:58:43.168874 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_film".
2022-01-14 12:58:43.169112 (Thread-1): On model.sakila_dbt_project.dim_film: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_film"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "sakila_wh".INFORMATION_SCHEMA.columns
      where table_name = 'dim_film'
        
        and table_schema = 'stg_dwh'
        
      order by ordinal_position

  
2022-01-14 12:58:43.229850 (Thread-1): SQL status: SELECT 22 in 0.06 seconds
2022-01-14 12:58:43.233481 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_film"
2022-01-14 12:58:43.234335 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_film".
2022-01-14 12:58:43.234562 (Thread-1): On model.sakila_dbt_project.dim_film: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_film"} */

      delete
    from "sakila_wh"."stg_dwh"."dim_film"
    where (film_id) in (
        select (film_id)
        from "dim_film__dbt_tmp182842596887"
    );

    insert into "sakila_wh"."stg_dwh"."dim_film" ("film_id", "title", "description", "release_year", "language_id", "lang_name", "original_language_id", "rental_duration", "rental_rate", "length", "length_desc", "replacement_cost", "rating", "category_id", "category_desc", "special_features", "has_trailers", "has_commentaries", "has_behind_the_scenes", "has_deleted_scenes", "last_update", "dbt_time")
    (
       select "film_id", "title", "description", "release_year", "language_id", "lang_name", "original_language_id", "rental_duration", "rental_rate", "length", "length_desc", "replacement_cost", "rating", "category_id", "category_desc", "special_features", "has_trailers", "has_commentaries", "has_behind_the_scenes", "has_deleted_scenes", "last_update", "dbt_time"
       from "dim_film__dbt_tmp182842596887"
    );
  
2022-01-14 12:58:43.292202 (Thread-1): SQL status: INSERT 0 0 in 0.06 seconds
2022-01-14 12:58:43.295092 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 12:58:43.295503 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_film".
2022-01-14 12:58:43.295712 (Thread-1): On model.sakila_dbt_project.dim_film: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_film"} */

        insert into "sakila_wh"."stg_dwh"."dim_film"(film_id) VALUES (-1)
      
2022-01-14 12:58:43.351277 (Thread-1): SQL status: INSERT 0 1 in 0.06 seconds
2022-01-14 12:58:43.352703 (Thread-1): On model.sakila_dbt_project.dim_film: COMMIT
2022-01-14 12:58:43.352990 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_film".
2022-01-14 12:58:43.353338 (Thread-1): On model.sakila_dbt_project.dim_film: COMMIT
2022-01-14 12:58:43.413130 (Thread-1): SQL status: COMMIT in 0.06 seconds
2022-01-14 12:58:43.414226 (Thread-1): finished collecting timing info
2022-01-14 12:58:43.414543 (Thread-1): On model.sakila_dbt_project.dim_film: Close
2022-01-14 12:58:43.415121 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2d6dc256-0dfd-4627-9d51-9818b334abaf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108736040>]}
2022-01-14 12:58:43.415571 (Thread-1): 18:28:43 | 3 of 8 OK created incremental model stg_dwh.dim_film................. [INSERT 0 0 in 0.83s]
2022-01-14 12:58:43.415834 (Thread-1): Finished running node model.sakila_dbt_project.dim_film
2022-01-14 12:58:43.416089 (Thread-1): Began running node model.sakila_dbt_project.dim_staff
2022-01-14 12:58:43.416516 (Thread-1): 18:28:43 | 4 of 8 START table model stg_dwh.dim_staff........................... [RUN]
2022-01-14 12:58:43.416959 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-14 12:58:43.417192 (Thread-1): Compiling model.sakila_dbt_project.dim_staff
2022-01-14 12:58:43.421055 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_staff"
2022-01-14 12:58:43.421681 (Thread-1): finished collecting timing info
2022-01-14 12:58:43.424334 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_staff"
2022-01-14 12:58:43.424920 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-14 12:58:43.425109 (Thread-1): On model.sakila_dbt_project.dim_staff: BEGIN
2022-01-14 12:58:43.425287 (Thread-1): Opening a new connection, currently in state closed
2022-01-14 12:58:43.767074 (Thread-1): SQL status: BEGIN in 0.34 seconds
2022-01-14 12:58:43.767676 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-14 12:58:43.767940 (Thread-1): On model.sakila_dbt_project.dim_staff: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_staff"} */


  create  table "sakila_wh"."stg_dwh"."dim_staff__dbt_tmp"
  as (
    

with staff_base as (
select
*,
(case when active::int = 1 then 1 else 0 end) as "active_int",
(case when active::int = 1 then 'yes' else 'no' end) as "active_desc",
'2022-01-14 12:58:36'::timestamp as dbt_time
from
"sakila_wh"."stg"."staff"
)

select
	staff_id,
	first_name,
	last_name,
	email,
  active_int as active,
  active_desc,
	last_update,
  dbt_time
from
	staff_base
  );
2022-01-14 12:58:43.830990 (Thread-1): SQL status: SELECT 2 in 0.06 seconds
2022-01-14 12:58:43.835170 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-14 12:58:43.835425 (Thread-1): On model.sakila_dbt_project.dim_staff: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_staff"} */
alter table "sakila_wh"."stg_dwh"."dim_staff" rename to "dim_staff__dbt_backup"
2022-01-14 12:58:43.891917 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-14 12:58:43.895625 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-14 12:58:43.895879 (Thread-1): On model.sakila_dbt_project.dim_staff: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_staff"} */
alter table "sakila_wh"."stg_dwh"."dim_staff__dbt_tmp" rename to "dim_staff"
2022-01-14 12:58:43.950558 (Thread-1): SQL status: ALTER TABLE in 0.05 seconds
2022-01-14 12:58:43.953812 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 12:58:43.954250 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-14 12:58:43.954462 (Thread-1): On model.sakila_dbt_project.dim_staff: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_staff"} */

        insert into "sakila_wh"."stg_dwh"."dim_staff"(staff_id) VALUES (-1)
      
2022-01-14 12:58:44.009117 (Thread-1): SQL status: INSERT 0 1 in 0.05 seconds
2022-01-14 12:58:44.010930 (Thread-1): On model.sakila_dbt_project.dim_staff: COMMIT
2022-01-14 12:58:44.011185 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-14 12:58:44.011388 (Thread-1): On model.sakila_dbt_project.dim_staff: COMMIT
2022-01-14 12:58:44.066609 (Thread-1): SQL status: COMMIT in 0.05 seconds
2022-01-14 12:58:44.070029 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-14 12:58:44.070305 (Thread-1): On model.sakila_dbt_project.dim_staff: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_staff"} */
drop table if exists "sakila_wh"."stg_dwh"."dim_staff__dbt_backup" cascade
2022-01-14 12:58:44.130122 (Thread-1): SQL status: DROP TABLE in 0.06 seconds
2022-01-14 12:58:44.132287 (Thread-1): finished collecting timing info
2022-01-14 12:58:44.132644 (Thread-1): On model.sakila_dbt_project.dim_staff: Close
2022-01-14 12:58:44.133413 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2d6dc256-0dfd-4627-9d51-9818b334abaf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108736a90>]}
2022-01-14 12:58:44.133897 (Thread-1): 18:28:44 | 4 of 8 OK created table model stg_dwh.dim_staff...................... [SELECT 2 in 0.72s]
2022-01-14 12:58:44.134167 (Thread-1): Finished running node model.sakila_dbt_project.dim_staff
2022-01-14 12:58:44.134412 (Thread-1): Began running node model.sakila_dbt_project.hello_world
2022-01-14 12:58:44.134886 (Thread-1): 18:28:44 | 5 of 8 START view model stg.hello_world.............................. [RUN]
2022-01-14 12:58:44.135286 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-14 12:58:44.135491 (Thread-1): Compiling model.sakila_dbt_project.hello_world
2022-01-14 12:58:44.137365 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.hello_world"
2022-01-14 12:58:44.138024 (Thread-1): finished collecting timing info
2022-01-14 12:58:44.158066 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.hello_world"
2022-01-14 12:58:44.158790 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-14 12:58:44.158982 (Thread-1): On model.sakila_dbt_project.hello_world: BEGIN
2022-01-14 12:58:44.159161 (Thread-1): Opening a new connection, currently in state closed
2022-01-14 12:58:44.494189 (Thread-1): SQL status: BEGIN in 0.34 seconds
2022-01-14 12:58:44.494606 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-14 12:58:44.494871 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */

  create view "sakila_wh"."stg"."hello_world__dbt_tmp" as (
    select
	customer.customer_id::int,
	customer.store_id::int,
	customer.first_name,
	customer.last_name,
	concat(customer.first_name,' ',customer.last_name) as full_name,
	substring(email from POSITION('@' in email)+1 for char_length(email)-POSITION('@' in email)) as domain,
	customer.email,
	customer.active::int,
	customer.address_id::int,
	address.address,
	city.city_id::int,
	city.city,
	(case when customer.active = 0 then 'no' else 'yes' end)::varchar(100) as "active_desc",
	customer.create_date::timestamp,
	customer.last_update::timestamp
from
	stg.customer as customer

	left join stg.address on 1=1
	and customer.address_id =address.address_id

	left join stg.city on 1=1
	and address.city_id = city.city_id
  );

2022-01-14 12:58:44.556892 (Thread-1): SQL status: CREATE VIEW in 0.06 seconds
2022-01-14 12:58:44.561999 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-14 12:58:44.562200 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
alter table "sakila_wh"."stg"."hello_world" rename to "hello_world__dbt_backup"
2022-01-14 12:58:44.617344 (Thread-1): SQL status: ALTER TABLE in 0.05 seconds
2022-01-14 12:58:44.621269 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-14 12:58:44.621514 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
alter table "sakila_wh"."stg"."hello_world__dbt_tmp" rename to "hello_world"
2022-01-14 12:58:44.676650 (Thread-1): SQL status: ALTER TABLE in 0.05 seconds
2022-01-14 12:58:44.678480 (Thread-1): On model.sakila_dbt_project.hello_world: COMMIT
2022-01-14 12:58:44.678716 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-14 12:58:44.678916 (Thread-1): On model.sakila_dbt_project.hello_world: COMMIT
2022-01-14 12:58:44.733955 (Thread-1): SQL status: COMMIT in 0.05 seconds
2022-01-14 12:58:44.736688 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-14 12:58:44.736943 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
drop view if exists "sakila_wh"."stg"."hello_world__dbt_backup" cascade
2022-01-14 12:58:44.792977 (Thread-1): SQL status: DROP VIEW in 0.06 seconds
2022-01-14 12:58:44.794928 (Thread-1): finished collecting timing info
2022-01-14 12:58:44.795246 (Thread-1): On model.sakila_dbt_project.hello_world: Close
2022-01-14 12:58:44.795819 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2d6dc256-0dfd-4627-9d51-9818b334abaf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1089bdd00>]}
2022-01-14 12:58:44.796272 (Thread-1): 18:28:44 | 5 of 8 OK created view model stg.hello_world......................... [CREATE VIEW in 0.66s]
2022-01-14 12:58:44.796540 (Thread-1): Finished running node model.sakila_dbt_project.hello_world
2022-01-14 12:58:44.796807 (Thread-1): Began running node model.sakila_dbt_project.my_first_dbt_model
2022-01-14 12:58:44.797240 (Thread-1): 18:28:44 | 6 of 8 START table model stg.my_first_dbt_model...................... [RUN]
2022-01-14 12:58:44.797684 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-14 12:58:44.797905 (Thread-1): Compiling model.sakila_dbt_project.my_first_dbt_model
2022-01-14 12:58:44.800622 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.my_first_dbt_model"
2022-01-14 12:58:44.801241 (Thread-1): finished collecting timing info
2022-01-14 12:58:44.804620 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.my_first_dbt_model"
2022-01-14 12:58:44.805250 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-14 12:58:44.805441 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: BEGIN
2022-01-14 12:58:44.805616 (Thread-1): Opening a new connection, currently in state closed
2022-01-14 12:58:45.394709 (Thread-1): SQL status: BEGIN in 0.59 seconds
2022-01-14 12:58:45.394985 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-14 12:58:45.395152 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */


  create  table "sakila_wh"."stg"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-14 12:58:45.454008 (Thread-1): SQL status: SELECT 2 in 0.06 seconds
2022-01-14 12:58:45.457689 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-14 12:58:45.457941 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
alter table "sakila_wh"."stg"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2022-01-14 12:58:45.512859 (Thread-1): SQL status: ALTER TABLE in 0.05 seconds
2022-01-14 12:58:45.516434 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-14 12:58:45.516695 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
alter table "sakila_wh"."stg"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-14 12:58:45.573674 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-14 12:58:45.575731 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: COMMIT
2022-01-14 12:58:45.575966 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-14 12:58:45.576166 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: COMMIT
2022-01-14 12:58:45.633488 (Thread-1): SQL status: COMMIT in 0.06 seconds
2022-01-14 12:58:45.636484 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-14 12:58:45.636739 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
drop table if exists "sakila_wh"."stg"."my_first_dbt_model__dbt_backup" cascade
2022-01-14 12:58:45.712395 (Thread-1): SQL status: DROP TABLE in 0.08 seconds
2022-01-14 12:58:45.714442 (Thread-1): finished collecting timing info
2022-01-14 12:58:45.714762 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: Close
2022-01-14 12:58:45.715326 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2d6dc256-0dfd-4627-9d51-9818b334abaf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1087bd5e0>]}
2022-01-14 12:58:45.715773 (Thread-1): 18:28:45 | 6 of 8 OK created table model stg.my_first_dbt_model................. [SELECT 2 in 0.92s]
2022-01-14 12:58:45.716040 (Thread-1): Finished running node model.sakila_dbt_project.my_first_dbt_model
2022-01-14 12:58:45.716297 (Thread-1): Began running node model.sakila_dbt_project.dim_store
2022-01-14 12:58:45.716746 (Thread-1): 18:28:45 | 7 of 8 START table model stg_dwh.dim_store........................... [RUN]
2022-01-14 12:58:45.717311 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_store".
2022-01-14 12:58:45.717561 (Thread-1): Compiling model.sakila_dbt_project.dim_store
2022-01-14 12:58:45.722748 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_store"
2022-01-14 12:58:45.723397 (Thread-1): finished collecting timing info
2022-01-14 12:58:45.727752 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_store"
2022-01-14 12:58:45.728369 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_store".
2022-01-14 12:58:45.728554 (Thread-1): On model.sakila_dbt_project.dim_store: BEGIN
2022-01-14 12:58:45.728726 (Thread-1): Opening a new connection, currently in state closed
2022-01-14 12:58:46.064204 (Thread-1): SQL status: BEGIN in 0.34 seconds
2022-01-14 12:58:46.064703 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_store".
2022-01-14 12:58:46.064960 (Thread-1): On model.sakila_dbt_project.dim_store: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_store"} */


  create  table "sakila_wh"."stg_dwh"."dim_store__dbt_tmp"
  as (
    

with stg_store as (
		select
    *,
    '2022-01-14 12:58:36'::timestamp as dbt_time
     from "sakila_wh"."stg"."store"
),

staff as (
 select * from "sakila_wh"."stg_dwh"."dim_staff"
),

address as (
  select * from "sakila_wh"."stg"."address"
),

city as (
  select * from "sakila_wh"."stg"."city"
),

country as (
  select * from "sakila_wh"."stg"."country"
),
stg_store_1 as (-- add staff
		select
		stg_store.*,
		staff.first_name as staff_first_name,
		staff.last_name as staff_last_name
		from
		stg_store
		left join staff  on 1=1
		and stg_store.manager_staff_id = staff.staff_id
),
stg_store_2 as (-- add adress
		select
		stg_store_1.*,
		address.address,
		city.city_id,
		city.city,
		country.country_id,
		country.country
		from
		stg_store_1

		left join address on 1=1
		and stg_store_1.address_id =address.address_id

		left join city on 1=1
		and address.city_id = city.city_id

		left join country on  1=1
		and city.country_id = country.country_id
)

select
  store_id,
  manager_staff_id,
  staff_first_name,
  staff_last_name,
  address_id,
  address,
  city_id,
  city,
  country_id,
  country,
  last_update,
  dbt_time
from stg_store_2
  );
2022-01-14 12:58:46.130403 (Thread-1): SQL status: SELECT 2 in 0.07 seconds
2022-01-14 12:58:46.161082 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_store".
2022-01-14 12:58:46.161339 (Thread-1): On model.sakila_dbt_project.dim_store: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_store"} */
alter table "sakila_wh"."stg_dwh"."dim_store" rename to "dim_store__dbt_backup"
2022-01-14 12:58:46.216200 (Thread-1): SQL status: ALTER TABLE in 0.05 seconds
2022-01-14 12:58:46.219872 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_store".
2022-01-14 12:58:46.220120 (Thread-1): On model.sakila_dbt_project.dim_store: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_store"} */
alter table "sakila_wh"."stg_dwh"."dim_store__dbt_tmp" rename to "dim_store"
2022-01-14 12:58:46.276905 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-14 12:58:46.279649 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 12:58:46.280046 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_store".
2022-01-14 12:58:46.280256 (Thread-1): On model.sakila_dbt_project.dim_store: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_store"} */

        insert into "sakila_wh"."stg_dwh"."dim_store"(store_id) VALUES (-1)
      
2022-01-14 12:58:46.339140 (Thread-1): SQL status: INSERT 0 1 in 0.06 seconds
2022-01-14 12:58:46.340920 (Thread-1): On model.sakila_dbt_project.dim_store: COMMIT
2022-01-14 12:58:46.341160 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_store".
2022-01-14 12:58:46.341353 (Thread-1): On model.sakila_dbt_project.dim_store: COMMIT
2022-01-14 12:58:46.398878 (Thread-1): SQL status: COMMIT in 0.06 seconds
2022-01-14 12:58:46.402213 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_store".
2022-01-14 12:58:46.402445 (Thread-1): On model.sakila_dbt_project.dim_store: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_store"} */
drop table if exists "sakila_wh"."stg_dwh"."dim_store__dbt_backup" cascade
2022-01-14 12:58:46.459739 (Thread-1): SQL status: DROP TABLE in 0.06 seconds
2022-01-14 12:58:46.461810 (Thread-1): finished collecting timing info
2022-01-14 12:58:46.462156 (Thread-1): On model.sakila_dbt_project.dim_store: Close
2022-01-14 12:58:46.462827 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2d6dc256-0dfd-4627-9d51-9818b334abaf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1085ae850>]}
2022-01-14 12:58:46.463238 (Thread-1): 18:28:46 | 7 of 8 OK created table model stg_dwh.dim_store...................... [SELECT 2 in 0.75s]
2022-01-14 12:58:46.463480 (Thread-1): Finished running node model.sakila_dbt_project.dim_store
2022-01-14 12:58:46.463695 (Thread-1): Began running node model.sakila_dbt_project.my_second_dbt_model
2022-01-14 12:58:46.463971 (Thread-1): 18:28:46 | 8 of 8 START view model stg.my_second_dbt_model...................... [RUN]
2022-01-14 12:58:46.464408 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-14 12:58:46.464608 (Thread-1): Compiling model.sakila_dbt_project.my_second_dbt_model
2022-01-14 12:58:46.467200 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.my_second_dbt_model"
2022-01-14 12:58:46.467891 (Thread-1): finished collecting timing info
2022-01-14 12:58:46.471327 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.my_second_dbt_model"
2022-01-14 12:58:46.471969 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-14 12:58:46.472152 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: BEGIN
2022-01-14 12:58:46.472320 (Thread-1): Opening a new connection, currently in state closed
2022-01-14 12:58:46.809045 (Thread-1): SQL status: BEGIN in 0.34 seconds
2022-01-14 12:58:46.809731 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-14 12:58:46.810029 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */

  create view "sakila_wh"."stg"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "sakila_wh"."stg"."my_first_dbt_model"
where id = 1
  );

2022-01-14 12:58:46.869143 (Thread-1): SQL status: CREATE VIEW in 0.06 seconds
2022-01-14 12:58:46.872934 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-14 12:58:46.873206 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
alter table "sakila_wh"."stg"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-14 12:58:46.930239 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-14 12:58:46.932342 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: COMMIT
2022-01-14 12:58:46.932650 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-14 12:58:46.932898 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: COMMIT
2022-01-14 12:58:46.988910 (Thread-1): SQL status: COMMIT in 0.06 seconds
2022-01-14 12:58:46.991687 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-14 12:58:46.991930 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
drop view if exists "sakila_wh"."stg"."my_second_dbt_model__dbt_backup" cascade
2022-01-14 12:58:47.046808 (Thread-1): SQL status: DROP VIEW in 0.05 seconds
2022-01-14 12:58:47.048984 (Thread-1): finished collecting timing info
2022-01-14 12:58:47.049339 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: Close
2022-01-14 12:58:47.050138 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2d6dc256-0dfd-4627-9d51-9818b334abaf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1085887f0>]}
2022-01-14 12:58:47.050588 (Thread-1): 18:28:47 | 8 of 8 OK created view model stg.my_second_dbt_model................. [CREATE VIEW in 0.59s]
2022-01-14 12:58:47.050882 (Thread-1): Finished running node model.sakila_dbt_project.my_second_dbt_model
2022-01-14 12:58:47.051986 (MainThread): Acquiring new postgres connection "master".
2022-01-14 12:58:47.052215 (MainThread): Using postgres connection "master".
2022-01-14 12:58:47.052382 (MainThread): On master: BEGIN
2022-01-14 12:58:47.052601 (MainThread): Opening a new connection, currently in state closed
2022-01-14 12:58:47.388412 (MainThread): SQL status: BEGIN in 0.34 seconds
2022-01-14 12:58:47.388735 (MainThread): On master: COMMIT
2022-01-14 12:58:47.388938 (MainThread): Using postgres connection "master".
2022-01-14 12:58:47.389125 (MainThread): On master: COMMIT
2022-01-14 12:58:47.445066 (MainThread): SQL status: COMMIT in 0.06 seconds
2022-01-14 12:58:47.445696 (MainThread): On master: Close
2022-01-14 12:58:47.446400 (MainThread): 18:28:47 | 
2022-01-14 12:58:47.446727 (MainThread): 18:28:47 | Finished running 2 incremental models, 4 table models, 2 view models in 9.54s.
2022-01-14 12:58:47.447014 (MainThread): Connection 'master' was properly closed.
2022-01-14 12:58:47.447243 (MainThread): Connection 'model.sakila_dbt_project.my_second_dbt_model' was properly closed.
2022-01-14 12:58:47.458975 (MainThread): 
2022-01-14 12:58:47.459234 (MainThread): Completed successfully
2022-01-14 12:58:47.459447 (MainThread): 
Done. PASS=8 WARN=0 ERROR=0 SKIP=0 TOTAL=8
2022-01-14 12:58:47.459704 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1085fa1c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1085fae50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1089c01c0>]}
2022-01-14 12:58:47.459965 (MainThread): Flushing usage events
2022-01-14 13:02:35.249827 (MainThread): Running with dbt=0.21.1
2022-01-14 13:02:35.333304 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2022-01-14 13:02:35.334906 (MainThread): Tracking: tracking
2022-01-14 13:02:35.353877 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105776700>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1057798e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105779b80>]}
2022-01-14 13:02:35.375434 (MainThread): Partial parsing not enabled
2022-01-14 13:02:35.419536 (MainThread): Parsing macros/catalog.sql
2022-01-14 13:02:35.422920 (MainThread): Parsing macros/relations.sql
2022-01-14 13:02:35.424172 (MainThread): Parsing macros/adapters.sql
2022-01-14 13:02:35.445217 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2022-01-14 13:02:35.446871 (MainThread): Parsing macros/core.sql
2022-01-14 13:02:35.450371 (MainThread): Parsing macros/materializations/test.sql
2022-01-14 13:02:35.456719 (MainThread): Parsing macros/materializations/helpers.sql
2022-01-14 13:02:35.466371 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2022-01-14 13:02:35.468004 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2022-01-14 13:02:35.484374 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2022-01-14 13:02:35.514549 (MainThread): Parsing macros/materializations/seed/seed.sql
2022-01-14 13:02:35.535918 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2022-01-14 13:02:35.537518 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2022-01-14 13:02:35.547238 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2022-01-14 13:02:35.565482 (MainThread): Parsing macros/materializations/common/merge.sql
2022-01-14 13:02:35.578133 (MainThread): Parsing macros/materializations/table/table.sql
2022-01-14 13:02:35.585746 (MainThread): Parsing macros/materializations/view/view.sql
2022-01-14 13:02:35.592182 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2022-01-14 13:02:35.596046 (MainThread): Parsing macros/etc/get_custom_alias.sql
2022-01-14 13:02:35.597426 (MainThread): Parsing macros/etc/query.sql
2022-01-14 13:02:35.598313 (MainThread): Parsing macros/etc/is_incremental.sql
2022-01-14 13:02:35.599677 (MainThread): Parsing macros/etc/datetime.sql
2022-01-14 13:02:35.607452 (MainThread): Parsing macros/etc/where_subquery.sql
2022-01-14 13:02:35.609089 (MainThread): Parsing macros/etc/get_custom_schema.sql
2022-01-14 13:02:35.611317 (MainThread): Parsing macros/etc/get_custom_database.sql
2022-01-14 13:02:35.612913 (MainThread): Parsing macros/adapters/common.sql
2022-01-14 13:02:35.664662 (MainThread): Parsing macros/schema_tests/relationships.sql
2022-01-14 13:02:35.666227 (MainThread): Parsing macros/schema_tests/not_null.sql
2022-01-14 13:02:35.667320 (MainThread): Parsing macros/schema_tests/unique.sql
2022-01-14 13:02:35.668597 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2022-01-14 13:02:35.670601 (MainThread): Parsing macros/cross_db_utils/except.sql
2022-01-14 13:02:35.671623 (MainThread): Parsing macros/cross_db_utils/replace.sql
2022-01-14 13:02:35.672768 (MainThread): Parsing macros/cross_db_utils/concat.sql
2022-01-14 13:02:35.673685 (MainThread): Parsing macros/cross_db_utils/datatypes.sql
2022-01-14 13:02:35.679641 (MainThread): Parsing macros/cross_db_utils/_is_relation.sql
2022-01-14 13:02:35.680721 (MainThread): Parsing macros/cross_db_utils/length.sql
2022-01-14 13:02:35.681922 (MainThread): Parsing macros/cross_db_utils/dateadd.sql
2022-01-14 13:02:35.684637 (MainThread): Parsing macros/cross_db_utils/intersect.sql
2022-01-14 13:02:35.685664 (MainThread): Parsing macros/cross_db_utils/right.sql
2022-01-14 13:02:35.687721 (MainThread): Parsing macros/cross_db_utils/datediff.sql
2022-01-14 13:02:35.697311 (MainThread): Parsing macros/cross_db_utils/safe_cast.sql
2022-01-14 13:02:35.699120 (MainThread): Parsing macros/cross_db_utils/hash.sql
2022-01-14 13:02:35.700417 (MainThread): Parsing macros/cross_db_utils/cast_bool_to_text.sql
2022-01-14 13:02:35.701708 (MainThread): Parsing macros/cross_db_utils/identifier.sql
2022-01-14 13:02:35.703197 (MainThread): Parsing macros/cross_db_utils/position.sql
2022-01-14 13:02:35.704601 (MainThread): Parsing macros/cross_db_utils/literal.sql
2022-01-14 13:02:35.705467 (MainThread): Parsing macros/cross_db_utils/current_timestamp.sql
2022-01-14 13:02:35.708649 (MainThread): Parsing macros/cross_db_utils/width_bucket.sql
2022-01-14 13:02:35.713616 (MainThread): Parsing macros/cross_db_utils/last_day.sql
2022-01-14 13:02:35.716861 (MainThread): Parsing macros/cross_db_utils/split_part.sql
2022-01-14 13:02:35.718858 (MainThread): Parsing macros/cross_db_utils/date_trunc.sql
2022-01-14 13:02:35.720447 (MainThread): Parsing macros/cross_db_utils/_is_ephemeral.sql
2022-01-14 13:02:35.722243 (MainThread): Parsing macros/materializations/insert_by_period_materialization.sql
2022-01-14 13:02:35.745224 (MainThread): Parsing macros/web/get_url_host.sql
2022-01-14 13:02:35.747031 (MainThread): Parsing macros/web/get_url_path.sql
2022-01-14 13:02:35.749406 (MainThread): Parsing macros/web/get_url_parameter.sql
2022-01-14 13:02:35.750848 (MainThread): Parsing macros/jinja_helpers/pretty_log_format.sql
2022-01-14 13:02:35.752065 (MainThread): Parsing macros/jinja_helpers/pretty_time.sql
2022-01-14 13:02:35.753173 (MainThread): Parsing macros/jinja_helpers/log_info.sql
2022-01-14 13:02:35.754194 (MainThread): Parsing macros/jinja_helpers/slugify.sql
2022-01-14 13:02:35.755332 (MainThread): Parsing macros/schema_tests/fewer_rows_than.sql
2022-01-14 13:02:35.756887 (MainThread): Parsing macros/schema_tests/equal_rowcount.sql
2022-01-14 13:02:35.758430 (MainThread): Parsing macros/schema_tests/relationships_where.sql
2022-01-14 13:02:35.760564 (MainThread): Parsing macros/schema_tests/recency.sql
2022-01-14 13:02:35.762333 (MainThread): Parsing macros/schema_tests/not_constant.sql
2022-01-14 13:02:35.763493 (MainThread): Parsing macros/schema_tests/accepted_range.sql
2022-01-14 13:02:35.765801 (MainThread): Parsing macros/schema_tests/not_accepted_values.sql
2022-01-14 13:02:35.767737 (MainThread): Parsing macros/schema_tests/test_unique_where.sql
2022-01-14 13:02:35.769063 (MainThread): Parsing macros/schema_tests/at_least_one.sql
2022-01-14 13:02:35.770218 (MainThread): Parsing macros/schema_tests/unique_combination_of_columns.sql
2022-01-14 13:02:35.772794 (MainThread): Parsing macros/schema_tests/cardinality_equality.sql
2022-01-14 13:02:35.774613 (MainThread): Parsing macros/schema_tests/expression_is_true.sql
2022-01-14 13:02:35.776272 (MainThread): Parsing macros/schema_tests/sequential_values.sql
2022-01-14 13:02:35.779350 (MainThread): Parsing macros/schema_tests/test_not_null_where.sql
2022-01-14 13:02:35.780678 (MainThread): Parsing macros/schema_tests/equality.sql
2022-01-14 13:02:35.783827 (MainThread): Parsing macros/schema_tests/mutually_exclusive_ranges.sql
2022-01-14 13:02:35.792179 (MainThread): Parsing macros/sql/date_spine.sql
2022-01-14 13:02:35.796890 (MainThread): Parsing macros/sql/nullcheck_table.sql
2022-01-14 13:02:35.798450 (MainThread): Parsing macros/sql/get_relations_by_pattern.sql
2022-01-14 13:02:35.801602 (MainThread): Parsing macros/sql/generate_series.sql
2022-01-14 13:02:35.829040 (MainThread): Parsing macros/sql/get_relations_by_prefix.sql
2022-01-14 13:02:35.833402 (MainThread): Parsing macros/sql/get_tables_by_prefix_sql.sql
2022-01-14 13:02:35.835547 (MainThread): Parsing macros/sql/star.sql
2022-01-14 13:02:35.839725 (MainThread): Parsing macros/sql/unpivot.sql
2022-01-14 13:02:35.849819 (MainThread): Parsing macros/sql/union.sql
2022-01-14 13:02:35.859343 (MainThread): Parsing macros/sql/groupby.sql
2022-01-14 13:02:35.860883 (MainThread): Parsing macros/sql/surrogate_key.sql
2022-01-14 13:02:35.864795 (MainThread): Parsing macros/sql/safe_add.sql
2022-01-14 13:02:35.866602 (MainThread): Parsing macros/sql/nullcheck.sql
2022-01-14 13:02:35.868437 (MainThread): Parsing macros/sql/get_tables_by_pattern_sql.sql
2022-01-14 13:02:35.875452 (MainThread): Parsing macros/sql/get_column_values.sql
2022-01-14 13:02:35.881079 (MainThread): Parsing macros/sql/pivot.sql
2022-01-14 13:02:35.885381 (MainThread): Parsing macros/sql/get_query_results_as_dict.sql
2022-01-14 13:02:35.887758 (MainThread): Parsing macros/sql/haversine_distance.sql
2022-01-14 13:02:36.185300 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-14 13:02:36.193166 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 13:02:36.196985 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-14 13:02:36.199668 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 13:02:36.200775 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-14 13:02:36.202695 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 13:02:36.203760 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-14 13:02:36.207426 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 13:02:36.208976 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-14 13:02:36.216868 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 13:02:36.218555 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_film".
2022-01-14 13:02:36.223054 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 13:02:36.224761 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-14 13:02:36.226568 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 13:02:36.227674 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_store".
2022-01-14 13:02:36.231983 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 13:02:36.264636 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 13:02:36.273530 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 13:02:36.275165 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 13:02:36.276871 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 13:02:36.279091 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 13:02:36.280829 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 13:02:36.297692 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 13:02:36.299372 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 13:02:36.301133 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 13:02:36.302726 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 13:02:36.304300 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 13:02:36.305897 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 13:02:36.307709 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 13:02:36.309307 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 13:02:36.310935 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 13:02:36.312907 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 13:02:36.336228 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'fea7e4fa-fe49-4b3d-b845-f50521259504', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059ea0d0>]}
2022-01-14 13:02:36.345250 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-01-14 13:02:36.345890 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'fea7e4fa-fe49-4b3d-b845-f50521259504', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1057e2d30>]}
2022-01-14 13:02:36.346137 (MainThread): Found 8 models, 16 tests, 0 snapshots, 0 analyses, 347 macros, 0 operations, 0 seed files, 12 sources, 0 exposures
2022-01-14 13:02:36.347812 (MainThread): 
2022-01-14 13:02:36.348119 (MainThread): Acquiring new postgres connection "master".
2022-01-14 13:02:36.349049 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_sakila_wh".
2022-01-14 13:02:36.358129 (ThreadPoolExecutor-0_0): Using postgres connection "list_sakila_wh".
2022-01-14 13:02:36.358327 (ThreadPoolExecutor-0_0): On list_sakila_wh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh"} */

    select distinct nspname from pg_namespace
  
2022-01-14 13:02:36.358486 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2022-01-14 13:02:36.746786 (ThreadPoolExecutor-0_0): SQL status: SELECT 10 in 0.39 seconds
2022-01-14 13:02:36.748404 (ThreadPoolExecutor-0_0): On list_sakila_wh: Close
2022-01-14 13:02:36.749128 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "create_sakila_wh_stg_dwh".
2022-01-14 13:02:36.749449 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "create_sakila_wh_stg_dwh".
2022-01-14 13:02:36.749674 (ThreadPoolExecutor-0_0): Creating schema ""sakila_wh"."stg_dwh""
2022-01-14 13:02:36.755570 (ThreadPoolExecutor-0_0): Using postgres connection "create_sakila_wh_stg_dwh".
2022-01-14 13:02:36.755777 (ThreadPoolExecutor-0_0): On create_sakila_wh_stg_dwh: BEGIN
2022-01-14 13:02:36.755953 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2022-01-14 13:02:37.090570 (ThreadPoolExecutor-0_0): SQL status: BEGIN in 0.33 seconds
2022-01-14 13:02:37.091080 (ThreadPoolExecutor-0_0): Using postgres connection "create_sakila_wh_stg_dwh".
2022-01-14 13:02:37.091341 (ThreadPoolExecutor-0_0): On create_sakila_wh_stg_dwh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "create_sakila_wh_stg_dwh"} */
create schema if not exists "stg_dwh"
2022-01-14 13:02:37.148437 (ThreadPoolExecutor-0_0): SQL status: CREATE SCHEMA in 0.06 seconds
2022-01-14 13:02:37.149782 (ThreadPoolExecutor-0_0): On create_sakila_wh_stg_dwh: COMMIT
2022-01-14 13:02:37.150043 (ThreadPoolExecutor-0_0): Using postgres connection "create_sakila_wh_stg_dwh".
2022-01-14 13:02:37.150247 (ThreadPoolExecutor-0_0): On create_sakila_wh_stg_dwh: COMMIT
2022-01-14 13:02:37.205831 (ThreadPoolExecutor-0_0): SQL status: COMMIT in 0.06 seconds
2022-01-14 13:02:37.206477 (ThreadPoolExecutor-0_0): On create_sakila_wh_stg_dwh: Close
2022-01-14 13:02:37.208680 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_stg_dwh".
2022-01-14 13:02:37.215689 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_stg_dwh".
2022-01-14 13:02:37.215925 (ThreadPoolExecutor-1_0): On list_sakila_wh_stg_dwh: BEGIN
2022-01-14 13:02:37.216112 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2022-01-14 13:02:37.551325 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.34 seconds
2022-01-14 13:02:37.551905 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_stg_dwh".
2022-01-14 13:02:37.552266 (ThreadPoolExecutor-1_0): On list_sakila_wh_stg_dwh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_stg_dwh"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'stg_dwh'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'stg_dwh'
  
2022-01-14 13:02:37.613436 (ThreadPoolExecutor-1_0): SQL status: SELECT 0 in 0.06 seconds
2022-01-14 13:02:37.615118 (ThreadPoolExecutor-1_0): On list_sakila_wh_stg_dwh: ROLLBACK
2022-01-14 13:02:37.669268 (ThreadPoolExecutor-1_0): On list_sakila_wh_stg_dwh: Close
2022-01-14 13:02:37.675353 (MainThread): Using postgres connection "master".
2022-01-14 13:02:37.675555 (MainThread): On master: BEGIN
2022-01-14 13:02:37.675731 (MainThread): Opening a new connection, currently in state init
2022-01-14 13:02:38.013116 (MainThread): SQL status: BEGIN in 0.34 seconds
2022-01-14 13:02:38.013534 (MainThread): Using postgres connection "master".
2022-01-14 13:02:38.013811 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-14 13:02:38.086955 (MainThread): SQL status: SELECT 47 in 0.07 seconds
2022-01-14 13:02:38.089322 (MainThread): On master: ROLLBACK
2022-01-14 13:02:38.143117 (MainThread): Using postgres connection "master".
2022-01-14 13:02:38.143358 (MainThread): On master: BEGIN
2022-01-14 13:02:38.254317 (MainThread): SQL status: BEGIN in 0.11 seconds
2022-01-14 13:02:38.254920 (MainThread): On master: COMMIT
2022-01-14 13:02:38.255284 (MainThread): Using postgres connection "master".
2022-01-14 13:02:38.255528 (MainThread): On master: COMMIT
2022-01-14 13:02:38.310683 (MainThread): SQL status: COMMIT in 0.05 seconds
2022-01-14 13:02:38.311310 (MainThread): On master: Close
2022-01-14 13:02:38.312025 (MainThread): 18:32:38 | Concurrency: 1 threads (target='dev')
2022-01-14 13:02:38.312369 (MainThread): 18:32:38 | 
2022-01-14 13:02:38.315892 (Thread-1): Began running node model.sakila_dbt_project.dim_customer
2022-01-14 13:02:38.316301 (Thread-1): 18:32:38 | 1 of 8 START incremental model stg_dwh.dim_customer.................. [RUN]
2022-01-14 13:02:38.316762 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-14 13:02:38.317016 (Thread-1): Compiling model.sakila_dbt_project.dim_customer
2022-01-14 13:02:38.323432 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_customer"
2022-01-14 13:02:38.324120 (Thread-1): finished collecting timing info
2022-01-14 13:02:38.370500 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_customer"
2022-01-14 13:02:38.371217 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-14 13:02:38.371390 (Thread-1): On model.sakila_dbt_project.dim_customer: BEGIN
2022-01-14 13:02:38.371546 (Thread-1): Opening a new connection, currently in state closed
2022-01-14 13:02:38.706544 (Thread-1): SQL status: BEGIN in 0.33 seconds
2022-01-14 13:02:38.706960 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-14 13:02:38.707222 (Thread-1): On model.sakila_dbt_project.dim_customer: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_customer"} */

      

  create  table "sakila_wh"."stg_dwh"."dim_customer"
  as (
    

with customer_base as (

select
 *,
	concat(customer.first_name,' ',customer.last_name) as full_name,
	substring(email from POSITION('@' in email)+1 for char_length(email)-POSITION('@' in email)) as domain,
	customer.active::int as active_int,
	(case when customer.active = 0 then 'no' else 'yes' end)::varchar(100) as "active_desc",
  '2022-01-14 13:02:35'::timestamp as dbt_time
from
	"sakila_wh"."stg"."customer" as customer),

  address as (
    select * from "sakila_wh"."stg"."address"
  ),

  city as (
    select * from "sakila_wh"."stg"."city"
  ),

  country as (
    select * from "sakila_wh"."stg"."country"
  )

  select
  customer_base.customer_id,
  customer_base.store_id,
  customer_base.first_name,
  customer_base.last_name,
  customer_base.full_name,
  customer_base.domain,
  customer_base.email,
  customer_base.active_int as active,
  customer_base.active_desc,

  address.address_id,
  address.address,
  city.city_id,
  city.city,
  country.country_id,
  country.country,

  customer_base.create_date,
  customer_base.last_update,
  customer_base.dbt_time

  from
  customer_base

	left join address on 1=1
	and customer_base.address_id =address.address_id

	left join city on 1=1
	and address.city_id = city.city_id

  left join country on 1=1
  and country.country_id = city.country_id

  where 1=1

  
  );
  
2022-01-14 13:02:38.786239 (Thread-1): SQL status: SELECT 599 in 0.08 seconds
2022-01-14 13:02:38.799950 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 13:02:38.800343 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-14 13:02:38.800526 (Thread-1): On model.sakila_dbt_project.dim_customer: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_customer"} */

        insert into "sakila_wh"."stg_dwh"."dim_customer"(customer_id) VALUES (-1)
      
2022-01-14 13:02:39.577392 (Thread-1): SQL status: INSERT 0 1 in 0.78 seconds
2022-01-14 13:02:39.578952 (Thread-1): On model.sakila_dbt_project.dim_customer: COMMIT
2022-01-14 13:02:39.579254 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_customer".
2022-01-14 13:02:39.579462 (Thread-1): On model.sakila_dbt_project.dim_customer: COMMIT
2022-01-14 13:02:41.160770 (Thread-1): SQL status: COMMIT in 1.58 seconds
2022-01-14 13:02:41.161668 (Thread-1): finished collecting timing info
2022-01-14 13:02:41.161944 (Thread-1): On model.sakila_dbt_project.dim_customer: Close
2022-01-14 13:02:41.162531 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fea7e4fa-fe49-4b3d-b845-f50521259504', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105abdb20>]}
2022-01-14 13:02:41.163100 (Thread-1): 18:32:41 | 1 of 8 OK created incremental model stg_dwh.dim_customer............. [SELECT 599 in 2.85s]
2022-01-14 13:02:41.163407 (Thread-1): Finished running node model.sakila_dbt_project.dim_customer
2022-01-14 13:02:41.163677 (Thread-1): Began running node model.sakila_dbt_project.dim_date
2022-01-14 13:02:41.164116 (Thread-1): 18:32:41 | 2 of 8 START table model stg_dwh.dim_date............................ [RUN]
2022-01-14 13:02:41.164549 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-14 13:02:41.164784 (Thread-1): Compiling model.sakila_dbt_project.dim_date
2022-01-14 13:02:41.166762 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_date"
2022-01-14 13:02:41.167373 (Thread-1): finished collecting timing info
2022-01-14 13:02:41.183317 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_date"
2022-01-14 13:02:41.184011 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-14 13:02:41.184188 (Thread-1): On model.sakila_dbt_project.dim_date: BEGIN
2022-01-14 13:02:41.184353 (Thread-1): Opening a new connection, currently in state closed
2022-01-14 13:02:41.518454 (Thread-1): SQL status: BEGIN in 0.33 seconds
2022-01-14 13:02:41.518899 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-14 13:02:41.519260 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */


  create  table "sakila_wh"."stg_dwh"."dim_date__dbt_tmp"
  as (
    with dates as (
SELECT
       TO_CHAR(datum, 'yyyymmdd')::INT AS date_dim_id,
       datum AS date_key,
       EXTRACT(EPOCH FROM datum) AS epoch,
       TO_CHAR(datum, 'TMDay') AS day_name,
       EXTRACT(ISODOW FROM datum) AS day_of_week,
       EXTRACT(DAY FROM datum) AS day_of_month,
       datum - DATE_TRUNC('quarter', datum)::DATE + 1 AS day_of_quarter,
       EXTRACT(DOY FROM datum) AS day_of_year,
       TO_CHAR(datum, 'W')::INT AS week_of_month,
       EXTRACT(WEEK FROM datum) AS week_of_year,
       EXTRACT(MONTH FROM datum) AS month_actual,
       TO_CHAR(datum, 'TMMonth') AS month_name,
       TO_CHAR(datum, 'Mon') AS month_name_abbreviated,
       EXTRACT(QUARTER FROM datum) AS quarter_actual,
       CASE
           WHEN EXTRACT(QUARTER FROM datum) = 1 THEN 'First'
           WHEN EXTRACT(QUARTER FROM datum) = 2 THEN 'Second'
           WHEN EXTRACT(QUARTER FROM datum) = 3 THEN 'Third'
           WHEN EXTRACT(QUARTER FROM datum) = 4 THEN 'Fourth'
           END AS quarter_name,
       EXTRACT(YEAR FROM datum) AS year_actual,
       datum + (1 - EXTRACT(ISODOW FROM datum))::INT AS first_day_of_week,
       datum + (7 - EXTRACT(ISODOW FROM datum))::INT AS last_day_of_week,
       datum + (1 - EXTRACT(DAY FROM datum))::INT AS first_day_of_month,
       (DATE_TRUNC('MONTH', datum) + INTERVAL '1 MONTH - 1 day')::DATE AS last_day_of_month,
       DATE_TRUNC('quarter', datum)::DATE AS first_day_of_quarter,
       (DATE_TRUNC('quarter', datum) + INTERVAL '3 MONTH - 1 day')::DATE AS last_day_of_quarter,
       TO_DATE(EXTRACT(YEAR FROM datum) || '-01-01', 'YYYY-MM-DD') AS first_day_of_year,
       TO_DATE(EXTRACT(YEAR FROM datum) || '-12-31', 'YYYY-MM-DD') AS last_day_of_year,
       TO_CHAR(datum, 'yyyymm') AS yyyymm,
       CASE
           WHEN EXTRACT(ISODOW FROM datum) IN (6, 7) THEN TRUE
           ELSE FALSE
           END AS weekend_indr
FROM (SELECT '2000-01-01'::DATE + SEQUENCE.DAY AS datum
      FROM GENERATE_SERIES(0, 29219) AS SEQUENCE (DAY)
      GROUP BY SEQUENCE.DAY) DQ
)
select
*
from
dates
where
date_key <= CURRENT_DATE
order by date_dim_id asc
  );
2022-01-14 13:02:42.408919 (Thread-1): SQL status: SELECT 8050 in 0.89 seconds
2022-01-14 13:02:42.417359 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-14 13:02:42.417586 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
alter table "sakila_wh"."stg_dwh"."dim_date__dbt_tmp" rename to "dim_date"
2022-01-14 13:02:42.472358 (Thread-1): SQL status: ALTER TABLE in 0.05 seconds
2022-01-14 13:02:42.474796 (Thread-1): On model.sakila_dbt_project.dim_date: COMMIT
2022-01-14 13:02:42.475133 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-14 13:02:42.475414 (Thread-1): On model.sakila_dbt_project.dim_date: COMMIT
2022-01-14 13:02:42.530278 (Thread-1): SQL status: COMMIT in 0.05 seconds
2022-01-14 13:02:42.536817 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-14 13:02:42.537035 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
drop table if exists "sakila_wh"."stg_dwh"."dim_date__dbt_backup" cascade
2022-01-14 13:02:42.593849 (Thread-1): SQL status: DROP TABLE in 0.06 seconds
2022-01-14 13:02:42.596047 (Thread-1): finished collecting timing info
2022-01-14 13:02:42.596407 (Thread-1): On model.sakila_dbt_project.dim_date: Close
2022-01-14 13:02:42.597202 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fea7e4fa-fe49-4b3d-b845-f50521259504', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105af8ac0>]}
2022-01-14 13:02:42.597673 (Thread-1): 18:32:42 | 2 of 8 OK created table model stg_dwh.dim_date....................... [SELECT 8050 in 1.43s]
2022-01-14 13:02:42.597958 (Thread-1): Finished running node model.sakila_dbt_project.dim_date
2022-01-14 13:02:42.598233 (Thread-1): Began running node model.sakila_dbt_project.dim_film
2022-01-14 13:02:42.598586 (Thread-1): 18:32:42 | 3 of 8 START incremental model stg_dwh.dim_film...................... [RUN]
2022-01-14 13:02:42.599083 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_film".
2022-01-14 13:02:42.599290 (Thread-1): Compiling model.sakila_dbt_project.dim_film
2022-01-14 13:02:42.605762 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_film"
2022-01-14 13:02:42.606373 (Thread-1): finished collecting timing info
2022-01-14 13:02:42.609441 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_film"
2022-01-14 13:02:42.610032 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_film".
2022-01-14 13:02:42.610215 (Thread-1): On model.sakila_dbt_project.dim_film: BEGIN
2022-01-14 13:02:42.610390 (Thread-1): Opening a new connection, currently in state closed
2022-01-14 13:02:42.942805 (Thread-1): SQL status: BEGIN in 0.33 seconds
2022-01-14 13:02:42.943411 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_film".
2022-01-14 13:02:42.943673 (Thread-1): On model.sakila_dbt_project.dim_film: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_film"} */

      

  create  table "sakila_wh"."stg_dwh"."dim_film"
  as (
    

with stg_film as (
	select
	*,
	(case
	when length<=75 then 'short'
	when (length>75 and length<=120) then 'medium'
	when length>120 then 'long'
	else 'na' end) as length_desc,
	COALESCE(original_language_id,0) as original_language_id_zero,
	case when POSITION('Trailers' in special_features::varchar)>0 then 1 else 0 end  as has_trailers,
	case when POSITION('Commentaries' in special_features::varchar)>0 then 1 else 0 end  as has_commentaries,
	case when POSITION('Deleted Scenes' in special_features::varchar)>0 then 1 else 0 end  as has_deleted_scenes,
	case when POSITION('Behind the Scenes' in special_features::varchar)>0 then 1 else 0 end  as has_behind_the_scenes,
	'2022-01-14 13:02:35'::timestamp as dbt_time
	from
	"sakila_wh"."stg"."film"
),

language as (
	select * from "sakila_wh"."stg"."language"
),

category as (
	select * from "sakila_wh"."stg"."category"
),

film_category as (
	select * from "sakila_wh"."stg"."film_category"
),

stg_film_1 as (
	select
	stg_film.*,
	language.name as lang_name
	from
	stg_film
	left join language on 1=1
	and stg_film.language_id = language.language_id
),

stg_film_2 as (
	select
		stg_film_1.*,
		category.category_id,
		category.name as category_desc
	from
	stg_film_1

	left join film_category on 1=1
	and stg_film_1.film_id = film_category.film_id

	left join category on 1=1
	and film_category.category_id  = category.category_id
)


select
  film_id,
  title,
  description,
  release_year,
  language_id,
  lang_name,
  original_language_id_zero as original_language_id,
  rental_duration,
  rental_rate,
  length,
  length_desc,
  replacement_cost,
  rating,
  category_id,
  category_desc,
  special_features,
  has_trailers,
  has_commentaries,
  has_behind_the_scenes,
  has_deleted_scenes,
  last_update,
	dbt_time
from
stg_film_2

where 1=1


  );
  
2022-01-14 13:02:43.034380 (Thread-1): SQL status: SELECT 1000 in 0.09 seconds
2022-01-14 13:02:43.037933 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 13:02:43.038347 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_film".
2022-01-14 13:02:43.038568 (Thread-1): On model.sakila_dbt_project.dim_film: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_film"} */

        insert into "sakila_wh"."stg_dwh"."dim_film"(film_id) VALUES (-1)
      
2022-01-14 13:02:43.093701 (Thread-1): SQL status: INSERT 0 1 in 0.05 seconds
2022-01-14 13:02:43.095454 (Thread-1): On model.sakila_dbt_project.dim_film: COMMIT
2022-01-14 13:02:43.095763 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_film".
2022-01-14 13:02:43.096020 (Thread-1): On model.sakila_dbt_project.dim_film: COMMIT
2022-01-14 13:02:43.151024 (Thread-1): SQL status: COMMIT in 0.05 seconds
2022-01-14 13:02:43.151956 (Thread-1): finished collecting timing info
2022-01-14 13:02:43.152337 (Thread-1): On model.sakila_dbt_project.dim_film: Close
2022-01-14 13:02:43.152947 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fea7e4fa-fe49-4b3d-b845-f50521259504', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105abd2e0>]}
2022-01-14 13:02:43.153395 (Thread-1): 18:32:43 | 3 of 8 OK created incremental model stg_dwh.dim_film................. [SELECT 1000 in 0.55s]
2022-01-14 13:02:43.153662 (Thread-1): Finished running node model.sakila_dbt_project.dim_film
2022-01-14 13:02:43.153927 (Thread-1): Began running node model.sakila_dbt_project.dim_staff
2022-01-14 13:02:43.154356 (Thread-1): 18:32:43 | 4 of 8 START table model stg_dwh.dim_staff........................... [RUN]
2022-01-14 13:02:43.154804 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-14 13:02:43.155085 (Thread-1): Compiling model.sakila_dbt_project.dim_staff
2022-01-14 13:02:43.158746 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_staff"
2022-01-14 13:02:43.159343 (Thread-1): finished collecting timing info
2022-01-14 13:02:43.161915 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_staff"
2022-01-14 13:02:43.162559 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-14 13:02:43.162755 (Thread-1): On model.sakila_dbt_project.dim_staff: BEGIN
2022-01-14 13:02:43.162930 (Thread-1): Opening a new connection, currently in state closed
2022-01-14 13:02:43.496119 (Thread-1): SQL status: BEGIN in 0.33 seconds
2022-01-14 13:02:43.496516 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-14 13:02:43.496779 (Thread-1): On model.sakila_dbt_project.dim_staff: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_staff"} */


  create  table "sakila_wh"."stg_dwh"."dim_staff__dbt_tmp"
  as (
    

with staff_base as (
select
*,
(case when active::int = 1 then 1 else 0 end) as "active_int",
(case when active::int = 1 then 'yes' else 'no' end) as "active_desc",
'2022-01-14 13:02:35'::timestamp as dbt_time
from
"sakila_wh"."stg"."staff"
)

select
	staff_id,
	first_name,
	last_name,
	email,
  active_int as active,
  active_desc,
	last_update,
  dbt_time
from
	staff_base
  );
2022-01-14 13:02:43.561220 (Thread-1): SQL status: SELECT 2 in 0.06 seconds
2022-01-14 13:02:43.564630 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-14 13:02:43.564882 (Thread-1): On model.sakila_dbt_project.dim_staff: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_staff"} */
alter table "sakila_wh"."stg_dwh"."dim_staff__dbt_tmp" rename to "dim_staff"
2022-01-14 13:02:43.619529 (Thread-1): SQL status: ALTER TABLE in 0.05 seconds
2022-01-14 13:02:43.621518 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 13:02:43.621843 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-14 13:02:43.622011 (Thread-1): On model.sakila_dbt_project.dim_staff: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_staff"} */

        insert into "sakila_wh"."stg_dwh"."dim_staff"(staff_id) VALUES (-1)
      
2022-01-14 13:02:43.676848 (Thread-1): SQL status: INSERT 0 1 in 0.05 seconds
2022-01-14 13:02:43.678059 (Thread-1): On model.sakila_dbt_project.dim_staff: COMMIT
2022-01-14 13:02:43.678272 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-14 13:02:43.678420 (Thread-1): On model.sakila_dbt_project.dim_staff: COMMIT
2022-01-14 13:02:43.733741 (Thread-1): SQL status: COMMIT in 0.06 seconds
2022-01-14 13:02:43.735733 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_staff".
2022-01-14 13:02:43.735927 (Thread-1): On model.sakila_dbt_project.dim_staff: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_staff"} */
drop table if exists "sakila_wh"."stg_dwh"."dim_staff__dbt_backup" cascade
2022-01-14 13:02:43.793457 (Thread-1): SQL status: DROP TABLE in 0.06 seconds
2022-01-14 13:02:43.794666 (Thread-1): finished collecting timing info
2022-01-14 13:02:43.794939 (Thread-1): On model.sakila_dbt_project.dim_staff: Close
2022-01-14 13:02:43.795465 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fea7e4fa-fe49-4b3d-b845-f50521259504', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105abd550>]}
2022-01-14 13:02:43.795819 (Thread-1): 18:32:43 | 4 of 8 OK created table model stg_dwh.dim_staff...................... [SELECT 2 in 0.64s]
2022-01-14 13:02:43.796013 (Thread-1): Finished running node model.sakila_dbt_project.dim_staff
2022-01-14 13:02:43.796197 (Thread-1): Began running node model.sakila_dbt_project.hello_world
2022-01-14 13:02:43.796589 (Thread-1): 18:32:43 | 5 of 8 START view model stg_dwh.hello_world.......................... [RUN]
2022-01-14 13:02:43.796919 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-14 13:02:43.797089 (Thread-1): Compiling model.sakila_dbt_project.hello_world
2022-01-14 13:02:43.798693 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.hello_world"
2022-01-14 13:02:43.799233 (Thread-1): finished collecting timing info
2022-01-14 13:02:43.815896 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.hello_world"
2022-01-14 13:02:43.816550 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-14 13:02:43.816719 (Thread-1): On model.sakila_dbt_project.hello_world: BEGIN
2022-01-14 13:02:43.816882 (Thread-1): Opening a new connection, currently in state closed
2022-01-14 13:02:44.155354 (Thread-1): SQL status: BEGIN in 0.34 seconds
2022-01-14 13:02:44.155935 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-14 13:02:44.156195 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */

  create view "sakila_wh"."stg_dwh"."hello_world__dbt_tmp" as (
    select
	customer.customer_id::int,
	customer.store_id::int,
	customer.first_name,
	customer.last_name,
	concat(customer.first_name,' ',customer.last_name) as full_name,
	substring(email from POSITION('@' in email)+1 for char_length(email)-POSITION('@' in email)) as domain,
	customer.email,
	customer.active::int,
	customer.address_id::int,
	address.address,
	city.city_id::int,
	city.city,
	(case when customer.active = 0 then 'no' else 'yes' end)::varchar(100) as "active_desc",
	customer.create_date::timestamp,
	customer.last_update::timestamp
from
	stg.customer as customer

	left join stg.address on 1=1
	and customer.address_id =address.address_id

	left join stg.city on 1=1
	and address.city_id = city.city_id
  );

2022-01-14 13:02:44.222533 (Thread-1): SQL status: CREATE VIEW in 0.07 seconds
2022-01-14 13:02:44.226150 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-14 13:02:44.226415 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
alter table "sakila_wh"."stg_dwh"."hello_world__dbt_tmp" rename to "hello_world"
2022-01-14 13:02:44.291058 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-14 13:02:44.293258 (Thread-1): On model.sakila_dbt_project.hello_world: COMMIT
2022-01-14 13:02:44.293545 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-14 13:02:44.293790 (Thread-1): On model.sakila_dbt_project.hello_world: COMMIT
2022-01-14 13:02:44.348897 (Thread-1): SQL status: COMMIT in 0.05 seconds
2022-01-14 13:02:44.352788 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-14 13:02:44.352998 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
drop view if exists "sakila_wh"."stg_dwh"."hello_world__dbt_backup" cascade
2022-01-14 13:02:44.413891 (Thread-1): SQL status: DROP VIEW in 0.06 seconds
2022-01-14 13:02:44.415678 (Thread-1): finished collecting timing info
2022-01-14 13:02:44.415970 (Thread-1): On model.sakila_dbt_project.hello_world: Close
2022-01-14 13:02:44.416525 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fea7e4fa-fe49-4b3d-b845-f50521259504', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105b81f10>]}
2022-01-14 13:02:44.416977 (Thread-1): 18:32:44 | 5 of 8 OK created view model stg_dwh.hello_world..................... [CREATE VIEW in 0.62s]
2022-01-14 13:02:44.417244 (Thread-1): Finished running node model.sakila_dbt_project.hello_world
2022-01-14 13:02:44.417500 (Thread-1): Began running node model.sakila_dbt_project.my_first_dbt_model
2022-01-14 13:02:44.417926 (Thread-1): 18:32:44 | 6 of 8 START table model stg_dwh.my_first_dbt_model.................. [RUN]
2022-01-14 13:02:44.418418 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-14 13:02:44.418624 (Thread-1): Compiling model.sakila_dbt_project.my_first_dbt_model
2022-01-14 13:02:44.421276 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.my_first_dbt_model"
2022-01-14 13:02:44.421865 (Thread-1): finished collecting timing info
2022-01-14 13:02:44.424393 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.my_first_dbt_model"
2022-01-14 13:02:44.424961 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-14 13:02:44.425154 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: BEGIN
2022-01-14 13:02:44.425320 (Thread-1): Opening a new connection, currently in state closed
2022-01-14 13:02:44.759398 (Thread-1): SQL status: BEGIN in 0.33 seconds
2022-01-14 13:02:44.759838 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-14 13:02:44.760117 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */


  create  table "sakila_wh"."stg_dwh"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-14 13:02:44.821510 (Thread-1): SQL status: SELECT 2 in 0.06 seconds
2022-01-14 13:02:44.824925 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-14 13:02:44.825157 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
alter table "sakila_wh"."stg_dwh"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-14 13:02:44.879587 (Thread-1): SQL status: ALTER TABLE in 0.05 seconds
2022-01-14 13:02:44.881657 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: COMMIT
2022-01-14 13:02:44.881897 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-14 13:02:44.882099 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: COMMIT
2022-01-14 13:02:44.936412 (Thread-1): SQL status: COMMIT in 0.05 seconds
2022-01-14 13:02:44.939314 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-14 13:02:44.939552 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
drop table if exists "sakila_wh"."stg_dwh"."my_first_dbt_model__dbt_backup" cascade
2022-01-14 13:02:44.994642 (Thread-1): SQL status: DROP TABLE in 0.05 seconds
2022-01-14 13:02:44.996676 (Thread-1): finished collecting timing info
2022-01-14 13:02:44.997097 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: Close
2022-01-14 13:02:44.997743 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fea7e4fa-fe49-4b3d-b845-f50521259504', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105b6bb20>]}
2022-01-14 13:02:44.998245 (Thread-1): 18:32:44 | 6 of 8 OK created table model stg_dwh.my_first_dbt_model............. [SELECT 2 in 0.58s]
2022-01-14 13:02:44.998522 (Thread-1): Finished running node model.sakila_dbt_project.my_first_dbt_model
2022-01-14 13:02:44.998787 (Thread-1): Began running node model.sakila_dbt_project.dim_store
2022-01-14 13:02:44.999277 (Thread-1): 18:32:44 | 7 of 8 START table model stg_dwh.dim_store........................... [RUN]
2022-01-14 13:02:44.999661 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_store".
2022-01-14 13:02:44.999868 (Thread-1): Compiling model.sakila_dbt_project.dim_store
2022-01-14 13:02:45.004742 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_store"
2022-01-14 13:02:45.005339 (Thread-1): finished collecting timing info
2022-01-14 13:02:45.008034 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_store"
2022-01-14 13:02:45.008617 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_store".
2022-01-14 13:02:45.008805 (Thread-1): On model.sakila_dbt_project.dim_store: BEGIN
2022-01-14 13:02:45.008984 (Thread-1): Opening a new connection, currently in state closed
2022-01-14 13:02:45.340585 (Thread-1): SQL status: BEGIN in 0.33 seconds
2022-01-14 13:02:45.340999 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_store".
2022-01-14 13:02:45.341282 (Thread-1): On model.sakila_dbt_project.dim_store: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_store"} */


  create  table "sakila_wh"."stg_dwh"."dim_store__dbt_tmp"
  as (
    

with stg_store as (
		select
    *,
    '2022-01-14 13:02:35'::timestamp as dbt_time
     from "sakila_wh"."stg"."store"
),

staff as (
 select * from "sakila_wh"."stg_dwh"."dim_staff"
),

address as (
  select * from "sakila_wh"."stg"."address"
),

city as (
  select * from "sakila_wh"."stg"."city"
),

country as (
  select * from "sakila_wh"."stg"."country"
),
stg_store_1 as (-- add staff
		select
		stg_store.*,
		staff.first_name as staff_first_name,
		staff.last_name as staff_last_name
		from
		stg_store
		left join staff  on 1=1
		and stg_store.manager_staff_id = staff.staff_id
),
stg_store_2 as (-- add adress
		select
		stg_store_1.*,
		address.address,
		city.city_id,
		city.city,
		country.country_id,
		country.country
		from
		stg_store_1

		left join address on 1=1
		and stg_store_1.address_id =address.address_id

		left join city on 1=1
		and address.city_id = city.city_id

		left join country on  1=1
		and city.country_id = country.country_id
)

select
  store_id,
  manager_staff_id,
  staff_first_name,
  staff_last_name,
  address_id,
  address,
  city_id,
  city,
  country_id,
  country,
  last_update,
  dbt_time
from stg_store_2
  );
2022-01-14 13:02:45.408498 (Thread-1): SQL status: SELECT 2 in 0.07 seconds
2022-01-14 13:02:45.412493 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_store".
2022-01-14 13:02:45.412741 (Thread-1): On model.sakila_dbt_project.dim_store: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_store"} */
alter table "sakila_wh"."stg_dwh"."dim_store__dbt_tmp" rename to "dim_store"
2022-01-14 13:02:45.467479 (Thread-1): SQL status: ALTER TABLE in 0.05 seconds
2022-01-14 13:02:45.470304 (Thread-1): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 13:02:45.470710 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_store".
2022-01-14 13:02:45.470921 (Thread-1): On model.sakila_dbt_project.dim_store: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_store"} */

        insert into "sakila_wh"."stg_dwh"."dim_store"(store_id) VALUES (-1)
      
2022-01-14 13:02:45.525963 (Thread-1): SQL status: INSERT 0 1 in 0.05 seconds
2022-01-14 13:02:45.527591 (Thread-1): On model.sakila_dbt_project.dim_store: COMMIT
2022-01-14 13:02:45.527839 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_store".
2022-01-14 13:02:45.528036 (Thread-1): On model.sakila_dbt_project.dim_store: COMMIT
2022-01-14 13:02:45.582761 (Thread-1): SQL status: COMMIT in 0.05 seconds
2022-01-14 13:02:45.585087 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_store".
2022-01-14 13:02:45.585285 (Thread-1): On model.sakila_dbt_project.dim_store: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_store"} */
drop table if exists "sakila_wh"."stg_dwh"."dim_store__dbt_backup" cascade
2022-01-14 13:02:45.639615 (Thread-1): SQL status: DROP TABLE in 0.05 seconds
2022-01-14 13:02:45.641398 (Thread-1): finished collecting timing info
2022-01-14 13:02:45.641676 (Thread-1): On model.sakila_dbt_project.dim_store: Close
2022-01-14 13:02:45.642227 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fea7e4fa-fe49-4b3d-b845-f50521259504', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105b0b1f0>]}
2022-01-14 13:02:45.642674 (Thread-1): 18:32:45 | 7 of 8 OK created table model stg_dwh.dim_store...................... [SELECT 2 in 0.64s]
2022-01-14 13:02:45.642941 (Thread-1): Finished running node model.sakila_dbt_project.dim_store
2022-01-14 13:02:45.643196 (Thread-1): Began running node model.sakila_dbt_project.my_second_dbt_model
2022-01-14 13:02:45.643627 (Thread-1): 18:32:45 | 8 of 8 START view model stg_dwh.my_second_dbt_model.................. [RUN]
2022-01-14 13:02:45.644066 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-14 13:02:45.644264 (Thread-1): Compiling model.sakila_dbt_project.my_second_dbt_model
2022-01-14 13:02:45.648596 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.my_second_dbt_model"
2022-01-14 13:02:45.649221 (Thread-1): finished collecting timing info
2022-01-14 13:02:45.651952 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.my_second_dbt_model"
2022-01-14 13:02:45.652526 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-14 13:02:45.652708 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: BEGIN
2022-01-14 13:02:45.652884 (Thread-1): Opening a new connection, currently in state closed
2022-01-14 13:02:45.989513 (Thread-1): SQL status: BEGIN in 0.34 seconds
2022-01-14 13:02:45.990087 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-14 13:02:45.990446 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */

  create view "sakila_wh"."stg_dwh"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "sakila_wh"."stg_dwh"."my_first_dbt_model"
where id = 1
  );

2022-01-14 13:02:46.051026 (Thread-1): SQL status: CREATE VIEW in 0.06 seconds
2022-01-14 13:02:46.054413 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-14 13:02:46.054659 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
alter table "sakila_wh"."stg_dwh"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-14 13:02:46.109498 (Thread-1): SQL status: ALTER TABLE in 0.05 seconds
2022-01-14 13:02:46.111719 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: COMMIT
2022-01-14 13:02:46.112005 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-14 13:02:46.112245 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: COMMIT
2022-01-14 13:02:46.167639 (Thread-1): SQL status: COMMIT in 0.06 seconds
2022-01-14 13:02:46.170788 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-14 13:02:46.171118 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
drop view if exists "sakila_wh"."stg_dwh"."my_second_dbt_model__dbt_backup" cascade
2022-01-14 13:02:46.231208 (Thread-1): SQL status: DROP VIEW in 0.06 seconds
2022-01-14 13:02:46.233100 (Thread-1): finished collecting timing info
2022-01-14 13:02:46.233403 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: Close
2022-01-14 13:02:46.233963 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fea7e4fa-fe49-4b3d-b845-f50521259504', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105ada6d0>]}
2022-01-14 13:02:46.234399 (Thread-1): 18:32:46 | 8 of 8 OK created view model stg_dwh.my_second_dbt_model............. [CREATE VIEW in 0.59s]
2022-01-14 13:02:46.234654 (Thread-1): Finished running node model.sakila_dbt_project.my_second_dbt_model
2022-01-14 13:02:46.235866 (MainThread): Acquiring new postgres connection "master".
2022-01-14 13:02:46.236137 (MainThread): Using postgres connection "master".
2022-01-14 13:02:46.236335 (MainThread): On master: BEGIN
2022-01-14 13:02:46.236499 (MainThread): Opening a new connection, currently in state closed
2022-01-14 13:02:46.569774 (MainThread): SQL status: BEGIN in 0.33 seconds
2022-01-14 13:02:46.570351 (MainThread): On master: COMMIT
2022-01-14 13:02:46.570602 (MainThread): Using postgres connection "master".
2022-01-14 13:02:46.570833 (MainThread): On master: COMMIT
2022-01-14 13:02:46.624782 (MainThread): SQL status: COMMIT in 0.05 seconds
2022-01-14 13:02:46.625357 (MainThread): On master: Close
2022-01-14 13:02:46.626063 (MainThread): 18:32:46 | 
2022-01-14 13:02:46.626394 (MainThread): 18:32:46 | Finished running 2 incremental models, 4 table models, 2 view models in 10.28s.
2022-01-14 13:02:46.626681 (MainThread): Connection 'master' was properly closed.
2022-01-14 13:02:46.626909 (MainThread): Connection 'model.sakila_dbt_project.my_second_dbt_model' was properly closed.
2022-01-14 13:02:46.637402 (MainThread): 
2022-01-14 13:02:46.637658 (MainThread): Completed successfully
2022-01-14 13:02:46.637896 (MainThread): 
Done. PASS=8 WARN=0 ERROR=0 SKIP=0 TOTAL=8
2022-01-14 13:02:46.638205 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1057e2d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105aaeb20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105aaebe0>]}
2022-01-14 13:02:46.638536 (MainThread): Flushing usage events
2022-01-14 13:12:21.491497 (MainThread): Running with dbt=0.21.1
2022-01-14 13:12:21.571829 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2022-01-14 13:12:21.573752 (MainThread): Tracking: tracking
2022-01-14 13:12:21.592224 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10afa1070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10af83a30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10af946d0>]}
2022-01-14 13:12:21.613477 (MainThread): Partial parsing not enabled
2022-01-14 13:12:21.663209 (MainThread): Parsing macros/catalog.sql
2022-01-14 13:12:21.666544 (MainThread): Parsing macros/relations.sql
2022-01-14 13:12:21.667809 (MainThread): Parsing macros/adapters.sql
2022-01-14 13:12:21.689019 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2022-01-14 13:12:21.690670 (MainThread): Parsing macros/core.sql
2022-01-14 13:12:21.694094 (MainThread): Parsing macros/materializations/test.sql
2022-01-14 13:12:21.700378 (MainThread): Parsing macros/materializations/helpers.sql
2022-01-14 13:12:21.709953 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2022-01-14 13:12:21.711568 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2022-01-14 13:12:21.728019 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2022-01-14 13:12:21.757994 (MainThread): Parsing macros/materializations/seed/seed.sql
2022-01-14 13:12:21.779315 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2022-01-14 13:12:21.780929 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2022-01-14 13:12:21.790585 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2022-01-14 13:12:21.808745 (MainThread): Parsing macros/materializations/common/merge.sql
2022-01-14 13:12:21.821669 (MainThread): Parsing macros/materializations/table/table.sql
2022-01-14 13:12:21.828867 (MainThread): Parsing macros/materializations/view/view.sql
2022-01-14 13:12:21.835396 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2022-01-14 13:12:21.839154 (MainThread): Parsing macros/etc/get_custom_alias.sql
2022-01-14 13:12:21.840510 (MainThread): Parsing macros/etc/query.sql
2022-01-14 13:12:21.841380 (MainThread): Parsing macros/etc/is_incremental.sql
2022-01-14 13:12:21.842727 (MainThread): Parsing macros/etc/datetime.sql
2022-01-14 13:12:21.850289 (MainThread): Parsing macros/etc/where_subquery.sql
2022-01-14 13:12:21.851910 (MainThread): Parsing macros/etc/get_custom_schema.sql
2022-01-14 13:12:21.854506 (MainThread): Parsing macros/etc/get_custom_database.sql
2022-01-14 13:12:21.855961 (MainThread): Parsing macros/adapters/common.sql
2022-01-14 13:12:21.907765 (MainThread): Parsing macros/schema_tests/relationships.sql
2022-01-14 13:12:21.909328 (MainThread): Parsing macros/schema_tests/not_null.sql
2022-01-14 13:12:21.910421 (MainThread): Parsing macros/schema_tests/unique.sql
2022-01-14 13:12:21.911645 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2022-01-14 13:12:21.913816 (MainThread): Parsing macros/cross_db_utils/except.sql
2022-01-14 13:12:21.914804 (MainThread): Parsing macros/cross_db_utils/replace.sql
2022-01-14 13:12:21.915944 (MainThread): Parsing macros/cross_db_utils/concat.sql
2022-01-14 13:12:21.916990 (MainThread): Parsing macros/cross_db_utils/datatypes.sql
2022-01-14 13:12:21.922606 (MainThread): Parsing macros/cross_db_utils/_is_relation.sql
2022-01-14 13:12:21.923660 (MainThread): Parsing macros/cross_db_utils/length.sql
2022-01-14 13:12:21.924946 (MainThread): Parsing macros/cross_db_utils/dateadd.sql
2022-01-14 13:12:21.927608 (MainThread): Parsing macros/cross_db_utils/intersect.sql
2022-01-14 13:12:21.928565 (MainThread): Parsing macros/cross_db_utils/right.sql
2022-01-14 13:12:21.930731 (MainThread): Parsing macros/cross_db_utils/datediff.sql
2022-01-14 13:12:21.940229 (MainThread): Parsing macros/cross_db_utils/safe_cast.sql
2022-01-14 13:12:21.941943 (MainThread): Parsing macros/cross_db_utils/hash.sql
2022-01-14 13:12:21.943237 (MainThread): Parsing macros/cross_db_utils/cast_bool_to_text.sql
2022-01-14 13:12:21.944551 (MainThread): Parsing macros/cross_db_utils/identifier.sql
2022-01-14 13:12:21.946050 (MainThread): Parsing macros/cross_db_utils/position.sql
2022-01-14 13:12:21.947477 (MainThread): Parsing macros/cross_db_utils/literal.sql
2022-01-14 13:12:21.948380 (MainThread): Parsing macros/cross_db_utils/current_timestamp.sql
2022-01-14 13:12:21.951632 (MainThread): Parsing macros/cross_db_utils/width_bucket.sql
2022-01-14 13:12:21.956672 (MainThread): Parsing macros/cross_db_utils/last_day.sql
2022-01-14 13:12:21.959895 (MainThread): Parsing macros/cross_db_utils/split_part.sql
2022-01-14 13:12:21.961585 (MainThread): Parsing macros/cross_db_utils/date_trunc.sql
2022-01-14 13:12:21.963104 (MainThread): Parsing macros/cross_db_utils/_is_ephemeral.sql
2022-01-14 13:12:21.964936 (MainThread): Parsing macros/materializations/insert_by_period_materialization.sql
2022-01-14 13:12:21.987988 (MainThread): Parsing macros/web/get_url_host.sql
2022-01-14 13:12:21.989722 (MainThread): Parsing macros/web/get_url_path.sql
2022-01-14 13:12:21.992070 (MainThread): Parsing macros/web/get_url_parameter.sql
2022-01-14 13:12:21.993598 (MainThread): Parsing macros/jinja_helpers/pretty_log_format.sql
2022-01-14 13:12:21.994637 (MainThread): Parsing macros/jinja_helpers/pretty_time.sql
2022-01-14 13:12:21.995759 (MainThread): Parsing macros/jinja_helpers/log_info.sql
2022-01-14 13:12:21.996782 (MainThread): Parsing macros/jinja_helpers/slugify.sql
2022-01-14 13:12:21.997867 (MainThread): Parsing macros/schema_tests/fewer_rows_than.sql
2022-01-14 13:12:21.999400 (MainThread): Parsing macros/schema_tests/equal_rowcount.sql
2022-01-14 13:12:22.000893 (MainThread): Parsing macros/schema_tests/relationships_where.sql
2022-01-14 13:12:22.002996 (MainThread): Parsing macros/schema_tests/recency.sql
2022-01-14 13:12:22.004767 (MainThread): Parsing macros/schema_tests/not_constant.sql
2022-01-14 13:12:22.005906 (MainThread): Parsing macros/schema_tests/accepted_range.sql
2022-01-14 13:12:22.008199 (MainThread): Parsing macros/schema_tests/not_accepted_values.sql
2022-01-14 13:12:22.010198 (MainThread): Parsing macros/schema_tests/test_unique_where.sql
2022-01-14 13:12:22.011579 (MainThread): Parsing macros/schema_tests/at_least_one.sql
2022-01-14 13:12:22.012873 (MainThread): Parsing macros/schema_tests/unique_combination_of_columns.sql
2022-01-14 13:12:22.015436 (MainThread): Parsing macros/schema_tests/cardinality_equality.sql
2022-01-14 13:12:22.017232 (MainThread): Parsing macros/schema_tests/expression_is_true.sql
2022-01-14 13:12:22.018866 (MainThread): Parsing macros/schema_tests/sequential_values.sql
2022-01-14 13:12:22.021821 (MainThread): Parsing macros/schema_tests/test_not_null_where.sql
2022-01-14 13:12:22.023126 (MainThread): Parsing macros/schema_tests/equality.sql
2022-01-14 13:12:22.026232 (MainThread): Parsing macros/schema_tests/mutually_exclusive_ranges.sql
2022-01-14 13:12:22.034363 (MainThread): Parsing macros/sql/date_spine.sql
2022-01-14 13:12:22.038840 (MainThread): Parsing macros/sql/nullcheck_table.sql
2022-01-14 13:12:22.040331 (MainThread): Parsing macros/sql/get_relations_by_pattern.sql
2022-01-14 13:12:22.043406 (MainThread): Parsing macros/sql/generate_series.sql
2022-01-14 13:12:22.071343 (MainThread): Parsing macros/sql/get_relations_by_prefix.sql
2022-01-14 13:12:22.075772 (MainThread): Parsing macros/sql/get_tables_by_prefix_sql.sql
2022-01-14 13:12:22.077891 (MainThread): Parsing macros/sql/star.sql
2022-01-14 13:12:22.082027 (MainThread): Parsing macros/sql/unpivot.sql
2022-01-14 13:12:22.091949 (MainThread): Parsing macros/sql/union.sql
2022-01-14 13:12:22.101244 (MainThread): Parsing macros/sql/groupby.sql
2022-01-14 13:12:22.102755 (MainThread): Parsing macros/sql/surrogate_key.sql
2022-01-14 13:12:22.106620 (MainThread): Parsing macros/sql/safe_add.sql
2022-01-14 13:12:22.108419 (MainThread): Parsing macros/sql/nullcheck.sql
2022-01-14 13:12:22.110309 (MainThread): Parsing macros/sql/get_tables_by_pattern_sql.sql
2022-01-14 13:12:22.117378 (MainThread): Parsing macros/sql/get_column_values.sql
2022-01-14 13:12:22.122847 (MainThread): Parsing macros/sql/pivot.sql
2022-01-14 13:12:22.127160 (MainThread): Parsing macros/sql/get_query_results_as_dict.sql
2022-01-14 13:12:22.129693 (MainThread): Parsing macros/sql/haversine_distance.sql
2022-01-14 13:12:22.425497 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-14 13:12:22.433561 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 13:12:22.437201 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-14 13:12:22.439888 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 13:12:22.440967 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-14 13:12:22.442827 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 13:12:22.443872 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-14 13:12:22.446242 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 13:12:22.477604 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 13:12:22.486524 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 13:12:22.488377 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 13:12:22.490061 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 13:12:22.491840 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 13:12:22.493446 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 13:12:22.507889 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 13:12:22.509704 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 13:12:22.532454 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e90c178a-4c8a-42e3-873c-e5260f4e8137', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b101160>]}
2022-01-14 13:12:22.541209 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-01-14 13:12:22.541685 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e90c178a-4c8a-42e3-873c-e5260f4e8137', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b11ae80>]}
2022-01-14 13:12:22.541921 (MainThread): Found 4 models, 8 tests, 0 snapshots, 0 analyses, 347 macros, 0 operations, 0 seed files, 12 sources, 0 exposures
2022-01-14 13:12:22.543303 (MainThread): 
2022-01-14 13:12:22.543658 (MainThread): Acquiring new postgres connection "master".
2022-01-14 13:12:22.544396 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_sakila_wh".
2022-01-14 13:12:22.553543 (ThreadPoolExecutor-0_0): Using postgres connection "list_sakila_wh".
2022-01-14 13:12:22.553751 (ThreadPoolExecutor-0_0): On list_sakila_wh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh"} */

    select distinct nspname from pg_namespace
  
2022-01-14 13:12:22.553910 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2022-01-14 13:12:23.165653 (ThreadPoolExecutor-0_0): SQL status: SELECT 9 in 0.61 seconds
2022-01-14 13:12:23.168076 (ThreadPoolExecutor-0_0): On list_sakila_wh: Close
2022-01-14 13:12:23.169106 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "create_sakila_wh_stg_dwh".
2022-01-14 13:12:23.169560 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "create_sakila_wh_stg_dwh".
2022-01-14 13:12:23.169847 (ThreadPoolExecutor-0_0): Creating schema ""sakila_wh"."stg_dwh""
2022-01-14 13:12:23.175951 (ThreadPoolExecutor-0_0): Using postgres connection "create_sakila_wh_stg_dwh".
2022-01-14 13:12:23.176178 (ThreadPoolExecutor-0_0): On create_sakila_wh_stg_dwh: BEGIN
2022-01-14 13:12:23.176355 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2022-01-14 13:12:23.522183 (ThreadPoolExecutor-0_0): SQL status: BEGIN in 0.35 seconds
2022-01-14 13:12:23.522562 (ThreadPoolExecutor-0_0): Using postgres connection "create_sakila_wh_stg_dwh".
2022-01-14 13:12:23.522830 (ThreadPoolExecutor-0_0): On create_sakila_wh_stg_dwh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "create_sakila_wh_stg_dwh"} */
create schema if not exists "stg_dwh"
2022-01-14 13:12:23.578641 (ThreadPoolExecutor-0_0): SQL status: CREATE SCHEMA in 0.06 seconds
2022-01-14 13:12:23.580387 (ThreadPoolExecutor-0_0): On create_sakila_wh_stg_dwh: COMMIT
2022-01-14 13:12:23.580682 (ThreadPoolExecutor-0_0): Using postgres connection "create_sakila_wh_stg_dwh".
2022-01-14 13:12:23.580933 (ThreadPoolExecutor-0_0): On create_sakila_wh_stg_dwh: COMMIT
2022-01-14 13:12:23.636099 (ThreadPoolExecutor-0_0): SQL status: COMMIT in 0.05 seconds
2022-01-14 13:12:23.636520 (ThreadPoolExecutor-0_0): On create_sakila_wh_stg_dwh: Close
2022-01-14 13:12:23.638296 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_stg_dwh".
2022-01-14 13:12:23.644763 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_stg_dwh".
2022-01-14 13:12:23.644961 (ThreadPoolExecutor-1_0): On list_sakila_wh_stg_dwh: BEGIN
2022-01-14 13:12:23.645134 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2022-01-14 13:12:23.981081 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.34 seconds
2022-01-14 13:12:23.981496 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_stg_dwh".
2022-01-14 13:12:23.981767 (ThreadPoolExecutor-1_0): On list_sakila_wh_stg_dwh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_stg_dwh"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'stg_dwh'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'stg_dwh'
  
2022-01-14 13:12:24.041485 (ThreadPoolExecutor-1_0): SQL status: SELECT 0 in 0.06 seconds
2022-01-14 13:12:24.043221 (ThreadPoolExecutor-1_0): On list_sakila_wh_stg_dwh: ROLLBACK
2022-01-14 13:12:24.097578 (ThreadPoolExecutor-1_0): On list_sakila_wh_stg_dwh: Close
2022-01-14 13:12:24.103477 (MainThread): Using postgres connection "master".
2022-01-14 13:12:24.103716 (MainThread): On master: BEGIN
2022-01-14 13:12:24.103895 (MainThread): Opening a new connection, currently in state init
2022-01-14 13:12:24.440425 (MainThread): SQL status: BEGIN in 0.34 seconds
2022-01-14 13:12:24.440761 (MainThread): Using postgres connection "master".
2022-01-14 13:12:24.440982 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-14 13:12:24.511457 (MainThread): SQL status: SELECT 47 in 0.07 seconds
2022-01-14 13:12:24.514838 (MainThread): On master: ROLLBACK
2022-01-14 13:12:24.569062 (MainThread): Using postgres connection "master".
2022-01-14 13:12:24.569775 (MainThread): On master: BEGIN
2022-01-14 13:12:24.681527 (MainThread): SQL status: BEGIN in 0.11 seconds
2022-01-14 13:12:24.682134 (MainThread): On master: COMMIT
2022-01-14 13:12:24.682403 (MainThread): Using postgres connection "master".
2022-01-14 13:12:24.682646 (MainThread): On master: COMMIT
2022-01-14 13:12:24.740013 (MainThread): SQL status: COMMIT in 0.06 seconds
2022-01-14 13:12:24.740396 (MainThread): On master: Close
2022-01-14 13:12:24.740961 (MainThread): 18:42:24 | Concurrency: 1 threads (target='dev')
2022-01-14 13:12:24.741192 (MainThread): 18:42:24 | 
2022-01-14 13:12:24.743912 (Thread-1): Began running node model.sakila_dbt_project.dim_date
2022-01-14 13:12:24.744246 (Thread-1): 18:42:24 | 1 of 4 START table model stg_dwh.dim_date............................ [RUN]
2022-01-14 13:12:24.745557 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-14 13:12:24.745772 (Thread-1): Compiling model.sakila_dbt_project.dim_date
2022-01-14 13:12:24.747502 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_date"
2022-01-14 13:12:24.748101 (Thread-1): finished collecting timing info
2022-01-14 13:12:24.774211 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_date"
2022-01-14 13:12:24.774879 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-14 13:12:24.775058 (Thread-1): On model.sakila_dbt_project.dim_date: BEGIN
2022-01-14 13:12:24.775214 (Thread-1): Opening a new connection, currently in state closed
2022-01-14 13:12:25.113991 (Thread-1): SQL status: BEGIN in 0.34 seconds
2022-01-14 13:12:25.114376 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-14 13:12:25.114627 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */


  create  table "sakila_wh"."stg_dwh"."dim_date__dbt_tmp"
  as (
    with dates as (
SELECT
       TO_CHAR(datum, 'yyyymmdd')::INT AS date_dim_id,
       datum AS date_key,
       EXTRACT(EPOCH FROM datum) AS epoch,
       TO_CHAR(datum, 'TMDay') AS day_name,
       EXTRACT(ISODOW FROM datum) AS day_of_week,
       EXTRACT(DAY FROM datum) AS day_of_month,
       datum - DATE_TRUNC('quarter', datum)::DATE + 1 AS day_of_quarter,
       EXTRACT(DOY FROM datum) AS day_of_year,
       TO_CHAR(datum, 'W')::INT AS week_of_month,
       EXTRACT(WEEK FROM datum) AS week_of_year,
       EXTRACT(MONTH FROM datum) AS month_actual,
       TO_CHAR(datum, 'TMMonth') AS month_name,
       TO_CHAR(datum, 'Mon') AS month_name_abbreviated,
       EXTRACT(QUARTER FROM datum) AS quarter_actual,
       CASE
           WHEN EXTRACT(QUARTER FROM datum) = 1 THEN 'First'
           WHEN EXTRACT(QUARTER FROM datum) = 2 THEN 'Second'
           WHEN EXTRACT(QUARTER FROM datum) = 3 THEN 'Third'
           WHEN EXTRACT(QUARTER FROM datum) = 4 THEN 'Fourth'
           END AS quarter_name,
       EXTRACT(YEAR FROM datum) AS year_actual,
       datum + (1 - EXTRACT(ISODOW FROM datum))::INT AS first_day_of_week,
       datum + (7 - EXTRACT(ISODOW FROM datum))::INT AS last_day_of_week,
       datum + (1 - EXTRACT(DAY FROM datum))::INT AS first_day_of_month,
       (DATE_TRUNC('MONTH', datum) + INTERVAL '1 MONTH - 1 day')::DATE AS last_day_of_month,
       DATE_TRUNC('quarter', datum)::DATE AS first_day_of_quarter,
       (DATE_TRUNC('quarter', datum) + INTERVAL '3 MONTH - 1 day')::DATE AS last_day_of_quarter,
       TO_DATE(EXTRACT(YEAR FROM datum) || '-01-01', 'YYYY-MM-DD') AS first_day_of_year,
       TO_DATE(EXTRACT(YEAR FROM datum) || '-12-31', 'YYYY-MM-DD') AS last_day_of_year,
       TO_CHAR(datum, 'yyyymm') AS yyyymm,
       CASE
           WHEN EXTRACT(ISODOW FROM datum) IN (6, 7) THEN TRUE
           ELSE FALSE
           END AS weekend_indr
FROM (SELECT '2000-01-01'::DATE + SEQUENCE.DAY AS datum
      FROM GENERATE_SERIES(0, 29219) AS SEQUENCE (DAY)
      GROUP BY SEQUENCE.DAY) DQ
)
select
*
from
dates
where
date_key <= CURRENT_DATE
order by date_dim_id asc
  );
2022-01-14 13:12:26.008152 (Thread-1): SQL status: SELECT 8050 in 0.89 seconds
2022-01-14 13:12:26.015049 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-14 13:12:26.015277 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
alter table "sakila_wh"."stg_dwh"."dim_date__dbt_tmp" rename to "dim_date"
2022-01-14 13:12:26.071274 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-14 13:12:26.082174 (Thread-1): On model.sakila_dbt_project.dim_date: COMMIT
2022-01-14 13:12:26.082401 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-14 13:12:26.082550 (Thread-1): On model.sakila_dbt_project.dim_date: COMMIT
2022-01-14 13:12:26.137375 (Thread-1): SQL status: COMMIT in 0.05 seconds
2022-01-14 13:12:26.143758 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-14 13:12:26.143979 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
drop table if exists "sakila_wh"."stg_dwh"."dim_date__dbt_backup" cascade
2022-01-14 13:12:26.199795 (Thread-1): SQL status: DROP TABLE in 0.06 seconds
2022-01-14 13:12:26.201998 (Thread-1): finished collecting timing info
2022-01-14 13:12:26.202354 (Thread-1): On model.sakila_dbt_project.dim_date: Close
2022-01-14 13:12:26.203070 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e90c178a-4c8a-42e3-873c-e5260f4e8137', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b10f430>]}
2022-01-14 13:12:26.203535 (Thread-1): 18:42:26 | 1 of 4 OK created table model stg_dwh.dim_date....................... [SELECT 8050 in 1.46s]
2022-01-14 13:12:26.203817 (Thread-1): Finished running node model.sakila_dbt_project.dim_date
2022-01-14 13:12:26.204080 (Thread-1): Began running node model.sakila_dbt_project.hello_world
2022-01-14 13:12:26.204536 (Thread-1): 18:42:26 | 2 of 4 START view model stg_dwh.hello_world.......................... [RUN]
2022-01-14 13:12:26.205048 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-14 13:12:26.205290 (Thread-1): Compiling model.sakila_dbt_project.hello_world
2022-01-14 13:12:26.207255 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.hello_world"
2022-01-14 13:12:26.207834 (Thread-1): finished collecting timing info
2022-01-14 13:12:26.227051 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.hello_world"
2022-01-14 13:12:26.227700 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-14 13:12:26.227872 (Thread-1): On model.sakila_dbt_project.hello_world: BEGIN
2022-01-14 13:12:26.228030 (Thread-1): Opening a new connection, currently in state closed
2022-01-14 13:12:26.561617 (Thread-1): SQL status: BEGIN in 0.33 seconds
2022-01-14 13:12:26.562599 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-14 13:12:26.563118 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */

  create view "sakila_wh"."stg_dwh"."hello_world__dbt_tmp" as (
    select
	customer.customer_id::int,
	customer.store_id::int,
	customer.first_name,
	customer.last_name,
	concat(customer.first_name,' ',customer.last_name) as full_name,
	substring(email from POSITION('@' in email)+1 for char_length(email)-POSITION('@' in email)) as domain,
	customer.email,
	customer.active::int,
	customer.address_id::int,
	address.address,
	city.city_id::int,
	city.city,
	(case when customer.active = 0 then 'no' else 'yes' end)::varchar(100) as "active_desc",
	customer.create_date::timestamp,
	customer.last_update::timestamp
from
	stg.customer as customer

	left join stg.address on 1=1
	and customer.address_id =address.address_id

	left join stg.city on 1=1
	and address.city_id = city.city_id
  );

2022-01-14 13:12:26.627868 (Thread-1): SQL status: CREATE VIEW in 0.06 seconds
2022-01-14 13:12:26.630399 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-14 13:12:26.630583 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
alter table "sakila_wh"."stg_dwh"."hello_world__dbt_tmp" rename to "hello_world"
2022-01-14 13:12:26.686505 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-14 13:12:26.688573 (Thread-1): On model.sakila_dbt_project.hello_world: COMMIT
2022-01-14 13:12:26.688866 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-14 13:12:26.689118 (Thread-1): On model.sakila_dbt_project.hello_world: COMMIT
2022-01-14 13:12:26.744368 (Thread-1): SQL status: COMMIT in 0.05 seconds
2022-01-14 13:12:26.747713 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-14 13:12:26.747908 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
drop view if exists "sakila_wh"."stg_dwh"."hello_world__dbt_backup" cascade
2022-01-14 13:12:26.810090 (Thread-1): SQL status: DROP VIEW in 0.06 seconds
2022-01-14 13:12:26.811871 (Thread-1): finished collecting timing info
2022-01-14 13:12:26.812162 (Thread-1): On model.sakila_dbt_project.hello_world: Close
2022-01-14 13:12:26.812737 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e90c178a-4c8a-42e3-873c-e5260f4e8137', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b101160>]}
2022-01-14 13:12:26.813168 (Thread-1): 18:42:26 | 2 of 4 OK created view model stg_dwh.hello_world..................... [CREATE VIEW in 0.61s]
2022-01-14 13:12:26.813396 (Thread-1): Finished running node model.sakila_dbt_project.hello_world
2022-01-14 13:12:26.813612 (Thread-1): Began running node model.sakila_dbt_project.my_first_dbt_model
2022-01-14 13:12:26.813959 (Thread-1): 18:42:26 | 3 of 4 START table model stg_dwh.my_first_dbt_model.................. [RUN]
2022-01-14 13:12:26.814349 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-14 13:12:26.814550 (Thread-1): Compiling model.sakila_dbt_project.my_first_dbt_model
2022-01-14 13:12:26.817217 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.my_first_dbt_model"
2022-01-14 13:12:26.817824 (Thread-1): finished collecting timing info
2022-01-14 13:12:26.820327 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.my_first_dbt_model"
2022-01-14 13:12:26.820999 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-14 13:12:26.821186 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: BEGIN
2022-01-14 13:12:26.821358 (Thread-1): Opening a new connection, currently in state closed
2022-01-14 13:12:27.153060 (Thread-1): SQL status: BEGIN in 0.33 seconds
2022-01-14 13:12:27.153451 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-14 13:12:27.153715 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */


  create  table "sakila_wh"."stg_dwh"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-14 13:12:27.213485 (Thread-1): SQL status: SELECT 2 in 0.06 seconds
2022-01-14 13:12:27.216979 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-14 13:12:27.217205 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
alter table "sakila_wh"."stg_dwh"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-14 13:12:27.271842 (Thread-1): SQL status: ALTER TABLE in 0.05 seconds
2022-01-14 13:12:27.273778 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: COMMIT
2022-01-14 13:12:27.274034 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-14 13:12:27.274236 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: COMMIT
2022-01-14 13:12:27.329289 (Thread-1): SQL status: COMMIT in 0.05 seconds
2022-01-14 13:12:27.332555 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-14 13:12:27.332790 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
drop table if exists "sakila_wh"."stg_dwh"."my_first_dbt_model__dbt_backup" cascade
2022-01-14 13:12:27.389165 (Thread-1): SQL status: DROP TABLE in 0.06 seconds
2022-01-14 13:12:27.390782 (Thread-1): finished collecting timing info
2022-01-14 13:12:27.391066 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: Close
2022-01-14 13:12:27.391615 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e90c178a-4c8a-42e3-873c-e5260f4e8137', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b323c70>]}
2022-01-14 13:12:27.392067 (Thread-1): 18:42:27 | 3 of 4 OK created table model stg_dwh.my_first_dbt_model............. [SELECT 2 in 0.58s]
2022-01-14 13:12:27.392337 (Thread-1): Finished running node model.sakila_dbt_project.my_first_dbt_model
2022-01-14 13:12:27.393017 (Thread-1): Began running node model.sakila_dbt_project.my_second_dbt_model
2022-01-14 13:12:27.393409 (Thread-1): 18:42:27 | 4 of 4 START view model stg_dwh.my_second_dbt_model.................. [RUN]
2022-01-14 13:12:27.393805 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-14 13:12:27.394003 (Thread-1): Compiling model.sakila_dbt_project.my_second_dbt_model
2022-01-14 13:12:27.396742 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.my_second_dbt_model"
2022-01-14 13:12:27.397367 (Thread-1): finished collecting timing info
2022-01-14 13:12:27.400011 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.my_second_dbt_model"
2022-01-14 13:12:27.400622 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-14 13:12:27.400806 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: BEGIN
2022-01-14 13:12:27.400980 (Thread-1): Opening a new connection, currently in state closed
2022-01-14 13:12:27.737565 (Thread-1): SQL status: BEGIN in 0.34 seconds
2022-01-14 13:12:27.737882 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-14 13:12:27.738088 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */

  create view "sakila_wh"."stg_dwh"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "sakila_wh"."stg_dwh"."my_first_dbt_model"
where id = 1
  );

2022-01-14 13:12:27.798603 (Thread-1): SQL status: CREATE VIEW in 0.06 seconds
2022-01-14 13:12:27.801960 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-14 13:12:27.802203 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
alter table "sakila_wh"."stg_dwh"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-14 13:12:27.856496 (Thread-1): SQL status: ALTER TABLE in 0.05 seconds
2022-01-14 13:12:27.858126 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: COMMIT
2022-01-14 13:12:27.858362 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-14 13:12:27.858558 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: COMMIT
2022-01-14 13:12:27.914696 (Thread-1): SQL status: COMMIT in 0.06 seconds
2022-01-14 13:12:27.917339 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-14 13:12:27.917583 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
drop view if exists "sakila_wh"."stg_dwh"."my_second_dbt_model__dbt_backup" cascade
2022-01-14 13:12:27.973026 (Thread-1): SQL status: DROP VIEW in 0.06 seconds
2022-01-14 13:12:27.974418 (Thread-1): finished collecting timing info
2022-01-14 13:12:27.974658 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: Close
2022-01-14 13:12:27.975133 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e90c178a-4c8a-42e3-873c-e5260f4e8137', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b2e31c0>]}
2022-01-14 13:12:27.975519 (Thread-1): 18:42:27 | 4 of 4 OK created view model stg_dwh.my_second_dbt_model............. [CREATE VIEW in 0.58s]
2022-01-14 13:12:27.975746 (Thread-1): Finished running node model.sakila_dbt_project.my_second_dbt_model
2022-01-14 13:12:27.976795 (MainThread): Acquiring new postgres connection "master".
2022-01-14 13:12:27.977026 (MainThread): Using postgres connection "master".
2022-01-14 13:12:27.977197 (MainThread): On master: BEGIN
2022-01-14 13:12:27.977367 (MainThread): Opening a new connection, currently in state closed
2022-01-14 13:12:28.320511 (MainThread): SQL status: BEGIN in 0.34 seconds
2022-01-14 13:12:28.320920 (MainThread): On master: COMMIT
2022-01-14 13:12:28.321182 (MainThread): Using postgres connection "master".
2022-01-14 13:12:28.321425 (MainThread): On master: COMMIT
2022-01-14 13:12:28.376151 (MainThread): SQL status: COMMIT in 0.05 seconds
2022-01-14 13:12:28.376576 (MainThread): On master: Close
2022-01-14 13:12:28.377294 (MainThread): 18:42:28 | 
2022-01-14 13:12:28.377652 (MainThread): 18:42:28 | Finished running 2 table models, 2 view models in 5.83s.
2022-01-14 13:12:28.377889 (MainThread): Connection 'master' was properly closed.
2022-01-14 13:12:28.378078 (MainThread): Connection 'model.sakila_dbt_project.my_second_dbt_model' was properly closed.
2022-01-14 13:12:28.389014 (MainThread): 
2022-01-14 13:12:28.389328 (MainThread): Completed successfully
2022-01-14 13:12:28.389558 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2022-01-14 13:12:28.389832 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10afb9b80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b325940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b325ee0>]}
2022-01-14 13:12:28.390112 (MainThread): Flushing usage events
2022-01-14 16:27:10.178994 (MainThread): Running with dbt=0.21.1
2022-01-14 16:27:10.300763 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2022-01-14 16:27:10.303536 (MainThread): Tracking: tracking
2022-01-14 16:27:10.335237 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e48070>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e29a30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e3a6d0>]}
2022-01-14 16:27:10.359819 (MainThread): Partial parsing not enabled
2022-01-14 16:27:10.418952 (MainThread): Parsing macros/catalog.sql
2022-01-14 16:27:10.422909 (MainThread): Parsing macros/relations.sql
2022-01-14 16:27:10.424433 (MainThread): Parsing macros/adapters.sql
2022-01-14 16:27:10.450520 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2022-01-14 16:27:10.452544 (MainThread): Parsing macros/core.sql
2022-01-14 16:27:10.456705 (MainThread): Parsing macros/materializations/test.sql
2022-01-14 16:27:10.464199 (MainThread): Parsing macros/materializations/helpers.sql
2022-01-14 16:27:10.474984 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2022-01-14 16:27:10.476826 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2022-01-14 16:27:10.493388 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2022-01-14 16:27:10.523558 (MainThread): Parsing macros/materializations/seed/seed.sql
2022-01-14 16:27:10.545172 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2022-01-14 16:27:10.546839 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2022-01-14 16:27:10.556340 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2022-01-14 16:27:10.575116 (MainThread): Parsing macros/materializations/common/merge.sql
2022-01-14 16:27:10.588338 (MainThread): Parsing macros/materializations/table/table.sql
2022-01-14 16:27:10.595787 (MainThread): Parsing macros/materializations/view/view.sql
2022-01-14 16:27:10.602502 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2022-01-14 16:27:10.606121 (MainThread): Parsing macros/etc/get_custom_alias.sql
2022-01-14 16:27:10.607491 (MainThread): Parsing macros/etc/query.sql
2022-01-14 16:27:10.608380 (MainThread): Parsing macros/etc/is_incremental.sql
2022-01-14 16:27:10.609752 (MainThread): Parsing macros/etc/datetime.sql
2022-01-14 16:27:10.617749 (MainThread): Parsing macros/etc/where_subquery.sql
2022-01-14 16:27:10.619454 (MainThread): Parsing macros/etc/get_custom_schema.sql
2022-01-14 16:27:10.621751 (MainThread): Parsing macros/etc/get_custom_database.sql
2022-01-14 16:27:10.623227 (MainThread): Parsing macros/adapters/common.sql
2022-01-14 16:27:10.675092 (MainThread): Parsing macros/schema_tests/relationships.sql
2022-01-14 16:27:10.676650 (MainThread): Parsing macros/schema_tests/not_null.sql
2022-01-14 16:27:10.677740 (MainThread): Parsing macros/schema_tests/unique.sql
2022-01-14 16:27:10.678964 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2022-01-14 16:27:10.681344 (MainThread): Parsing macros/cross_db_utils/except.sql
2022-01-14 16:27:10.682660 (MainThread): Parsing macros/cross_db_utils/replace.sql
2022-01-14 16:27:10.683853 (MainThread): Parsing macros/cross_db_utils/concat.sql
2022-01-14 16:27:10.684813 (MainThread): Parsing macros/cross_db_utils/datatypes.sql
2022-01-14 16:27:10.690477 (MainThread): Parsing macros/cross_db_utils/_is_relation.sql
2022-01-14 16:27:10.691548 (MainThread): Parsing macros/cross_db_utils/length.sql
2022-01-14 16:27:10.692839 (MainThread): Parsing macros/cross_db_utils/dateadd.sql
2022-01-14 16:27:10.695710 (MainThread): Parsing macros/cross_db_utils/intersect.sql
2022-01-14 16:27:10.696685 (MainThread): Parsing macros/cross_db_utils/right.sql
2022-01-14 16:27:10.698834 (MainThread): Parsing macros/cross_db_utils/datediff.sql
2022-01-14 16:27:10.707996 (MainThread): Parsing macros/cross_db_utils/safe_cast.sql
2022-01-14 16:27:10.709809 (MainThread): Parsing macros/cross_db_utils/hash.sql
2022-01-14 16:27:10.711095 (MainThread): Parsing macros/cross_db_utils/cast_bool_to_text.sql
2022-01-14 16:27:10.712444 (MainThread): Parsing macros/cross_db_utils/identifier.sql
2022-01-14 16:27:10.714194 (MainThread): Parsing macros/cross_db_utils/position.sql
2022-01-14 16:27:10.715662 (MainThread): Parsing macros/cross_db_utils/literal.sql
2022-01-14 16:27:10.716542 (MainThread): Parsing macros/cross_db_utils/current_timestamp.sql
2022-01-14 16:27:10.719800 (MainThread): Parsing macros/cross_db_utils/width_bucket.sql
2022-01-14 16:27:10.724482 (MainThread): Parsing macros/cross_db_utils/last_day.sql
2022-01-14 16:27:10.727695 (MainThread): Parsing macros/cross_db_utils/split_part.sql
2022-01-14 16:27:10.729360 (MainThread): Parsing macros/cross_db_utils/date_trunc.sql
2022-01-14 16:27:10.731157 (MainThread): Parsing macros/cross_db_utils/_is_ephemeral.sql
2022-01-14 16:27:10.733072 (MainThread): Parsing macros/materializations/insert_by_period_materialization.sql
2022-01-14 16:27:10.756141 (MainThread): Parsing macros/web/get_url_host.sql
2022-01-14 16:27:10.758051 (MainThread): Parsing macros/web/get_url_path.sql
2022-01-14 16:27:10.760421 (MainThread): Parsing macros/web/get_url_parameter.sql
2022-01-14 16:27:10.761926 (MainThread): Parsing macros/jinja_helpers/pretty_log_format.sql
2022-01-14 16:27:10.762958 (MainThread): Parsing macros/jinja_helpers/pretty_time.sql
2022-01-14 16:27:10.764133 (MainThread): Parsing macros/jinja_helpers/log_info.sql
2022-01-14 16:27:10.765255 (MainThread): Parsing macros/jinja_helpers/slugify.sql
2022-01-14 16:27:10.766332 (MainThread): Parsing macros/schema_tests/fewer_rows_than.sql
2022-01-14 16:27:10.767844 (MainThread): Parsing macros/schema_tests/equal_rowcount.sql
2022-01-14 16:27:10.769328 (MainThread): Parsing macros/schema_tests/relationships_where.sql
2022-01-14 16:27:10.771450 (MainThread): Parsing macros/schema_tests/recency.sql
2022-01-14 16:27:10.773209 (MainThread): Parsing macros/schema_tests/not_constant.sql
2022-01-14 16:27:10.774336 (MainThread): Parsing macros/schema_tests/accepted_range.sql
2022-01-14 16:27:10.776669 (MainThread): Parsing macros/schema_tests/not_accepted_values.sql
2022-01-14 16:27:10.778566 (MainThread): Parsing macros/schema_tests/test_unique_where.sql
2022-01-14 16:27:10.779862 (MainThread): Parsing macros/schema_tests/at_least_one.sql
2022-01-14 16:27:10.781182 (MainThread): Parsing macros/schema_tests/unique_combination_of_columns.sql
2022-01-14 16:27:10.783727 (MainThread): Parsing macros/schema_tests/cardinality_equality.sql
2022-01-14 16:27:10.785517 (MainThread): Parsing macros/schema_tests/expression_is_true.sql
2022-01-14 16:27:10.787379 (MainThread): Parsing macros/schema_tests/sequential_values.sql
2022-01-14 16:27:10.790247 (MainThread): Parsing macros/schema_tests/test_not_null_where.sql
2022-01-14 16:27:10.791566 (MainThread): Parsing macros/schema_tests/equality.sql
2022-01-14 16:27:10.794816 (MainThread): Parsing macros/schema_tests/mutually_exclusive_ranges.sql
2022-01-14 16:27:10.803143 (MainThread): Parsing macros/sql/date_spine.sql
2022-01-14 16:27:10.807433 (MainThread): Parsing macros/sql/nullcheck_table.sql
2022-01-14 16:27:10.808917 (MainThread): Parsing macros/sql/get_relations_by_pattern.sql
2022-01-14 16:27:10.812301 (MainThread): Parsing macros/sql/generate_series.sql
2022-01-14 16:27:10.841605 (MainThread): Parsing macros/sql/get_relations_by_prefix.sql
2022-01-14 16:27:10.845956 (MainThread): Parsing macros/sql/get_tables_by_prefix_sql.sql
2022-01-14 16:27:10.848047 (MainThread): Parsing macros/sql/star.sql
2022-01-14 16:27:10.852247 (MainThread): Parsing macros/sql/unpivot.sql
2022-01-14 16:27:10.862293 (MainThread): Parsing macros/sql/union.sql
2022-01-14 16:27:10.872256 (MainThread): Parsing macros/sql/groupby.sql
2022-01-14 16:27:10.873885 (MainThread): Parsing macros/sql/surrogate_key.sql
2022-01-14 16:27:10.877766 (MainThread): Parsing macros/sql/safe_add.sql
2022-01-14 16:27:10.879582 (MainThread): Parsing macros/sql/nullcheck.sql
2022-01-14 16:27:10.881597 (MainThread): Parsing macros/sql/get_tables_by_pattern_sql.sql
2022-01-14 16:27:10.888698 (MainThread): Parsing macros/sql/get_column_values.sql
2022-01-14 16:27:10.894223 (MainThread): Parsing macros/sql/pivot.sql
2022-01-14 16:27:10.898714 (MainThread): Parsing macros/sql/get_query_results_as_dict.sql
2022-01-14 16:27:10.901191 (MainThread): Parsing macros/sql/haversine_distance.sql
2022-01-14 16:27:11.207764 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-14 16:27:11.216487 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 16:27:11.220559 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-14 16:27:11.223894 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 16:27:11.225370 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-14 16:27:11.227620 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 16:27:11.228838 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-14 16:27:11.232141 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 16:27:11.267188 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 16:27:11.276322 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 16:27:11.278010 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 16:27:11.279787 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 16:27:11.281767 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 16:27:11.283445 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 16:27:11.298236 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 16:27:11.300140 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 16:27:11.323795 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '275ea2bc-a881-413f-85aa-65153ba73b7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106fc2520>]}
2022-01-14 16:27:11.332936 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-01-14 16:27:11.333568 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '275ea2bc-a881-413f-85aa-65153ba73b7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107022340>]}
2022-01-14 16:27:11.333871 (MainThread): Found 4 models, 8 tests, 0 snapshots, 0 analyses, 347 macros, 0 operations, 0 seed files, 12 sources, 0 exposures
2022-01-14 16:27:11.335536 (MainThread): 
2022-01-14 16:27:11.335914 (MainThread): Acquiring new postgres connection "master".
2022-01-14 16:27:11.336812 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_sakila_wh".
2022-01-14 16:27:11.346855 (ThreadPoolExecutor-0_0): Using postgres connection "list_sakila_wh".
2022-01-14 16:27:11.347083 (ThreadPoolExecutor-0_0): On list_sakila_wh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh"} */

    select distinct nspname from pg_namespace
  
2022-01-14 16:27:11.347245 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2022-01-14 16:27:11.728911 (ThreadPoolExecutor-0_0): SQL status: SELECT 9 in 0.38 seconds
2022-01-14 16:27:11.731466 (ThreadPoolExecutor-0_0): On list_sakila_wh: Close
2022-01-14 16:27:11.732595 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "create_sakila_wh_dwh_dwh".
2022-01-14 16:27:11.732929 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "create_sakila_wh_dwh_dwh".
2022-01-14 16:27:11.733156 (ThreadPoolExecutor-0_0): Creating schema ""sakila_wh"."dwh_dwh""
2022-01-14 16:27:11.739227 (ThreadPoolExecutor-0_0): Using postgres connection "create_sakila_wh_dwh_dwh".
2022-01-14 16:27:11.739412 (ThreadPoolExecutor-0_0): On create_sakila_wh_dwh_dwh: BEGIN
2022-01-14 16:27:11.739578 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2022-01-14 16:27:12.065579 (ThreadPoolExecutor-0_0): SQL status: BEGIN in 0.33 seconds
2022-01-14 16:27:12.065968 (ThreadPoolExecutor-0_0): Using postgres connection "create_sakila_wh_dwh_dwh".
2022-01-14 16:27:12.066213 (ThreadPoolExecutor-0_0): On create_sakila_wh_dwh_dwh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "create_sakila_wh_dwh_dwh"} */
create schema if not exists "dwh_dwh"
2022-01-14 16:27:12.119079 (ThreadPoolExecutor-0_0): SQL status: CREATE SCHEMA in 0.05 seconds
2022-01-14 16:27:12.120566 (ThreadPoolExecutor-0_0): On create_sakila_wh_dwh_dwh: COMMIT
2022-01-14 16:27:12.120836 (ThreadPoolExecutor-0_0): Using postgres connection "create_sakila_wh_dwh_dwh".
2022-01-14 16:27:12.121029 (ThreadPoolExecutor-0_0): On create_sakila_wh_dwh_dwh: COMMIT
2022-01-14 16:27:12.176179 (ThreadPoolExecutor-0_0): SQL status: COMMIT in 0.05 seconds
2022-01-14 16:27:12.176653 (ThreadPoolExecutor-0_0): On create_sakila_wh_dwh_dwh: Close
2022-01-14 16:27:12.178434 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_dwh_dwh".
2022-01-14 16:27:12.185333 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh_dwh".
2022-01-14 16:27:12.185557 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_dwh: BEGIN
2022-01-14 16:27:12.185730 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2022-01-14 16:27:12.516595 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.33 seconds
2022-01-14 16:27:12.517155 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh_dwh".
2022-01-14 16:27:12.517413 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_dwh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_dwh_dwh"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dwh_dwh'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dwh_dwh'
  
2022-01-14 16:27:12.575550 (ThreadPoolExecutor-1_0): SQL status: SELECT 0 in 0.06 seconds
2022-01-14 16:27:12.577515 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_dwh: ROLLBACK
2022-01-14 16:27:12.630815 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh_dwh: Close
2022-01-14 16:27:12.637007 (MainThread): Using postgres connection "master".
2022-01-14 16:27:12.637236 (MainThread): On master: BEGIN
2022-01-14 16:27:12.637410 (MainThread): Opening a new connection, currently in state init
2022-01-14 16:27:12.978376 (MainThread): SQL status: BEGIN in 0.34 seconds
2022-01-14 16:27:12.978947 (MainThread): Using postgres connection "master".
2022-01-14 16:27:12.979192 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-14 16:27:13.050156 (MainThread): SQL status: SELECT 47 in 0.07 seconds
2022-01-14 16:27:13.052778 (MainThread): On master: ROLLBACK
2022-01-14 16:27:13.110795 (MainThread): Using postgres connection "master".
2022-01-14 16:27:13.111092 (MainThread): On master: BEGIN
2022-01-14 16:27:13.220045 (MainThread): SQL status: BEGIN in 0.11 seconds
2022-01-14 16:27:13.220548 (MainThread): On master: COMMIT
2022-01-14 16:27:13.220983 (MainThread): Using postgres connection "master".
2022-01-14 16:27:13.221275 (MainThread): On master: COMMIT
2022-01-14 16:27:13.274951 (MainThread): SQL status: COMMIT in 0.05 seconds
2022-01-14 16:27:13.275343 (MainThread): On master: Close
2022-01-14 16:27:13.275851 (MainThread): 21:57:13 | Concurrency: 1 threads (target='dev')
2022-01-14 16:27:13.276155 (MainThread): 21:57:13 | 
2022-01-14 16:27:13.278658 (Thread-1): Began running node model.sakila_dbt_project.dim_date
2022-01-14 16:27:13.279983 (Thread-1): 21:57:13 | 1 of 4 START table model dwh_dwh.dim_date............................ [RUN]
2022-01-14 16:27:13.280419 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-14 16:27:13.280629 (Thread-1): Compiling model.sakila_dbt_project.dim_date
2022-01-14 16:27:13.282304 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_date"
2022-01-14 16:27:13.283660 (Thread-1): finished collecting timing info
2022-01-14 16:27:13.310259 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_date"
2022-01-14 16:27:13.310905 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-14 16:27:13.311069 (Thread-1): On model.sakila_dbt_project.dim_date: BEGIN
2022-01-14 16:27:13.311217 (Thread-1): Opening a new connection, currently in state closed
2022-01-14 16:27:13.638972 (Thread-1): SQL status: BEGIN in 0.33 seconds
2022-01-14 16:27:13.639339 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-14 16:27:13.639584 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */


  create  table "sakila_wh"."dwh_dwh"."dim_date__dbt_tmp"
  as (
    with dates as (
SELECT
       TO_CHAR(datum, 'yyyymmdd')::INT AS date_dim_id,
       datum AS date_key,
       EXTRACT(EPOCH FROM datum) AS epoch,
       TO_CHAR(datum, 'TMDay') AS day_name,
       EXTRACT(ISODOW FROM datum) AS day_of_week,
       EXTRACT(DAY FROM datum) AS day_of_month,
       datum - DATE_TRUNC('quarter', datum)::DATE + 1 AS day_of_quarter,
       EXTRACT(DOY FROM datum) AS day_of_year,
       TO_CHAR(datum, 'W')::INT AS week_of_month,
       EXTRACT(WEEK FROM datum) AS week_of_year,
       EXTRACT(MONTH FROM datum) AS month_actual,
       TO_CHAR(datum, 'TMMonth') AS month_name,
       TO_CHAR(datum, 'Mon') AS month_name_abbreviated,
       EXTRACT(QUARTER FROM datum) AS quarter_actual,
       CASE
           WHEN EXTRACT(QUARTER FROM datum) = 1 THEN 'First'
           WHEN EXTRACT(QUARTER FROM datum) = 2 THEN 'Second'
           WHEN EXTRACT(QUARTER FROM datum) = 3 THEN 'Third'
           WHEN EXTRACT(QUARTER FROM datum) = 4 THEN 'Fourth'
           END AS quarter_name,
       EXTRACT(YEAR FROM datum) AS year_actual,
       datum + (1 - EXTRACT(ISODOW FROM datum))::INT AS first_day_of_week,
       datum + (7 - EXTRACT(ISODOW FROM datum))::INT AS last_day_of_week,
       datum + (1 - EXTRACT(DAY FROM datum))::INT AS first_day_of_month,
       (DATE_TRUNC('MONTH', datum) + INTERVAL '1 MONTH - 1 day')::DATE AS last_day_of_month,
       DATE_TRUNC('quarter', datum)::DATE AS first_day_of_quarter,
       (DATE_TRUNC('quarter', datum) + INTERVAL '3 MONTH - 1 day')::DATE AS last_day_of_quarter,
       TO_DATE(EXTRACT(YEAR FROM datum) || '-01-01', 'YYYY-MM-DD') AS first_day_of_year,
       TO_DATE(EXTRACT(YEAR FROM datum) || '-12-31', 'YYYY-MM-DD') AS last_day_of_year,
       TO_CHAR(datum, 'yyyymm') AS yyyymm,
       CASE
           WHEN EXTRACT(ISODOW FROM datum) IN (6, 7) THEN TRUE
           ELSE FALSE
           END AS weekend_indr
FROM (SELECT '2000-01-01'::DATE + SEQUENCE.DAY AS datum
      FROM GENERATE_SERIES(0, 29219) AS SEQUENCE (DAY)
      GROUP BY SEQUENCE.DAY) DQ
)
select
*
from
dates
where
date_key <= CURRENT_DATE
order by date_dim_id asc
  );
2022-01-14 16:27:14.531695 (Thread-1): SQL status: SELECT 8050 in 0.89 seconds
2022-01-14 16:27:14.538652 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-14 16:27:14.538866 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
alter table "sakila_wh"."dwh_dwh"."dim_date__dbt_tmp" rename to "dim_date"
2022-01-14 16:27:14.594221 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-14 16:27:14.607507 (Thread-1): On model.sakila_dbt_project.dim_date: COMMIT
2022-01-14 16:27:14.607736 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-14 16:27:14.607898 (Thread-1): On model.sakila_dbt_project.dim_date: COMMIT
2022-01-14 16:27:14.664374 (Thread-1): SQL status: COMMIT in 0.06 seconds
2022-01-14 16:27:14.670919 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-14 16:27:14.671147 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
drop table if exists "sakila_wh"."dwh_dwh"."dim_date__dbt_backup" cascade
2022-01-14 16:27:14.724725 (Thread-1): SQL status: DROP TABLE in 0.05 seconds
2022-01-14 16:27:14.726944 (Thread-1): finished collecting timing info
2022-01-14 16:27:14.727280 (Thread-1): On model.sakila_dbt_project.dim_date: Close
2022-01-14 16:27:14.727965 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '275ea2bc-a881-413f-85aa-65153ba73b7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ff0c40>]}
2022-01-14 16:27:14.728438 (Thread-1): 21:57:14 | 1 of 4 OK created table model dwh_dwh.dim_date....................... [SELECT 8050 in 1.45s]
2022-01-14 16:27:14.728698 (Thread-1): Finished running node model.sakila_dbt_project.dim_date
2022-01-14 16:27:14.728946 (Thread-1): Began running node model.sakila_dbt_project.hello_world
2022-01-14 16:27:14.729359 (Thread-1): 21:57:14 | 2 of 4 START view model dwh_dwh.hello_world.......................... [RUN]
2022-01-14 16:27:14.729737 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-14 16:27:14.730023 (Thread-1): Compiling model.sakila_dbt_project.hello_world
2022-01-14 16:27:14.732064 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.hello_world"
2022-01-14 16:27:14.733694 (Thread-1): finished collecting timing info
2022-01-14 16:27:14.753060 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.hello_world"
2022-01-14 16:27:14.754170 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-14 16:27:14.754368 (Thread-1): On model.sakila_dbt_project.hello_world: BEGIN
2022-01-14 16:27:14.754541 (Thread-1): Opening a new connection, currently in state closed
2022-01-14 16:27:15.114105 (Thread-1): SQL status: BEGIN in 0.36 seconds
2022-01-14 16:27:15.114555 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-14 16:27:15.114817 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */

  create view "sakila_wh"."dwh_dwh"."hello_world__dbt_tmp" as (
    select
	customer.customer_id::int,
	customer.store_id::int,
	customer.first_name,
	customer.last_name,
	concat(customer.first_name,' ',customer.last_name) as full_name,
	substring(email from POSITION('@' in email)+1 for char_length(email)-POSITION('@' in email)) as domain,
	customer.email,
	customer.active::int,
	customer.address_id::int,
	address.address,
	city.city_id::int,
	city.city,
	(case when customer.active = 0 then 'no' else 'yes' end)::varchar(100) as "active_desc",
	customer.create_date::timestamp,
	customer.last_update::timestamp
from
	stg.customer as customer

	left join stg.address on 1=1
	and customer.address_id =address.address_id

	left join stg.city on 1=1
	and address.city_id = city.city_id
  );

2022-01-14 16:27:15.188995 (Thread-1): SQL status: CREATE VIEW in 0.07 seconds
2022-01-14 16:27:15.192960 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-14 16:27:15.193184 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
alter table "sakila_wh"."dwh_dwh"."hello_world__dbt_tmp" rename to "hello_world"
2022-01-14 16:27:15.254687 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-14 16:27:15.256082 (Thread-1): On model.sakila_dbt_project.hello_world: COMMIT
2022-01-14 16:27:15.256280 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-14 16:27:15.256440 (Thread-1): On model.sakila_dbt_project.hello_world: COMMIT
2022-01-14 16:27:15.321475 (Thread-1): SQL status: COMMIT in 0.06 seconds
2022-01-14 16:27:15.326234 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-14 16:27:15.326455 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
drop view if exists "sakila_wh"."dwh_dwh"."hello_world__dbt_backup" cascade
2022-01-14 16:27:15.389176 (Thread-1): SQL status: DROP VIEW in 0.06 seconds
2022-01-14 16:27:15.391403 (Thread-1): finished collecting timing info
2022-01-14 16:27:15.391742 (Thread-1): On model.sakila_dbt_project.hello_world: Close
2022-01-14 16:27:15.392389 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '275ea2bc-a881-413f-85aa-65153ba73b7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10719adc0>]}
2022-01-14 16:27:15.392830 (Thread-1): 21:57:15 | 2 of 4 OK created view model dwh_dwh.hello_world..................... [CREATE VIEW in 0.66s]
2022-01-14 16:27:15.393131 (Thread-1): Finished running node model.sakila_dbt_project.hello_world
2022-01-14 16:27:15.393495 (Thread-1): Began running node model.sakila_dbt_project.my_first_dbt_model
2022-01-14 16:27:15.393843 (Thread-1): 21:57:15 | 3 of 4 START table model dwh_dwh.my_first_dbt_model.................. [RUN]
2022-01-14 16:27:15.394393 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-14 16:27:15.394632 (Thread-1): Compiling model.sakila_dbt_project.my_first_dbt_model
2022-01-14 16:27:15.397609 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.my_first_dbt_model"
2022-01-14 16:27:15.398314 (Thread-1): finished collecting timing info
2022-01-14 16:27:15.401001 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.my_first_dbt_model"
2022-01-14 16:27:15.401681 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-14 16:27:15.401872 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: BEGIN
2022-01-14 16:27:15.402046 (Thread-1): Opening a new connection, currently in state closed
2022-01-14 16:27:15.761156 (Thread-1): SQL status: BEGIN in 0.36 seconds
2022-01-14 16:27:15.761554 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-14 16:27:15.761931 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */


  create  table "sakila_wh"."dwh_dwh"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-14 16:27:15.826588 (Thread-1): SQL status: SELECT 2 in 0.06 seconds
2022-01-14 16:27:15.830615 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-14 16:27:15.830858 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
alter table "sakila_wh"."dwh_dwh"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-14 16:27:15.889165 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-14 16:27:15.891617 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: COMMIT
2022-01-14 16:27:15.891981 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-14 16:27:15.892236 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: COMMIT
2022-01-14 16:27:15.948863 (Thread-1): SQL status: COMMIT in 0.06 seconds
2022-01-14 16:27:15.951629 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-14 16:27:15.951867 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
drop table if exists "sakila_wh"."dwh_dwh"."my_first_dbt_model__dbt_backup" cascade
2022-01-14 16:27:16.018093 (Thread-1): SQL status: DROP TABLE in 0.07 seconds
2022-01-14 16:27:16.019909 (Thread-1): finished collecting timing info
2022-01-14 16:27:16.020193 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: Close
2022-01-14 16:27:16.020772 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '275ea2bc-a881-413f-85aa-65153ba73b7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10718b1c0>]}
2022-01-14 16:27:16.021228 (Thread-1): 21:57:16 | 3 of 4 OK created table model dwh_dwh.my_first_dbt_model............. [SELECT 2 in 0.63s]
2022-01-14 16:27:16.021494 (Thread-1): Finished running node model.sakila_dbt_project.my_first_dbt_model
2022-01-14 16:27:16.023351 (Thread-1): Began running node model.sakila_dbt_project.my_second_dbt_model
2022-01-14 16:27:16.023780 (Thread-1): 21:57:16 | 4 of 4 START view model dwh_dwh.my_second_dbt_model.................. [RUN]
2022-01-14 16:27:16.024221 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-14 16:27:16.024457 (Thread-1): Compiling model.sakila_dbt_project.my_second_dbt_model
2022-01-14 16:27:16.027106 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.my_second_dbt_model"
2022-01-14 16:27:16.027681 (Thread-1): finished collecting timing info
2022-01-14 16:27:16.030384 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.my_second_dbt_model"
2022-01-14 16:27:16.031031 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-14 16:27:16.031212 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: BEGIN
2022-01-14 16:27:16.031386 (Thread-1): Opening a new connection, currently in state closed
2022-01-14 16:27:16.388188 (Thread-1): SQL status: BEGIN in 0.36 seconds
2022-01-14 16:27:16.388725 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-14 16:27:16.389075 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */

  create view "sakila_wh"."dwh_dwh"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "sakila_wh"."dwh_dwh"."my_first_dbt_model"
where id = 1
  );

2022-01-14 16:27:16.450293 (Thread-1): SQL status: CREATE VIEW in 0.06 seconds
2022-01-14 16:27:16.453970 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-14 16:27:16.454233 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
alter table "sakila_wh"."dwh_dwh"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-14 16:27:16.512015 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-14 16:27:16.514063 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: COMMIT
2022-01-14 16:27:16.514301 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-14 16:27:16.514495 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: COMMIT
2022-01-14 16:27:16.571541 (Thread-1): SQL status: COMMIT in 0.06 seconds
2022-01-14 16:27:16.574569 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-14 16:27:16.574814 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
drop view if exists "sakila_wh"."dwh_dwh"."my_second_dbt_model__dbt_backup" cascade
2022-01-14 16:27:16.637989 (Thread-1): SQL status: DROP VIEW in 0.06 seconds
2022-01-14 16:27:16.640175 (Thread-1): finished collecting timing info
2022-01-14 16:27:16.640516 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: Close
2022-01-14 16:27:16.641184 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '275ea2bc-a881-413f-85aa-65153ba73b7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10707f8e0>]}
2022-01-14 16:27:16.641683 (Thread-1): 21:57:16 | 4 of 4 OK created view model dwh_dwh.my_second_dbt_model............. [CREATE VIEW in 0.62s]
2022-01-14 16:27:16.641948 (Thread-1): Finished running node model.sakila_dbt_project.my_second_dbt_model
2022-01-14 16:27:16.643061 (MainThread): Acquiring new postgres connection "master".
2022-01-14 16:27:16.643280 (MainThread): Using postgres connection "master".
2022-01-14 16:27:16.643439 (MainThread): On master: BEGIN
2022-01-14 16:27:16.643598 (MainThread): Opening a new connection, currently in state closed
2022-01-14 16:27:17.003187 (MainThread): SQL status: BEGIN in 0.36 seconds
2022-01-14 16:27:17.003612 (MainThread): On master: COMMIT
2022-01-14 16:27:17.003873 (MainThread): Using postgres connection "master".
2022-01-14 16:27:17.004106 (MainThread): On master: COMMIT
2022-01-14 16:27:17.060377 (MainThread): SQL status: COMMIT in 0.06 seconds
2022-01-14 16:27:17.060979 (MainThread): On master: Close
2022-01-14 16:27:17.061670 (MainThread): 21:57:17 | 
2022-01-14 16:27:17.062002 (MainThread): 21:57:17 | Finished running 2 table models, 2 view models in 5.73s.
2022-01-14 16:27:17.062295 (MainThread): Connection 'master' was properly closed.
2022-01-14 16:27:17.062554 (MainThread): Connection 'model.sakila_dbt_project.my_second_dbt_model' was properly closed.
2022-01-14 16:27:17.074114 (MainThread): 
2022-01-14 16:27:17.074378 (MainThread): Completed successfully
2022-01-14 16:27:17.074584 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2022-01-14 16:27:17.074834 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106e5de50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071cd7c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071cd160>]}
2022-01-14 16:27:17.075100 (MainThread): Flushing usage events
2022-01-14 16:33:18.789832 (MainThread): Running with dbt=0.21.1
2022-01-14 16:33:18.900516 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2022-01-14 16:33:18.903379 (MainThread): Tracking: tracking
2022-01-14 16:33:18.931544 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1110525b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111647ca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111647310>]}
2022-01-14 16:33:18.955730 (MainThread): Partial parsing not enabled
2022-01-14 16:33:19.012035 (MainThread): Parsing macros/catalog.sql
2022-01-14 16:33:19.015761 (MainThread): Parsing macros/relations.sql
2022-01-14 16:33:19.017308 (MainThread): Parsing macros/adapters.sql
2022-01-14 16:33:19.042093 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2022-01-14 16:33:19.043705 (MainThread): Parsing macros/core.sql
2022-01-14 16:33:19.047003 (MainThread): Parsing macros/materializations/test.sql
2022-01-14 16:33:19.053784 (MainThread): Parsing macros/materializations/helpers.sql
2022-01-14 16:33:19.062996 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2022-01-14 16:33:19.064743 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2022-01-14 16:33:19.080849 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2022-01-14 16:33:19.111002 (MainThread): Parsing macros/materializations/seed/seed.sql
2022-01-14 16:33:19.132054 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2022-01-14 16:33:19.133656 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2022-01-14 16:33:19.143096 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2022-01-14 16:33:19.161335 (MainThread): Parsing macros/materializations/common/merge.sql
2022-01-14 16:33:19.174388 (MainThread): Parsing macros/materializations/table/table.sql
2022-01-14 16:33:19.182012 (MainThread): Parsing macros/materializations/view/view.sql
2022-01-14 16:33:19.188630 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2022-01-14 16:33:19.192083 (MainThread): Parsing macros/etc/get_custom_alias.sql
2022-01-14 16:33:19.193414 (MainThread): Parsing macros/etc/query.sql
2022-01-14 16:33:19.194293 (MainThread): Parsing macros/etc/is_incremental.sql
2022-01-14 16:33:19.195646 (MainThread): Parsing macros/etc/datetime.sql
2022-01-14 16:33:19.203963 (MainThread): Parsing macros/etc/where_subquery.sql
2022-01-14 16:33:19.205633 (MainThread): Parsing macros/etc/get_custom_schema.sql
2022-01-14 16:33:19.207801 (MainThread): Parsing macros/etc/get_custom_database.sql
2022-01-14 16:33:19.209227 (MainThread): Parsing macros/adapters/common.sql
2022-01-14 16:33:19.261156 (MainThread): Parsing macros/schema_tests/relationships.sql
2022-01-14 16:33:19.263023 (MainThread): Parsing macros/schema_tests/not_null.sql
2022-01-14 16:33:19.264314 (MainThread): Parsing macros/schema_tests/unique.sql
2022-01-14 16:33:19.265567 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2022-01-14 16:33:19.267565 (MainThread): Parsing macros/cross_db_utils/except.sql
2022-01-14 16:33:19.268538 (MainThread): Parsing macros/cross_db_utils/replace.sql
2022-01-14 16:33:19.269691 (MainThread): Parsing macros/cross_db_utils/concat.sql
2022-01-14 16:33:19.270663 (MainThread): Parsing macros/cross_db_utils/datatypes.sql
2022-01-14 16:33:19.276068 (MainThread): Parsing macros/cross_db_utils/_is_relation.sql
2022-01-14 16:33:19.277105 (MainThread): Parsing macros/cross_db_utils/length.sql
2022-01-14 16:33:19.278297 (MainThread): Parsing macros/cross_db_utils/dateadd.sql
2022-01-14 16:33:19.281643 (MainThread): Parsing macros/cross_db_utils/intersect.sql
2022-01-14 16:33:19.282739 (MainThread): Parsing macros/cross_db_utils/right.sql
2022-01-14 16:33:19.284805 (MainThread): Parsing macros/cross_db_utils/datediff.sql
2022-01-14 16:33:19.293972 (MainThread): Parsing macros/cross_db_utils/safe_cast.sql
2022-01-14 16:33:19.295647 (MainThread): Parsing macros/cross_db_utils/hash.sql
2022-01-14 16:33:19.296997 (MainThread): Parsing macros/cross_db_utils/cast_bool_to_text.sql
2022-01-14 16:33:19.298436 (MainThread): Parsing macros/cross_db_utils/identifier.sql
2022-01-14 16:33:19.299980 (MainThread): Parsing macros/cross_db_utils/position.sql
2022-01-14 16:33:19.301403 (MainThread): Parsing macros/cross_db_utils/literal.sql
2022-01-14 16:33:19.302327 (MainThread): Parsing macros/cross_db_utils/current_timestamp.sql
2022-01-14 16:33:19.305773 (MainThread): Parsing macros/cross_db_utils/width_bucket.sql
2022-01-14 16:33:19.310856 (MainThread): Parsing macros/cross_db_utils/last_day.sql
2022-01-14 16:33:19.314391 (MainThread): Parsing macros/cross_db_utils/split_part.sql
2022-01-14 16:33:19.316135 (MainThread): Parsing macros/cross_db_utils/date_trunc.sql
2022-01-14 16:33:19.317629 (MainThread): Parsing macros/cross_db_utils/_is_ephemeral.sql
2022-01-14 16:33:19.319417 (MainThread): Parsing macros/materializations/insert_by_period_materialization.sql
2022-01-14 16:33:19.342809 (MainThread): Parsing macros/web/get_url_host.sql
2022-01-14 16:33:19.344525 (MainThread): Parsing macros/web/get_url_path.sql
2022-01-14 16:33:19.347017 (MainThread): Parsing macros/web/get_url_parameter.sql
2022-01-14 16:33:19.348723 (MainThread): Parsing macros/jinja_helpers/pretty_log_format.sql
2022-01-14 16:33:19.349774 (MainThread): Parsing macros/jinja_helpers/pretty_time.sql
2022-01-14 16:33:19.350892 (MainThread): Parsing macros/jinja_helpers/log_info.sql
2022-01-14 16:33:19.351923 (MainThread): Parsing macros/jinja_helpers/slugify.sql
2022-01-14 16:33:19.353007 (MainThread): Parsing macros/schema_tests/fewer_rows_than.sql
2022-01-14 16:33:19.354545 (MainThread): Parsing macros/schema_tests/equal_rowcount.sql
2022-01-14 16:33:19.356037 (MainThread): Parsing macros/schema_tests/relationships_where.sql
2022-01-14 16:33:19.358130 (MainThread): Parsing macros/schema_tests/recency.sql
2022-01-14 16:33:19.359758 (MainThread): Parsing macros/schema_tests/not_constant.sql
2022-01-14 16:33:19.360888 (MainThread): Parsing macros/schema_tests/accepted_range.sql
2022-01-14 16:33:19.363353 (MainThread): Parsing macros/schema_tests/not_accepted_values.sql
2022-01-14 16:33:19.365480 (MainThread): Parsing macros/schema_tests/test_unique_where.sql
2022-01-14 16:33:19.366858 (MainThread): Parsing macros/schema_tests/at_least_one.sql
2022-01-14 16:33:19.368018 (MainThread): Parsing macros/schema_tests/unique_combination_of_columns.sql
2022-01-14 16:33:19.370597 (MainThread): Parsing macros/schema_tests/cardinality_equality.sql
2022-01-14 16:33:19.372415 (MainThread): Parsing macros/schema_tests/expression_is_true.sql
2022-01-14 16:33:19.374053 (MainThread): Parsing macros/schema_tests/sequential_values.sql
2022-01-14 16:33:19.376777 (MainThread): Parsing macros/schema_tests/test_not_null_where.sql
2022-01-14 16:33:19.378085 (MainThread): Parsing macros/schema_tests/equality.sql
2022-01-14 16:33:19.381622 (MainThread): Parsing macros/schema_tests/mutually_exclusive_ranges.sql
2022-01-14 16:33:19.389887 (MainThread): Parsing macros/sql/date_spine.sql
2022-01-14 16:33:19.394119 (MainThread): Parsing macros/sql/nullcheck_table.sql
2022-01-14 16:33:19.395611 (MainThread): Parsing macros/sql/get_relations_by_pattern.sql
2022-01-14 16:33:19.399049 (MainThread): Parsing macros/sql/generate_series.sql
2022-01-14 16:33:19.427715 (MainThread): Parsing macros/sql/get_relations_by_prefix.sql
2022-01-14 16:33:19.432256 (MainThread): Parsing macros/sql/get_tables_by_prefix_sql.sql
2022-01-14 16:33:19.434401 (MainThread): Parsing macros/sql/star.sql
2022-01-14 16:33:19.438539 (MainThread): Parsing macros/sql/unpivot.sql
2022-01-14 16:33:19.448600 (MainThread): Parsing macros/sql/union.sql
2022-01-14 16:33:19.460430 (MainThread): Parsing macros/sql/groupby.sql
2022-01-14 16:33:19.462230 (MainThread): Parsing macros/sql/surrogate_key.sql
2022-01-14 16:33:19.466340 (MainThread): Parsing macros/sql/safe_add.sql
2022-01-14 16:33:19.468170 (MainThread): Parsing macros/sql/nullcheck.sql
2022-01-14 16:33:19.469969 (MainThread): Parsing macros/sql/get_tables_by_pattern_sql.sql
2022-01-14 16:33:19.476902 (MainThread): Parsing macros/sql/get_column_values.sql
2022-01-14 16:33:19.482509 (MainThread): Parsing macros/sql/pivot.sql
2022-01-14 16:33:19.486897 (MainThread): Parsing macros/sql/get_query_results_as_dict.sql
2022-01-14 16:33:19.489365 (MainThread): Parsing macros/sql/haversine_distance.sql
2022-01-14 16:33:19.785784 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-14 16:33:19.797223 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-14 16:33:19.800803 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-14 16:33:19.803701 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-14 16:33:19.836515 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 16:33:19.845516 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 16:33:19.847258 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 16:33:19.849172 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 16:33:19.850803 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 16:33:19.852421 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 16:33:19.866919 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 16:33:19.868575 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 16:33:19.890972 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b4766e02-a148-4598-a500-dceeb05efa13', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11181a0d0>]}
2022-01-14 16:33:19.898664 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-01-14 16:33:19.899154 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b4766e02-a148-4598-a500-dceeb05efa13', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11181afd0>]}
2022-01-14 16:33:19.899400 (MainThread): Found 4 models, 8 tests, 0 snapshots, 0 analyses, 347 macros, 0 operations, 0 seed files, 12 sources, 0 exposures
2022-01-14 16:33:19.900721 (MainThread): 
2022-01-14 16:33:19.901026 (MainThread): Acquiring new postgres connection "master".
2022-01-14 16:33:19.901917 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_sakila_wh".
2022-01-14 16:33:19.910901 (ThreadPoolExecutor-0_0): Using postgres connection "list_sakila_wh".
2022-01-14 16:33:19.911099 (ThreadPoolExecutor-0_0): On list_sakila_wh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh"} */

    select distinct nspname from pg_namespace
  
2022-01-14 16:33:19.911265 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2022-01-14 16:33:20.293308 (ThreadPoolExecutor-0_0): SQL status: SELECT 9 in 0.38 seconds
2022-01-14 16:33:20.295766 (ThreadPoolExecutor-0_0): On list_sakila_wh: Close
2022-01-14 16:33:20.296706 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "create_sakila_wh_dwh".
2022-01-14 16:33:20.297086 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "create_sakila_wh_dwh".
2022-01-14 16:33:20.297363 (ThreadPoolExecutor-0_0): Creating schema ""sakila_wh"."dwh""
2022-01-14 16:33:20.303731 (ThreadPoolExecutor-0_0): Using postgres connection "create_sakila_wh_dwh".
2022-01-14 16:33:20.303961 (ThreadPoolExecutor-0_0): On create_sakila_wh_dwh: BEGIN
2022-01-14 16:33:20.304139 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state closed
2022-01-14 16:33:20.632001 (ThreadPoolExecutor-0_0): SQL status: BEGIN in 0.33 seconds
2022-01-14 16:33:20.632394 (ThreadPoolExecutor-0_0): Using postgres connection "create_sakila_wh_dwh".
2022-01-14 16:33:20.632648 (ThreadPoolExecutor-0_0): On create_sakila_wh_dwh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "create_sakila_wh_dwh"} */
create schema if not exists "dwh"
2022-01-14 16:33:20.688479 (ThreadPoolExecutor-0_0): SQL status: CREATE SCHEMA in 0.06 seconds
2022-01-14 16:33:20.690196 (ThreadPoolExecutor-0_0): On create_sakila_wh_dwh: COMMIT
2022-01-14 16:33:20.690488 (ThreadPoolExecutor-0_0): Using postgres connection "create_sakila_wh_dwh".
2022-01-14 16:33:20.690737 (ThreadPoolExecutor-0_0): On create_sakila_wh_dwh: COMMIT
2022-01-14 16:33:20.743893 (ThreadPoolExecutor-0_0): SQL status: COMMIT in 0.05 seconds
2022-01-14 16:33:20.744368 (ThreadPoolExecutor-0_0): On create_sakila_wh_dwh: Close
2022-01-14 16:33:20.745992 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_dwh".
2022-01-14 16:33:20.752445 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-14 16:33:20.752661 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: BEGIN
2022-01-14 16:33:20.752837 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2022-01-14 16:33:21.093854 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.34 seconds
2022-01-14 16:33:21.094448 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-14 16:33:21.094768 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_dwh"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dwh'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dwh'
  
2022-01-14 16:33:21.152947 (ThreadPoolExecutor-1_0): SQL status: SELECT 0 in 0.06 seconds
2022-01-14 16:33:21.155252 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: ROLLBACK
2022-01-14 16:33:21.212706 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: Close
2022-01-14 16:33:21.218935 (MainThread): Using postgres connection "master".
2022-01-14 16:33:21.219176 (MainThread): On master: BEGIN
2022-01-14 16:33:21.219361 (MainThread): Opening a new connection, currently in state init
2022-01-14 16:33:21.544499 (MainThread): SQL status: BEGIN in 0.33 seconds
2022-01-14 16:33:21.544916 (MainThread): Using postgres connection "master".
2022-01-14 16:33:21.545192 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-14 16:33:21.613926 (MainThread): SQL status: SELECT 47 in 0.07 seconds
2022-01-14 16:33:21.617137 (MainThread): On master: ROLLBACK
2022-01-14 16:33:21.670942 (MainThread): Using postgres connection "master".
2022-01-14 16:33:21.671542 (MainThread): On master: BEGIN
2022-01-14 16:33:21.778839 (MainThread): SQL status: BEGIN in 0.11 seconds
2022-01-14 16:33:21.779426 (MainThread): On master: COMMIT
2022-01-14 16:33:21.779690 (MainThread): Using postgres connection "master".
2022-01-14 16:33:21.779932 (MainThread): On master: COMMIT
2022-01-14 16:33:21.832072 (MainThread): SQL status: COMMIT in 0.05 seconds
2022-01-14 16:33:21.832503 (MainThread): On master: Close
2022-01-14 16:33:21.833079 (MainThread): 22:03:21 | Concurrency: 1 threads (target='dev')
2022-01-14 16:33:21.833359 (MainThread): 22:03:21 | 
2022-01-14 16:33:21.836698 (Thread-1): Began running node model.sakila_dbt_project.dim_date
2022-01-14 16:33:21.838200 (Thread-1): 22:03:21 | 1 of 4 START table model dwh.dim_date................................ [RUN]
2022-01-14 16:33:21.838675 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-14 16:33:21.838894 (Thread-1): Compiling model.sakila_dbt_project.dim_date
2022-01-14 16:33:21.840588 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_date"
2022-01-14 16:33:21.842061 (Thread-1): finished collecting timing info
2022-01-14 16:33:21.871095 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_date"
2022-01-14 16:33:21.871767 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-14 16:33:21.871943 (Thread-1): On model.sakila_dbt_project.dim_date: BEGIN
2022-01-14 16:33:21.872138 (Thread-1): Opening a new connection, currently in state closed
2022-01-14 16:33:22.200574 (Thread-1): SQL status: BEGIN in 0.33 seconds
2022-01-14 16:33:22.200987 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-14 16:33:22.201271 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */


  create  table "sakila_wh"."dwh"."dim_date__dbt_tmp"
  as (
    with dates as (
SELECT
       TO_CHAR(datum, 'yyyymmdd')::INT AS date_dim_id,
       datum AS date_key,
       EXTRACT(EPOCH FROM datum) AS epoch,
       TO_CHAR(datum, 'TMDay') AS day_name,
       EXTRACT(ISODOW FROM datum) AS day_of_week,
       EXTRACT(DAY FROM datum) AS day_of_month,
       datum - DATE_TRUNC('quarter', datum)::DATE + 1 AS day_of_quarter,
       EXTRACT(DOY FROM datum) AS day_of_year,
       TO_CHAR(datum, 'W')::INT AS week_of_month,
       EXTRACT(WEEK FROM datum) AS week_of_year,
       EXTRACT(MONTH FROM datum) AS month_actual,
       TO_CHAR(datum, 'TMMonth') AS month_name,
       TO_CHAR(datum, 'Mon') AS month_name_abbreviated,
       EXTRACT(QUARTER FROM datum) AS quarter_actual,
       CASE
           WHEN EXTRACT(QUARTER FROM datum) = 1 THEN 'First'
           WHEN EXTRACT(QUARTER FROM datum) = 2 THEN 'Second'
           WHEN EXTRACT(QUARTER FROM datum) = 3 THEN 'Third'
           WHEN EXTRACT(QUARTER FROM datum) = 4 THEN 'Fourth'
           END AS quarter_name,
       EXTRACT(YEAR FROM datum) AS year_actual,
       datum + (1 - EXTRACT(ISODOW FROM datum))::INT AS first_day_of_week,
       datum + (7 - EXTRACT(ISODOW FROM datum))::INT AS last_day_of_week,
       datum + (1 - EXTRACT(DAY FROM datum))::INT AS first_day_of_month,
       (DATE_TRUNC('MONTH', datum) + INTERVAL '1 MONTH - 1 day')::DATE AS last_day_of_month,
       DATE_TRUNC('quarter', datum)::DATE AS first_day_of_quarter,
       (DATE_TRUNC('quarter', datum) + INTERVAL '3 MONTH - 1 day')::DATE AS last_day_of_quarter,
       TO_DATE(EXTRACT(YEAR FROM datum) || '-01-01', 'YYYY-MM-DD') AS first_day_of_year,
       TO_DATE(EXTRACT(YEAR FROM datum) || '-12-31', 'YYYY-MM-DD') AS last_day_of_year,
       TO_CHAR(datum, 'yyyymm') AS yyyymm,
       CASE
           WHEN EXTRACT(ISODOW FROM datum) IN (6, 7) THEN TRUE
           ELSE FALSE
           END AS weekend_indr
FROM (SELECT '2000-01-01'::DATE + SEQUENCE.DAY AS datum
      FROM GENERATE_SERIES(0, 29219) AS SEQUENCE (DAY)
      GROUP BY SEQUENCE.DAY) DQ
)
select
*
from
dates
where
date_key <= CURRENT_DATE
order by date_dim_id asc
  );
2022-01-14 16:33:23.180410 (Thread-1): SQL status: SELECT 8050 in 0.98 seconds
2022-01-14 16:33:23.188057 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-14 16:33:23.188282 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
alter table "sakila_wh"."dwh"."dim_date__dbt_tmp" rename to "dim_date"
2022-01-14 16:33:23.242132 (Thread-1): SQL status: ALTER TABLE in 0.05 seconds
2022-01-14 16:33:23.254773 (Thread-1): On model.sakila_dbt_project.dim_date: COMMIT
2022-01-14 16:33:23.255003 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-14 16:33:23.255170 (Thread-1): On model.sakila_dbt_project.dim_date: COMMIT
2022-01-14 16:33:23.309125 (Thread-1): SQL status: COMMIT in 0.05 seconds
2022-01-14 16:33:23.316389 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-14 16:33:23.316611 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
drop table if exists "sakila_wh"."dwh"."dim_date__dbt_backup" cascade
2022-01-14 16:33:23.369628 (Thread-1): SQL status: DROP TABLE in 0.05 seconds
2022-01-14 16:33:23.371819 (Thread-1): finished collecting timing info
2022-01-14 16:33:23.372170 (Thread-1): On model.sakila_dbt_project.dim_date: Close
2022-01-14 16:33:23.372868 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b4766e02-a148-4598-a500-dceeb05efa13', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1118bbd00>]}
2022-01-14 16:33:23.373355 (Thread-1): 22:03:23 | 1 of 4 OK created table model dwh.dim_date........................... [SELECT 8050 in 1.53s]
2022-01-14 16:33:23.373633 (Thread-1): Finished running node model.sakila_dbt_project.dim_date
2022-01-14 16:33:23.373894 (Thread-1): Began running node model.sakila_dbt_project.hello_world
2022-01-14 16:33:23.374335 (Thread-1): 22:03:23 | 2 of 4 START view model dwh.hello_world.............................. [RUN]
2022-01-14 16:33:23.374814 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-14 16:33:23.375059 (Thread-1): Compiling model.sakila_dbt_project.hello_world
2022-01-14 16:33:23.376967 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.hello_world"
2022-01-14 16:33:23.378240 (Thread-1): finished collecting timing info
2022-01-14 16:33:23.397525 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.hello_world"
2022-01-14 16:33:23.398660 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-14 16:33:23.398882 (Thread-1): On model.sakila_dbt_project.hello_world: BEGIN
2022-01-14 16:33:23.399055 (Thread-1): Opening a new connection, currently in state closed
2022-01-14 16:33:23.721895 (Thread-1): SQL status: BEGIN in 0.32 seconds
2022-01-14 16:33:23.722298 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-14 16:33:23.722557 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */

  create view "sakila_wh"."dwh"."hello_world__dbt_tmp" as (
    select
	customer.customer_id::int,
	customer.store_id::int,
	customer.first_name,
	customer.last_name,
	concat(customer.first_name,' ',customer.last_name) as full_name,
	substring(email from POSITION('@' in email)+1 for char_length(email)-POSITION('@' in email)) as domain,
	customer.email,
	customer.active::int,
	customer.address_id::int,
	address.address,
	city.city_id::int,
	city.city,
	(case when customer.active = 0 then 'no' else 'yes' end)::varchar(100) as "active_desc",
	customer.create_date::timestamp,
	customer.last_update::timestamp
from
	stg.customer as customer

	left join stg.address on 1=1
	and customer.address_id =address.address_id

	left join stg.city on 1=1
	and address.city_id = city.city_id
  );

2022-01-14 16:33:23.785696 (Thread-1): SQL status: CREATE VIEW in 0.06 seconds
2022-01-14 16:33:23.789164 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-14 16:33:23.789402 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
alter table "sakila_wh"."dwh"."hello_world__dbt_tmp" rename to "hello_world"
2022-01-14 16:33:23.843014 (Thread-1): SQL status: ALTER TABLE in 0.05 seconds
2022-01-14 16:33:23.844978 (Thread-1): On model.sakila_dbt_project.hello_world: COMMIT
2022-01-14 16:33:23.845264 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-14 16:33:23.845511 (Thread-1): On model.sakila_dbt_project.hello_world: COMMIT
2022-01-14 16:33:23.898757 (Thread-1): SQL status: COMMIT in 0.05 seconds
2022-01-14 16:33:23.902793 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-14 16:33:23.903013 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
drop view if exists "sakila_wh"."dwh"."hello_world__dbt_backup" cascade
2022-01-14 16:33:23.956758 (Thread-1): SQL status: DROP VIEW in 0.05 seconds
2022-01-14 16:33:23.958879 (Thread-1): finished collecting timing info
2022-01-14 16:33:23.959177 (Thread-1): On model.sakila_dbt_project.hello_world: Close
2022-01-14 16:33:23.959737 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b4766e02-a148-4598-a500-dceeb05efa13', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11197cfd0>]}
2022-01-14 16:33:23.960184 (Thread-1): 22:03:23 | 2 of 4 OK created view model dwh.hello_world......................... [CREATE VIEW in 0.59s]
2022-01-14 16:33:23.960450 (Thread-1): Finished running node model.sakila_dbt_project.hello_world
2022-01-14 16:33:23.960716 (Thread-1): Began running node model.sakila_dbt_project.my_first_dbt_model
2022-01-14 16:33:23.961141 (Thread-1): 22:03:23 | 3 of 4 START table model dwh.my_first_dbt_model...................... [RUN]
2022-01-14 16:33:23.961566 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-14 16:33:23.961793 (Thread-1): Compiling model.sakila_dbt_project.my_first_dbt_model
2022-01-14 16:33:23.964659 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.my_first_dbt_model"
2022-01-14 16:33:23.966359 (Thread-1): finished collecting timing info
2022-01-14 16:33:23.968849 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.my_first_dbt_model"
2022-01-14 16:33:23.969413 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-14 16:33:23.969593 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: BEGIN
2022-01-14 16:33:23.969762 (Thread-1): Opening a new connection, currently in state closed
2022-01-14 16:33:24.296967 (Thread-1): SQL status: BEGIN in 0.33 seconds
2022-01-14 16:33:24.297349 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-14 16:33:24.297594 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */


  create  table "sakila_wh"."dwh"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-14 16:33:24.359027 (Thread-1): SQL status: SELECT 2 in 0.06 seconds
2022-01-14 16:33:24.362983 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-14 16:33:24.363227 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
alter table "sakila_wh"."dwh"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-14 16:33:24.415987 (Thread-1): SQL status: ALTER TABLE in 0.05 seconds
2022-01-14 16:33:24.417903 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: COMMIT
2022-01-14 16:33:24.418131 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-14 16:33:24.418412 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: COMMIT
2022-01-14 16:33:24.472105 (Thread-1): SQL status: COMMIT in 0.05 seconds
2022-01-14 16:33:24.475366 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-14 16:33:24.475614 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
drop table if exists "sakila_wh"."dwh"."my_first_dbt_model__dbt_backup" cascade
2022-01-14 16:33:24.528946 (Thread-1): SQL status: DROP TABLE in 0.05 seconds
2022-01-14 16:33:24.530290 (Thread-1): finished collecting timing info
2022-01-14 16:33:24.530585 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: Close
2022-01-14 16:33:24.531180 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b4766e02-a148-4598-a500-dceeb05efa13', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1119fb6d0>]}
2022-01-14 16:33:24.531620 (Thread-1): 22:03:24 | 3 of 4 OK created table model dwh.my_first_dbt_model................. [SELECT 2 in 0.57s]
2022-01-14 16:33:24.531857 (Thread-1): Finished running node model.sakila_dbt_project.my_first_dbt_model
2022-01-14 16:33:24.532405 (Thread-1): Began running node model.sakila_dbt_project.my_second_dbt_model
2022-01-14 16:33:24.532778 (Thread-1): 22:03:24 | 4 of 4 START view model dwh.my_second_dbt_model...................... [RUN]
2022-01-14 16:33:24.533189 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-14 16:33:24.533385 (Thread-1): Compiling model.sakila_dbt_project.my_second_dbt_model
2022-01-14 16:33:24.536050 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.my_second_dbt_model"
2022-01-14 16:33:24.536660 (Thread-1): finished collecting timing info
2022-01-14 16:33:24.539803 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.my_second_dbt_model"
2022-01-14 16:33:24.540467 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-14 16:33:24.540653 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: BEGIN
2022-01-14 16:33:24.540822 (Thread-1): Opening a new connection, currently in state closed
2022-01-14 16:33:24.874955 (Thread-1): SQL status: BEGIN in 0.33 seconds
2022-01-14 16:33:24.875460 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-14 16:33:24.875717 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */

  create view "sakila_wh"."dwh"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "sakila_wh"."dwh"."my_first_dbt_model"
where id = 1
  );

2022-01-14 16:33:24.933054 (Thread-1): SQL status: CREATE VIEW in 0.06 seconds
2022-01-14 16:33:24.936287 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-14 16:33:24.936479 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
alter table "sakila_wh"."dwh"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-14 16:33:24.990717 (Thread-1): SQL status: ALTER TABLE in 0.05 seconds
2022-01-14 16:33:24.992945 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: COMMIT
2022-01-14 16:33:24.993236 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-14 16:33:24.993483 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: COMMIT
2022-01-14 16:33:25.046570 (Thread-1): SQL status: COMMIT in 0.05 seconds
2022-01-14 16:33:25.049735 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-14 16:33:25.049956 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
drop view if exists "sakila_wh"."dwh"."my_second_dbt_model__dbt_backup" cascade
2022-01-14 16:33:25.103106 (Thread-1): SQL status: DROP VIEW in 0.05 seconds
2022-01-14 16:33:25.104703 (Thread-1): finished collecting timing info
2022-01-14 16:33:25.104989 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: Close
2022-01-14 16:33:25.105547 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b4766e02-a148-4598-a500-dceeb05efa13', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1119847c0>]}
2022-01-14 16:33:25.105937 (Thread-1): 22:03:25 | 4 of 4 OK created view model dwh.my_second_dbt_model................. [CREATE VIEW in 0.57s]
2022-01-14 16:33:25.106157 (Thread-1): Finished running node model.sakila_dbt_project.my_second_dbt_model
2022-01-14 16:33:25.107146 (MainThread): Acquiring new postgres connection "master".
2022-01-14 16:33:25.107370 (MainThread): Using postgres connection "master".
2022-01-14 16:33:25.107538 (MainThread): On master: BEGIN
2022-01-14 16:33:25.107705 (MainThread): Opening a new connection, currently in state closed
2022-01-14 16:33:25.434775 (MainThread): SQL status: BEGIN in 0.33 seconds
2022-01-14 16:33:25.435206 (MainThread): On master: COMMIT
2022-01-14 16:33:25.435479 (MainThread): Using postgres connection "master".
2022-01-14 16:33:25.435715 (MainThread): On master: COMMIT
2022-01-14 16:33:25.489211 (MainThread): SQL status: COMMIT in 0.05 seconds
2022-01-14 16:33:25.489821 (MainThread): On master: Close
2022-01-14 16:33:25.490526 (MainThread): 22:03:25 | 
2022-01-14 16:33:25.490857 (MainThread): 22:03:25 | Finished running 2 table models, 2 view models in 5.59s.
2022-01-14 16:33:25.491144 (MainThread): Connection 'master' was properly closed.
2022-01-14 16:33:25.491377 (MainThread): Connection 'model.sakila_dbt_project.my_second_dbt_model' was properly closed.
2022-01-14 16:33:25.502997 (MainThread): 
2022-01-14 16:33:25.503264 (MainThread): Completed successfully
2022-01-14 16:33:25.503474 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2022-01-14 16:33:25.503741 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1117e9a00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1119e4820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1119e49d0>]}
2022-01-14 16:33:25.504004 (MainThread): Flushing usage events
2022-01-14 16:38:22.784340 (MainThread): Running with dbt=0.21.1
2022-01-14 16:38:22.867934 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2022-01-14 16:38:22.869685 (MainThread): Tracking: tracking
2022-01-14 16:38:22.888402 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112f0ac40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112f0d5e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112f0d9a0>]}
2022-01-14 16:38:22.910231 (MainThread): Partial parsing not enabled
2022-01-14 16:38:22.950176 (MainThread): Parsing macros/catalog.sql
2022-01-14 16:38:22.953739 (MainThread): Parsing macros/relations.sql
2022-01-14 16:38:22.955229 (MainThread): Parsing macros/adapters.sql
2022-01-14 16:38:22.977353 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2022-01-14 16:38:22.979013 (MainThread): Parsing macros/core.sql
2022-01-14 16:38:22.982537 (MainThread): Parsing macros/materializations/test.sql
2022-01-14 16:38:22.989099 (MainThread): Parsing macros/materializations/helpers.sql
2022-01-14 16:38:22.998927 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2022-01-14 16:38:23.000722 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2022-01-14 16:38:23.018121 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2022-01-14 16:38:23.048102 (MainThread): Parsing macros/materializations/seed/seed.sql
2022-01-14 16:38:23.069513 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2022-01-14 16:38:23.071142 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2022-01-14 16:38:23.080801 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2022-01-14 16:38:23.099062 (MainThread): Parsing macros/materializations/common/merge.sql
2022-01-14 16:38:23.112302 (MainThread): Parsing macros/materializations/table/table.sql
2022-01-14 16:38:23.119551 (MainThread): Parsing macros/materializations/view/view.sql
2022-01-14 16:38:23.126097 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2022-01-14 16:38:23.130096 (MainThread): Parsing macros/etc/get_custom_alias.sql
2022-01-14 16:38:23.131687 (MainThread): Parsing macros/etc/query.sql
2022-01-14 16:38:23.132595 (MainThread): Parsing macros/etc/is_incremental.sql
2022-01-14 16:38:23.133959 (MainThread): Parsing macros/etc/datetime.sql
2022-01-14 16:38:23.141720 (MainThread): Parsing macros/etc/where_subquery.sql
2022-01-14 16:38:23.143354 (MainThread): Parsing macros/etc/get_custom_schema.sql
2022-01-14 16:38:23.145675 (MainThread): Parsing macros/etc/get_custom_database.sql
2022-01-14 16:38:23.147370 (MainThread): Parsing macros/adapters/common.sql
2022-01-14 16:38:23.199015 (MainThread): Parsing macros/schema_tests/relationships.sql
2022-01-14 16:38:23.200779 (MainThread): Parsing macros/schema_tests/not_null.sql
2022-01-14 16:38:23.201964 (MainThread): Parsing macros/schema_tests/unique.sql
2022-01-14 16:38:23.203179 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2022-01-14 16:38:23.205158 (MainThread): Parsing macros/cross_db_utils/except.sql
2022-01-14 16:38:23.206118 (MainThread): Parsing macros/cross_db_utils/replace.sql
2022-01-14 16:38:23.207341 (MainThread): Parsing macros/cross_db_utils/concat.sql
2022-01-14 16:38:23.208279 (MainThread): Parsing macros/cross_db_utils/datatypes.sql
2022-01-14 16:38:23.214543 (MainThread): Parsing macros/cross_db_utils/_is_relation.sql
2022-01-14 16:38:23.215630 (MainThread): Parsing macros/cross_db_utils/length.sql
2022-01-14 16:38:23.216828 (MainThread): Parsing macros/cross_db_utils/dateadd.sql
2022-01-14 16:38:23.219527 (MainThread): Parsing macros/cross_db_utils/intersect.sql
2022-01-14 16:38:23.220497 (MainThread): Parsing macros/cross_db_utils/right.sql
2022-01-14 16:38:23.222545 (MainThread): Parsing macros/cross_db_utils/datediff.sql
2022-01-14 16:38:23.232264 (MainThread): Parsing macros/cross_db_utils/safe_cast.sql
2022-01-14 16:38:23.234024 (MainThread): Parsing macros/cross_db_utils/hash.sql
2022-01-14 16:38:23.235324 (MainThread): Parsing macros/cross_db_utils/cast_bool_to_text.sql
2022-01-14 16:38:23.236636 (MainThread): Parsing macros/cross_db_utils/identifier.sql
2022-01-14 16:38:23.238154 (MainThread): Parsing macros/cross_db_utils/position.sql
2022-01-14 16:38:23.239574 (MainThread): Parsing macros/cross_db_utils/literal.sql
2022-01-14 16:38:23.240461 (MainThread): Parsing macros/cross_db_utils/current_timestamp.sql
2022-01-14 16:38:23.243928 (MainThread): Parsing macros/cross_db_utils/width_bucket.sql
2022-01-14 16:38:23.248841 (MainThread): Parsing macros/cross_db_utils/last_day.sql
2022-01-14 16:38:23.252253 (MainThread): Parsing macros/cross_db_utils/split_part.sql
2022-01-14 16:38:23.253933 (MainThread): Parsing macros/cross_db_utils/date_trunc.sql
2022-01-14 16:38:23.255398 (MainThread): Parsing macros/cross_db_utils/_is_ephemeral.sql
2022-01-14 16:38:23.257121 (MainThread): Parsing macros/materializations/insert_by_period_materialization.sql
2022-01-14 16:38:23.280727 (MainThread): Parsing macros/web/get_url_host.sql
2022-01-14 16:38:23.282458 (MainThread): Parsing macros/web/get_url_path.sql
2022-01-14 16:38:23.284823 (MainThread): Parsing macros/web/get_url_parameter.sql
2022-01-14 16:38:23.286261 (MainThread): Parsing macros/jinja_helpers/pretty_log_format.sql
2022-01-14 16:38:23.287335 (MainThread): Parsing macros/jinja_helpers/pretty_time.sql
2022-01-14 16:38:23.288465 (MainThread): Parsing macros/jinja_helpers/log_info.sql
2022-01-14 16:38:23.289496 (MainThread): Parsing macros/jinja_helpers/slugify.sql
2022-01-14 16:38:23.290690 (MainThread): Parsing macros/schema_tests/fewer_rows_than.sql
2022-01-14 16:38:23.292223 (MainThread): Parsing macros/schema_tests/equal_rowcount.sql
2022-01-14 16:38:23.293728 (MainThread): Parsing macros/schema_tests/relationships_where.sql
2022-01-14 16:38:23.296191 (MainThread): Parsing macros/schema_tests/recency.sql
2022-01-14 16:38:23.297807 (MainThread): Parsing macros/schema_tests/not_constant.sql
2022-01-14 16:38:23.298936 (MainThread): Parsing macros/schema_tests/accepted_range.sql
2022-01-14 16:38:23.301227 (MainThread): Parsing macros/schema_tests/not_accepted_values.sql
2022-01-14 16:38:23.303191 (MainThread): Parsing macros/schema_tests/test_unique_where.sql
2022-01-14 16:38:23.304498 (MainThread): Parsing macros/schema_tests/at_least_one.sql
2022-01-14 16:38:23.305648 (MainThread): Parsing macros/schema_tests/unique_combination_of_columns.sql
2022-01-14 16:38:23.308318 (MainThread): Parsing macros/schema_tests/cardinality_equality.sql
2022-01-14 16:38:23.310154 (MainThread): Parsing macros/schema_tests/expression_is_true.sql
2022-01-14 16:38:23.312146 (MainThread): Parsing macros/schema_tests/sequential_values.sql
2022-01-14 16:38:23.315106 (MainThread): Parsing macros/schema_tests/test_not_null_where.sql
2022-01-14 16:38:23.316408 (MainThread): Parsing macros/schema_tests/equality.sql
2022-01-14 16:38:23.319597 (MainThread): Parsing macros/schema_tests/mutually_exclusive_ranges.sql
2022-01-14 16:38:23.328138 (MainThread): Parsing macros/sql/date_spine.sql
2022-01-14 16:38:23.332814 (MainThread): Parsing macros/sql/nullcheck_table.sql
2022-01-14 16:38:23.334314 (MainThread): Parsing macros/sql/get_relations_by_pattern.sql
2022-01-14 16:38:23.337561 (MainThread): Parsing macros/sql/generate_series.sql
2022-01-14 16:38:23.365839 (MainThread): Parsing macros/sql/get_relations_by_prefix.sql
2022-01-14 16:38:23.370484 (MainThread): Parsing macros/sql/get_tables_by_prefix_sql.sql
2022-01-14 16:38:23.372631 (MainThread): Parsing macros/sql/star.sql
2022-01-14 16:38:23.376789 (MainThread): Parsing macros/sql/unpivot.sql
2022-01-14 16:38:23.386979 (MainThread): Parsing macros/sql/union.sql
2022-01-14 16:38:23.396858 (MainThread): Parsing macros/sql/groupby.sql
2022-01-14 16:38:23.398419 (MainThread): Parsing macros/sql/surrogate_key.sql
2022-01-14 16:38:23.402214 (MainThread): Parsing macros/sql/safe_add.sql
2022-01-14 16:38:23.404045 (MainThread): Parsing macros/sql/nullcheck.sql
2022-01-14 16:38:23.405862 (MainThread): Parsing macros/sql/get_tables_by_pattern_sql.sql
2022-01-14 16:38:23.413326 (MainThread): Parsing macros/sql/get_column_values.sql
2022-01-14 16:38:23.418742 (MainThread): Parsing macros/sql/pivot.sql
2022-01-14 16:38:23.423048 (MainThread): Parsing macros/sql/get_query_results_as_dict.sql
2022-01-14 16:38:23.425512 (MainThread): Parsing macros/sql/haversine_distance.sql
2022-01-14 16:38:23.725772 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-14 16:38:23.737449 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-14 16:38:23.740870 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-14 16:38:23.743629 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-14 16:38:23.776827 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 16:38:23.785939 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 16:38:23.787704 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 16:38:23.789494 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 16:38:23.791161 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 16:38:23.792792 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 16:38:23.807215 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 16:38:23.808875 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-14 16:38:23.832076 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '265315ec-b8a1-4913-b38c-33f668ad0f4b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1130cb0d0>]}
2022-01-14 16:38:23.839672 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-01-14 16:38:23.840115 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '265315ec-b8a1-4913-b38c-33f668ad0f4b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1130cbfa0>]}
2022-01-14 16:38:23.840345 (MainThread): Found 4 models, 8 tests, 0 snapshots, 0 analyses, 347 macros, 0 operations, 0 seed files, 12 sources, 0 exposures
2022-01-14 16:38:23.841641 (MainThread): 
2022-01-14 16:38:23.841934 (MainThread): Acquiring new postgres connection "master".
2022-01-14 16:38:23.842663 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_sakila_wh".
2022-01-14 16:38:23.851014 (ThreadPoolExecutor-0_0): Using postgres connection "list_sakila_wh".
2022-01-14 16:38:23.851222 (ThreadPoolExecutor-0_0): On list_sakila_wh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh"} */

    select distinct nspname from pg_namespace
  
2022-01-14 16:38:23.851375 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2022-01-14 16:38:24.261900 (ThreadPoolExecutor-0_0): SQL status: SELECT 10 in 0.41 seconds
2022-01-14 16:38:24.264120 (ThreadPoolExecutor-0_0): On list_sakila_wh: Close
2022-01-14 16:38:24.265554 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_dwh".
2022-01-14 16:38:24.272180 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-14 16:38:24.272394 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: BEGIN
2022-01-14 16:38:24.272580 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2022-01-14 16:38:24.596680 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.32 seconds
2022-01-14 16:38:24.597003 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-14 16:38:24.597281 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_dwh"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dwh'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dwh'
  
2022-01-14 16:38:24.656578 (ThreadPoolExecutor-1_0): SQL status: SELECT 4 in 0.06 seconds
2022-01-14 16:38:24.658908 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: ROLLBACK
2022-01-14 16:38:24.711980 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: Close
2022-01-14 16:38:24.717326 (MainThread): Using postgres connection "master".
2022-01-14 16:38:24.717546 (MainThread): On master: BEGIN
2022-01-14 16:38:24.717723 (MainThread): Opening a new connection, currently in state init
2022-01-14 16:38:25.050279 (MainThread): SQL status: BEGIN in 0.33 seconds
2022-01-14 16:38:25.050763 (MainThread): Using postgres connection "master".
2022-01-14 16:38:25.051052 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-14 16:38:25.123907 (MainThread): SQL status: SELECT 51 in 0.07 seconds
2022-01-14 16:38:25.127680 (MainThread): On master: ROLLBACK
2022-01-14 16:38:25.181655 (MainThread): Using postgres connection "master".
2022-01-14 16:38:25.182061 (MainThread): On master: BEGIN
2022-01-14 16:38:25.294370 (MainThread): SQL status: BEGIN in 0.11 seconds
2022-01-14 16:38:25.294781 (MainThread): On master: COMMIT
2022-01-14 16:38:25.295052 (MainThread): Using postgres connection "master".
2022-01-14 16:38:25.295297 (MainThread): On master: COMMIT
2022-01-14 16:38:25.354498 (MainThread): SQL status: COMMIT in 0.06 seconds
2022-01-14 16:38:25.354962 (MainThread): On master: Close
2022-01-14 16:38:25.355668 (MainThread): 22:08:25 | Concurrency: 1 threads (target='dev')
2022-01-14 16:38:25.356033 (MainThread): 22:08:25 | 
2022-01-14 16:38:25.358424 (Thread-1): Began running node model.sakila_dbt_project.dim_date
2022-01-14 16:38:25.358831 (Thread-1): 22:08:25 | 1 of 4 START table model dwh.dim_date................................ [RUN]
2022-01-14 16:38:25.359287 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-14 16:38:25.359495 (Thread-1): Compiling model.sakila_dbt_project.dim_date
2022-01-14 16:38:25.361332 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_date"
2022-01-14 16:38:25.361957 (Thread-1): finished collecting timing info
2022-01-14 16:38:25.389555 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_date"
2022-01-14 16:38:25.390276 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-14 16:38:25.390460 (Thread-1): On model.sakila_dbt_project.dim_date: BEGIN
2022-01-14 16:38:25.390624 (Thread-1): Opening a new connection, currently in state closed
2022-01-14 16:38:25.749249 (Thread-1): SQL status: BEGIN in 0.36 seconds
2022-01-14 16:38:25.749581 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-14 16:38:25.749794 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */


  create  table "sakila_wh"."dwh"."dim_date__dbt_tmp"
  as (
    with dates as (
SELECT
       TO_CHAR(datum, 'yyyymmdd')::INT AS date_dim_id,
       datum AS date_key,
       EXTRACT(EPOCH FROM datum) AS epoch,
       TO_CHAR(datum, 'TMDay') AS day_name,
       EXTRACT(ISODOW FROM datum) AS day_of_week,
       EXTRACT(DAY FROM datum) AS day_of_month,
       datum - DATE_TRUNC('quarter', datum)::DATE + 1 AS day_of_quarter,
       EXTRACT(DOY FROM datum) AS day_of_year,
       TO_CHAR(datum, 'W')::INT AS week_of_month,
       EXTRACT(WEEK FROM datum) AS week_of_year,
       EXTRACT(MONTH FROM datum) AS month_actual,
       TO_CHAR(datum, 'TMMonth') AS month_name,
       TO_CHAR(datum, 'Mon') AS month_name_abbreviated,
       EXTRACT(QUARTER FROM datum) AS quarter_actual,
       CASE
           WHEN EXTRACT(QUARTER FROM datum) = 1 THEN 'First'
           WHEN EXTRACT(QUARTER FROM datum) = 2 THEN 'Second'
           WHEN EXTRACT(QUARTER FROM datum) = 3 THEN 'Third'
           WHEN EXTRACT(QUARTER FROM datum) = 4 THEN 'Fourth'
           END AS quarter_name,
       EXTRACT(YEAR FROM datum) AS year_actual,
       datum + (1 - EXTRACT(ISODOW FROM datum))::INT AS first_day_of_week,
       datum + (7 - EXTRACT(ISODOW FROM datum))::INT AS last_day_of_week,
       datum + (1 - EXTRACT(DAY FROM datum))::INT AS first_day_of_month,
       (DATE_TRUNC('MONTH', datum) + INTERVAL '1 MONTH - 1 day')::DATE AS last_day_of_month,
       DATE_TRUNC('quarter', datum)::DATE AS first_day_of_quarter,
       (DATE_TRUNC('quarter', datum) + INTERVAL '3 MONTH - 1 day')::DATE AS last_day_of_quarter,
       TO_DATE(EXTRACT(YEAR FROM datum) || '-01-01', 'YYYY-MM-DD') AS first_day_of_year,
       TO_DATE(EXTRACT(YEAR FROM datum) || '-12-31', 'YYYY-MM-DD') AS last_day_of_year,
       TO_CHAR(datum, 'yyyymm') AS yyyymm,
       CASE
           WHEN EXTRACT(ISODOW FROM datum) IN (6, 7) THEN TRUE
           ELSE FALSE
           END AS weekend_indr
FROM (SELECT '2000-01-01'::DATE + SEQUENCE.DAY AS datum
      FROM GENERATE_SERIES(0, 29219) AS SEQUENCE (DAY)
      GROUP BY SEQUENCE.DAY) DQ
)
select
*
from
dates
where
date_key <= CURRENT_DATE
order by date_dim_id asc
  );
2022-01-14 16:38:26.787628 (Thread-1): SQL status: SELECT 8050 in 1.04 seconds
2022-01-14 16:38:26.796078 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-14 16:38:26.796307 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
alter table "sakila_wh"."dwh"."dim_date" rename to "dim_date__dbt_backup"
2022-01-14 16:38:26.851264 (Thread-1): SQL status: ALTER TABLE in 0.05 seconds
2022-01-14 16:38:26.854499 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-14 16:38:26.854729 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
alter table "sakila_wh"."dwh"."dim_date__dbt_tmp" rename to "dim_date"
2022-01-14 16:38:26.908553 (Thread-1): SQL status: ALTER TABLE in 0.05 seconds
2022-01-14 16:38:26.921777 (Thread-1): On model.sakila_dbt_project.dim_date: COMMIT
2022-01-14 16:38:26.922021 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-14 16:38:26.922194 (Thread-1): On model.sakila_dbt_project.dim_date: COMMIT
2022-01-14 16:38:26.976551 (Thread-1): SQL status: COMMIT in 0.05 seconds
2022-01-14 16:38:26.983656 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-14 16:38:26.983859 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
drop table if exists "sakila_wh"."dwh"."dim_date__dbt_backup" cascade
2022-01-14 16:38:27.050087 (Thread-1): SQL status: DROP TABLE in 0.07 seconds
2022-01-14 16:38:27.051957 (Thread-1): finished collecting timing info
2022-01-14 16:38:27.052264 (Thread-1): On model.sakila_dbt_project.dim_date: Close
2022-01-14 16:38:27.052848 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '265315ec-b8a1-4913-b38c-33f668ad0f4b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113079520>]}
2022-01-14 16:38:27.053299 (Thread-1): 22:08:27 | 1 of 4 OK created table model dwh.dim_date........................... [SELECT 8050 in 1.69s]
2022-01-14 16:38:27.053573 (Thread-1): Finished running node model.sakila_dbt_project.dim_date
2022-01-14 16:38:27.053837 (Thread-1): Began running node model.sakila_dbt_project.hello_world
2022-01-14 16:38:27.054260 (Thread-1): 22:08:27 | 2 of 4 START table model dwh.hello_world............................. [RUN]
2022-01-14 16:38:27.054645 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-14 16:38:27.054850 (Thread-1): Compiling model.sakila_dbt_project.hello_world
2022-01-14 16:38:27.056612 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.hello_world"
2022-01-14 16:38:27.057214 (Thread-1): finished collecting timing info
2022-01-14 16:38:27.059869 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.hello_world"
2022-01-14 16:38:27.060472 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-14 16:38:27.060656 (Thread-1): On model.sakila_dbt_project.hello_world: BEGIN
2022-01-14 16:38:27.060835 (Thread-1): Opening a new connection, currently in state closed
2022-01-14 16:38:27.391096 (Thread-1): SQL status: BEGIN in 0.33 seconds
2022-01-14 16:38:27.391518 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-14 16:38:27.391725 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */


  create  table "sakila_wh"."dwh"."hello_world__dbt_tmp"
  as (
    select
	customer.customer_id::int,
	customer.store_id::int,
	customer.first_name,
	customer.last_name,
	concat(customer.first_name,' ',customer.last_name) as full_name,
	substring(email from POSITION('@' in email)+1 for char_length(email)-POSITION('@' in email)) as domain,
	customer.email,
	customer.active::int,
	customer.address_id::int,
	address.address,
	city.city_id::int,
	city.city,
	(case when customer.active = 0 then 'no' else 'yes' end)::varchar(100) as "active_desc",
	customer.create_date::timestamp,
	customer.last_update::timestamp
from
	stg.customer as customer

	left join stg.address on 1=1
	and customer.address_id =address.address_id

	left join stg.city on 1=1
	and address.city_id = city.city_id
  );
2022-01-14 16:38:27.462702 (Thread-1): SQL status: SELECT 599 in 0.07 seconds
2022-01-14 16:38:27.466458 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-14 16:38:27.466712 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
alter table "sakila_wh"."dwh"."hello_world" rename to "hello_world__dbt_backup"
2022-01-14 16:38:27.521745 (Thread-1): SQL status: ALTER TABLE in 0.05 seconds
2022-01-14 16:38:27.525802 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-14 16:38:27.526037 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
alter table "sakila_wh"."dwh"."hello_world__dbt_tmp" rename to "hello_world"
2022-01-14 16:38:27.578701 (Thread-1): SQL status: ALTER TABLE in 0.05 seconds
2022-01-14 16:38:27.581113 (Thread-1): On model.sakila_dbt_project.hello_world: COMMIT
2022-01-14 16:38:27.581363 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-14 16:38:27.581565 (Thread-1): On model.sakila_dbt_project.hello_world: COMMIT
2022-01-14 16:38:27.635369 (Thread-1): SQL status: COMMIT in 0.05 seconds
2022-01-14 16:38:27.640232 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-14 16:38:27.640462 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
drop view if exists "sakila_wh"."dwh"."hello_world__dbt_backup" cascade
2022-01-14 16:38:27.695469 (Thread-1): SQL status: DROP VIEW in 0.05 seconds
2022-01-14 16:38:27.696815 (Thread-1): finished collecting timing info
2022-01-14 16:38:27.697047 (Thread-1): On model.sakila_dbt_project.hello_world: Close
2022-01-14 16:38:27.697541 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '265315ec-b8a1-4913-b38c-33f668ad0f4b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11327af10>]}
2022-01-14 16:38:27.697936 (Thread-1): 22:08:27 | 2 of 4 OK created table model dwh.hello_world........................ [SELECT 599 in 0.64s]
2022-01-14 16:38:27.698167 (Thread-1): Finished running node model.sakila_dbt_project.hello_world
2022-01-14 16:38:27.698387 (Thread-1): Began running node model.sakila_dbt_project.my_first_dbt_model
2022-01-14 16:38:27.698762 (Thread-1): 22:08:27 | 3 of 4 START table model dwh.my_first_dbt_model...................... [RUN]
2022-01-14 16:38:27.699125 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-14 16:38:27.699321 (Thread-1): Compiling model.sakila_dbt_project.my_first_dbt_model
2022-01-14 16:38:27.701951 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.my_first_dbt_model"
2022-01-14 16:38:27.702556 (Thread-1): finished collecting timing info
2022-01-14 16:38:27.705076 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.my_first_dbt_model"
2022-01-14 16:38:27.705648 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-14 16:38:27.705832 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: BEGIN
2022-01-14 16:38:27.706004 (Thread-1): Opening a new connection, currently in state closed
2022-01-14 16:38:28.031460 (Thread-1): SQL status: BEGIN in 0.33 seconds
2022-01-14 16:38:28.031774 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-14 16:38:28.031984 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */


  create  table "sakila_wh"."dwh"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-14 16:38:28.090283 (Thread-1): SQL status: SELECT 2 in 0.06 seconds
2022-01-14 16:38:28.093929 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-14 16:38:28.094177 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
alter table "sakila_wh"."dwh"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2022-01-14 16:38:28.148814 (Thread-1): SQL status: ALTER TABLE in 0.05 seconds
2022-01-14 16:38:28.152183 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-14 16:38:28.152429 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
alter table "sakila_wh"."dwh"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-14 16:38:28.205508 (Thread-1): SQL status: ALTER TABLE in 0.05 seconds
2022-01-14 16:38:28.207799 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: COMMIT
2022-01-14 16:38:28.208037 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-14 16:38:28.208286 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: COMMIT
2022-01-14 16:38:28.261256 (Thread-1): SQL status: COMMIT in 0.05 seconds
2022-01-14 16:38:28.263799 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-14 16:38:28.264023 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
drop table if exists "sakila_wh"."dwh"."my_first_dbt_model__dbt_backup" cascade
2022-01-14 16:38:28.320301 (Thread-1): SQL status: DROP TABLE in 0.06 seconds
2022-01-14 16:38:28.322235 (Thread-1): finished collecting timing info
2022-01-14 16:38:28.322520 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: Close
2022-01-14 16:38:28.323067 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '265315ec-b8a1-4913-b38c-33f668ad0f4b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11322dd90>]}
2022-01-14 16:38:28.323516 (Thread-1): 22:08:28 | 3 of 4 OK created table model dwh.my_first_dbt_model................. [SELECT 2 in 0.62s]
2022-01-14 16:38:28.323787 (Thread-1): Finished running node model.sakila_dbt_project.my_first_dbt_model
2022-01-14 16:38:28.324476 (Thread-1): Began running node model.sakila_dbt_project.my_second_dbt_model
2022-01-14 16:38:28.324899 (Thread-1): 22:08:28 | 4 of 4 START table model dwh.my_second_dbt_model..................... [RUN]
2022-01-14 16:38:28.325366 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-14 16:38:28.325602 (Thread-1): Compiling model.sakila_dbt_project.my_second_dbt_model
2022-01-14 16:38:28.328395 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.my_second_dbt_model"
2022-01-14 16:38:28.329022 (Thread-1): finished collecting timing info
2022-01-14 16:38:28.331727 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.my_second_dbt_model"
2022-01-14 16:38:28.332321 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-14 16:38:28.332506 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: BEGIN
2022-01-14 16:38:28.332680 (Thread-1): Opening a new connection, currently in state closed
2022-01-14 16:38:28.653059 (Thread-1): SQL status: BEGIN in 0.32 seconds
2022-01-14 16:38:28.653482 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-14 16:38:28.653759 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */


  create  table "sakila_wh"."dwh"."my_second_dbt_model__dbt_tmp"
  as (
    -- Use the `ref` function to select from other models

select *
from "sakila_wh"."dwh"."my_first_dbt_model"
where id = 1
  );
2022-01-14 16:38:28.718497 (Thread-1): SQL status: SELECT 1 in 0.06 seconds
2022-01-14 16:38:28.722504 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-14 16:38:28.722736 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
alter table "sakila_wh"."dwh"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-14 16:38:28.777766 (Thread-1): SQL status: ALTER TABLE in 0.05 seconds
2022-01-14 16:38:28.779821 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: COMMIT
2022-01-14 16:38:28.780070 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-14 16:38:28.780272 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: COMMIT
2022-01-14 16:38:28.834512 (Thread-1): SQL status: COMMIT in 0.05 seconds
2022-01-14 16:38:28.838975 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-14 16:38:28.839211 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
drop table if exists "sakila_wh"."dwh"."my_second_dbt_model__dbt_backup" cascade
2022-01-14 16:38:28.894327 (Thread-1): SQL status: DROP TABLE in 0.05 seconds
2022-01-14 16:38:28.896539 (Thread-1): finished collecting timing info
2022-01-14 16:38:28.896911 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: Close
2022-01-14 16:38:28.897593 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '265315ec-b8a1-4913-b38c-33f668ad0f4b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113221370>]}
2022-01-14 16:38:28.898022 (Thread-1): 22:08:28 | 4 of 4 OK created table model dwh.my_second_dbt_model................ [SELECT 1 in 0.57s]
2022-01-14 16:38:28.898253 (Thread-1): Finished running node model.sakila_dbt_project.my_second_dbt_model
2022-01-14 16:38:28.899265 (MainThread): Acquiring new postgres connection "master".
2022-01-14 16:38:28.899495 (MainThread): Using postgres connection "master".
2022-01-14 16:38:28.899663 (MainThread): On master: BEGIN
2022-01-14 16:38:28.899831 (MainThread): Opening a new connection, currently in state closed
2022-01-14 16:38:29.223612 (MainThread): SQL status: BEGIN in 0.32 seconds
2022-01-14 16:38:29.223966 (MainThread): On master: COMMIT
2022-01-14 16:38:29.224180 (MainThread): Using postgres connection "master".
2022-01-14 16:38:29.224376 (MainThread): On master: COMMIT
2022-01-14 16:38:29.277806 (MainThread): SQL status: COMMIT in 0.05 seconds
2022-01-14 16:38:29.278302 (MainThread): On master: Close
2022-01-14 16:38:29.279008 (MainThread): 22:08:29 | 
2022-01-14 16:38:29.279351 (MainThread): 22:08:29 | Finished running 4 table models in 5.44s.
2022-01-14 16:38:29.279660 (MainThread): Connection 'master' was properly closed.
2022-01-14 16:38:29.279864 (MainThread): Connection 'model.sakila_dbt_project.my_second_dbt_model' was properly closed.
2022-01-14 16:38:29.289674 (MainThread): 
2022-01-14 16:38:29.289970 (MainThread): Completed successfully
2022-01-14 16:38:29.290211 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2022-01-14 16:38:29.290483 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1131626a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1132210a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1132213d0>]}
2022-01-14 16:38:29.290756 (MainThread): Flushing usage events
2022-01-15 07:16:54.841824 (MainThread): Running with dbt=0.21.1
2022-01-15 07:16:54.978461 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2022-01-15 07:16:54.980359 (MainThread): Tracking: tracking
2022-01-15 07:16:55.005754 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d633640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dc26e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dc26340>]}
2022-01-15 07:16:55.028536 (MainThread): Partial parsing not enabled
2022-01-15 07:16:55.085788 (MainThread): Parsing macros/catalog.sql
2022-01-15 07:16:55.089640 (MainThread): Parsing macros/relations.sql
2022-01-15 07:16:55.091176 (MainThread): Parsing macros/adapters.sql
2022-01-15 07:16:55.115010 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2022-01-15 07:16:55.116796 (MainThread): Parsing macros/core.sql
2022-01-15 07:16:55.120585 (MainThread): Parsing macros/materializations/test.sql
2022-01-15 07:16:55.127001 (MainThread): Parsing macros/materializations/helpers.sql
2022-01-15 07:16:55.136600 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2022-01-15 07:16:55.138220 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2022-01-15 07:16:55.154715 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2022-01-15 07:16:55.185155 (MainThread): Parsing macros/materializations/seed/seed.sql
2022-01-15 07:16:55.206773 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2022-01-15 07:16:55.208400 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2022-01-15 07:16:55.218044 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2022-01-15 07:16:55.236856 (MainThread): Parsing macros/materializations/common/merge.sql
2022-01-15 07:16:55.250213 (MainThread): Parsing macros/materializations/table/table.sql
2022-01-15 07:16:55.257683 (MainThread): Parsing macros/materializations/view/view.sql
2022-01-15 07:16:55.264672 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2022-01-15 07:16:55.268259 (MainThread): Parsing macros/etc/get_custom_alias.sql
2022-01-15 07:16:55.269641 (MainThread): Parsing macros/etc/query.sql
2022-01-15 07:16:55.270548 (MainThread): Parsing macros/etc/is_incremental.sql
2022-01-15 07:16:55.271947 (MainThread): Parsing macros/etc/datetime.sql
2022-01-15 07:16:55.280062 (MainThread): Parsing macros/etc/where_subquery.sql
2022-01-15 07:16:55.281854 (MainThread): Parsing macros/etc/get_custom_schema.sql
2022-01-15 07:16:55.284098 (MainThread): Parsing macros/etc/get_custom_database.sql
2022-01-15 07:16:55.285586 (MainThread): Parsing macros/adapters/common.sql
2022-01-15 07:16:55.337503 (MainThread): Parsing macros/schema_tests/relationships.sql
2022-01-15 07:16:55.339146 (MainThread): Parsing macros/schema_tests/not_null.sql
2022-01-15 07:16:55.340253 (MainThread): Parsing macros/schema_tests/unique.sql
2022-01-15 07:16:55.341494 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2022-01-15 07:16:55.343586 (MainThread): Parsing macros/cross_db_utils/except.sql
2022-01-15 07:16:55.344585 (MainThread): Parsing macros/cross_db_utils/replace.sql
2022-01-15 07:16:55.345927 (MainThread): Parsing macros/cross_db_utils/concat.sql
2022-01-15 07:16:55.346879 (MainThread): Parsing macros/cross_db_utils/datatypes.sql
2022-01-15 07:16:55.352416 (MainThread): Parsing macros/cross_db_utils/_is_relation.sql
2022-01-15 07:16:55.353468 (MainThread): Parsing macros/cross_db_utils/length.sql
2022-01-15 07:16:55.354672 (MainThread): Parsing macros/cross_db_utils/dateadd.sql
2022-01-15 07:16:55.357424 (MainThread): Parsing macros/cross_db_utils/intersect.sql
2022-01-15 07:16:55.358399 (MainThread): Parsing macros/cross_db_utils/right.sql
2022-01-15 07:16:55.360451 (MainThread): Parsing macros/cross_db_utils/datediff.sql
2022-01-15 07:16:55.369884 (MainThread): Parsing macros/cross_db_utils/safe_cast.sql
2022-01-15 07:16:55.371594 (MainThread): Parsing macros/cross_db_utils/hash.sql
2022-01-15 07:16:55.372894 (MainThread): Parsing macros/cross_db_utils/cast_bool_to_text.sql
2022-01-15 07:16:55.374218 (MainThread): Parsing macros/cross_db_utils/identifier.sql
2022-01-15 07:16:55.375827 (MainThread): Parsing macros/cross_db_utils/position.sql
2022-01-15 07:16:55.377249 (MainThread): Parsing macros/cross_db_utils/literal.sql
2022-01-15 07:16:55.378139 (MainThread): Parsing macros/cross_db_utils/current_timestamp.sql
2022-01-15 07:16:55.381914 (MainThread): Parsing macros/cross_db_utils/width_bucket.sql
2022-01-15 07:16:55.386682 (MainThread): Parsing macros/cross_db_utils/last_day.sql
2022-01-15 07:16:55.389868 (MainThread): Parsing macros/cross_db_utils/split_part.sql
2022-01-15 07:16:55.391522 (MainThread): Parsing macros/cross_db_utils/date_trunc.sql
2022-01-15 07:16:55.392978 (MainThread): Parsing macros/cross_db_utils/_is_ephemeral.sql
2022-01-15 07:16:55.394735 (MainThread): Parsing macros/materializations/insert_by_period_materialization.sql
2022-01-15 07:16:55.418611 (MainThread): Parsing macros/web/get_url_host.sql
2022-01-15 07:16:55.420337 (MainThread): Parsing macros/web/get_url_path.sql
2022-01-15 07:16:55.422768 (MainThread): Parsing macros/web/get_url_parameter.sql
2022-01-15 07:16:55.424224 (MainThread): Parsing macros/jinja_helpers/pretty_log_format.sql
2022-01-15 07:16:55.425245 (MainThread): Parsing macros/jinja_helpers/pretty_time.sql
2022-01-15 07:16:55.426359 (MainThread): Parsing macros/jinja_helpers/log_info.sql
2022-01-15 07:16:55.427509 (MainThread): Parsing macros/jinja_helpers/slugify.sql
2022-01-15 07:16:55.428750 (MainThread): Parsing macros/schema_tests/fewer_rows_than.sql
2022-01-15 07:16:55.430379 (MainThread): Parsing macros/schema_tests/equal_rowcount.sql
2022-01-15 07:16:55.431862 (MainThread): Parsing macros/schema_tests/relationships_where.sql
2022-01-15 07:16:55.433971 (MainThread): Parsing macros/schema_tests/recency.sql
2022-01-15 07:16:55.435778 (MainThread): Parsing macros/schema_tests/not_constant.sql
2022-01-15 07:16:55.436911 (MainThread): Parsing macros/schema_tests/accepted_range.sql
2022-01-15 07:16:55.439298 (MainThread): Parsing macros/schema_tests/not_accepted_values.sql
2022-01-15 07:16:55.441428 (MainThread): Parsing macros/schema_tests/test_unique_where.sql
2022-01-15 07:16:55.442753 (MainThread): Parsing macros/schema_tests/at_least_one.sql
2022-01-15 07:16:55.444036 (MainThread): Parsing macros/schema_tests/unique_combination_of_columns.sql
2022-01-15 07:16:55.446844 (MainThread): Parsing macros/schema_tests/cardinality_equality.sql
2022-01-15 07:16:55.448706 (MainThread): Parsing macros/schema_tests/expression_is_true.sql
2022-01-15 07:16:55.450328 (MainThread): Parsing macros/schema_tests/sequential_values.sql
2022-01-15 07:16:55.453201 (MainThread): Parsing macros/schema_tests/test_not_null_where.sql
2022-01-15 07:16:55.454582 (MainThread): Parsing macros/schema_tests/equality.sql
2022-01-15 07:16:55.457850 (MainThread): Parsing macros/schema_tests/mutually_exclusive_ranges.sql
2022-01-15 07:16:55.466085 (MainThread): Parsing macros/sql/date_spine.sql
2022-01-15 07:16:55.470375 (MainThread): Parsing macros/sql/nullcheck_table.sql
2022-01-15 07:16:55.471989 (MainThread): Parsing macros/sql/get_relations_by_pattern.sql
2022-01-15 07:16:55.475082 (MainThread): Parsing macros/sql/generate_series.sql
2022-01-15 07:16:55.504596 (MainThread): Parsing macros/sql/get_relations_by_prefix.sql
2022-01-15 07:16:55.508996 (MainThread): Parsing macros/sql/get_tables_by_prefix_sql.sql
2022-01-15 07:16:55.511128 (MainThread): Parsing macros/sql/star.sql
2022-01-15 07:16:55.515430 (MainThread): Parsing macros/sql/unpivot.sql
2022-01-15 07:16:55.525603 (MainThread): Parsing macros/sql/union.sql
2022-01-15 07:16:55.535253 (MainThread): Parsing macros/sql/groupby.sql
2022-01-15 07:16:55.536831 (MainThread): Parsing macros/sql/surrogate_key.sql
2022-01-15 07:16:55.540665 (MainThread): Parsing macros/sql/safe_add.sql
2022-01-15 07:16:55.542469 (MainThread): Parsing macros/sql/nullcheck.sql
2022-01-15 07:16:55.544331 (MainThread): Parsing macros/sql/get_tables_by_pattern_sql.sql
2022-01-15 07:16:55.551577 (MainThread): Parsing macros/sql/get_column_values.sql
2022-01-15 07:16:55.557049 (MainThread): Parsing macros/sql/pivot.sql
2022-01-15 07:16:55.561549 (MainThread): Parsing macros/sql/get_query_results_as_dict.sql
2022-01-15 07:16:55.564122 (MainThread): Parsing macros/sql/haversine_distance.sql
2022-01-15 07:16:55.867975 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-15 07:16:55.879424 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-15 07:16:55.883066 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-15 07:16:55.890360 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-15 07:16:55.893712 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-15 07:16:55.927029 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 07:16:55.936508 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 07:16:55.938246 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 07:16:55.940168 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 07:16:55.941943 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 07:16:55.943620 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 07:16:55.958720 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 07:16:55.960469 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 07:16:55.983389 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b23f2a38-b393-46d1-9536-bad973e25433', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dd940d0>]}
2022-01-15 07:16:55.990923 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-01-15 07:16:55.991401 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b23f2a38-b393-46d1-9536-bad973e25433', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dd94fa0>]}
2022-01-15 07:16:55.991632 (MainThread): Found 5 models, 8 tests, 0 snapshots, 0 analyses, 347 macros, 0 operations, 0 seed files, 12 sources, 0 exposures
2022-01-15 07:16:55.993010 (MainThread): 
2022-01-15 07:16:55.993344 (MainThread): Acquiring new postgres connection "master".
2022-01-15 07:16:55.994137 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_sakila_wh".
2022-01-15 07:16:56.002800 (ThreadPoolExecutor-0_0): Using postgres connection "list_sakila_wh".
2022-01-15 07:16:56.002976 (ThreadPoolExecutor-0_0): On list_sakila_wh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh"} */

    select distinct nspname from pg_namespace
  
2022-01-15 07:16:56.003116 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2022-01-15 07:16:56.409817 (ThreadPoolExecutor-0_0): SQL status: SELECT 10 in 0.41 seconds
2022-01-15 07:16:56.412338 (ThreadPoolExecutor-0_0): On list_sakila_wh: Close
2022-01-15 07:16:56.414032 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_dwh".
2022-01-15 07:16:56.420454 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-15 07:16:56.420659 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: BEGIN
2022-01-15 07:16:56.420833 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2022-01-15 07:16:56.792361 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.37 seconds
2022-01-15 07:16:56.792783 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-15 07:16:56.793053 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_dwh"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dwh'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dwh'
  
2022-01-15 07:16:56.876327 (ThreadPoolExecutor-1_0): SQL status: SELECT 4 in 0.08 seconds
2022-01-15 07:16:56.878883 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: ROLLBACK
2022-01-15 07:16:56.947493 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: Close
2022-01-15 07:16:56.952924 (MainThread): Using postgres connection "master".
2022-01-15 07:16:56.953146 (MainThread): On master: BEGIN
2022-01-15 07:16:56.953319 (MainThread): Opening a new connection, currently in state init
2022-01-15 07:16:57.346424 (MainThread): SQL status: BEGIN in 0.39 seconds
2022-01-15 07:16:57.346821 (MainThread): Using postgres connection "master".
2022-01-15 07:16:57.349768 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-15 07:16:57.429094 (MainThread): SQL status: SELECT 47 in 0.08 seconds
2022-01-15 07:16:57.433011 (MainThread): On master: ROLLBACK
2022-01-15 07:16:57.493934 (MainThread): Using postgres connection "master".
2022-01-15 07:16:57.494472 (MainThread): On master: BEGIN
2022-01-15 07:16:57.614529 (MainThread): SQL status: BEGIN in 0.12 seconds
2022-01-15 07:16:57.614806 (MainThread): On master: COMMIT
2022-01-15 07:16:57.614969 (MainThread): Using postgres connection "master".
2022-01-15 07:16:57.615121 (MainThread): On master: COMMIT
2022-01-15 07:16:57.676248 (MainThread): SQL status: COMMIT in 0.06 seconds
2022-01-15 07:16:57.676908 (MainThread): On master: Close
2022-01-15 07:16:57.677594 (MainThread): 12:46:57 | Concurrency: 1 threads (target='dev')
2022-01-15 07:16:57.677870 (MainThread): 12:46:57 | 
2022-01-15 07:16:57.681287 (Thread-1): Began running node model.sakila_dbt_project.dim_date
2022-01-15 07:16:57.681715 (Thread-1): 12:46:57 | 1 of 5 START table model dwh.dim_date................................ [RUN]
2022-01-15 07:16:57.682177 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-15 07:16:57.682423 (Thread-1): Compiling model.sakila_dbt_project.dim_date
2022-01-15 07:16:57.684349 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_date"
2022-01-15 07:16:57.685571 (Thread-1): finished collecting timing info
2022-01-15 07:16:57.712251 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_date"
2022-01-15 07:16:57.713101 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-15 07:16:57.713286 (Thread-1): On model.sakila_dbt_project.dim_date: BEGIN
2022-01-15 07:16:57.713449 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 07:16:58.091221 (Thread-1): SQL status: BEGIN in 0.38 seconds
2022-01-15 07:16:58.091605 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-15 07:16:58.091850 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */


  create  table "sakila_wh"."dwh"."dim_date__dbt_tmp"
  as (
    with dates as (
SELECT
       TO_CHAR(datum, 'yyyymmdd')::INT AS date_dim_id,
       datum AS date_key,
       EXTRACT(EPOCH FROM datum) AS epoch,
       TO_CHAR(datum, 'TMDay') AS day_name,
       EXTRACT(ISODOW FROM datum) AS day_of_week,
       EXTRACT(DAY FROM datum) AS day_of_month,
       datum - DATE_TRUNC('quarter', datum)::DATE + 1 AS day_of_quarter,
       EXTRACT(DOY FROM datum) AS day_of_year,
       TO_CHAR(datum, 'W')::INT AS week_of_month,
       EXTRACT(WEEK FROM datum) AS week_of_year,
       EXTRACT(MONTH FROM datum) AS month_actual,
       TO_CHAR(datum, 'TMMonth') AS month_name,
       TO_CHAR(datum, 'Mon') AS month_name_abbreviated,
       EXTRACT(QUARTER FROM datum) AS quarter_actual,
       CASE
           WHEN EXTRACT(QUARTER FROM datum) = 1 THEN 'First'
           WHEN EXTRACT(QUARTER FROM datum) = 2 THEN 'Second'
           WHEN EXTRACT(QUARTER FROM datum) = 3 THEN 'Third'
           WHEN EXTRACT(QUARTER FROM datum) = 4 THEN 'Fourth'
           END AS quarter_name,
       EXTRACT(YEAR FROM datum) AS year_actual,
       datum + (1 - EXTRACT(ISODOW FROM datum))::INT AS first_day_of_week,
       datum + (7 - EXTRACT(ISODOW FROM datum))::INT AS last_day_of_week,
       datum + (1 - EXTRACT(DAY FROM datum))::INT AS first_day_of_month,
       (DATE_TRUNC('MONTH', datum) + INTERVAL '1 MONTH - 1 day')::DATE AS last_day_of_month,
       DATE_TRUNC('quarter', datum)::DATE AS first_day_of_quarter,
       (DATE_TRUNC('quarter', datum) + INTERVAL '3 MONTH - 1 day')::DATE AS last_day_of_quarter,
       TO_DATE(EXTRACT(YEAR FROM datum) || '-01-01', 'YYYY-MM-DD') AS first_day_of_year,
       TO_DATE(EXTRACT(YEAR FROM datum) || '-12-31', 'YYYY-MM-DD') AS last_day_of_year,
       TO_CHAR(datum, 'yyyymm') AS yyyymm,
       CASE
           WHEN EXTRACT(ISODOW FROM datum) IN (6, 7) THEN TRUE
           ELSE FALSE
           END AS weekend_indr
FROM (SELECT '2000-01-01'::DATE + SEQUENCE.DAY AS datum
      FROM GENERATE_SERIES(0, 29219) AS SEQUENCE (DAY)
      GROUP BY SEQUENCE.DAY) DQ
)
select
*
from
dates
where
date_key <= CURRENT_DATE
order by date_dim_id asc
  );
2022-01-15 07:16:59.094774 (Thread-1): SQL status: SELECT 8051 in 1.00 seconds
2022-01-15 07:16:59.103393 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-15 07:16:59.103619 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
alter table "sakila_wh"."dwh"."dim_date" rename to "dim_date__dbt_backup"
2022-01-15 07:16:59.165026 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-15 07:16:59.168341 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-15 07:16:59.168573 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
alter table "sakila_wh"."dwh"."dim_date__dbt_tmp" rename to "dim_date"
2022-01-15 07:16:59.230357 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-15 07:16:59.242692 (Thread-1): On model.sakila_dbt_project.dim_date: COMMIT
2022-01-15 07:16:59.242923 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-15 07:16:59.243092 (Thread-1): On model.sakila_dbt_project.dim_date: COMMIT
2022-01-15 07:16:59.305136 (Thread-1): SQL status: COMMIT in 0.06 seconds
2022-01-15 07:16:59.312624 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-15 07:16:59.312881 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
drop table if exists "sakila_wh"."dwh"."dim_date__dbt_backup" cascade
2022-01-15 07:16:59.380771 (Thread-1): SQL status: DROP TABLE in 0.07 seconds
2022-01-15 07:16:59.382202 (Thread-1): finished collecting timing info
2022-01-15 07:16:59.382447 (Thread-1): On model.sakila_dbt_project.dim_date: Close
2022-01-15 07:16:59.382941 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b23f2a38-b393-46d1-9536-bad973e25433', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10df6afd0>]}
2022-01-15 07:16:59.383318 (Thread-1): 12:46:59 | 1 of 5 OK created table model dwh.dim_date........................... [SELECT 8051 in 1.70s]
2022-01-15 07:16:59.383531 (Thread-1): Finished running node model.sakila_dbt_project.dim_date
2022-01-15 07:16:59.383738 (Thread-1): Began running node model.sakila_dbt_project.hello_world
2022-01-15 07:16:59.384106 (Thread-1): 12:46:59 | 2 of 5 START table model dwh.hello_world............................. [RUN]
2022-01-15 07:16:59.384453 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-15 07:16:59.384640 (Thread-1): Compiling model.sakila_dbt_project.hello_world
2022-01-15 07:16:59.386366 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.hello_world"
2022-01-15 07:16:59.386979 (Thread-1): finished collecting timing info
2022-01-15 07:16:59.389548 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.hello_world"
2022-01-15 07:16:59.390140 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-15 07:16:59.390303 (Thread-1): On model.sakila_dbt_project.hello_world: BEGIN
2022-01-15 07:16:59.390455 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 07:16:59.765029 (Thread-1): SQL status: BEGIN in 0.37 seconds
2022-01-15 07:16:59.765410 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-15 07:16:59.765677 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */


  create  table "sakila_wh"."dwh"."hello_world__dbt_tmp"
  as (
    select
	customer.customer_id::int,
	customer.store_id::int,
	customer.first_name,
	customer.last_name,
	concat(customer.first_name,' ',customer.last_name) as full_name,
	substring(email from POSITION('@' in email)+1 for char_length(email)-POSITION('@' in email)) as domain,
	customer.email,
	customer.active::int,
	customer.address_id::int,
	address.address,
	city.city_id::int,
	city.city,
	(case when customer.active = 0 then 'no' else 'yes' end)::varchar(100) as "active_desc",
	customer.create_date::timestamp,
	customer.last_update::timestamp
from
	stg.customer as customer

	left join stg.address on 1=1
	and customer.address_id =address.address_id

	left join stg.city on 1=1
	and address.city_id = city.city_id
  );
2022-01-15 07:16:59.845016 (Thread-1): SQL status: SELECT 599 in 0.08 seconds
2022-01-15 07:16:59.850473 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-15 07:16:59.850717 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
alter table "sakila_wh"."dwh"."hello_world" rename to "hello_world__dbt_backup"
2022-01-15 07:16:59.912305 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-15 07:16:59.915726 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-15 07:16:59.915980 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
alter table "sakila_wh"."dwh"."hello_world__dbt_tmp" rename to "hello_world"
2022-01-15 07:16:59.976093 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-15 07:16:59.978330 (Thread-1): On model.sakila_dbt_project.hello_world: COMMIT
2022-01-15 07:16:59.978558 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-15 07:16:59.978751 (Thread-1): On model.sakila_dbt_project.hello_world: COMMIT
2022-01-15 07:17:00.043602 (Thread-1): SQL status: COMMIT in 0.06 seconds
2022-01-15 07:17:00.046504 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-15 07:17:00.046781 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
drop table if exists "sakila_wh"."dwh"."hello_world__dbt_backup" cascade
2022-01-15 07:17:00.112379 (Thread-1): SQL status: DROP TABLE in 0.07 seconds
2022-01-15 07:17:00.114428 (Thread-1): finished collecting timing info
2022-01-15 07:17:00.114735 (Thread-1): On model.sakila_dbt_project.hello_world: Close
2022-01-15 07:17:00.115429 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b23f2a38-b393-46d1-9536-bad973e25433', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10de17dc0>]}
2022-01-15 07:17:00.115941 (Thread-1): 12:47:00 | 2 of 5 OK created table model dwh.hello_world........................ [SELECT 599 in 0.73s]
2022-01-15 07:17:00.116237 (Thread-1): Finished running node model.sakila_dbt_project.hello_world
2022-01-15 07:17:00.116496 (Thread-1): Began running node model.sakila_dbt_project.my_first_dbt_model
2022-01-15 07:17:00.116925 (Thread-1): 12:47:00 | 3 of 5 START table model dwh.my_first_dbt_model...................... [RUN]
2022-01-15 07:17:00.117369 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-15 07:17:00.117564 (Thread-1): Compiling model.sakila_dbt_project.my_first_dbt_model
2022-01-15 07:17:00.120280 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.my_first_dbt_model"
2022-01-15 07:17:00.120970 (Thread-1): finished collecting timing info
2022-01-15 07:17:00.123639 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.my_first_dbt_model"
2022-01-15 07:17:00.124270 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-15 07:17:00.124451 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: BEGIN
2022-01-15 07:17:00.124618 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 07:17:00.499492 (Thread-1): SQL status: BEGIN in 0.37 seconds
2022-01-15 07:17:00.499810 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-15 07:17:00.500012 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */


  create  table "sakila_wh"."dwh"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-15 07:17:00.573269 (Thread-1): SQL status: SELECT 2 in 0.07 seconds
2022-01-15 07:17:00.576942 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-15 07:17:00.577182 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
alter table "sakila_wh"."dwh"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2022-01-15 07:17:00.638961 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-15 07:17:00.642532 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-15 07:17:00.642777 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
alter table "sakila_wh"."dwh"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-15 07:17:00.703744 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-15 07:17:00.705817 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: COMMIT
2022-01-15 07:17:00.706052 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-15 07:17:00.706247 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: COMMIT
2022-01-15 07:17:00.767728 (Thread-1): SQL status: COMMIT in 0.06 seconds
2022-01-15 07:17:00.770596 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-15 07:17:00.770825 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
drop table if exists "sakila_wh"."dwh"."my_first_dbt_model__dbt_backup" cascade
2022-01-15 07:17:00.833478 (Thread-1): SQL status: DROP TABLE in 0.06 seconds
2022-01-15 07:17:00.835352 (Thread-1): finished collecting timing info
2022-01-15 07:17:00.835653 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: Close
2022-01-15 07:17:00.836225 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b23f2a38-b393-46d1-9536-bad973e25433', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dfea100>]}
2022-01-15 07:17:00.836668 (Thread-1): 12:47:00 | 3 of 5 OK created table model dwh.my_first_dbt_model................. [SELECT 2 in 0.72s]
2022-01-15 07:17:00.836934 (Thread-1): Finished running node model.sakila_dbt_project.my_first_dbt_model
2022-01-15 07:17:00.837184 (Thread-1): Began running node model.sakila_dbt_project.payment_inc
2022-01-15 07:17:00.837633 (Thread-1): 12:47:00 | 4 of 5 START incremental model dwh.payment_inc....................... [RUN]
2022-01-15 07:17:00.838156 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-15 07:17:00.838353 (Thread-1): Compiling model.sakila_dbt_project.payment_inc
2022-01-15 07:17:00.842188 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.payment_inc"
2022-01-15 07:17:00.842856 (Thread-1): finished collecting timing info
2022-01-15 07:17:00.882287 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.payment_inc"
2022-01-15 07:17:00.883006 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-15 07:17:00.883191 (Thread-1): On model.sakila_dbt_project.payment_inc: BEGIN
2022-01-15 07:17:00.883346 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 07:17:01.254334 (Thread-1): SQL status: BEGIN in 0.37 seconds
2022-01-15 07:17:01.254740 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-15 07:17:01.255015 (Thread-1): On model.sakila_dbt_project.payment_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.payment_inc"} */

      

  create  table "sakila_wh"."dwh"."payment_inc"
  as (
    

select
*,
'2022-01-15 07:16:54' as dbt_tran_time
from
stg.payment
where 1=1




-- - INTERVAL '3 DAY'
-- unique_key='payment_id'
  );
  
2022-01-15 07:17:01.356469 (Thread-1): SQL status: SELECT 16049 in 0.10 seconds
2022-01-15 07:17:01.358467 (Thread-1): On model.sakila_dbt_project.payment_inc: COMMIT
2022-01-15 07:17:01.358695 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-15 07:17:01.358888 (Thread-1): On model.sakila_dbt_project.payment_inc: COMMIT
2022-01-15 07:17:01.418877 (Thread-1): SQL status: COMMIT in 0.06 seconds
2022-01-15 07:17:01.419857 (Thread-1): finished collecting timing info
2022-01-15 07:17:01.420236 (Thread-1): On model.sakila_dbt_project.payment_inc: Close
2022-01-15 07:17:01.420839 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b23f2a38-b393-46d1-9536-bad973e25433', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dfea040>]}
2022-01-15 07:17:01.421297 (Thread-1): 12:47:01 | 4 of 5 OK created incremental model dwh.payment_inc.................. [SELECT 16049 in 0.58s]
2022-01-15 07:17:01.421569 (Thread-1): Finished running node model.sakila_dbt_project.payment_inc
2022-01-15 07:17:01.421825 (Thread-1): Began running node model.sakila_dbt_project.my_second_dbt_model
2022-01-15 07:17:01.422244 (Thread-1): 12:47:01 | 5 of 5 START table model dwh.my_second_dbt_model..................... [RUN]
2022-01-15 07:17:01.422674 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-15 07:17:01.422900 (Thread-1): Compiling model.sakila_dbt_project.my_second_dbt_model
2022-01-15 07:17:01.425894 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.my_second_dbt_model"
2022-01-15 07:17:01.426535 (Thread-1): finished collecting timing info
2022-01-15 07:17:01.429207 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.my_second_dbt_model"
2022-01-15 07:17:01.429951 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-15 07:17:01.430140 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: BEGIN
2022-01-15 07:17:01.430311 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 07:17:01.832959 (Thread-1): SQL status: BEGIN in 0.40 seconds
2022-01-15 07:17:01.833386 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-15 07:17:01.833658 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */


  create  table "sakila_wh"."dwh"."my_second_dbt_model__dbt_tmp"
  as (
    -- Use the `ref` function to select from other models

select *
from "sakila_wh"."dwh"."my_first_dbt_model"
where id = 1
  );
2022-01-15 07:17:01.899711 (Thread-1): SQL status: SELECT 1 in 0.07 seconds
2022-01-15 07:17:01.903218 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-15 07:17:01.903455 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
alter table "sakila_wh"."dwh"."my_second_dbt_model" rename to "my_second_dbt_model__dbt_backup"
2022-01-15 07:17:01.976852 (Thread-1): SQL status: ALTER TABLE in 0.07 seconds
2022-01-15 07:17:01.980999 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-15 07:17:01.981230 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
alter table "sakila_wh"."dwh"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-15 07:17:02.043568 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-15 07:17:02.046086 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: COMMIT
2022-01-15 07:17:02.046372 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-15 07:17:02.046638 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: COMMIT
2022-01-15 07:17:02.116159 (Thread-1): SQL status: COMMIT in 0.07 seconds
2022-01-15 07:17:02.118637 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-15 07:17:02.118854 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
drop table if exists "sakila_wh"."dwh"."my_second_dbt_model__dbt_backup" cascade
2022-01-15 07:17:02.181416 (Thread-1): SQL status: DROP TABLE in 0.06 seconds
2022-01-15 07:17:02.182962 (Thread-1): finished collecting timing info
2022-01-15 07:17:02.183203 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: Close
2022-01-15 07:17:02.183695 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b23f2a38-b393-46d1-9536-bad973e25433', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dfea040>]}
2022-01-15 07:17:02.184082 (Thread-1): 12:47:02 | 5 of 5 OK created table model dwh.my_second_dbt_model................ [SELECT 1 in 0.76s]
2022-01-15 07:17:02.184304 (Thread-1): Finished running node model.sakila_dbt_project.my_second_dbt_model
2022-01-15 07:17:02.185432 (MainThread): Acquiring new postgres connection "master".
2022-01-15 07:17:02.185657 (MainThread): Using postgres connection "master".
2022-01-15 07:17:02.185822 (MainThread): On master: BEGIN
2022-01-15 07:17:02.185992 (MainThread): Opening a new connection, currently in state closed
2022-01-15 07:17:02.561731 (MainThread): SQL status: BEGIN in 0.38 seconds
2022-01-15 07:17:02.562132 (MainThread): On master: COMMIT
2022-01-15 07:17:02.562399 (MainThread): Using postgres connection "master".
2022-01-15 07:17:02.562641 (MainThread): On master: COMMIT
2022-01-15 07:17:02.624096 (MainThread): SQL status: COMMIT in 0.06 seconds
2022-01-15 07:17:02.624550 (MainThread): On master: Close
2022-01-15 07:17:02.625220 (MainThread): 12:47:02 | 
2022-01-15 07:17:02.625499 (MainThread): 12:47:02 | Finished running 4 table models, 1 incremental model in 6.63s.
2022-01-15 07:17:02.625731 (MainThread): Connection 'master' was properly closed.
2022-01-15 07:17:02.625920 (MainThread): Connection 'model.sakila_dbt_project.my_second_dbt_model' was properly closed.
2022-01-15 07:17:02.636244 (MainThread): 
2022-01-15 07:17:02.636482 (MainThread): Completed successfully
2022-01-15 07:17:02.636673 (MainThread): 
Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2022-01-15 07:17:02.636911 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dde7d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10de191c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dfd6fd0>]}
2022-01-15 07:17:02.637153 (MainThread): Flushing usage events
2022-01-15 07:35:46.292140 (MainThread): Running with dbt=0.21.1
2022-01-15 07:35:46.482861 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2022-01-15 07:35:46.487837 (MainThread): Tracking: tracking
2022-01-15 07:35:46.537070 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1044f5640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104afee20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104afe340>]}
2022-01-15 07:35:46.577493 (MainThread): Partial parsing not enabled
2022-01-15 07:35:46.689183 (MainThread): Parsing macros/catalog.sql
2022-01-15 07:35:46.697590 (MainThread): Parsing macros/relations.sql
2022-01-15 07:35:46.700704 (MainThread): Parsing macros/adapters.sql
2022-01-15 07:35:46.740432 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2022-01-15 07:35:46.743233 (MainThread): Parsing macros/core.sql
2022-01-15 07:35:46.751978 (MainThread): Parsing macros/materializations/test.sql
2022-01-15 07:35:46.761702 (MainThread): Parsing macros/materializations/helpers.sql
2022-01-15 07:35:46.774441 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2022-01-15 07:35:46.777054 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2022-01-15 07:35:46.801156 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2022-01-15 07:35:46.837978 (MainThread): Parsing macros/materializations/seed/seed.sql
2022-01-15 07:35:46.861834 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2022-01-15 07:35:46.863516 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2022-01-15 07:35:46.873409 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2022-01-15 07:35:46.892595 (MainThread): Parsing macros/materializations/common/merge.sql
2022-01-15 07:35:46.906003 (MainThread): Parsing macros/materializations/table/table.sql
2022-01-15 07:35:46.913775 (MainThread): Parsing macros/materializations/view/view.sql
2022-01-15 07:35:46.920605 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2022-01-15 07:35:46.924437 (MainThread): Parsing macros/etc/get_custom_alias.sql
2022-01-15 07:35:46.926041 (MainThread): Parsing macros/etc/query.sql
2022-01-15 07:35:46.927075 (MainThread): Parsing macros/etc/is_incremental.sql
2022-01-15 07:35:46.928716 (MainThread): Parsing macros/etc/datetime.sql
2022-01-15 07:35:46.937915 (MainThread): Parsing macros/etc/where_subquery.sql
2022-01-15 07:35:46.939972 (MainThread): Parsing macros/etc/get_custom_schema.sql
2022-01-15 07:35:46.942534 (MainThread): Parsing macros/etc/get_custom_database.sql
2022-01-15 07:35:46.944094 (MainThread): Parsing macros/adapters/common.sql
2022-01-15 07:35:46.997186 (MainThread): Parsing macros/schema_tests/relationships.sql
2022-01-15 07:35:46.998817 (MainThread): Parsing macros/schema_tests/not_null.sql
2022-01-15 07:35:46.999952 (MainThread): Parsing macros/schema_tests/unique.sql
2022-01-15 07:35:47.001335 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2022-01-15 07:35:47.003447 (MainThread): Parsing macros/cross_db_utils/except.sql
2022-01-15 07:35:47.004447 (MainThread): Parsing macros/cross_db_utils/replace.sql
2022-01-15 07:35:47.005610 (MainThread): Parsing macros/cross_db_utils/concat.sql
2022-01-15 07:35:47.006544 (MainThread): Parsing macros/cross_db_utils/datatypes.sql
2022-01-15 07:35:47.012542 (MainThread): Parsing macros/cross_db_utils/_is_relation.sql
2022-01-15 07:35:47.013726 (MainThread): Parsing macros/cross_db_utils/length.sql
2022-01-15 07:35:47.014999 (MainThread): Parsing macros/cross_db_utils/dateadd.sql
2022-01-15 07:35:47.017997 (MainThread): Parsing macros/cross_db_utils/intersect.sql
2022-01-15 07:35:47.019102 (MainThread): Parsing macros/cross_db_utils/right.sql
2022-01-15 07:35:47.021368 (MainThread): Parsing macros/cross_db_utils/datediff.sql
2022-01-15 07:35:47.030919 (MainThread): Parsing macros/cross_db_utils/safe_cast.sql
2022-01-15 07:35:47.032742 (MainThread): Parsing macros/cross_db_utils/hash.sql
2022-01-15 07:35:47.034116 (MainThread): Parsing macros/cross_db_utils/cast_bool_to_text.sql
2022-01-15 07:35:47.035477 (MainThread): Parsing macros/cross_db_utils/identifier.sql
2022-01-15 07:35:47.037023 (MainThread): Parsing macros/cross_db_utils/position.sql
2022-01-15 07:35:47.038484 (MainThread): Parsing macros/cross_db_utils/literal.sql
2022-01-15 07:35:47.039384 (MainThread): Parsing macros/cross_db_utils/current_timestamp.sql
2022-01-15 07:35:47.042893 (MainThread): Parsing macros/cross_db_utils/width_bucket.sql
2022-01-15 07:35:47.047833 (MainThread): Parsing macros/cross_db_utils/last_day.sql
2022-01-15 07:35:47.051601 (MainThread): Parsing macros/cross_db_utils/split_part.sql
2022-01-15 07:35:47.053471 (MainThread): Parsing macros/cross_db_utils/date_trunc.sql
2022-01-15 07:35:47.055039 (MainThread): Parsing macros/cross_db_utils/_is_ephemeral.sql
2022-01-15 07:35:47.056835 (MainThread): Parsing macros/materializations/insert_by_period_materialization.sql
2022-01-15 07:35:47.080930 (MainThread): Parsing macros/web/get_url_host.sql
2022-01-15 07:35:47.082704 (MainThread): Parsing macros/web/get_url_path.sql
2022-01-15 07:35:47.085141 (MainThread): Parsing macros/web/get_url_parameter.sql
2022-01-15 07:35:47.086626 (MainThread): Parsing macros/jinja_helpers/pretty_log_format.sql
2022-01-15 07:35:47.087667 (MainThread): Parsing macros/jinja_helpers/pretty_time.sql
2022-01-15 07:35:47.088801 (MainThread): Parsing macros/jinja_helpers/log_info.sql
2022-01-15 07:35:47.089969 (MainThread): Parsing macros/jinja_helpers/slugify.sql
2022-01-15 07:35:47.091088 (MainThread): Parsing macros/schema_tests/fewer_rows_than.sql
2022-01-15 07:35:47.092780 (MainThread): Parsing macros/schema_tests/equal_rowcount.sql
2022-01-15 07:35:47.094318 (MainThread): Parsing macros/schema_tests/relationships_where.sql
2022-01-15 07:35:47.096499 (MainThread): Parsing macros/schema_tests/recency.sql
2022-01-15 07:35:47.098168 (MainThread): Parsing macros/schema_tests/not_constant.sql
2022-01-15 07:35:47.099345 (MainThread): Parsing macros/schema_tests/accepted_range.sql
2022-01-15 07:35:47.101859 (MainThread): Parsing macros/schema_tests/not_accepted_values.sql
2022-01-15 07:35:47.103891 (MainThread): Parsing macros/schema_tests/test_unique_where.sql
2022-01-15 07:35:47.105326 (MainThread): Parsing macros/schema_tests/at_least_one.sql
2022-01-15 07:35:47.106516 (MainThread): Parsing macros/schema_tests/unique_combination_of_columns.sql
2022-01-15 07:35:47.109384 (MainThread): Parsing macros/schema_tests/cardinality_equality.sql
2022-01-15 07:35:47.111489 (MainThread): Parsing macros/schema_tests/expression_is_true.sql
2022-01-15 07:35:47.113228 (MainThread): Parsing macros/schema_tests/sequential_values.sql
2022-01-15 07:35:47.116063 (MainThread): Parsing macros/schema_tests/test_not_null_where.sql
2022-01-15 07:35:47.117440 (MainThread): Parsing macros/schema_tests/equality.sql
2022-01-15 07:35:47.120714 (MainThread): Parsing macros/schema_tests/mutually_exclusive_ranges.sql
2022-01-15 07:35:47.129050 (MainThread): Parsing macros/sql/date_spine.sql
2022-01-15 07:35:47.133472 (MainThread): Parsing macros/sql/nullcheck_table.sql
2022-01-15 07:35:47.135025 (MainThread): Parsing macros/sql/get_relations_by_pattern.sql
2022-01-15 07:35:47.138311 (MainThread): Parsing macros/sql/generate_series.sql
2022-01-15 07:35:47.167144 (MainThread): Parsing macros/sql/get_relations_by_prefix.sql
2022-01-15 07:35:47.171640 (MainThread): Parsing macros/sql/get_tables_by_prefix_sql.sql
2022-01-15 07:35:47.173738 (MainThread): Parsing macros/sql/star.sql
2022-01-15 07:35:47.177883 (MainThread): Parsing macros/sql/unpivot.sql
2022-01-15 07:35:47.187813 (MainThread): Parsing macros/sql/union.sql
2022-01-15 07:35:47.197407 (MainThread): Parsing macros/sql/groupby.sql
2022-01-15 07:35:47.199027 (MainThread): Parsing macros/sql/surrogate_key.sql
2022-01-15 07:35:47.202927 (MainThread): Parsing macros/sql/safe_add.sql
2022-01-15 07:35:47.204824 (MainThread): Parsing macros/sql/nullcheck.sql
2022-01-15 07:35:47.206654 (MainThread): Parsing macros/sql/get_tables_by_pattern_sql.sql
2022-01-15 07:35:47.214170 (MainThread): Parsing macros/sql/get_column_values.sql
2022-01-15 07:35:47.219867 (MainThread): Parsing macros/sql/pivot.sql
2022-01-15 07:35:47.224306 (MainThread): Parsing macros/sql/get_query_results_as_dict.sql
2022-01-15 07:35:47.226895 (MainThread): Parsing macros/sql/haversine_distance.sql
2022-01-15 07:35:47.539219 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-15 07:35:47.553169 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-15 07:35:47.557368 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-15 07:35:47.566053 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-15 07:35:47.570269 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-15 07:35:47.607005 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 07:35:47.616528 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 07:35:47.618429 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 07:35:47.620882 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 07:35:47.622712 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 07:35:47.624445 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 07:35:47.642219 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 07:35:47.644296 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 07:35:47.672162 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bddf208b-eebe-41be-8280-ba52ce541c88', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c610d0>]}
2022-01-15 07:35:47.682475 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-01-15 07:35:47.683119 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bddf208b-eebe-41be-8280-ba52ce541c88', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c61fa0>]}
2022-01-15 07:35:47.683447 (MainThread): Found 5 models, 8 tests, 0 snapshots, 0 analyses, 347 macros, 0 operations, 0 seed files, 12 sources, 0 exposures
2022-01-15 07:35:47.685217 (MainThread): 
2022-01-15 07:35:47.685621 (MainThread): Acquiring new postgres connection "master".
2022-01-15 07:35:47.686781 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_sakila_wh".
2022-01-15 07:35:47.697215 (ThreadPoolExecutor-0_0): Using postgres connection "list_sakila_wh".
2022-01-15 07:35:47.697464 (ThreadPoolExecutor-0_0): On list_sakila_wh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh"} */

    select distinct nspname from pg_namespace
  
2022-01-15 07:35:47.697637 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2022-01-15 07:35:48.186409 (ThreadPoolExecutor-0_0): SQL status: SELECT 10 in 0.49 seconds
2022-01-15 07:35:48.190771 (ThreadPoolExecutor-0_0): On list_sakila_wh: Close
2022-01-15 07:35:48.192943 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_dwh".
2022-01-15 07:35:48.200395 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-15 07:35:48.200669 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: BEGIN
2022-01-15 07:35:48.200865 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2022-01-15 07:35:48.590418 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.39 seconds
2022-01-15 07:35:48.590840 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-15 07:35:48.591098 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_dwh"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dwh'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dwh'
  
2022-01-15 07:35:48.657452 (ThreadPoolExecutor-1_0): SQL status: SELECT 5 in 0.07 seconds
2022-01-15 07:35:48.660221 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: ROLLBACK
2022-01-15 07:35:48.720080 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: Close
2022-01-15 07:35:48.725853 (MainThread): Using postgres connection "master".
2022-01-15 07:35:48.726096 (MainThread): On master: BEGIN
2022-01-15 07:35:48.726276 (MainThread): Opening a new connection, currently in state init
2022-01-15 07:35:49.099959 (MainThread): SQL status: BEGIN in 0.37 seconds
2022-01-15 07:35:49.100231 (MainThread): Using postgres connection "master".
2022-01-15 07:35:49.100562 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-15 07:35:49.177646 (MainThread): SQL status: SELECT 47 in 0.08 seconds
2022-01-15 07:35:49.181765 (MainThread): On master: ROLLBACK
2022-01-15 07:35:49.244021 (MainThread): Using postgres connection "master".
2022-01-15 07:35:49.244563 (MainThread): On master: BEGIN
2022-01-15 07:35:49.364380 (MainThread): SQL status: BEGIN in 0.12 seconds
2022-01-15 07:35:49.364784 (MainThread): On master: COMMIT
2022-01-15 07:35:49.365022 (MainThread): Using postgres connection "master".
2022-01-15 07:35:49.365224 (MainThread): On master: COMMIT
2022-01-15 07:35:49.441017 (MainThread): SQL status: COMMIT in 0.08 seconds
2022-01-15 07:35:49.441452 (MainThread): On master: Close
2022-01-15 07:35:49.442102 (MainThread): 13:05:49 | Concurrency: 1 threads (target='dev')
2022-01-15 07:35:49.442430 (MainThread): 13:05:49 | 
2022-01-15 07:35:49.445269 (Thread-1): Began running node model.sakila_dbt_project.dim_date
2022-01-15 07:35:49.445625 (Thread-1): 13:05:49 | 1 of 5 START table model dwh.dim_date................................ [RUN]
2022-01-15 07:35:49.446022 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-15 07:35:49.446236 (Thread-1): Compiling model.sakila_dbt_project.dim_date
2022-01-15 07:35:49.448024 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_date"
2022-01-15 07:35:49.448540 (Thread-1): finished collecting timing info
2022-01-15 07:35:49.474154 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_date"
2022-01-15 07:35:49.474875 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-15 07:35:49.475129 (Thread-1): On model.sakila_dbt_project.dim_date: BEGIN
2022-01-15 07:35:49.475291 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 07:35:49.852994 (Thread-1): SQL status: BEGIN in 0.38 seconds
2022-01-15 07:35:49.853410 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-15 07:35:49.853709 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */


  create  table "sakila_wh"."dwh"."dim_date__dbt_tmp"
  as (
    with dates as (
SELECT
       TO_CHAR(datum, 'yyyymmdd')::INT AS date_dim_id,
       datum AS date_key,
       EXTRACT(EPOCH FROM datum) AS epoch,
       TO_CHAR(datum, 'TMDay') AS day_name,
       EXTRACT(ISODOW FROM datum) AS day_of_week,
       EXTRACT(DAY FROM datum) AS day_of_month,
       datum - DATE_TRUNC('quarter', datum)::DATE + 1 AS day_of_quarter,
       EXTRACT(DOY FROM datum) AS day_of_year,
       TO_CHAR(datum, 'W')::INT AS week_of_month,
       EXTRACT(WEEK FROM datum) AS week_of_year,
       EXTRACT(MONTH FROM datum) AS month_actual,
       TO_CHAR(datum, 'TMMonth') AS month_name,
       TO_CHAR(datum, 'Mon') AS month_name_abbreviated,
       EXTRACT(QUARTER FROM datum) AS quarter_actual,
       CASE
           WHEN EXTRACT(QUARTER FROM datum) = 1 THEN 'First'
           WHEN EXTRACT(QUARTER FROM datum) = 2 THEN 'Second'
           WHEN EXTRACT(QUARTER FROM datum) = 3 THEN 'Third'
           WHEN EXTRACT(QUARTER FROM datum) = 4 THEN 'Fourth'
           END AS quarter_name,
       EXTRACT(YEAR FROM datum) AS year_actual,
       datum + (1 - EXTRACT(ISODOW FROM datum))::INT AS first_day_of_week,
       datum + (7 - EXTRACT(ISODOW FROM datum))::INT AS last_day_of_week,
       datum + (1 - EXTRACT(DAY FROM datum))::INT AS first_day_of_month,
       (DATE_TRUNC('MONTH', datum) + INTERVAL '1 MONTH - 1 day')::DATE AS last_day_of_month,
       DATE_TRUNC('quarter', datum)::DATE AS first_day_of_quarter,
       (DATE_TRUNC('quarter', datum) + INTERVAL '3 MONTH - 1 day')::DATE AS last_day_of_quarter,
       TO_DATE(EXTRACT(YEAR FROM datum) || '-01-01', 'YYYY-MM-DD') AS first_day_of_year,
       TO_DATE(EXTRACT(YEAR FROM datum) || '-12-31', 'YYYY-MM-DD') AS last_day_of_year,
       TO_CHAR(datum, 'yyyymm') AS yyyymm,
       CASE
           WHEN EXTRACT(ISODOW FROM datum) IN (6, 7) THEN TRUE
           ELSE FALSE
           END AS weekend_indr
FROM (SELECT '2000-01-01'::DATE + SEQUENCE.DAY AS datum
      FROM GENERATE_SERIES(0, 29219) AS SEQUENCE (DAY)
      GROUP BY SEQUENCE.DAY) DQ
)
select
*
from
dates
where
date_key <= CURRENT_DATE
order by date_dim_id asc
  );
2022-01-15 07:35:50.832731 (Thread-1): SQL status: SELECT 8051 in 0.98 seconds
2022-01-15 07:35:50.841205 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-15 07:35:50.841421 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
alter table "sakila_wh"."dwh"."dim_date" rename to "dim_date__dbt_backup"
2022-01-15 07:35:50.903620 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-15 07:35:50.905841 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-15 07:35:50.905999 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
alter table "sakila_wh"."dwh"."dim_date__dbt_tmp" rename to "dim_date"
2022-01-15 07:35:50.968536 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-15 07:35:50.979303 (Thread-1): On model.sakila_dbt_project.dim_date: COMMIT
2022-01-15 07:35:50.979515 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-15 07:35:50.979674 (Thread-1): On model.sakila_dbt_project.dim_date: COMMIT
2022-01-15 07:35:51.044740 (Thread-1): SQL status: COMMIT in 0.06 seconds
2022-01-15 07:35:51.051677 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-15 07:35:51.051897 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
drop table if exists "sakila_wh"."dwh"."dim_date__dbt_backup" cascade
2022-01-15 07:35:51.120481 (Thread-1): SQL status: DROP TABLE in 0.07 seconds
2022-01-15 07:35:51.122255 (Thread-1): finished collecting timing info
2022-01-15 07:35:51.122555 (Thread-1): On model.sakila_dbt_project.dim_date: Close
2022-01-15 07:35:51.123131 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bddf208b-eebe-41be-8280-ba52ce541c88', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e2cd60>]}
2022-01-15 07:35:51.123594 (Thread-1): 13:05:51 | 1 of 5 OK created table model dwh.dim_date........................... [SELECT 8051 in 1.68s]
2022-01-15 07:35:51.123865 (Thread-1): Finished running node model.sakila_dbt_project.dim_date
2022-01-15 07:35:51.124125 (Thread-1): Began running node model.sakila_dbt_project.hello_world
2022-01-15 07:35:51.124564 (Thread-1): 13:05:51 | 2 of 5 START table model dwh.hello_world............................. [RUN]
2022-01-15 07:35:51.125001 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-15 07:35:51.125191 (Thread-1): Compiling model.sakila_dbt_project.hello_world
2022-01-15 07:35:51.126918 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.hello_world"
2022-01-15 07:35:51.127520 (Thread-1): finished collecting timing info
2022-01-15 07:35:51.130022 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.hello_world"
2022-01-15 07:35:51.130560 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-15 07:35:51.130721 (Thread-1): On model.sakila_dbt_project.hello_world: BEGIN
2022-01-15 07:35:51.130871 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 07:35:51.544756 (Thread-1): SQL status: BEGIN in 0.41 seconds
2022-01-15 07:35:51.545069 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-15 07:35:51.545255 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */


  create  table "sakila_wh"."dwh"."hello_world__dbt_tmp"
  as (
    select
	customer.customer_id::int,
	customer.store_id::int,
	customer.first_name,
	customer.last_name,
	concat(customer.first_name,' ',customer.last_name) as full_name,
	substring(email from POSITION('@' in email)+1 for char_length(email)-POSITION('@' in email)) as domain,
	customer.email,
	customer.active::int,
	customer.address_id::int,
	address.address,
	city.city_id::int,
	city.city,
	(case when customer.active = 0 then 'no' else 'yes' end)::varchar(100) as "active_desc",
	customer.create_date::timestamp,
	customer.last_update::timestamp
from
	stg.customer as customer

	left join stg.address on 1=1
	and customer.address_id =address.address_id

	left join stg.city on 1=1
	and address.city_id = city.city_id
  );
2022-01-15 07:35:51.628072 (Thread-1): SQL status: SELECT 599 in 0.08 seconds
2022-01-15 07:35:51.636914 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-15 07:35:51.637573 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
alter table "sakila_wh"."dwh"."hello_world" rename to "hello_world__dbt_backup"
2022-01-15 07:35:51.698175 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-15 07:35:51.703009 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-15 07:35:51.703566 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
alter table "sakila_wh"."dwh"."hello_world__dbt_tmp" rename to "hello_world"
2022-01-15 07:35:51.764182 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-15 07:35:51.766334 (Thread-1): On model.sakila_dbt_project.hello_world: COMMIT
2022-01-15 07:35:51.766704 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-15 07:35:51.766918 (Thread-1): On model.sakila_dbt_project.hello_world: COMMIT
2022-01-15 07:35:51.828448 (Thread-1): SQL status: COMMIT in 0.06 seconds
2022-01-15 07:35:51.830627 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-15 07:35:51.830838 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
drop table if exists "sakila_wh"."dwh"."hello_world__dbt_backup" cascade
2022-01-15 07:35:51.894195 (Thread-1): SQL status: DROP TABLE in 0.06 seconds
2022-01-15 07:35:51.896186 (Thread-1): finished collecting timing info
2022-01-15 07:35:51.896514 (Thread-1): On model.sakila_dbt_project.hello_world: Close
2022-01-15 07:35:51.897162 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bddf208b-eebe-41be-8280-ba52ce541c88', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e69ca0>]}
2022-01-15 07:35:51.897680 (Thread-1): 13:05:51 | 2 of 5 OK created table model dwh.hello_world........................ [SELECT 599 in 0.77s]
2022-01-15 07:35:51.897950 (Thread-1): Finished running node model.sakila_dbt_project.hello_world
2022-01-15 07:35:51.898212 (Thread-1): Began running node model.sakila_dbt_project.my_first_dbt_model
2022-01-15 07:35:51.898646 (Thread-1): 13:05:51 | 3 of 5 START table model dwh.my_first_dbt_model...................... [RUN]
2022-01-15 07:35:51.899096 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-15 07:35:51.899338 (Thread-1): Compiling model.sakila_dbt_project.my_first_dbt_model
2022-01-15 07:35:51.902099 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.my_first_dbt_model"
2022-01-15 07:35:51.902709 (Thread-1): finished collecting timing info
2022-01-15 07:35:51.905410 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.my_first_dbt_model"
2022-01-15 07:35:51.905969 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-15 07:35:51.906151 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: BEGIN
2022-01-15 07:35:51.906321 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 07:35:52.283882 (Thread-1): SQL status: BEGIN in 0.38 seconds
2022-01-15 07:35:52.284268 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-15 07:35:52.284518 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */


  create  table "sakila_wh"."dwh"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-15 07:35:52.355515 (Thread-1): SQL status: SELECT 2 in 0.07 seconds
2022-01-15 07:35:52.358952 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-15 07:35:52.359163 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
alter table "sakila_wh"."dwh"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2022-01-15 07:35:52.423404 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-15 07:35:52.426898 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-15 07:35:52.427131 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
alter table "sakila_wh"."dwh"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-15 07:35:52.489843 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-15 07:35:52.491654 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: COMMIT
2022-01-15 07:35:52.491885 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-15 07:35:52.492103 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: COMMIT
2022-01-15 07:35:52.552150 (Thread-1): SQL status: COMMIT in 0.06 seconds
2022-01-15 07:35:52.554832 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-15 07:35:52.555059 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
drop table if exists "sakila_wh"."dwh"."my_first_dbt_model__dbt_backup" cascade
2022-01-15 07:35:52.623034 (Thread-1): SQL status: DROP TABLE in 0.07 seconds
2022-01-15 07:35:52.624555 (Thread-1): finished collecting timing info
2022-01-15 07:35:52.624838 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: Close
2022-01-15 07:35:52.625362 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bddf208b-eebe-41be-8280-ba52ce541c88', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104d2f760>]}
2022-01-15 07:35:52.625774 (Thread-1): 13:05:52 | 3 of 5 OK created table model dwh.my_first_dbt_model................. [SELECT 2 in 0.73s]
2022-01-15 07:35:52.626001 (Thread-1): Finished running node model.sakila_dbt_project.my_first_dbt_model
2022-01-15 07:35:52.626219 (Thread-1): Began running node model.sakila_dbt_project.payment_inc
2022-01-15 07:35:52.626499 (Thread-1): 13:05:52 | 4 of 5 START incremental model dwh.payment_inc....................... [RUN]
2022-01-15 07:35:52.626985 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-15 07:35:52.627266 (Thread-1): Compiling model.sakila_dbt_project.payment_inc
2022-01-15 07:35:52.633642 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.payment_inc"
2022-01-15 07:35:52.634313 (Thread-1): finished collecting timing info
2022-01-15 07:35:52.672010 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-15 07:35:52.672357 (Thread-1): On model.sakila_dbt_project.payment_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.payment_inc"} */

    

  create temporary table "payment_inc__dbt_tmp130552665656"
  as (
    

select
*,
'2022-01-15 07:35:46' as dbt_tran_time
from
stg.payment
where 1=1


and payment_date::timestamp > (select max(payment_date) from "sakila_wh"."dwh"."payment_inc")



-- - INTERVAL '3 DAY'
-- unique_key='payment_id'
  );
  
2022-01-15 07:35:52.672552 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 07:35:53.062824 (Thread-1): SQL status: SELECT 3 in 0.39 seconds
2022-01-15 07:35:53.072172 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-15 07:35:53.072411 (Thread-1): On model.sakila_dbt_project.payment_inc: BEGIN
2022-01-15 07:35:53.135896 (Thread-1): SQL status: BEGIN in 0.06 seconds
2022-01-15 07:35:53.136220 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-15 07:35:53.136388 (Thread-1): On model.sakila_dbt_project.payment_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.payment_inc"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'payment_inc__dbt_tmp130552665656'
        
      order by ordinal_position

  
2022-01-15 07:35:53.211003 (Thread-1): SQL status: SELECT 7 in 0.07 seconds
2022-01-15 07:35:53.218137 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-15 07:35:53.218368 (Thread-1): On model.sakila_dbt_project.payment_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.payment_inc"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "sakila_wh".INFORMATION_SCHEMA.columns
      where table_name = 'payment_inc'
        
        and table_schema = 'dwh'
        
      order by ordinal_position

  
2022-01-15 07:35:53.285481 (Thread-1): SQL status: SELECT 7 in 0.07 seconds
2022-01-15 07:35:53.297543 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-15 07:35:53.297765 (Thread-1): On model.sakila_dbt_project.payment_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.payment_inc"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "sakila_wh".INFORMATION_SCHEMA.columns
      where table_name = 'payment_inc'
        
        and table_schema = 'dwh'
        
      order by ordinal_position

  
2022-01-15 07:35:53.369280 (Thread-1): SQL status: SELECT 7 in 0.07 seconds
2022-01-15 07:35:53.371412 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.payment_inc"
2022-01-15 07:35:53.372179 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-15 07:35:53.372397 (Thread-1): On model.sakila_dbt_project.payment_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.payment_inc"} */

      delete
    from "sakila_wh"."dwh"."payment_inc"
    where (payment_id) in (
        select (payment_id)
        from "payment_inc__dbt_tmp130552665656"
    );

    insert into "sakila_wh"."dwh"."payment_inc" ("payment_id", "customer_id", "staff_id", "rental_id", "amount", "payment_date", "dbt_tran_time")
    (
       select "payment_id", "customer_id", "staff_id", "rental_id", "amount", "payment_date", "dbt_tran_time"
       from "payment_inc__dbt_tmp130552665656"
    );
  
2022-01-15 07:35:53.444405 (Thread-1): SQL status: INSERT 0 3 in 0.07 seconds
2022-01-15 07:35:53.446848 (Thread-1): On model.sakila_dbt_project.payment_inc: COMMIT
2022-01-15 07:35:53.447139 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-15 07:35:53.447394 (Thread-1): On model.sakila_dbt_project.payment_inc: COMMIT
2022-01-15 07:35:53.512468 (Thread-1): SQL status: COMMIT in 0.06 seconds
2022-01-15 07:35:53.513216 (Thread-1): finished collecting timing info
2022-01-15 07:35:53.513526 (Thread-1): On model.sakila_dbt_project.payment_inc: Close
2022-01-15 07:35:53.514053 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bddf208b-eebe-41be-8280-ba52ce541c88', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104d2fc10>]}
2022-01-15 07:35:53.514469 (Thread-1): 13:05:53 | 4 of 5 OK created incremental model dwh.payment_inc.................. [INSERT 0 3 in 0.89s]
2022-01-15 07:35:53.514693 (Thread-1): Finished running node model.sakila_dbt_project.payment_inc
2022-01-15 07:35:53.514908 (Thread-1): Began running node model.sakila_dbt_project.my_second_dbt_model
2022-01-15 07:35:53.515279 (Thread-1): 13:05:53 | 5 of 5 START table model dwh.my_second_dbt_model..................... [RUN]
2022-01-15 07:35:53.515677 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-15 07:35:53.515885 (Thread-1): Compiling model.sakila_dbt_project.my_second_dbt_model
2022-01-15 07:35:53.518720 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.my_second_dbt_model"
2022-01-15 07:35:53.520072 (Thread-1): finished collecting timing info
2022-01-15 07:35:53.522779 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.my_second_dbt_model"
2022-01-15 07:35:53.523384 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-15 07:35:53.523564 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: BEGIN
2022-01-15 07:35:53.523732 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 07:35:53.895290 (Thread-1): SQL status: BEGIN in 0.37 seconds
2022-01-15 07:35:53.895671 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-15 07:35:53.895918 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */


  create  table "sakila_wh"."dwh"."my_second_dbt_model__dbt_tmp"
  as (
    -- Use the `ref` function to select from other models

select *
from "sakila_wh"."dwh"."my_first_dbt_model"
where id = 1
  );
2022-01-15 07:35:53.966542 (Thread-1): SQL status: SELECT 1 in 0.07 seconds
2022-01-15 07:35:53.970668 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-15 07:35:53.970912 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
alter table "sakila_wh"."dwh"."my_second_dbt_model" rename to "my_second_dbt_model__dbt_backup"
2022-01-15 07:35:54.031114 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-15 07:35:54.034556 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-15 07:35:54.034819 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
alter table "sakila_wh"."dwh"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-15 07:35:54.095627 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-15 07:35:54.097880 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: COMMIT
2022-01-15 07:35:54.098144 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-15 07:35:54.098340 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: COMMIT
2022-01-15 07:35:54.159348 (Thread-1): SQL status: COMMIT in 0.06 seconds
2022-01-15 07:35:54.163772 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-15 07:35:54.164018 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
drop table if exists "sakila_wh"."dwh"."my_second_dbt_model__dbt_backup" cascade
2022-01-15 07:35:54.229036 (Thread-1): SQL status: DROP TABLE in 0.06 seconds
2022-01-15 07:35:54.231230 (Thread-1): finished collecting timing info
2022-01-15 07:35:54.231593 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: Close
2022-01-15 07:35:54.232345 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bddf208b-eebe-41be-8280-ba52ce541c88', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e9cc10>]}
2022-01-15 07:35:54.232740 (Thread-1): 13:05:54 | 5 of 5 OK created table model dwh.my_second_dbt_model................ [SELECT 1 in 0.72s]
2022-01-15 07:35:54.232970 (Thread-1): Finished running node model.sakila_dbt_project.my_second_dbt_model
2022-01-15 07:35:54.235196 (MainThread): Acquiring new postgres connection "master".
2022-01-15 07:35:54.235429 (MainThread): Using postgres connection "master".
2022-01-15 07:35:54.235596 (MainThread): On master: BEGIN
2022-01-15 07:35:54.235762 (MainThread): Opening a new connection, currently in state closed
2022-01-15 07:35:54.608928 (MainThread): SQL status: BEGIN in 0.37 seconds
2022-01-15 07:35:54.609335 (MainThread): On master: COMMIT
2022-01-15 07:35:54.609590 (MainThread): Using postgres connection "master".
2022-01-15 07:35:54.609824 (MainThread): On master: COMMIT
2022-01-15 07:35:54.671370 (MainThread): SQL status: COMMIT in 0.06 seconds
2022-01-15 07:35:54.671722 (MainThread): On master: Close
2022-01-15 07:35:54.672279 (MainThread): 13:05:54 | 
2022-01-15 07:35:54.672544 (MainThread): 13:05:54 | Finished running 4 table models, 1 incremental model in 6.99s.
2022-01-15 07:35:54.672785 (MainThread): Connection 'master' was properly closed.
2022-01-15 07:35:54.672976 (MainThread): Connection 'model.sakila_dbt_project.my_second_dbt_model' was properly closed.
2022-01-15 07:35:54.682047 (MainThread): 
2022-01-15 07:35:54.682290 (MainThread): Completed successfully
2022-01-15 07:35:54.682504 (MainThread): 
Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2022-01-15 07:35:54.682776 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e92c40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e92d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104d96310>]}
2022-01-15 07:35:54.683057 (MainThread): Flushing usage events
2022-01-15 07:43:52.786957 (MainThread): Running with dbt=0.21.1
2022-01-15 07:43:52.885485 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2022-01-15 07:43:52.887551 (MainThread): Tracking: tracking
2022-01-15 07:43:52.905959 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b234f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107119e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107119370>]}
2022-01-15 07:43:52.928157 (MainThread): Partial parsing not enabled
2022-01-15 07:43:52.981639 (MainThread): Parsing macros/catalog.sql
2022-01-15 07:43:52.985477 (MainThread): Parsing macros/relations.sql
2022-01-15 07:43:52.987067 (MainThread): Parsing macros/adapters.sql
2022-01-15 07:43:53.011427 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2022-01-15 07:43:53.013362 (MainThread): Parsing macros/core.sql
2022-01-15 07:43:53.017510 (MainThread): Parsing macros/materializations/test.sql
2022-01-15 07:43:53.024927 (MainThread): Parsing macros/materializations/helpers.sql
2022-01-15 07:43:53.035622 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2022-01-15 07:43:53.037486 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2022-01-15 07:43:53.054903 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2022-01-15 07:43:53.085092 (MainThread): Parsing macros/materializations/seed/seed.sql
2022-01-15 07:43:53.106755 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2022-01-15 07:43:53.108421 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2022-01-15 07:43:53.118119 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2022-01-15 07:43:53.136708 (MainThread): Parsing macros/materializations/common/merge.sql
2022-01-15 07:43:53.149837 (MainThread): Parsing macros/materializations/table/table.sql
2022-01-15 07:43:53.157485 (MainThread): Parsing macros/materializations/view/view.sql
2022-01-15 07:43:53.164263 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2022-01-15 07:43:53.167882 (MainThread): Parsing macros/etc/get_custom_alias.sql
2022-01-15 07:43:53.169243 (MainThread): Parsing macros/etc/query.sql
2022-01-15 07:43:53.170130 (MainThread): Parsing macros/etc/is_incremental.sql
2022-01-15 07:43:53.171512 (MainThread): Parsing macros/etc/datetime.sql
2022-01-15 07:43:53.179507 (MainThread): Parsing macros/etc/where_subquery.sql
2022-01-15 07:43:53.181312 (MainThread): Parsing macros/etc/get_custom_schema.sql
2022-01-15 07:43:53.183549 (MainThread): Parsing macros/etc/get_custom_database.sql
2022-01-15 07:43:53.184994 (MainThread): Parsing macros/adapters/common.sql
2022-01-15 07:43:53.237120 (MainThread): Parsing macros/schema_tests/relationships.sql
2022-01-15 07:43:53.238717 (MainThread): Parsing macros/schema_tests/not_null.sql
2022-01-15 07:43:53.239917 (MainThread): Parsing macros/schema_tests/unique.sql
2022-01-15 07:43:53.241204 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2022-01-15 07:43:53.243360 (MainThread): Parsing macros/cross_db_utils/except.sql
2022-01-15 07:43:53.244359 (MainThread): Parsing macros/cross_db_utils/replace.sql
2022-01-15 07:43:53.245527 (MainThread): Parsing macros/cross_db_utils/concat.sql
2022-01-15 07:43:53.246465 (MainThread): Parsing macros/cross_db_utils/datatypes.sql
2022-01-15 07:43:53.252242 (MainThread): Parsing macros/cross_db_utils/_is_relation.sql
2022-01-15 07:43:53.253393 (MainThread): Parsing macros/cross_db_utils/length.sql
2022-01-15 07:43:53.254745 (MainThread): Parsing macros/cross_db_utils/dateadd.sql
2022-01-15 07:43:53.257531 (MainThread): Parsing macros/cross_db_utils/intersect.sql
2022-01-15 07:43:53.258528 (MainThread): Parsing macros/cross_db_utils/right.sql
2022-01-15 07:43:53.260632 (MainThread): Parsing macros/cross_db_utils/datediff.sql
2022-01-15 07:43:53.270129 (MainThread): Parsing macros/cross_db_utils/safe_cast.sql
2022-01-15 07:43:53.271890 (MainThread): Parsing macros/cross_db_utils/hash.sql
2022-01-15 07:43:53.273224 (MainThread): Parsing macros/cross_db_utils/cast_bool_to_text.sql
2022-01-15 07:43:53.274569 (MainThread): Parsing macros/cross_db_utils/identifier.sql
2022-01-15 07:43:53.276123 (MainThread): Parsing macros/cross_db_utils/position.sql
2022-01-15 07:43:53.277588 (MainThread): Parsing macros/cross_db_utils/literal.sql
2022-01-15 07:43:53.278503 (MainThread): Parsing macros/cross_db_utils/current_timestamp.sql
2022-01-15 07:43:53.282181 (MainThread): Parsing macros/cross_db_utils/width_bucket.sql
2022-01-15 07:43:53.287042 (MainThread): Parsing macros/cross_db_utils/last_day.sql
2022-01-15 07:43:53.290391 (MainThread): Parsing macros/cross_db_utils/split_part.sql
2022-01-15 07:43:53.292110 (MainThread): Parsing macros/cross_db_utils/date_trunc.sql
2022-01-15 07:43:53.293749 (MainThread): Parsing macros/cross_db_utils/_is_ephemeral.sql
2022-01-15 07:43:53.295502 (MainThread): Parsing macros/materializations/insert_by_period_materialization.sql
2022-01-15 07:43:53.320220 (MainThread): Parsing macros/web/get_url_host.sql
2022-01-15 07:43:53.322057 (MainThread): Parsing macros/web/get_url_path.sql
2022-01-15 07:43:53.324718 (MainThread): Parsing macros/web/get_url_parameter.sql
2022-01-15 07:43:53.326404 (MainThread): Parsing macros/jinja_helpers/pretty_log_format.sql
2022-01-15 07:43:53.327665 (MainThread): Parsing macros/jinja_helpers/pretty_time.sql
2022-01-15 07:43:53.328955 (MainThread): Parsing macros/jinja_helpers/log_info.sql
2022-01-15 07:43:53.330023 (MainThread): Parsing macros/jinja_helpers/slugify.sql
2022-01-15 07:43:53.331325 (MainThread): Parsing macros/schema_tests/fewer_rows_than.sql
2022-01-15 07:43:53.333075 (MainThread): Parsing macros/schema_tests/equal_rowcount.sql
2022-01-15 07:43:53.334604 (MainThread): Parsing macros/schema_tests/relationships_where.sql
2022-01-15 07:43:53.336697 (MainThread): Parsing macros/schema_tests/recency.sql
2022-01-15 07:43:53.338309 (MainThread): Parsing macros/schema_tests/not_constant.sql
2022-01-15 07:43:53.339435 (MainThread): Parsing macros/schema_tests/accepted_range.sql
2022-01-15 07:43:53.341720 (MainThread): Parsing macros/schema_tests/not_accepted_values.sql
2022-01-15 07:43:53.343859 (MainThread): Parsing macros/schema_tests/test_unique_where.sql
2022-01-15 07:43:53.345168 (MainThread): Parsing macros/schema_tests/at_least_one.sql
2022-01-15 07:43:53.346343 (MainThread): Parsing macros/schema_tests/unique_combination_of_columns.sql
2022-01-15 07:43:53.349385 (MainThread): Parsing macros/schema_tests/cardinality_equality.sql
2022-01-15 07:43:53.351218 (MainThread): Parsing macros/schema_tests/expression_is_true.sql
2022-01-15 07:43:53.352864 (MainThread): Parsing macros/schema_tests/sequential_values.sql
2022-01-15 07:43:53.355889 (MainThread): Parsing macros/schema_tests/test_not_null_where.sql
2022-01-15 07:43:53.357201 (MainThread): Parsing macros/schema_tests/equality.sql
2022-01-15 07:43:53.360316 (MainThread): Parsing macros/schema_tests/mutually_exclusive_ranges.sql
2022-01-15 07:43:53.368668 (MainThread): Parsing macros/sql/date_spine.sql
2022-01-15 07:43:53.372918 (MainThread): Parsing macros/sql/nullcheck_table.sql
2022-01-15 07:43:53.374492 (MainThread): Parsing macros/sql/get_relations_by_pattern.sql
2022-01-15 07:43:53.377590 (MainThread): Parsing macros/sql/generate_series.sql
2022-01-15 07:43:53.406620 (MainThread): Parsing macros/sql/get_relations_by_prefix.sql
2022-01-15 07:43:53.410967 (MainThread): Parsing macros/sql/get_tables_by_prefix_sql.sql
2022-01-15 07:43:53.413058 (MainThread): Parsing macros/sql/star.sql
2022-01-15 07:43:53.417519 (MainThread): Parsing macros/sql/unpivot.sql
2022-01-15 07:43:53.427513 (MainThread): Parsing macros/sql/union.sql
2022-01-15 07:43:53.437252 (MainThread): Parsing macros/sql/groupby.sql
2022-01-15 07:43:53.438813 (MainThread): Parsing macros/sql/surrogate_key.sql
2022-01-15 07:43:53.442702 (MainThread): Parsing macros/sql/safe_add.sql
2022-01-15 07:43:53.444509 (MainThread): Parsing macros/sql/nullcheck.sql
2022-01-15 07:43:53.446308 (MainThread): Parsing macros/sql/get_tables_by_pattern_sql.sql
2022-01-15 07:43:53.453584 (MainThread): Parsing macros/sql/get_column_values.sql
2022-01-15 07:43:53.458856 (MainThread): Parsing macros/sql/pivot.sql
2022-01-15 07:43:53.463414 (MainThread): Parsing macros/sql/get_query_results_as_dict.sql
2022-01-15 07:43:53.465944 (MainThread): Parsing macros/sql/haversine_distance.sql
2022-01-15 07:43:53.774348 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-15 07:43:53.786146 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-15 07:43:53.789811 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-15 07:43:53.797196 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-15 07:43:53.800682 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-15 07:43:53.833752 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 07:43:53.842645 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 07:43:53.844255 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 07:43:53.846031 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 07:43:53.847812 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 07:43:53.849899 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 07:43:53.865507 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 07:43:53.867218 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 07:43:53.890065 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f26cceb5-fea3-41d2-ab93-8997bf0b7aaf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1072890d0>]}
2022-01-15 07:43:53.898092 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-01-15 07:43:53.898640 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f26cceb5-fea3-41d2-ab93-8997bf0b7aaf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107289fd0>]}
2022-01-15 07:43:53.898880 (MainThread): Found 5 models, 8 tests, 0 snapshots, 0 analyses, 347 macros, 0 operations, 0 seed files, 12 sources, 0 exposures
2022-01-15 07:43:53.900451 (MainThread): 
2022-01-15 07:43:53.900771 (MainThread): Acquiring new postgres connection "master".
2022-01-15 07:43:53.901579 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_sakila_wh".
2022-01-15 07:43:53.910488 (ThreadPoolExecutor-0_0): Using postgres connection "list_sakila_wh".
2022-01-15 07:43:53.910652 (ThreadPoolExecutor-0_0): On list_sakila_wh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh"} */

    select distinct nspname from pg_namespace
  
2022-01-15 07:43:53.910800 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2022-01-15 07:43:54.318227 (ThreadPoolExecutor-0_0): SQL status: SELECT 12 in 0.41 seconds
2022-01-15 07:43:54.320468 (ThreadPoolExecutor-0_0): On list_sakila_wh: Close
2022-01-15 07:43:54.322073 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_dwh".
2022-01-15 07:43:54.328436 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-15 07:43:54.328607 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: BEGIN
2022-01-15 07:43:54.328761 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2022-01-15 07:43:54.727320 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.40 seconds
2022-01-15 07:43:54.727747 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-15 07:43:54.728023 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_dwh"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dwh'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dwh'
  
2022-01-15 07:43:54.797342 (ThreadPoolExecutor-1_0): SQL status: SELECT 5 in 0.07 seconds
2022-01-15 07:43:54.799630 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: ROLLBACK
2022-01-15 07:43:54.860851 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: Close
2022-01-15 07:43:54.867468 (MainThread): Using postgres connection "master".
2022-01-15 07:43:54.867706 (MainThread): On master: BEGIN
2022-01-15 07:43:54.867892 (MainThread): Opening a new connection, currently in state init
2022-01-15 07:43:55.246415 (MainThread): SQL status: BEGIN in 0.38 seconds
2022-01-15 07:43:55.246800 (MainThread): Using postgres connection "master".
2022-01-15 07:43:55.247066 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-15 07:43:55.324693 (MainThread): SQL status: SELECT 47 in 0.08 seconds
2022-01-15 07:43:55.329149 (MainThread): On master: ROLLBACK
2022-01-15 07:43:55.389792 (MainThread): Using postgres connection "master".
2022-01-15 07:43:55.390213 (MainThread): On master: BEGIN
2022-01-15 07:43:55.512164 (MainThread): SQL status: BEGIN in 0.12 seconds
2022-01-15 07:43:55.512778 (MainThread): On master: COMMIT
2022-01-15 07:43:55.513150 (MainThread): Using postgres connection "master".
2022-01-15 07:43:55.513555 (MainThread): On master: COMMIT
2022-01-15 07:43:55.573759 (MainThread): SQL status: COMMIT in 0.06 seconds
2022-01-15 07:43:55.574328 (MainThread): On master: Close
2022-01-15 07:43:55.574994 (MainThread): 13:13:55 | Concurrency: 1 threads (target='dev')
2022-01-15 07:43:55.575354 (MainThread): 13:13:55 | 
2022-01-15 07:43:55.578706 (Thread-1): Began running node model.sakila_dbt_project.dim_date
2022-01-15 07:43:55.579112 (Thread-1): 13:13:55 | 1 of 5 START table model dwh.dim_date................................ [RUN]
2022-01-15 07:43:55.579651 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-15 07:43:55.579927 (Thread-1): Compiling model.sakila_dbt_project.dim_date
2022-01-15 07:43:55.582111 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_date"
2022-01-15 07:43:55.582732 (Thread-1): finished collecting timing info
2022-01-15 07:43:55.608742 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_date"
2022-01-15 07:43:55.609416 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-15 07:43:55.609599 (Thread-1): On model.sakila_dbt_project.dim_date: BEGIN
2022-01-15 07:43:55.609759 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 07:43:55.986388 (Thread-1): SQL status: BEGIN in 0.38 seconds
2022-01-15 07:43:55.986786 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-15 07:43:55.987047 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */


  create  table "sakila_wh"."dwh"."dim_date__dbt_tmp"
  as (
    with dates as (
SELECT
       TO_CHAR(datum, 'yyyymmdd')::INT AS date_dim_id,
       datum AS date_key,
       EXTRACT(EPOCH FROM datum) AS epoch,
       TO_CHAR(datum, 'TMDay') AS day_name,
       EXTRACT(ISODOW FROM datum) AS day_of_week,
       EXTRACT(DAY FROM datum) AS day_of_month,
       datum - DATE_TRUNC('quarter', datum)::DATE + 1 AS day_of_quarter,
       EXTRACT(DOY FROM datum) AS day_of_year,
       TO_CHAR(datum, 'W')::INT AS week_of_month,
       EXTRACT(WEEK FROM datum) AS week_of_year,
       EXTRACT(MONTH FROM datum) AS month_actual,
       TO_CHAR(datum, 'TMMonth') AS month_name,
       TO_CHAR(datum, 'Mon') AS month_name_abbreviated,
       EXTRACT(QUARTER FROM datum) AS quarter_actual,
       CASE
           WHEN EXTRACT(QUARTER FROM datum) = 1 THEN 'First'
           WHEN EXTRACT(QUARTER FROM datum) = 2 THEN 'Second'
           WHEN EXTRACT(QUARTER FROM datum) = 3 THEN 'Third'
           WHEN EXTRACT(QUARTER FROM datum) = 4 THEN 'Fourth'
           END AS quarter_name,
       EXTRACT(YEAR FROM datum) AS year_actual,
       datum + (1 - EXTRACT(ISODOW FROM datum))::INT AS first_day_of_week,
       datum + (7 - EXTRACT(ISODOW FROM datum))::INT AS last_day_of_week,
       datum + (1 - EXTRACT(DAY FROM datum))::INT AS first_day_of_month,
       (DATE_TRUNC('MONTH', datum) + INTERVAL '1 MONTH - 1 day')::DATE AS last_day_of_month,
       DATE_TRUNC('quarter', datum)::DATE AS first_day_of_quarter,
       (DATE_TRUNC('quarter', datum) + INTERVAL '3 MONTH - 1 day')::DATE AS last_day_of_quarter,
       TO_DATE(EXTRACT(YEAR FROM datum) || '-01-01', 'YYYY-MM-DD') AS first_day_of_year,
       TO_DATE(EXTRACT(YEAR FROM datum) || '-12-31', 'YYYY-MM-DD') AS last_day_of_year,
       TO_CHAR(datum, 'yyyymm') AS yyyymm,
       CASE
           WHEN EXTRACT(ISODOW FROM datum) IN (6, 7) THEN TRUE
           ELSE FALSE
           END AS weekend_indr
FROM (SELECT '2000-01-01'::DATE + SEQUENCE.DAY AS datum
      FROM GENERATE_SERIES(0, 29219) AS SEQUENCE (DAY)
      GROUP BY SEQUENCE.DAY) DQ
)
select
*
from
dates
where
date_key <= CURRENT_DATE
order by date_dim_id asc
  );
2022-01-15 07:43:56.892315 (Thread-1): SQL status: SELECT 8051 in 0.90 seconds
2022-01-15 07:43:56.901237 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-15 07:43:56.901475 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
alter table "sakila_wh"."dwh"."dim_date" rename to "dim_date__dbt_backup"
2022-01-15 07:43:56.963296 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-15 07:43:56.967220 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-15 07:43:56.967463 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
alter table "sakila_wh"."dwh"."dim_date__dbt_tmp" rename to "dim_date"
2022-01-15 07:43:57.028231 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-15 07:43:57.040982 (Thread-1): On model.sakila_dbt_project.dim_date: COMMIT
2022-01-15 07:43:57.041233 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-15 07:43:57.041406 (Thread-1): On model.sakila_dbt_project.dim_date: COMMIT
2022-01-15 07:43:57.102889 (Thread-1): SQL status: COMMIT in 0.06 seconds
2022-01-15 07:43:57.109631 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-15 07:43:57.109851 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
drop table if exists "sakila_wh"."dwh"."dim_date__dbt_backup" cascade
2022-01-15 07:43:57.177480 (Thread-1): SQL status: DROP TABLE in 0.07 seconds
2022-01-15 07:43:57.179478 (Thread-1): finished collecting timing info
2022-01-15 07:43:57.179765 (Thread-1): On model.sakila_dbt_project.dim_date: Close
2022-01-15 07:43:57.180350 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f26cceb5-fea3-41d2-ab93-8997bf0b7aaf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10745ad90>]}
2022-01-15 07:43:57.180819 (Thread-1): 13:13:57 | 1 of 5 OK created table model dwh.dim_date........................... [SELECT 8051 in 1.60s]
2022-01-15 07:43:57.181212 (Thread-1): Finished running node model.sakila_dbt_project.dim_date
2022-01-15 07:43:57.181607 (Thread-1): Began running node model.sakila_dbt_project.hello_world
2022-01-15 07:43:57.182097 (Thread-1): 13:13:57 | 2 of 5 START table model dwh.hello_world............................. [RUN]
2022-01-15 07:43:57.182550 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-15 07:43:57.182746 (Thread-1): Compiling model.sakila_dbt_project.hello_world
2022-01-15 07:43:57.184571 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.hello_world"
2022-01-15 07:43:57.185223 (Thread-1): finished collecting timing info
2022-01-15 07:43:57.187911 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.hello_world"
2022-01-15 07:43:57.188506 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-15 07:43:57.188687 (Thread-1): On model.sakila_dbt_project.hello_world: BEGIN
2022-01-15 07:43:57.188858 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 07:43:57.562061 (Thread-1): SQL status: BEGIN in 0.37 seconds
2022-01-15 07:43:57.562647 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-15 07:43:57.563003 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */


  create  table "sakila_wh"."dwh"."hello_world__dbt_tmp"
  as (
    select
	customer.customer_id::int,
	customer.store_id::int,
	customer.first_name,
	customer.last_name,
	concat(customer.first_name,' ',customer.last_name) as full_name,
	substring(email from POSITION('@' in email)+1 for char_length(email)-POSITION('@' in email)) as domain,
	customer.email,
	customer.active::int,
	customer.address_id::int,
	address.address,
	city.city_id::int,
	city.city,
	(case when customer.active = 0 then 'no' else 'yes' end)::varchar(100) as "active_desc",
	customer.create_date::timestamp,
	customer.last_update::timestamp
from
	stg.customer as customer

	left join stg.address on 1=1
	and customer.address_id =address.address_id

	left join stg.city on 1=1
	and address.city_id = city.city_id
  );
2022-01-15 07:43:57.641553 (Thread-1): SQL status: SELECT 599 in 0.08 seconds
2022-01-15 07:43:57.646499 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-15 07:43:57.646710 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
alter table "sakila_wh"."dwh"."hello_world" rename to "hello_world__dbt_backup"
2022-01-15 07:43:57.708013 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-15 07:43:57.711653 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-15 07:43:57.711893 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
alter table "sakila_wh"."dwh"."hello_world__dbt_tmp" rename to "hello_world"
2022-01-15 07:43:57.772905 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-15 07:43:57.775107 (Thread-1): On model.sakila_dbt_project.hello_world: COMMIT
2022-01-15 07:43:57.775362 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-15 07:43:57.775562 (Thread-1): On model.sakila_dbt_project.hello_world: COMMIT
2022-01-15 07:43:57.836932 (Thread-1): SQL status: COMMIT in 0.06 seconds
2022-01-15 07:43:57.839586 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-15 07:43:57.839819 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
drop table if exists "sakila_wh"."dwh"."hello_world__dbt_backup" cascade
2022-01-15 07:43:57.907121 (Thread-1): SQL status: DROP TABLE in 0.07 seconds
2022-01-15 07:43:57.909153 (Thread-1): finished collecting timing info
2022-01-15 07:43:57.909501 (Thread-1): On model.sakila_dbt_project.hello_world: Close
2022-01-15 07:43:57.910158 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f26cceb5-fea3-41d2-ab93-8997bf0b7aaf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074d7cd0>]}
2022-01-15 07:43:57.910536 (Thread-1): 13:13:57 | 2 of 5 OK created table model dwh.hello_world........................ [SELECT 599 in 0.73s]
2022-01-15 07:43:57.910759 (Thread-1): Finished running node model.sakila_dbt_project.hello_world
2022-01-15 07:43:57.910975 (Thread-1): Began running node model.sakila_dbt_project.my_first_dbt_model
2022-01-15 07:43:57.911247 (Thread-1): 13:13:57 | 3 of 5 START table model dwh.my_first_dbt_model...................... [RUN]
2022-01-15 07:43:57.911594 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-15 07:43:57.911876 (Thread-1): Compiling model.sakila_dbt_project.my_first_dbt_model
2022-01-15 07:43:57.914878 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.my_first_dbt_model"
2022-01-15 07:43:57.915566 (Thread-1): finished collecting timing info
2022-01-15 07:43:57.918309 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.my_first_dbt_model"
2022-01-15 07:43:57.918896 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-15 07:43:57.919082 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: BEGIN
2022-01-15 07:43:57.919342 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 07:43:58.287905 (Thread-1): SQL status: BEGIN in 0.37 seconds
2022-01-15 07:43:58.288234 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-15 07:43:58.288447 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */


  create  table "sakila_wh"."dwh"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-15 07:43:58.355175 (Thread-1): SQL status: SELECT 2 in 0.07 seconds
2022-01-15 07:43:58.358738 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-15 07:43:58.358971 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
alter table "sakila_wh"."dwh"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2022-01-15 07:43:58.422123 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-15 07:43:58.426311 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-15 07:43:58.426571 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
alter table "sakila_wh"."dwh"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-15 07:43:58.488365 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-15 07:43:58.490885 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: COMMIT
2022-01-15 07:43:58.491177 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-15 07:43:58.491441 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: COMMIT
2022-01-15 07:43:58.551935 (Thread-1): SQL status: COMMIT in 0.06 seconds
2022-01-15 07:43:58.554339 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-15 07:43:58.554561 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
drop table if exists "sakila_wh"."dwh"."my_first_dbt_model__dbt_backup" cascade
2022-01-15 07:43:58.624177 (Thread-1): SQL status: DROP TABLE in 0.07 seconds
2022-01-15 07:43:58.626019 (Thread-1): finished collecting timing info
2022-01-15 07:43:58.626316 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: Close
2022-01-15 07:43:58.626874 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f26cceb5-fea3-41d2-ab93-8997bf0b7aaf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074db310>]}
2022-01-15 07:43:58.627376 (Thread-1): 13:13:58 | 3 of 5 OK created table model dwh.my_first_dbt_model................. [SELECT 2 in 0.72s]
2022-01-15 07:43:58.627653 (Thread-1): Finished running node model.sakila_dbt_project.my_first_dbt_model
2022-01-15 07:43:58.627918 (Thread-1): Began running node model.sakila_dbt_project.payment_inc
2022-01-15 07:43:58.628489 (Thread-1): 13:13:58 | 4 of 5 START incremental model dwh.payment_inc....................... [RUN]
2022-01-15 07:43:58.629008 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-15 07:43:58.629225 (Thread-1): Compiling model.sakila_dbt_project.payment_inc
2022-01-15 07:43:58.635666 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.payment_inc"
2022-01-15 07:43:58.636302 (Thread-1): finished collecting timing info
2022-01-15 07:43:58.674427 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-15 07:43:58.674670 (Thread-1): On model.sakila_dbt_project.payment_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.payment_inc"} */

    

  create temporary table "payment_inc__dbt_tmp131358668611"
  as (
    

select
*,
'2022-01-15 07:43:52' as dbt_tran_time
from
stg.payment
where 1=1


and payment_date::timestamp > (select max(payment_date) from "sakila_wh"."dwh"."payment_inc")



-- - INTERVAL '3 DAY'
-- unique_key='payment_id'
  );
  
2022-01-15 07:43:58.674860 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 07:43:59.080297 (Thread-1): SQL status: SELECT 2 in 0.41 seconds
2022-01-15 07:43:59.089698 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-15 07:43:59.089932 (Thread-1): On model.sakila_dbt_project.payment_inc: BEGIN
2022-01-15 07:43:59.151111 (Thread-1): SQL status: BEGIN in 0.06 seconds
2022-01-15 07:43:59.151447 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-15 07:43:59.151660 (Thread-1): On model.sakila_dbt_project.payment_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.payment_inc"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'payment_inc__dbt_tmp131358668611'
        
      order by ordinal_position

  
2022-01-15 07:43:59.224643 (Thread-1): SQL status: SELECT 7 in 0.07 seconds
2022-01-15 07:43:59.231425 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-15 07:43:59.231678 (Thread-1): On model.sakila_dbt_project.payment_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.payment_inc"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "sakila_wh".INFORMATION_SCHEMA.columns
      where table_name = 'payment_inc'
        
        and table_schema = 'dwh'
        
      order by ordinal_position

  
2022-01-15 07:43:59.299218 (Thread-1): SQL status: SELECT 7 in 0.07 seconds
2022-01-15 07:43:59.310887 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-15 07:43:59.311101 (Thread-1): On model.sakila_dbt_project.payment_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.payment_inc"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "sakila_wh".INFORMATION_SCHEMA.columns
      where table_name = 'payment_inc'
        
        and table_schema = 'dwh'
        
      order by ordinal_position

  
2022-01-15 07:43:59.379021 (Thread-1): SQL status: SELECT 7 in 0.07 seconds
2022-01-15 07:43:59.381489 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.payment_inc"
2022-01-15 07:43:59.382355 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-15 07:43:59.382583 (Thread-1): On model.sakila_dbt_project.payment_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.payment_inc"} */

      

    insert into "sakila_wh"."dwh"."payment_inc" ("payment_id", "customer_id", "staff_id", "rental_id", "amount", "payment_date", "dbt_tran_time")
    (
       select "payment_id", "customer_id", "staff_id", "rental_id", "amount", "payment_date", "dbt_tran_time"
       from "payment_inc__dbt_tmp131358668611"
    );
  
2022-01-15 07:43:59.444003 (Thread-1): SQL status: INSERT 0 2 in 0.06 seconds
2022-01-15 07:43:59.446385 (Thread-1): On model.sakila_dbt_project.payment_inc: COMMIT
2022-01-15 07:43:59.446678 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-15 07:43:59.446926 (Thread-1): On model.sakila_dbt_project.payment_inc: COMMIT
2022-01-15 07:43:59.509203 (Thread-1): SQL status: COMMIT in 0.06 seconds
2022-01-15 07:43:59.510177 (Thread-1): finished collecting timing info
2022-01-15 07:43:59.510560 (Thread-1): On model.sakila_dbt_project.payment_inc: Close
2022-01-15 07:43:59.511194 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f26cceb5-fea3-41d2-ab93-8997bf0b7aaf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107484ee0>]}
2022-01-15 07:43:59.511670 (Thread-1): 13:13:59 | 4 of 5 OK created incremental model dwh.payment_inc.................. [INSERT 0 2 in 0.88s]
2022-01-15 07:43:59.511950 (Thread-1): Finished running node model.sakila_dbt_project.payment_inc
2022-01-15 07:43:59.512232 (Thread-1): Began running node model.sakila_dbt_project.my_second_dbt_model
2022-01-15 07:43:59.512677 (Thread-1): 13:13:59 | 5 of 5 START table model dwh.my_second_dbt_model..................... [RUN]
2022-01-15 07:43:59.513292 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-15 07:43:59.513545 (Thread-1): Compiling model.sakila_dbt_project.my_second_dbt_model
2022-01-15 07:43:59.516412 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.my_second_dbt_model"
2022-01-15 07:43:59.517006 (Thread-1): finished collecting timing info
2022-01-15 07:43:59.519604 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.my_second_dbt_model"
2022-01-15 07:43:59.520166 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-15 07:43:59.520343 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: BEGIN
2022-01-15 07:43:59.520509 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 07:43:59.908287 (Thread-1): SQL status: BEGIN in 0.39 seconds
2022-01-15 07:43:59.908716 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-15 07:43:59.908994 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */


  create  table "sakila_wh"."dwh"."my_second_dbt_model__dbt_tmp"
  as (
    -- Use the `ref` function to select from other models

select *
from "sakila_wh"."dwh"."my_first_dbt_model"
where id = 1
  );
2022-01-15 07:43:59.974315 (Thread-1): SQL status: SELECT 1 in 0.07 seconds
2022-01-15 07:43:59.978117 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-15 07:43:59.978356 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
alter table "sakila_wh"."dwh"."my_second_dbt_model" rename to "my_second_dbt_model__dbt_backup"
2022-01-15 07:44:00.040763 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-15 07:44:00.044827 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-15 07:44:00.045056 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
alter table "sakila_wh"."dwh"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-15 07:44:00.113115 (Thread-1): SQL status: ALTER TABLE in 0.07 seconds
2022-01-15 07:44:00.114964 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: COMMIT
2022-01-15 07:44:00.115237 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-15 07:44:00.115476 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: COMMIT
2022-01-15 07:44:00.176861 (Thread-1): SQL status: COMMIT in 0.06 seconds
2022-01-15 07:44:00.181752 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-15 07:44:00.182021 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
drop table if exists "sakila_wh"."dwh"."my_second_dbt_model__dbt_backup" cascade
2022-01-15 07:44:00.249172 (Thread-1): SQL status: DROP TABLE in 0.07 seconds
2022-01-15 07:44:00.250877 (Thread-1): finished collecting timing info
2022-01-15 07:44:00.251187 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: Close
2022-01-15 07:44:00.251772 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f26cceb5-fea3-41d2-ab93-8997bf0b7aaf', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107509340>]}
2022-01-15 07:44:00.252246 (Thread-1): 13:14:00 | 5 of 5 OK created table model dwh.my_second_dbt_model................ [SELECT 1 in 0.74s]
2022-01-15 07:44:00.252522 (Thread-1): Finished running node model.sakila_dbt_project.my_second_dbt_model
2022-01-15 07:44:00.253893 (MainThread): Acquiring new postgres connection "master".
2022-01-15 07:44:00.254135 (MainThread): Using postgres connection "master".
2022-01-15 07:44:00.254305 (MainThread): On master: BEGIN
2022-01-15 07:44:00.254475 (MainThread): Opening a new connection, currently in state closed
2022-01-15 07:44:00.629795 (MainThread): SQL status: BEGIN in 0.38 seconds
2022-01-15 07:44:00.630212 (MainThread): On master: COMMIT
2022-01-15 07:44:00.630504 (MainThread): Using postgres connection "master".
2022-01-15 07:44:00.630703 (MainThread): On master: COMMIT
2022-01-15 07:44:00.691098 (MainThread): SQL status: COMMIT in 0.06 seconds
2022-01-15 07:44:00.691517 (MainThread): On master: Close
2022-01-15 07:44:00.692198 (MainThread): 13:14:00 | 
2022-01-15 07:44:00.692470 (MainThread): 13:14:00 | Finished running 4 table models, 1 incremental model in 6.79s.
2022-01-15 07:44:00.692666 (MainThread): Connection 'master' was properly closed.
2022-01-15 07:44:00.692824 (MainThread): Connection 'model.sakila_dbt_project.my_second_dbt_model' was properly closed.
2022-01-15 07:44:00.702094 (MainThread): 
2022-01-15 07:44:00.702346 (MainThread): Completed successfully
2022-01-15 07:44:00.702552 (MainThread): 
Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2022-01-15 07:44:00.702808 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10735c9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10735c880>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10735c2b0>]}
2022-01-15 07:44:00.703067 (MainThread): Flushing usage events
2022-01-15 07:56:40.815634 (MainThread): Running with dbt=0.21.1
2022-01-15 07:56:40.913349 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, data=False, schema=False, fail_fast=False, store_failures=False, greedy=False, threads=None, version_check=True, select=['example.my_first_dbt_model'], exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.test.TestTask'>, which='test', rpc_method='test')
2022-01-15 07:56:40.914955 (MainThread): Tracking: tracking
2022-01-15 07:56:40.935053 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e2598e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dc66400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e246dc0>]}
2022-01-15 07:56:40.956719 (MainThread): Partial parsing not enabled
2022-01-15 07:56:41.009113 (MainThread): Parsing macros/catalog.sql
2022-01-15 07:56:41.012528 (MainThread): Parsing macros/relations.sql
2022-01-15 07:56:41.013836 (MainThread): Parsing macros/adapters.sql
2022-01-15 07:56:41.035738 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2022-01-15 07:56:41.037393 (MainThread): Parsing macros/core.sql
2022-01-15 07:56:41.040953 (MainThread): Parsing macros/materializations/test.sql
2022-01-15 07:56:41.047575 (MainThread): Parsing macros/materializations/helpers.sql
2022-01-15 07:56:41.057286 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2022-01-15 07:56:41.058915 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2022-01-15 07:56:41.075606 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2022-01-15 07:56:41.106171 (MainThread): Parsing macros/materializations/seed/seed.sql
2022-01-15 07:56:41.127882 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2022-01-15 07:56:41.129745 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2022-01-15 07:56:41.139395 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2022-01-15 07:56:41.158187 (MainThread): Parsing macros/materializations/common/merge.sql
2022-01-15 07:56:41.171603 (MainThread): Parsing macros/materializations/table/table.sql
2022-01-15 07:56:41.178935 (MainThread): Parsing macros/materializations/view/view.sql
2022-01-15 07:56:41.185795 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2022-01-15 07:56:41.189399 (MainThread): Parsing macros/etc/get_custom_alias.sql
2022-01-15 07:56:41.190763 (MainThread): Parsing macros/etc/query.sql
2022-01-15 07:56:41.191646 (MainThread): Parsing macros/etc/is_incremental.sql
2022-01-15 07:56:41.193013 (MainThread): Parsing macros/etc/datetime.sql
2022-01-15 07:56:41.201129 (MainThread): Parsing macros/etc/where_subquery.sql
2022-01-15 07:56:41.202807 (MainThread): Parsing macros/etc/get_custom_schema.sql
2022-01-15 07:56:41.205040 (MainThread): Parsing macros/etc/get_custom_database.sql
2022-01-15 07:56:41.206474 (MainThread): Parsing macros/adapters/common.sql
2022-01-15 07:56:41.258756 (MainThread): Parsing macros/schema_tests/relationships.sql
2022-01-15 07:56:41.260321 (MainThread): Parsing macros/schema_tests/not_null.sql
2022-01-15 07:56:41.261419 (MainThread): Parsing macros/schema_tests/unique.sql
2022-01-15 07:56:41.262638 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2022-01-15 07:56:41.264988 (MainThread): Parsing macros/cross_db_utils/except.sql
2022-01-15 07:56:41.266319 (MainThread): Parsing macros/cross_db_utils/replace.sql
2022-01-15 07:56:41.267498 (MainThread): Parsing macros/cross_db_utils/concat.sql
2022-01-15 07:56:41.268422 (MainThread): Parsing macros/cross_db_utils/datatypes.sql
2022-01-15 07:56:41.274041 (MainThread): Parsing macros/cross_db_utils/_is_relation.sql
2022-01-15 07:56:41.275216 (MainThread): Parsing macros/cross_db_utils/length.sql
2022-01-15 07:56:41.276474 (MainThread): Parsing macros/cross_db_utils/dateadd.sql
2022-01-15 07:56:41.279246 (MainThread): Parsing macros/cross_db_utils/intersect.sql
2022-01-15 07:56:41.280315 (MainThread): Parsing macros/cross_db_utils/right.sql
2022-01-15 07:56:41.282608 (MainThread): Parsing macros/cross_db_utils/datediff.sql
2022-01-15 07:56:41.292074 (MainThread): Parsing macros/cross_db_utils/safe_cast.sql
2022-01-15 07:56:41.293772 (MainThread): Parsing macros/cross_db_utils/hash.sql
2022-01-15 07:56:41.295142 (MainThread): Parsing macros/cross_db_utils/cast_bool_to_text.sql
2022-01-15 07:56:41.296473 (MainThread): Parsing macros/cross_db_utils/identifier.sql
2022-01-15 07:56:41.298009 (MainThread): Parsing macros/cross_db_utils/position.sql
2022-01-15 07:56:41.299763 (MainThread): Parsing macros/cross_db_utils/literal.sql
2022-01-15 07:56:41.300648 (MainThread): Parsing macros/cross_db_utils/current_timestamp.sql
2022-01-15 07:56:41.303917 (MainThread): Parsing macros/cross_db_utils/width_bucket.sql
2022-01-15 07:56:41.308660 (MainThread): Parsing macros/cross_db_utils/last_day.sql
2022-01-15 07:56:41.312140 (MainThread): Parsing macros/cross_db_utils/split_part.sql
2022-01-15 07:56:41.313948 (MainThread): Parsing macros/cross_db_utils/date_trunc.sql
2022-01-15 07:56:41.315834 (MainThread): Parsing macros/cross_db_utils/_is_ephemeral.sql
2022-01-15 07:56:41.317775 (MainThread): Parsing macros/materializations/insert_by_period_materialization.sql
2022-01-15 07:56:41.341285 (MainThread): Parsing macros/web/get_url_host.sql
2022-01-15 07:56:41.342983 (MainThread): Parsing macros/web/get_url_path.sql
2022-01-15 07:56:41.345360 (MainThread): Parsing macros/web/get_url_parameter.sql
2022-01-15 07:56:41.346829 (MainThread): Parsing macros/jinja_helpers/pretty_log_format.sql
2022-01-15 07:56:41.347897 (MainThread): Parsing macros/jinja_helpers/pretty_time.sql
2022-01-15 07:56:41.349277 (MainThread): Parsing macros/jinja_helpers/log_info.sql
2022-01-15 07:56:41.350431 (MainThread): Parsing macros/jinja_helpers/slugify.sql
2022-01-15 07:56:41.351583 (MainThread): Parsing macros/schema_tests/fewer_rows_than.sql
2022-01-15 07:56:41.353128 (MainThread): Parsing macros/schema_tests/equal_rowcount.sql
2022-01-15 07:56:41.354635 (MainThread): Parsing macros/schema_tests/relationships_where.sql
2022-01-15 07:56:41.356794 (MainThread): Parsing macros/schema_tests/recency.sql
2022-01-15 07:56:41.358387 (MainThread): Parsing macros/schema_tests/not_constant.sql
2022-01-15 07:56:41.359613 (MainThread): Parsing macros/schema_tests/accepted_range.sql
2022-01-15 07:56:41.361939 (MainThread): Parsing macros/schema_tests/not_accepted_values.sql
2022-01-15 07:56:41.363878 (MainThread): Parsing macros/schema_tests/test_unique_where.sql
2022-01-15 07:56:41.365283 (MainThread): Parsing macros/schema_tests/at_least_one.sql
2022-01-15 07:56:41.366619 (MainThread): Parsing macros/schema_tests/unique_combination_of_columns.sql
2022-01-15 07:56:41.369463 (MainThread): Parsing macros/schema_tests/cardinality_equality.sql
2022-01-15 07:56:41.371291 (MainThread): Parsing macros/schema_tests/expression_is_true.sql
2022-01-15 07:56:41.373007 (MainThread): Parsing macros/schema_tests/sequential_values.sql
2022-01-15 07:56:41.375834 (MainThread): Parsing macros/schema_tests/test_not_null_where.sql
2022-01-15 07:56:41.377197 (MainThread): Parsing macros/schema_tests/equality.sql
2022-01-15 07:56:41.380338 (MainThread): Parsing macros/schema_tests/mutually_exclusive_ranges.sql
2022-01-15 07:56:41.388768 (MainThread): Parsing macros/sql/date_spine.sql
2022-01-15 07:56:41.393127 (MainThread): Parsing macros/sql/nullcheck_table.sql
2022-01-15 07:56:41.394626 (MainThread): Parsing macros/sql/get_relations_by_pattern.sql
2022-01-15 07:56:41.397806 (MainThread): Parsing macros/sql/generate_series.sql
2022-01-15 07:56:41.427063 (MainThread): Parsing macros/sql/get_relations_by_prefix.sql
2022-01-15 07:56:41.431526 (MainThread): Parsing macros/sql/get_tables_by_prefix_sql.sql
2022-01-15 07:56:41.433728 (MainThread): Parsing macros/sql/star.sql
2022-01-15 07:56:41.437908 (MainThread): Parsing macros/sql/unpivot.sql
2022-01-15 07:56:41.447770 (MainThread): Parsing macros/sql/union.sql
2022-01-15 07:56:41.457291 (MainThread): Parsing macros/sql/groupby.sql
2022-01-15 07:56:41.458793 (MainThread): Parsing macros/sql/surrogate_key.sql
2022-01-15 07:56:41.462558 (MainThread): Parsing macros/sql/safe_add.sql
2022-01-15 07:56:41.464333 (MainThread): Parsing macros/sql/nullcheck.sql
2022-01-15 07:56:41.466262 (MainThread): Parsing macros/sql/get_tables_by_pattern_sql.sql
2022-01-15 07:56:41.473199 (MainThread): Parsing macros/sql/get_column_values.sql
2022-01-15 07:56:41.478588 (MainThread): Parsing macros/sql/pivot.sql
2022-01-15 07:56:41.483163 (MainThread): Parsing macros/sql/get_query_results_as_dict.sql
2022-01-15 07:56:41.485387 (MainThread): Parsing macros/sql/haversine_distance.sql
2022-01-15 07:56:41.786480 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-15 07:56:41.798380 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-15 07:56:41.801988 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-15 07:56:41.809291 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-15 07:56:41.812521 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-15 07:56:41.845109 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 07:56:41.846828 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 07:56:41.848730 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 07:56:41.850771 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 07:56:41.852421 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 07:56:41.854319 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 07:56:41.868862 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 07:56:41.870559 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 07:56:41.893219 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c55d1687-74a0-47cc-8154-c66ca7099ff2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e4690d0>]}
2022-01-15 07:56:41.901299 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-01-15 07:56:41.901763 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c55d1687-74a0-47cc-8154-c66ca7099ff2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e469130>]}
2022-01-15 07:56:41.901997 (MainThread): Found 5 models, 8 tests, 0 snapshots, 0 analyses, 347 macros, 0 operations, 0 seed files, 12 sources, 0 exposures
2022-01-15 07:56:41.903181 (MainThread): 
2022-01-15 07:56:41.903491 (MainThread): Acquiring new postgres connection "master".
2022-01-15 07:56:41.904350 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_dwh".
2022-01-15 07:56:41.912811 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-15 07:56:41.912962 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: BEGIN
2022-01-15 07:56:41.913087 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2022-01-15 07:56:42.382028 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.47 seconds
2022-01-15 07:56:42.382412 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-15 07:56:42.382659 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_dwh"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dwh'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dwh'
  
2022-01-15 07:56:42.452264 (ThreadPoolExecutor-1_0): SQL status: SELECT 5 in 0.07 seconds
2022-01-15 07:56:42.453938 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: ROLLBACK
2022-01-15 07:56:42.516983 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: Close
2022-01-15 07:56:42.522901 (MainThread): Using postgres connection "master".
2022-01-15 07:56:42.523114 (MainThread): On master: BEGIN
2022-01-15 07:56:42.523285 (MainThread): Opening a new connection, currently in state init
2022-01-15 07:56:42.909595 (MainThread): SQL status: BEGIN in 0.39 seconds
2022-01-15 07:56:42.910063 (MainThread): Using postgres connection "master".
2022-01-15 07:56:42.910363 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-15 07:56:42.988537 (MainThread): SQL status: SELECT 47 in 0.08 seconds
2022-01-15 07:56:42.991895 (MainThread): On master: ROLLBACK
2022-01-15 07:56:43.054522 (MainThread): On master: Close
2022-01-15 07:56:43.055364 (MainThread): 13:26:43 | Concurrency: 1 threads (target='dev')
2022-01-15 07:56:43.055694 (MainThread): 13:26:43 | 
2022-01-15 07:56:43.058250 (Thread-1): Began running node test.sakila_dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
2022-01-15 07:56:43.058496 (Thread-1): 13:26:43 | 1 of 2 START test not_null_my_first_dbt_model_id..................... [RUN]
2022-01-15 07:56:43.059035 (Thread-1): Acquiring new postgres connection "test.sakila_dbt_project.not_null_my_first_dbt_model_id.5fb22c2710".
2022-01-15 07:56:43.059252 (Thread-1): Compiling test.sakila_dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
2022-01-15 07:56:43.070428 (Thread-1): Writing injected SQL for node "test.sakila_dbt_project.not_null_my_first_dbt_model_id.5fb22c2710"
2022-01-15 07:56:43.071432 (Thread-1): finished collecting timing info
2022-01-15 07:56:43.089362 (Thread-1): Writing runtime SQL for node "test.sakila_dbt_project.not_null_my_first_dbt_model_id.5fb22c2710"
2022-01-15 07:56:43.090333 (Thread-1): Using postgres connection "test.sakila_dbt_project.not_null_my_first_dbt_model_id.5fb22c2710".
2022-01-15 07:56:43.090492 (Thread-1): On test.sakila_dbt_project.not_null_my_first_dbt_model_id.5fb22c2710: BEGIN
2022-01-15 07:56:43.090643 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 07:56:43.471670 (Thread-1): SQL status: BEGIN in 0.38 seconds
2022-01-15 07:56:43.472055 (Thread-1): Using postgres connection "test.sakila_dbt_project.not_null_my_first_dbt_model_id.5fb22c2710".
2022-01-15 07:56:43.472249 (Thread-1): On test.sakila_dbt_project.not_null_my_first_dbt_model_id.5fb22c2710: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "test.sakila_dbt_project.not_null_my_first_dbt_model_id.5fb22c2710"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from "sakila_wh"."dwh"."my_first_dbt_model"
where id is null



      
    ) dbt_internal_test
2022-01-15 07:56:43.536455 (Thread-1): SQL status: SELECT 1 in 0.06 seconds
2022-01-15 07:56:43.539338 (Thread-1): finished collecting timing info
2022-01-15 07:56:43.539628 (Thread-1): On test.sakila_dbt_project.not_null_my_first_dbt_model_id.5fb22c2710: ROLLBACK
2022-01-15 07:56:43.599865 (Thread-1): On test.sakila_dbt_project.not_null_my_first_dbt_model_id.5fb22c2710: Close
2022-01-15 07:56:43.600959 (Thread-1): 13:26:43 | 1 of 2 FAIL 1 not_null_my_first_dbt_model_id......................... [FAIL 1 in 0.54s]
2022-01-15 07:56:43.601376 (Thread-1): Finished running node test.sakila_dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
2022-01-15 07:56:43.601750 (Thread-1): Began running node test.sakila_dbt_project.unique_my_first_dbt_model_id.16e066b321
2022-01-15 07:56:43.602197 (Thread-1): 13:26:43 | 2 of 2 START test unique_my_first_dbt_model_id....................... [RUN]
2022-01-15 07:56:43.602701 (Thread-1): Acquiring new postgres connection "test.sakila_dbt_project.unique_my_first_dbt_model_id.16e066b321".
2022-01-15 07:56:43.602956 (Thread-1): Compiling test.sakila_dbt_project.unique_my_first_dbt_model_id.16e066b321
2022-01-15 07:56:43.611286 (Thread-1): Writing injected SQL for node "test.sakila_dbt_project.unique_my_first_dbt_model_id.16e066b321"
2022-01-15 07:56:43.612008 (Thread-1): finished collecting timing info
2022-01-15 07:56:43.614396 (Thread-1): Writing runtime SQL for node "test.sakila_dbt_project.unique_my_first_dbt_model_id.16e066b321"
2022-01-15 07:56:43.615080 (Thread-1): Using postgres connection "test.sakila_dbt_project.unique_my_first_dbt_model_id.16e066b321".
2022-01-15 07:56:43.615286 (Thread-1): On test.sakila_dbt_project.unique_my_first_dbt_model_id.16e066b321: BEGIN
2022-01-15 07:56:43.615477 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 07:56:43.993646 (Thread-1): SQL status: BEGIN in 0.38 seconds
2022-01-15 07:56:43.994028 (Thread-1): Using postgres connection "test.sakila_dbt_project.unique_my_first_dbt_model_id.16e066b321".
2022-01-15 07:56:43.994285 (Thread-1): On test.sakila_dbt_project.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "test.sakila_dbt_project.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "sakila_wh"."dwh"."my_first_dbt_model"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
2022-01-15 07:56:44.056615 (Thread-1): SQL status: SELECT 1 in 0.06 seconds
2022-01-15 07:56:44.058823 (Thread-1): finished collecting timing info
2022-01-15 07:56:44.059117 (Thread-1): On test.sakila_dbt_project.unique_my_first_dbt_model_id.16e066b321: ROLLBACK
2022-01-15 07:56:44.122115 (Thread-1): On test.sakila_dbt_project.unique_my_first_dbt_model_id.16e066b321: Close
2022-01-15 07:56:44.122957 (Thread-1): 13:26:44 | 2 of 2 PASS unique_my_first_dbt_model_id............................. [PASS in 0.52s]
2022-01-15 07:56:44.123327 (Thread-1): Finished running node test.sakila_dbt_project.unique_my_first_dbt_model_id.16e066b321
2022-01-15 07:56:44.124751 (MainThread): Acquiring new postgres connection "master".
2022-01-15 07:56:44.125194 (MainThread): 13:26:44 | 
2022-01-15 07:56:44.125460 (MainThread): 13:26:44 | Finished running 2 tests in 2.22s.
2022-01-15 07:56:44.125709 (MainThread): Connection 'master' was properly closed.
2022-01-15 07:56:44.126039 (MainThread): Connection 'test.sakila_dbt_project.unique_my_first_dbt_model_id.16e066b321' was properly closed.
2022-01-15 07:56:44.134957 (MainThread): 
2022-01-15 07:56:44.135227 (MainThread): Completed with 1 error and 0 warnings:
2022-01-15 07:56:44.135432 (MainThread): 
2022-01-15 07:56:44.135640 (MainThread): Failure in test not_null_my_first_dbt_model_id (models/example/schema.yml)
2022-01-15 07:56:44.135824 (MainThread):   Got 1 result, configured to fail if != 0
2022-01-15 07:56:44.136004 (MainThread): 
2022-01-15 07:56:44.136187 (MainThread):   compiled SQL at target/compiled/sakila_dbt_project/models/example/schema.yml/schema_test/not_null_my_first_dbt_model_id.sql
2022-01-15 07:56:44.136378 (MainThread): 
Done. PASS=1 WARN=0 ERROR=1 SKIP=0 TOTAL=2
2022-01-15 07:56:44.136634 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e469a00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e581160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e4c4cd0>]}
2022-01-15 07:56:44.136908 (MainThread): Flushing usage events
2022-01-15 08:07:19.644300 (MainThread): Running with dbt=0.21.1
2022-01-15 08:07:19.722760 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2022-01-15 08:07:19.724585 (MainThread): Tracking: tracking
2022-01-15 08:07:19.743763 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c8b65b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ceabca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ceab310>]}
2022-01-15 08:07:19.766420 (MainThread): Partial parsing not enabled
2022-01-15 08:07:19.806205 (MainThread): Parsing macros/catalog.sql
2022-01-15 08:07:19.809730 (MainThread): Parsing macros/relations.sql
2022-01-15 08:07:19.811212 (MainThread): Parsing macros/adapters.sql
2022-01-15 08:07:19.833448 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2022-01-15 08:07:19.835074 (MainThread): Parsing macros/core.sql
2022-01-15 08:07:19.838506 (MainThread): Parsing macros/materializations/test.sql
2022-01-15 08:07:19.844992 (MainThread): Parsing macros/materializations/helpers.sql
2022-01-15 08:07:19.854924 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2022-01-15 08:07:19.856577 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2022-01-15 08:07:19.872985 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2022-01-15 08:07:19.903652 (MainThread): Parsing macros/materializations/seed/seed.sql
2022-01-15 08:07:19.924857 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2022-01-15 08:07:19.926529 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2022-01-15 08:07:19.936104 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2022-01-15 08:07:19.955006 (MainThread): Parsing macros/materializations/common/merge.sql
2022-01-15 08:07:19.968362 (MainThread): Parsing macros/materializations/table/table.sql
2022-01-15 08:07:19.975579 (MainThread): Parsing macros/materializations/view/view.sql
2022-01-15 08:07:19.982567 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2022-01-15 08:07:19.986087 (MainThread): Parsing macros/etc/get_custom_alias.sql
2022-01-15 08:07:19.987441 (MainThread): Parsing macros/etc/query.sql
2022-01-15 08:07:19.988315 (MainThread): Parsing macros/etc/is_incremental.sql
2022-01-15 08:07:19.989675 (MainThread): Parsing macros/etc/datetime.sql
2022-01-15 08:07:19.997372 (MainThread): Parsing macros/etc/where_subquery.sql
2022-01-15 08:07:19.999285 (MainThread): Parsing macros/etc/get_custom_schema.sql
2022-01-15 08:07:20.001713 (MainThread): Parsing macros/etc/get_custom_database.sql
2022-01-15 08:07:20.003145 (MainThread): Parsing macros/adapters/common.sql
2022-01-15 08:07:20.055160 (MainThread): Parsing macros/schema_tests/relationships.sql
2022-01-15 08:07:20.056778 (MainThread): Parsing macros/schema_tests/not_null.sql
2022-01-15 08:07:20.057879 (MainThread): Parsing macros/schema_tests/unique.sql
2022-01-15 08:07:20.059118 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2022-01-15 08:07:20.061426 (MainThread): Parsing macros/cross_db_utils/except.sql
2022-01-15 08:07:20.062413 (MainThread): Parsing macros/cross_db_utils/replace.sql
2022-01-15 08:07:20.063559 (MainThread): Parsing macros/cross_db_utils/concat.sql
2022-01-15 08:07:20.064473 (MainThread): Parsing macros/cross_db_utils/datatypes.sql
2022-01-15 08:07:20.070241 (MainThread): Parsing macros/cross_db_utils/_is_relation.sql
2022-01-15 08:07:20.071318 (MainThread): Parsing macros/cross_db_utils/length.sql
2022-01-15 08:07:20.072521 (MainThread): Parsing macros/cross_db_utils/dateadd.sql
2022-01-15 08:07:20.075225 (MainThread): Parsing macros/cross_db_utils/intersect.sql
2022-01-15 08:07:20.076186 (MainThread): Parsing macros/cross_db_utils/right.sql
2022-01-15 08:07:20.078221 (MainThread): Parsing macros/cross_db_utils/datediff.sql
2022-01-15 08:07:20.088345 (MainThread): Parsing macros/cross_db_utils/safe_cast.sql
2022-01-15 08:07:20.090202 (MainThread): Parsing macros/cross_db_utils/hash.sql
2022-01-15 08:07:20.091530 (MainThread): Parsing macros/cross_db_utils/cast_bool_to_text.sql
2022-01-15 08:07:20.092873 (MainThread): Parsing macros/cross_db_utils/identifier.sql
2022-01-15 08:07:20.094405 (MainThread): Parsing macros/cross_db_utils/position.sql
2022-01-15 08:07:20.095850 (MainThread): Parsing macros/cross_db_utils/literal.sql
2022-01-15 08:07:20.096751 (MainThread): Parsing macros/cross_db_utils/current_timestamp.sql
2022-01-15 08:07:20.101300 (MainThread): Parsing macros/cross_db_utils/width_bucket.sql
2022-01-15 08:07:20.106330 (MainThread): Parsing macros/cross_db_utils/last_day.sql
2022-01-15 08:07:20.109598 (MainThread): Parsing macros/cross_db_utils/split_part.sql
2022-01-15 08:07:20.111290 (MainThread): Parsing macros/cross_db_utils/date_trunc.sql
2022-01-15 08:07:20.112780 (MainThread): Parsing macros/cross_db_utils/_is_ephemeral.sql
2022-01-15 08:07:20.114502 (MainThread): Parsing macros/materializations/insert_by_period_materialization.sql
2022-01-15 08:07:20.137988 (MainThread): Parsing macros/web/get_url_host.sql
2022-01-15 08:07:20.139690 (MainThread): Parsing macros/web/get_url_path.sql
2022-01-15 08:07:20.142159 (MainThread): Parsing macros/web/get_url_parameter.sql
2022-01-15 08:07:20.143607 (MainThread): Parsing macros/jinja_helpers/pretty_log_format.sql
2022-01-15 08:07:20.144638 (MainThread): Parsing macros/jinja_helpers/pretty_time.sql
2022-01-15 08:07:20.145758 (MainThread): Parsing macros/jinja_helpers/log_info.sql
2022-01-15 08:07:20.146874 (MainThread): Parsing macros/jinja_helpers/slugify.sql
2022-01-15 08:07:20.148118 (MainThread): Parsing macros/schema_tests/fewer_rows_than.sql
2022-01-15 08:07:20.149821 (MainThread): Parsing macros/schema_tests/equal_rowcount.sql
2022-01-15 08:07:20.151385 (MainThread): Parsing macros/schema_tests/relationships_where.sql
2022-01-15 08:07:20.153476 (MainThread): Parsing macros/schema_tests/recency.sql
2022-01-15 08:07:20.155137 (MainThread): Parsing macros/schema_tests/not_constant.sql
2022-01-15 08:07:20.156310 (MainThread): Parsing macros/schema_tests/accepted_range.sql
2022-01-15 08:07:20.158711 (MainThread): Parsing macros/schema_tests/not_accepted_values.sql
2022-01-15 08:07:20.160943 (MainThread): Parsing macros/schema_tests/test_unique_where.sql
2022-01-15 08:07:20.162280 (MainThread): Parsing macros/schema_tests/at_least_one.sql
2022-01-15 08:07:20.163438 (MainThread): Parsing macros/schema_tests/unique_combination_of_columns.sql
2022-01-15 08:07:20.166317 (MainThread): Parsing macros/schema_tests/cardinality_equality.sql
2022-01-15 08:07:20.168160 (MainThread): Parsing macros/schema_tests/expression_is_true.sql
2022-01-15 08:07:20.169843 (MainThread): Parsing macros/schema_tests/sequential_values.sql
2022-01-15 08:07:20.172620 (MainThread): Parsing macros/schema_tests/test_not_null_where.sql
2022-01-15 08:07:20.173945 (MainThread): Parsing macros/schema_tests/equality.sql
2022-01-15 08:07:20.177130 (MainThread): Parsing macros/schema_tests/mutually_exclusive_ranges.sql
2022-01-15 08:07:20.185852 (MainThread): Parsing macros/sql/date_spine.sql
2022-01-15 08:07:20.190355 (MainThread): Parsing macros/sql/nullcheck_table.sql
2022-01-15 08:07:20.191857 (MainThread): Parsing macros/sql/get_relations_by_pattern.sql
2022-01-15 08:07:20.194961 (MainThread): Parsing macros/sql/generate_series.sql
2022-01-15 08:07:20.224949 (MainThread): Parsing macros/sql/get_relations_by_prefix.sql
2022-01-15 08:07:20.229393 (MainThread): Parsing macros/sql/get_tables_by_prefix_sql.sql
2022-01-15 08:07:20.231538 (MainThread): Parsing macros/sql/star.sql
2022-01-15 08:07:20.235730 (MainThread): Parsing macros/sql/unpivot.sql
2022-01-15 08:07:20.245822 (MainThread): Parsing macros/sql/union.sql
2022-01-15 08:07:20.255309 (MainThread): Parsing macros/sql/groupby.sql
2022-01-15 08:07:20.256831 (MainThread): Parsing macros/sql/surrogate_key.sql
2022-01-15 08:07:20.260791 (MainThread): Parsing macros/sql/safe_add.sql
2022-01-15 08:07:20.262590 (MainThread): Parsing macros/sql/nullcheck.sql
2022-01-15 08:07:20.264402 (MainThread): Parsing macros/sql/get_tables_by_pattern_sql.sql
2022-01-15 08:07:20.271538 (MainThread): Parsing macros/sql/get_column_values.sql
2022-01-15 08:07:20.276822 (MainThread): Parsing macros/sql/pivot.sql
2022-01-15 08:07:20.281224 (MainThread): Parsing macros/sql/get_query_results_as_dict.sql
2022-01-15 08:07:20.283527 (MainThread): Parsing macros/sql/haversine_distance.sql
2022-01-15 08:07:20.585413 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-15 08:07:20.596732 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-15 08:07:20.600586 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.film_test".
2022-01-15 08:07:20.603405 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-15 08:07:20.611541 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-15 08:07:20.614393 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-15 08:07:20.648672 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:07:20.650798 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:07:20.652424 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:07:20.654039 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:07:20.656529 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:07:20.658089 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:07:20.658481 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d073e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d068df0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d0cc7f0>]}
2022-01-15 08:07:20.658698 (MainThread): Flushing usage events
2022-01-15 08:07:22.553369 (MainThread): Connection 'model.sakila_dbt_project.dim_date' was properly closed.
2022-01-15 08:07:22.553713 (MainThread): Encountered an error:
2022-01-15 08:07:22.553952 (MainThread): Compilation Error
  Invalid test config given in models/example/schema.yml:
  	test definition dictionary must have exactly one key, got [('accepted_values', None), ('values', ['NC-17', 'PG-13', 'G', 'R', 'PG'])] instead (2 keys)
  	@: UnparsedNodeUpdate(original_file_path='model...ne)
2022-01-15 08:07:22.560922 (MainThread): Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/dbt/parser/schemas.py", line 293, in _parse_generic_test
    builder = TestBuilder(
  File "/usr/local/lib/python3.9/site-packages/dbt/parser/schema_test_builders.py", line 206, in __init__
    test_name, test_args = self.extract_test_args(test, column_name)
  File "/usr/local/lib/python3.9/site-packages/dbt/parser/schema_test_builders.py", line 271, in extract_test_args
    raise_compiler_error(
  File "/usr/local/lib/python3.9/site-packages/dbt/exceptions.py", line 447, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error
  test definition dictionary must have exactly one key, got [('accepted_values', None), ('values', ['NC-17', 'PG-13', 'G', 'R', 'PG'])] instead (2 keys)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/dbt/main.py", line 127, in main
    results, succeeded = handle_and_check(args)
  File "/usr/local/lib/python3.9/site-packages/dbt/main.py", line 205, in handle_and_check
    task, res = run_from_args(parsed)
  File "/usr/local/lib/python3.9/site-packages/dbt/main.py", line 258, in run_from_args
    results = task.run()
  File "/usr/local/lib/python3.9/site-packages/dbt/task/runnable.py", line 438, in run
    self._runtime_initialize()
  File "/usr/local/lib/python3.9/site-packages/dbt/task/runnable.py", line 154, in _runtime_initialize
    super()._runtime_initialize()
  File "/usr/local/lib/python3.9/site-packages/dbt/task/runnable.py", line 92, in _runtime_initialize
    self.load_manifest()
  File "/usr/local/lib/python3.9/site-packages/dbt/task/runnable.py", line 79, in load_manifest
    self.manifest = ManifestLoader.get_full_manifest(self.config)
  File "/usr/local/lib/python3.9/site-packages/dbt/parser/manifest.py", line 182, in get_full_manifest
    manifest = loader.load()
  File "/usr/local/lib/python3.9/site-packages/dbt/parser/manifest.py", line 325, in load
    self.parse_project(
  File "/usr/local/lib/python3.9/site-packages/dbt/parser/manifest.py", line 414, in parse_project
    parser.parse_file(block, dct=dct)
  File "/usr/local/lib/python3.9/site-packages/dbt/parser/schemas.py", line 493, in parse_file
    self.parse_tests(test_block)
  File "/usr/local/lib/python3.9/site-packages/dbt/parser/schemas.py", line 460, in parse_tests
    self.parse_column_tests(block, column)
  File "/usr/local/lib/python3.9/site-packages/dbt/parser/schemas.py", line 216, in parse_column_tests
    self.parse_test(block, test, column)
  File "/usr/local/lib/python3.9/site-packages/dbt/parser/schemas.py", line 456, in parse_test
    self.parse_node(block)
  File "/usr/local/lib/python3.9/site-packages/dbt/parser/schemas.py", line 395, in parse_node
    node = self._parse_generic_test(
  File "/usr/local/lib/python3.9/site-packages/dbt/parser/schemas.py", line 307, in _parse_generic_test
    raise CompilationException(msg) from exc
dbt.exceptions.CompilationException: Compilation Error
  Invalid test config given in models/example/schema.yml:
  	test definition dictionary must have exactly one key, got [('accepted_values', None), ('values', ['NC-17', 'PG-13', 'G', 'R', 'PG'])] instead (2 keys)
  	@: UnparsedNodeUpdate(original_file_path='model...ne)

2022-01-15 08:08:37.282818 (MainThread): Running with dbt=0.21.1
2022-01-15 08:08:37.365431 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2022-01-15 08:08:37.367542 (MainThread): Tracking: tracking
2022-01-15 08:08:37.388120 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112e909a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112ea45e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112ea49a0>]}
2022-01-15 08:08:37.410801 (MainThread): Partial parsing not enabled
2022-01-15 08:08:37.450396 (MainThread): Parsing macros/catalog.sql
2022-01-15 08:08:37.453863 (MainThread): Parsing macros/relations.sql
2022-01-15 08:08:37.455318 (MainThread): Parsing macros/adapters.sql
2022-01-15 08:08:37.477647 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2022-01-15 08:08:37.479265 (MainThread): Parsing macros/core.sql
2022-01-15 08:08:37.482824 (MainThread): Parsing macros/materializations/test.sql
2022-01-15 08:08:37.489351 (MainThread): Parsing macros/materializations/helpers.sql
2022-01-15 08:08:37.498797 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2022-01-15 08:08:37.500481 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2022-01-15 08:08:37.516863 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2022-01-15 08:08:37.547006 (MainThread): Parsing macros/materializations/seed/seed.sql
2022-01-15 08:08:37.568698 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2022-01-15 08:08:37.570375 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2022-01-15 08:08:37.579885 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2022-01-15 08:08:37.598451 (MainThread): Parsing macros/materializations/common/merge.sql
2022-01-15 08:08:37.613521 (MainThread): Parsing macros/materializations/table/table.sql
2022-01-15 08:08:37.631179 (MainThread): Parsing macros/materializations/view/view.sql
2022-01-15 08:08:37.638904 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2022-01-15 08:08:37.642992 (MainThread): Parsing macros/etc/get_custom_alias.sql
2022-01-15 08:08:37.644395 (MainThread): Parsing macros/etc/query.sql
2022-01-15 08:08:37.645285 (MainThread): Parsing macros/etc/is_incremental.sql
2022-01-15 08:08:37.646655 (MainThread): Parsing macros/etc/datetime.sql
2022-01-15 08:08:37.654626 (MainThread): Parsing macros/etc/where_subquery.sql
2022-01-15 08:08:37.656288 (MainThread): Parsing macros/etc/get_custom_schema.sql
2022-01-15 08:08:37.658461 (MainThread): Parsing macros/etc/get_custom_database.sql
2022-01-15 08:08:37.659887 (MainThread): Parsing macros/adapters/common.sql
2022-01-15 08:08:37.712142 (MainThread): Parsing macros/schema_tests/relationships.sql
2022-01-15 08:08:37.713718 (MainThread): Parsing macros/schema_tests/not_null.sql
2022-01-15 08:08:37.714842 (MainThread): Parsing macros/schema_tests/unique.sql
2022-01-15 08:08:37.716083 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2022-01-15 08:08:37.718334 (MainThread): Parsing macros/cross_db_utils/except.sql
2022-01-15 08:08:37.719319 (MainThread): Parsing macros/cross_db_utils/replace.sql
2022-01-15 08:08:37.720472 (MainThread): Parsing macros/cross_db_utils/concat.sql
2022-01-15 08:08:37.721676 (MainThread): Parsing macros/cross_db_utils/datatypes.sql
2022-01-15 08:08:37.727233 (MainThread): Parsing macros/cross_db_utils/_is_relation.sql
2022-01-15 08:08:37.728285 (MainThread): Parsing macros/cross_db_utils/length.sql
2022-01-15 08:08:37.729479 (MainThread): Parsing macros/cross_db_utils/dateadd.sql
2022-01-15 08:08:37.732357 (MainThread): Parsing macros/cross_db_utils/intersect.sql
2022-01-15 08:08:37.733366 (MainThread): Parsing macros/cross_db_utils/right.sql
2022-01-15 08:08:37.735551 (MainThread): Parsing macros/cross_db_utils/datediff.sql
2022-01-15 08:08:37.744782 (MainThread): Parsing macros/cross_db_utils/safe_cast.sql
2022-01-15 08:08:37.746597 (MainThread): Parsing macros/cross_db_utils/hash.sql
2022-01-15 08:08:37.747971 (MainThread): Parsing macros/cross_db_utils/cast_bool_to_text.sql
2022-01-15 08:08:37.749467 (MainThread): Parsing macros/cross_db_utils/identifier.sql
2022-01-15 08:08:37.751196 (MainThread): Parsing macros/cross_db_utils/position.sql
2022-01-15 08:08:37.752667 (MainThread): Parsing macros/cross_db_utils/literal.sql
2022-01-15 08:08:37.753562 (MainThread): Parsing macros/cross_db_utils/current_timestamp.sql
2022-01-15 08:08:37.756796 (MainThread): Parsing macros/cross_db_utils/width_bucket.sql
2022-01-15 08:08:37.761695 (MainThread): Parsing macros/cross_db_utils/last_day.sql
2022-01-15 08:08:37.765061 (MainThread): Parsing macros/cross_db_utils/split_part.sql
2022-01-15 08:08:37.766941 (MainThread): Parsing macros/cross_db_utils/date_trunc.sql
2022-01-15 08:08:37.768648 (MainThread): Parsing macros/cross_db_utils/_is_ephemeral.sql
2022-01-15 08:08:37.770438 (MainThread): Parsing macros/materializations/insert_by_period_materialization.sql
2022-01-15 08:08:37.793835 (MainThread): Parsing macros/web/get_url_host.sql
2022-01-15 08:08:37.795594 (MainThread): Parsing macros/web/get_url_path.sql
2022-01-15 08:08:37.797984 (MainThread): Parsing macros/web/get_url_parameter.sql
2022-01-15 08:08:37.799625 (MainThread): Parsing macros/jinja_helpers/pretty_log_format.sql
2022-01-15 08:08:37.800873 (MainThread): Parsing macros/jinja_helpers/pretty_time.sql
2022-01-15 08:08:37.802128 (MainThread): Parsing macros/jinja_helpers/log_info.sql
2022-01-15 08:08:37.803178 (MainThread): Parsing macros/jinja_helpers/slugify.sql
2022-01-15 08:08:37.804269 (MainThread): Parsing macros/schema_tests/fewer_rows_than.sql
2022-01-15 08:08:37.805805 (MainThread): Parsing macros/schema_tests/equal_rowcount.sql
2022-01-15 08:08:37.807494 (MainThread): Parsing macros/schema_tests/relationships_where.sql
2022-01-15 08:08:37.809587 (MainThread): Parsing macros/schema_tests/recency.sql
2022-01-15 08:08:37.811164 (MainThread): Parsing macros/schema_tests/not_constant.sql
2022-01-15 08:08:37.812289 (MainThread): Parsing macros/schema_tests/accepted_range.sql
2022-01-15 08:08:37.814567 (MainThread): Parsing macros/schema_tests/not_accepted_values.sql
2022-01-15 08:08:37.816578 (MainThread): Parsing macros/schema_tests/test_unique_where.sql
2022-01-15 08:08:37.818017 (MainThread): Parsing macros/schema_tests/at_least_one.sql
2022-01-15 08:08:37.819246 (MainThread): Parsing macros/schema_tests/unique_combination_of_columns.sql
2022-01-15 08:08:37.822010 (MainThread): Parsing macros/schema_tests/cardinality_equality.sql
2022-01-15 08:08:37.823834 (MainThread): Parsing macros/schema_tests/expression_is_true.sql
2022-01-15 08:08:37.825515 (MainThread): Parsing macros/schema_tests/sequential_values.sql
2022-01-15 08:08:37.828382 (MainThread): Parsing macros/schema_tests/test_not_null_where.sql
2022-01-15 08:08:37.829691 (MainThread): Parsing macros/schema_tests/equality.sql
2022-01-15 08:08:37.832798 (MainThread): Parsing macros/schema_tests/mutually_exclusive_ranges.sql
2022-01-15 08:08:37.841427 (MainThread): Parsing macros/sql/date_spine.sql
2022-01-15 08:08:37.845623 (MainThread): Parsing macros/sql/nullcheck_table.sql
2022-01-15 08:08:37.847176 (MainThread): Parsing macros/sql/get_relations_by_pattern.sql
2022-01-15 08:08:37.850714 (MainThread): Parsing macros/sql/generate_series.sql
2022-01-15 08:08:37.879219 (MainThread): Parsing macros/sql/get_relations_by_prefix.sql
2022-01-15 08:08:37.883718 (MainThread): Parsing macros/sql/get_tables_by_prefix_sql.sql
2022-01-15 08:08:37.886025 (MainThread): Parsing macros/sql/star.sql
2022-01-15 08:08:37.890140 (MainThread): Parsing macros/sql/unpivot.sql
2022-01-15 08:08:37.899994 (MainThread): Parsing macros/sql/union.sql
2022-01-15 08:08:37.909999 (MainThread): Parsing macros/sql/groupby.sql
2022-01-15 08:08:37.911571 (MainThread): Parsing macros/sql/surrogate_key.sql
2022-01-15 08:08:37.915335 (MainThread): Parsing macros/sql/safe_add.sql
2022-01-15 08:08:37.917233 (MainThread): Parsing macros/sql/nullcheck.sql
2022-01-15 08:08:37.919087 (MainThread): Parsing macros/sql/get_tables_by_pattern_sql.sql
2022-01-15 08:08:37.926126 (MainThread): Parsing macros/sql/get_column_values.sql
2022-01-15 08:08:37.931499 (MainThread): Parsing macros/sql/pivot.sql
2022-01-15 08:08:37.935976 (MainThread): Parsing macros/sql/get_query_results_as_dict.sql
2022-01-15 08:08:37.938240 (MainThread): Parsing macros/sql/haversine_distance.sql
2022-01-15 08:08:38.237756 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-15 08:08:38.249296 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-15 08:08:38.253052 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.film_test".
2022-01-15 08:08:38.255806 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-15 08:08:38.263430 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-15 08:08:38.266168 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-15 08:08:38.299647 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:08:38.301691 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:08:38.303376 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:08:38.305062 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:08:38.307733 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:08:38.309476 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:08:38.321614 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:08:38.321935 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:08:38.335722 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:08:38.337429 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:08:38.360140 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b15fb15c-bc7e-4ad7-8b07-eccfbd048a4f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1130330d0>]}
2022-01-15 08:08:38.368458 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-01-15 08:08:38.369010 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b15fb15c-bc7e-4ad7-8b07-eccfbd048a4f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113033160>]}
2022-01-15 08:08:38.369246 (MainThread): Found 6 models, 9 tests, 0 snapshots, 0 analyses, 347 macros, 0 operations, 0 seed files, 12 sources, 0 exposures
2022-01-15 08:08:38.370669 (MainThread): 
2022-01-15 08:08:38.370972 (MainThread): Acquiring new postgres connection "master".
2022-01-15 08:08:38.371843 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_sakila_wh".
2022-01-15 08:08:38.379959 (ThreadPoolExecutor-0_0): Using postgres connection "list_sakila_wh".
2022-01-15 08:08:38.380106 (ThreadPoolExecutor-0_0): On list_sakila_wh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh"} */

    select distinct nspname from pg_namespace
  
2022-01-15 08:08:38.380241 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2022-01-15 08:08:38.791654 (ThreadPoolExecutor-0_0): SQL status: SELECT 12 in 0.41 seconds
2022-01-15 08:08:38.793974 (ThreadPoolExecutor-0_0): On list_sakila_wh: Close
2022-01-15 08:08:38.795565 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_dwh".
2022-01-15 08:08:38.802611 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-15 08:08:38.802847 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: BEGIN
2022-01-15 08:08:38.803028 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2022-01-15 08:08:39.178618 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.38 seconds
2022-01-15 08:08:39.179045 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-15 08:08:39.179323 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_dwh"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dwh'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dwh'
  
2022-01-15 08:08:39.244697 (ThreadPoolExecutor-1_0): SQL status: SELECT 5 in 0.07 seconds
2022-01-15 08:08:39.246834 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: ROLLBACK
2022-01-15 08:08:39.307471 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: Close
2022-01-15 08:08:39.314026 (MainThread): Using postgres connection "master".
2022-01-15 08:08:39.314268 (MainThread): On master: BEGIN
2022-01-15 08:08:39.314449 (MainThread): Opening a new connection, currently in state init
2022-01-15 08:08:39.682581 (MainThread): SQL status: BEGIN in 0.37 seconds
2022-01-15 08:08:39.682969 (MainThread): Using postgres connection "master".
2022-01-15 08:08:39.683225 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-15 08:08:39.770298 (MainThread): SQL status: SELECT 47 in 0.09 seconds
2022-01-15 08:08:39.773373 (MainThread): On master: ROLLBACK
2022-01-15 08:08:39.839267 (MainThread): Using postgres connection "master".
2022-01-15 08:08:39.839675 (MainThread): On master: BEGIN
2022-01-15 08:08:39.965860 (MainThread): SQL status: BEGIN in 0.13 seconds
2022-01-15 08:08:39.966432 (MainThread): On master: COMMIT
2022-01-15 08:08:39.966707 (MainThread): Using postgres connection "master".
2022-01-15 08:08:39.966954 (MainThread): On master: COMMIT
2022-01-15 08:08:40.028950 (MainThread): SQL status: COMMIT in 0.06 seconds
2022-01-15 08:08:40.029411 (MainThread): On master: Close
2022-01-15 08:08:40.030125 (MainThread): 13:38:40 | Concurrency: 1 threads (target='dev')
2022-01-15 08:08:40.030500 (MainThread): 13:38:40 | 
2022-01-15 08:08:40.032698 (Thread-1): Began running node model.sakila_dbt_project.dim_date
2022-01-15 08:08:40.033065 (Thread-1): 13:38:40 | 1 of 6 START table model dwh.dim_date................................ [RUN]
2022-01-15 08:08:40.033456 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-15 08:08:40.033674 (Thread-1): Compiling model.sakila_dbt_project.dim_date
2022-01-15 08:08:40.035548 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_date"
2022-01-15 08:08:40.036207 (Thread-1): finished collecting timing info
2022-01-15 08:08:40.063975 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_date"
2022-01-15 08:08:40.064739 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-15 08:08:40.064951 (Thread-1): On model.sakila_dbt_project.dim_date: BEGIN
2022-01-15 08:08:40.065130 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 08:08:40.437535 (Thread-1): SQL status: BEGIN in 0.37 seconds
2022-01-15 08:08:40.437896 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-15 08:08:40.438130 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */


  create  table "sakila_wh"."dwh"."dim_date__dbt_tmp"
  as (
    with dates as (
SELECT
       TO_CHAR(datum, 'yyyymmdd')::INT AS date_dim_id,
       datum AS date_key,
       EXTRACT(EPOCH FROM datum) AS epoch,
       TO_CHAR(datum, 'TMDay') AS day_name,
       EXTRACT(ISODOW FROM datum) AS day_of_week,
       EXTRACT(DAY FROM datum) AS day_of_month,
       datum - DATE_TRUNC('quarter', datum)::DATE + 1 AS day_of_quarter,
       EXTRACT(DOY FROM datum) AS day_of_year,
       TO_CHAR(datum, 'W')::INT AS week_of_month,
       EXTRACT(WEEK FROM datum) AS week_of_year,
       EXTRACT(MONTH FROM datum) AS month_actual,
       TO_CHAR(datum, 'TMMonth') AS month_name,
       TO_CHAR(datum, 'Mon') AS month_name_abbreviated,
       EXTRACT(QUARTER FROM datum) AS quarter_actual,
       CASE
           WHEN EXTRACT(QUARTER FROM datum) = 1 THEN 'First'
           WHEN EXTRACT(QUARTER FROM datum) = 2 THEN 'Second'
           WHEN EXTRACT(QUARTER FROM datum) = 3 THEN 'Third'
           WHEN EXTRACT(QUARTER FROM datum) = 4 THEN 'Fourth'
           END AS quarter_name,
       EXTRACT(YEAR FROM datum) AS year_actual,
       datum + (1 - EXTRACT(ISODOW FROM datum))::INT AS first_day_of_week,
       datum + (7 - EXTRACT(ISODOW FROM datum))::INT AS last_day_of_week,
       datum + (1 - EXTRACT(DAY FROM datum))::INT AS first_day_of_month,
       (DATE_TRUNC('MONTH', datum) + INTERVAL '1 MONTH - 1 day')::DATE AS last_day_of_month,
       DATE_TRUNC('quarter', datum)::DATE AS first_day_of_quarter,
       (DATE_TRUNC('quarter', datum) + INTERVAL '3 MONTH - 1 day')::DATE AS last_day_of_quarter,
       TO_DATE(EXTRACT(YEAR FROM datum) || '-01-01', 'YYYY-MM-DD') AS first_day_of_year,
       TO_DATE(EXTRACT(YEAR FROM datum) || '-12-31', 'YYYY-MM-DD') AS last_day_of_year,
       TO_CHAR(datum, 'yyyymm') AS yyyymm,
       CASE
           WHEN EXTRACT(ISODOW FROM datum) IN (6, 7) THEN TRUE
           ELSE FALSE
           END AS weekend_indr
FROM (SELECT '2000-01-01'::DATE + SEQUENCE.DAY AS datum
      FROM GENERATE_SERIES(0, 29219) AS SEQUENCE (DAY)
      GROUP BY SEQUENCE.DAY) DQ
)
select
*
from
dates
where
date_key <= CURRENT_DATE
order by date_dim_id asc
  );
2022-01-15 08:08:41.347948 (Thread-1): SQL status: SELECT 8051 in 0.91 seconds
2022-01-15 08:08:41.356018 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-15 08:08:41.356238 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
alter table "sakila_wh"."dwh"."dim_date" rename to "dim_date__dbt_backup"
2022-01-15 08:08:41.417959 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-15 08:08:41.421533 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-15 08:08:41.421783 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
alter table "sakila_wh"."dwh"."dim_date__dbt_tmp" rename to "dim_date"
2022-01-15 08:08:41.482764 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-15 08:08:41.495226 (Thread-1): On model.sakila_dbt_project.dim_date: COMMIT
2022-01-15 08:08:41.495457 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-15 08:08:41.495625 (Thread-1): On model.sakila_dbt_project.dim_date: COMMIT
2022-01-15 08:08:41.557371 (Thread-1): SQL status: COMMIT in 0.06 seconds
2022-01-15 08:08:41.564170 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-15 08:08:41.564392 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
drop table if exists "sakila_wh"."dwh"."dim_date__dbt_backup" cascade
2022-01-15 08:08:41.630160 (Thread-1): SQL status: DROP TABLE in 0.07 seconds
2022-01-15 08:08:41.631540 (Thread-1): finished collecting timing info
2022-01-15 08:08:41.631783 (Thread-1): On model.sakila_dbt_project.dim_date: Close
2022-01-15 08:08:41.632308 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b15fb15c-bc7e-4ad7-8b07-eccfbd048a4f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1131dcb20>]}
2022-01-15 08:08:41.632704 (Thread-1): 13:38:41 | 1 of 6 OK created table model dwh.dim_date........................... [SELECT 8051 in 1.60s]
2022-01-15 08:08:41.632938 (Thread-1): Finished running node model.sakila_dbt_project.dim_date
2022-01-15 08:08:41.633163 (Thread-1): Began running node model.sakila_dbt_project.film_test
2022-01-15 08:08:41.633589 (Thread-1): 13:38:41 | 2 of 6 START table model dwh.film_test............................... [RUN]
2022-01-15 08:08:41.634027 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.film_test".
2022-01-15 08:08:41.634231 (Thread-1): Compiling model.sakila_dbt_project.film_test
2022-01-15 08:08:41.637249 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.film_test"
2022-01-15 08:08:41.637854 (Thread-1): finished collecting timing info
2022-01-15 08:08:41.640366 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.film_test"
2022-01-15 08:08:41.640974 (Thread-1): Using postgres connection "model.sakila_dbt_project.film_test".
2022-01-15 08:08:41.641159 (Thread-1): On model.sakila_dbt_project.film_test: BEGIN
2022-01-15 08:08:41.641330 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 08:08:42.015177 (Thread-1): SQL status: BEGIN in 0.37 seconds
2022-01-15 08:08:42.015756 (Thread-1): Using postgres connection "model.sakila_dbt_project.film_test".
2022-01-15 08:08:42.016020 (Thread-1): On model.sakila_dbt_project.film_test: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.film_test"} */


  create  table "sakila_wh"."dwh"."film_test__dbt_tmp"
  as (
    select * from 
stg.film
  );
2022-01-15 08:08:42.090011 (Thread-1): SQL status: SELECT 1000 in 0.07 seconds
2022-01-15 08:08:42.093403 (Thread-1): Using postgres connection "model.sakila_dbt_project.film_test".
2022-01-15 08:08:42.093608 (Thread-1): On model.sakila_dbt_project.film_test: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.film_test"} */
alter table "sakila_wh"."dwh"."film_test__dbt_tmp" rename to "film_test"
2022-01-15 08:08:42.154432 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-15 08:08:42.156606 (Thread-1): On model.sakila_dbt_project.film_test: COMMIT
2022-01-15 08:08:42.156861 (Thread-1): Using postgres connection "model.sakila_dbt_project.film_test".
2022-01-15 08:08:42.157061 (Thread-1): On model.sakila_dbt_project.film_test: COMMIT
2022-01-15 08:08:42.222145 (Thread-1): SQL status: COMMIT in 0.06 seconds
2022-01-15 08:08:42.225083 (Thread-1): Using postgres connection "model.sakila_dbt_project.film_test".
2022-01-15 08:08:42.225317 (Thread-1): On model.sakila_dbt_project.film_test: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.film_test"} */
drop table if exists "sakila_wh"."dwh"."film_test__dbt_backup" cascade
2022-01-15 08:08:42.285688 (Thread-1): SQL status: DROP TABLE in 0.06 seconds
2022-01-15 08:08:42.287041 (Thread-1): finished collecting timing info
2022-01-15 08:08:42.287330 (Thread-1): On model.sakila_dbt_project.film_test: Close
2022-01-15 08:08:42.287823 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b15fb15c-bc7e-4ad7-8b07-eccfbd048a4f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1131ec4c0>]}
2022-01-15 08:08:42.288213 (Thread-1): 13:38:42 | 2 of 6 OK created table model dwh.film_test.......................... [SELECT 1000 in 0.65s]
2022-01-15 08:08:42.288443 (Thread-1): Finished running node model.sakila_dbt_project.film_test
2022-01-15 08:08:42.288664 (Thread-1): Began running node model.sakila_dbt_project.hello_world
2022-01-15 08:08:42.289039 (Thread-1): 13:38:42 | 3 of 6 START table model dwh.hello_world............................. [RUN]
2022-01-15 08:08:42.289422 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-15 08:08:42.289618 (Thread-1): Compiling model.sakila_dbt_project.hello_world
2022-01-15 08:08:42.291389 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.hello_world"
2022-01-15 08:08:42.292026 (Thread-1): finished collecting timing info
2022-01-15 08:08:42.294726 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.hello_world"
2022-01-15 08:08:42.295313 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-15 08:08:42.295493 (Thread-1): On model.sakila_dbt_project.hello_world: BEGIN
2022-01-15 08:08:42.295671 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 08:08:42.675284 (Thread-1): SQL status: BEGIN in 0.38 seconds
2022-01-15 08:08:42.675660 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-15 08:08:42.675918 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */


  create  table "sakila_wh"."dwh"."hello_world__dbt_tmp"
  as (
    select
	customer.customer_id::int,
	customer.store_id::int,
	customer.first_name,
	customer.last_name,
	concat(customer.first_name,' ',customer.last_name) as full_name,
	substring(email from POSITION('@' in email)+1 for char_length(email)-POSITION('@' in email)) as domain,
	customer.email,
	customer.active::int,
	customer.address_id::int,
	address.address,
	city.city_id::int,
	city.city,
	(case when customer.active = 0 then 'no' else 'yes' end)::varchar(100) as "active_desc",
	customer.create_date::timestamp,
	customer.last_update::timestamp
from
	stg.customer as customer

	left join stg.address on 1=1
	and customer.address_id =address.address_id

	left join stg.city on 1=1
	and address.city_id = city.city_id
  );
2022-01-15 08:08:42.755554 (Thread-1): SQL status: SELECT 599 in 0.08 seconds
2022-01-15 08:08:42.759244 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-15 08:08:42.759509 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
alter table "sakila_wh"."dwh"."hello_world" rename to "hello_world__dbt_backup"
2022-01-15 08:08:42.829405 (Thread-1): SQL status: ALTER TABLE in 0.07 seconds
2022-01-15 08:08:42.833554 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-15 08:08:42.833815 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
alter table "sakila_wh"."dwh"."hello_world__dbt_tmp" rename to "hello_world"
2022-01-15 08:08:42.897275 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-15 08:08:42.899862 (Thread-1): On model.sakila_dbt_project.hello_world: COMMIT
2022-01-15 08:08:42.900159 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-15 08:08:42.900414 (Thread-1): On model.sakila_dbt_project.hello_world: COMMIT
2022-01-15 08:08:42.960828 (Thread-1): SQL status: COMMIT in 0.06 seconds
2022-01-15 08:08:42.964004 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-15 08:08:42.964274 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
drop table if exists "sakila_wh"."dwh"."hello_world__dbt_backup" cascade
2022-01-15 08:08:43.028822 (Thread-1): SQL status: DROP TABLE in 0.06 seconds
2022-01-15 08:08:43.040060 (Thread-1): finished collecting timing info
2022-01-15 08:08:43.058068 (Thread-1): On model.sakila_dbt_project.hello_world: Close
2022-01-15 08:08:43.059005 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b15fb15c-bc7e-4ad7-8b07-eccfbd048a4f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113135190>]}
2022-01-15 08:08:43.059594 (Thread-1): 13:38:43 | 3 of 6 OK created table model dwh.hello_world........................ [SELECT 599 in 0.77s]
2022-01-15 08:08:43.059933 (Thread-1): Finished running node model.sakila_dbt_project.hello_world
2022-01-15 08:08:43.060263 (Thread-1): Began running node model.sakila_dbt_project.my_first_dbt_model
2022-01-15 08:08:43.060824 (Thread-1): 13:38:43 | 4 of 6 START table model dwh.my_first_dbt_model...................... [RUN]
2022-01-15 08:08:43.061428 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-15 08:08:43.061663 (Thread-1): Compiling model.sakila_dbt_project.my_first_dbt_model
2022-01-15 08:08:43.066291 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.my_first_dbt_model"
2022-01-15 08:08:43.066941 (Thread-1): finished collecting timing info
2022-01-15 08:08:43.069552 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.my_first_dbt_model"
2022-01-15 08:08:43.070140 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-15 08:08:43.070318 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: BEGIN
2022-01-15 08:08:43.070479 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 08:08:43.446860 (Thread-1): SQL status: BEGIN in 0.38 seconds
2022-01-15 08:08:43.447342 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-15 08:08:43.447651 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */


  create  table "sakila_wh"."dwh"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    --union all
    --select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-15 08:08:43.512809 (Thread-1): SQL status: SELECT 1 in 0.06 seconds
2022-01-15 08:08:43.516542 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-15 08:08:43.516782 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
alter table "sakila_wh"."dwh"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2022-01-15 08:08:43.580531 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-15 08:08:43.584836 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-15 08:08:43.585203 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
alter table "sakila_wh"."dwh"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-15 08:08:43.645941 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-15 08:08:43.648599 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: COMMIT
2022-01-15 08:08:43.649069 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-15 08:08:43.649318 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: COMMIT
2022-01-15 08:08:43.710350 (Thread-1): SQL status: COMMIT in 0.06 seconds
2022-01-15 08:08:43.713691 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-15 08:08:43.713922 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
drop table if exists "sakila_wh"."dwh"."my_first_dbt_model__dbt_backup" cascade
2022-01-15 08:08:43.783864 (Thread-1): SQL status: DROP TABLE in 0.07 seconds
2022-01-15 08:08:43.785426 (Thread-1): finished collecting timing info
2022-01-15 08:08:43.785670 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: Close
2022-01-15 08:08:43.786141 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b15fb15c-bc7e-4ad7-8b07-eccfbd048a4f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1131ec4c0>]}
2022-01-15 08:08:43.786525 (Thread-1): 13:38:43 | 4 of 6 OK created table model dwh.my_first_dbt_model................. [SELECT 1 in 0.72s]
2022-01-15 08:08:43.786750 (Thread-1): Finished running node model.sakila_dbt_project.my_first_dbt_model
2022-01-15 08:08:43.786970 (Thread-1): Began running node model.sakila_dbt_project.payment_inc
2022-01-15 08:08:43.787343 (Thread-1): 13:38:43 | 5 of 6 START incremental model dwh.payment_inc....................... [RUN]
2022-01-15 08:08:43.787828 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-15 08:08:43.788030 (Thread-1): Compiling model.sakila_dbt_project.payment_inc
2022-01-15 08:08:43.794206 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.payment_inc"
2022-01-15 08:08:43.794847 (Thread-1): finished collecting timing info
2022-01-15 08:08:43.832379 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-15 08:08:43.832625 (Thread-1): On model.sakila_dbt_project.payment_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.payment_inc"} */

    

  create temporary table "payment_inc__dbt_tmp133843826041"
  as (
    

select
*,
'2022-01-15 08:08:37' as dbt_tran_time
from
stg.payment
where 1=1


and payment_date::timestamp > (select max(payment_date) from "sakila_wh"."dwh"."payment_inc")



-- - INTERVAL '3 DAY'
-- unique_key='payment_id'
  );
  
2022-01-15 08:08:43.832802 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 08:08:44.234018 (Thread-1): SQL status: SELECT 0 in 0.40 seconds
2022-01-15 08:08:44.242892 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-15 08:08:44.243125 (Thread-1): On model.sakila_dbt_project.payment_inc: BEGIN
2022-01-15 08:08:44.309769 (Thread-1): SQL status: BEGIN in 0.07 seconds
2022-01-15 08:08:44.310369 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-15 08:08:44.310724 (Thread-1): On model.sakila_dbt_project.payment_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.payment_inc"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'payment_inc__dbt_tmp133843826041'
        
      order by ordinal_position

  
2022-01-15 08:08:44.388157 (Thread-1): SQL status: SELECT 7 in 0.08 seconds
2022-01-15 08:08:44.396488 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-15 08:08:44.396726 (Thread-1): On model.sakila_dbt_project.payment_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.payment_inc"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "sakila_wh".INFORMATION_SCHEMA.columns
      where table_name = 'payment_inc'
        
        and table_schema = 'dwh'
        
      order by ordinal_position

  
2022-01-15 08:08:44.463133 (Thread-1): SQL status: SELECT 7 in 0.07 seconds
2022-01-15 08:08:44.475930 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-15 08:08:44.476180 (Thread-1): On model.sakila_dbt_project.payment_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.payment_inc"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "sakila_wh".INFORMATION_SCHEMA.columns
      where table_name = 'payment_inc'
        
        and table_schema = 'dwh'
        
      order by ordinal_position

  
2022-01-15 08:08:44.550680 (Thread-1): SQL status: SELECT 7 in 0.07 seconds
2022-01-15 08:08:44.553400 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.payment_inc"
2022-01-15 08:08:44.554185 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-15 08:08:44.554405 (Thread-1): On model.sakila_dbt_project.payment_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.payment_inc"} */

      delete
    from "sakila_wh"."dwh"."payment_inc"
    where (payment_id) in (
        select (payment_id)
        from "payment_inc__dbt_tmp133843826041"
    );

    insert into "sakila_wh"."dwh"."payment_inc" ("payment_id", "customer_id", "staff_id", "rental_id", "amount", "payment_date", "dbt_tran_time")
    (
       select "payment_id", "customer_id", "staff_id", "rental_id", "amount", "payment_date", "dbt_tran_time"
       from "payment_inc__dbt_tmp133843826041"
    );
  
2022-01-15 08:08:44.617340 (Thread-1): SQL status: INSERT 0 0 in 0.06 seconds
2022-01-15 08:08:44.619258 (Thread-1): On model.sakila_dbt_project.payment_inc: COMMIT
2022-01-15 08:08:44.619511 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-15 08:08:44.619782 (Thread-1): On model.sakila_dbt_project.payment_inc: COMMIT
2022-01-15 08:08:44.682899 (Thread-1): SQL status: COMMIT in 0.06 seconds
2022-01-15 08:08:44.683792 (Thread-1): finished collecting timing info
2022-01-15 08:08:44.684142 (Thread-1): On model.sakila_dbt_project.payment_inc: Close
2022-01-15 08:08:44.684859 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b15fb15c-bc7e-4ad7-8b07-eccfbd048a4f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11328ad60>]}
2022-01-15 08:08:44.685425 (Thread-1): 13:38:44 | 5 of 6 OK created incremental model dwh.payment_inc.................. [INSERT 0 0 in 0.90s]
2022-01-15 08:08:44.685698 (Thread-1): Finished running node model.sakila_dbt_project.payment_inc
2022-01-15 08:08:44.685963 (Thread-1): Began running node model.sakila_dbt_project.my_second_dbt_model
2022-01-15 08:08:44.686369 (Thread-1): 13:38:44 | 6 of 6 START table model dwh.my_second_dbt_model..................... [RUN]
2022-01-15 08:08:44.686818 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-15 08:08:44.687051 (Thread-1): Compiling model.sakila_dbt_project.my_second_dbt_model
2022-01-15 08:08:44.690083 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.my_second_dbt_model"
2022-01-15 08:08:44.690683 (Thread-1): finished collecting timing info
2022-01-15 08:08:44.693263 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.my_second_dbt_model"
2022-01-15 08:08:44.693848 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-15 08:08:44.694035 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: BEGIN
2022-01-15 08:08:44.694212 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 08:08:45.072783 (Thread-1): SQL status: BEGIN in 0.38 seconds
2022-01-15 08:08:45.073142 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-15 08:08:45.073355 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */


  create  table "sakila_wh"."dwh"."my_second_dbt_model__dbt_tmp"
  as (
    -- Use the `ref` function to select from other models

select *
from "sakila_wh"."dwh"."my_first_dbt_model"
where id = 1
  );
2022-01-15 08:08:45.140047 (Thread-1): SQL status: SELECT 1 in 0.07 seconds
2022-01-15 08:08:45.143910 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-15 08:08:45.144154 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
alter table "sakila_wh"."dwh"."my_second_dbt_model" rename to "my_second_dbt_model__dbt_backup"
2022-01-15 08:08:45.210862 (Thread-1): SQL status: ALTER TABLE in 0.07 seconds
2022-01-15 08:08:45.214819 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-15 08:08:45.215049 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
alter table "sakila_wh"."dwh"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-15 08:08:45.278772 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-15 08:08:45.281279 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: COMMIT
2022-01-15 08:08:45.281574 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-15 08:08:45.281919 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: COMMIT
2022-01-15 08:08:45.344584 (Thread-1): SQL status: COMMIT in 0.06 seconds
2022-01-15 08:08:45.347972 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-15 08:08:45.348206 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
drop table if exists "sakila_wh"."dwh"."my_second_dbt_model__dbt_backup" cascade
2022-01-15 08:08:45.411954 (Thread-1): SQL status: DROP TABLE in 0.06 seconds
2022-01-15 08:08:45.414125 (Thread-1): finished collecting timing info
2022-01-15 08:08:45.414475 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: Close
2022-01-15 08:08:45.415170 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b15fb15c-bc7e-4ad7-8b07-eccfbd048a4f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1130bffd0>]}
2022-01-15 08:08:45.415616 (Thread-1): 13:38:45 | 6 of 6 OK created table model dwh.my_second_dbt_model................ [SELECT 1 in 0.73s]
2022-01-15 08:08:45.415885 (Thread-1): Finished running node model.sakila_dbt_project.my_second_dbt_model
2022-01-15 08:08:45.417130 (MainThread): Acquiring new postgres connection "master".
2022-01-15 08:08:45.417364 (MainThread): Using postgres connection "master".
2022-01-15 08:08:45.417536 (MainThread): On master: BEGIN
2022-01-15 08:08:45.417704 (MainThread): Opening a new connection, currently in state closed
2022-01-15 08:08:45.806406 (MainThread): SQL status: BEGIN in 0.39 seconds
2022-01-15 08:08:45.806878 (MainThread): On master: COMMIT
2022-01-15 08:08:45.807163 (MainThread): Using postgres connection "master".
2022-01-15 08:08:45.807425 (MainThread): On master: COMMIT
2022-01-15 08:08:45.868540 (MainThread): SQL status: COMMIT in 0.06 seconds
2022-01-15 08:08:45.868976 (MainThread): On master: Close
2022-01-15 08:08:45.869572 (MainThread): 13:38:45 | 
2022-01-15 08:08:45.869845 (MainThread): 13:38:45 | Finished running 5 table models, 1 incremental model in 7.50s.
2022-01-15 08:08:45.870082 (MainThread): Connection 'master' was properly closed.
2022-01-15 08:08:45.870272 (MainThread): Connection 'model.sakila_dbt_project.my_second_dbt_model' was properly closed.
2022-01-15 08:08:45.880886 (MainThread): 
2022-01-15 08:08:45.881150 (MainThread): Completed successfully
2022-01-15 08:08:45.881373 (MainThread): 
Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
2022-01-15 08:08:45.881677 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11305bf40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1132946d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1132943d0>]}
2022-01-15 08:08:45.881951 (MainThread): Flushing usage events
2022-01-15 08:09:21.656863 (MainThread): Running with dbt=0.21.1
2022-01-15 08:09:21.740021 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, data=False, schema=False, fail_fast=False, store_failures=False, greedy=False, threads=None, version_check=True, select=['example.my_first_dbt_model'], exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.test.TestTask'>, which='test', rpc_method='test')
2022-01-15 08:09:21.741724 (MainThread): Tracking: tracking
2022-01-15 08:09:21.763092 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e8788e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e285250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e864dc0>]}
2022-01-15 08:09:21.786312 (MainThread): Partial parsing not enabled
2022-01-15 08:09:21.825941 (MainThread): Parsing macros/catalog.sql
2022-01-15 08:09:21.829197 (MainThread): Parsing macros/relations.sql
2022-01-15 08:09:21.830619 (MainThread): Parsing macros/adapters.sql
2022-01-15 08:09:21.852461 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2022-01-15 08:09:21.854121 (MainThread): Parsing macros/core.sql
2022-01-15 08:09:21.857639 (MainThread): Parsing macros/materializations/test.sql
2022-01-15 08:09:21.865011 (MainThread): Parsing macros/materializations/helpers.sql
2022-01-15 08:09:21.874336 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2022-01-15 08:09:21.875915 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2022-01-15 08:09:21.892282 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2022-01-15 08:09:21.922826 (MainThread): Parsing macros/materializations/seed/seed.sql
2022-01-15 08:09:21.944288 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2022-01-15 08:09:21.946077 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2022-01-15 08:09:21.955483 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2022-01-15 08:09:21.974289 (MainThread): Parsing macros/materializations/common/merge.sql
2022-01-15 08:09:21.987301 (MainThread): Parsing macros/materializations/table/table.sql
2022-01-15 08:09:21.994537 (MainThread): Parsing macros/materializations/view/view.sql
2022-01-15 08:09:22.001360 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2022-01-15 08:09:22.005085 (MainThread): Parsing macros/etc/get_custom_alias.sql
2022-01-15 08:09:22.006437 (MainThread): Parsing macros/etc/query.sql
2022-01-15 08:09:22.007315 (MainThread): Parsing macros/etc/is_incremental.sql
2022-01-15 08:09:22.008745 (MainThread): Parsing macros/etc/datetime.sql
2022-01-15 08:09:22.016725 (MainThread): Parsing macros/etc/where_subquery.sql
2022-01-15 08:09:22.018375 (MainThread): Parsing macros/etc/get_custom_schema.sql
2022-01-15 08:09:22.020667 (MainThread): Parsing macros/etc/get_custom_database.sql
2022-01-15 08:09:22.022156 (MainThread): Parsing macros/adapters/common.sql
2022-01-15 08:09:22.073912 (MainThread): Parsing macros/schema_tests/relationships.sql
2022-01-15 08:09:22.075468 (MainThread): Parsing macros/schema_tests/not_null.sql
2022-01-15 08:09:22.076601 (MainThread): Parsing macros/schema_tests/unique.sql
2022-01-15 08:09:22.077839 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2022-01-15 08:09:22.080057 (MainThread): Parsing macros/cross_db_utils/except.sql
2022-01-15 08:09:22.081032 (MainThread): Parsing macros/cross_db_utils/replace.sql
2022-01-15 08:09:22.082295 (MainThread): Parsing macros/cross_db_utils/concat.sql
2022-01-15 08:09:22.083217 (MainThread): Parsing macros/cross_db_utils/datatypes.sql
2022-01-15 08:09:22.088590 (MainThread): Parsing macros/cross_db_utils/_is_relation.sql
2022-01-15 08:09:22.089635 (MainThread): Parsing macros/cross_db_utils/length.sql
2022-01-15 08:09:22.090822 (MainThread): Parsing macros/cross_db_utils/dateadd.sql
2022-01-15 08:09:22.093515 (MainThread): Parsing macros/cross_db_utils/intersect.sql
2022-01-15 08:09:22.094523 (MainThread): Parsing macros/cross_db_utils/right.sql
2022-01-15 08:09:22.096725 (MainThread): Parsing macros/cross_db_utils/datediff.sql
2022-01-15 08:09:22.106243 (MainThread): Parsing macros/cross_db_utils/safe_cast.sql
2022-01-15 08:09:22.108092 (MainThread): Parsing macros/cross_db_utils/hash.sql
2022-01-15 08:09:22.109379 (MainThread): Parsing macros/cross_db_utils/cast_bool_to_text.sql
2022-01-15 08:09:22.110680 (MainThread): Parsing macros/cross_db_utils/identifier.sql
2022-01-15 08:09:22.112251 (MainThread): Parsing macros/cross_db_utils/position.sql
2022-01-15 08:09:22.113836 (MainThread): Parsing macros/cross_db_utils/literal.sql
2022-01-15 08:09:22.114716 (MainThread): Parsing macros/cross_db_utils/current_timestamp.sql
2022-01-15 08:09:22.118063 (MainThread): Parsing macros/cross_db_utils/width_bucket.sql
2022-01-15 08:09:22.123164 (MainThread): Parsing macros/cross_db_utils/last_day.sql
2022-01-15 08:09:22.126341 (MainThread): Parsing macros/cross_db_utils/split_part.sql
2022-01-15 08:09:22.128095 (MainThread): Parsing macros/cross_db_utils/date_trunc.sql
2022-01-15 08:09:22.129779 (MainThread): Parsing macros/cross_db_utils/_is_ephemeral.sql
2022-01-15 08:09:22.131582 (MainThread): Parsing macros/materializations/insert_by_period_materialization.sql
2022-01-15 08:09:22.154974 (MainThread): Parsing macros/web/get_url_host.sql
2022-01-15 08:09:22.156660 (MainThread): Parsing macros/web/get_url_path.sql
2022-01-15 08:09:22.159027 (MainThread): Parsing macros/web/get_url_parameter.sql
2022-01-15 08:09:22.160444 (MainThread): Parsing macros/jinja_helpers/pretty_log_format.sql
2022-01-15 08:09:22.161719 (MainThread): Parsing macros/jinja_helpers/pretty_time.sql
2022-01-15 08:09:22.163095 (MainThread): Parsing macros/jinja_helpers/log_info.sql
2022-01-15 08:09:22.164115 (MainThread): Parsing macros/jinja_helpers/slugify.sql
2022-01-15 08:09:22.165179 (MainThread): Parsing macros/schema_tests/fewer_rows_than.sql
2022-01-15 08:09:22.166847 (MainThread): Parsing macros/schema_tests/equal_rowcount.sql
2022-01-15 08:09:22.168379 (MainThread): Parsing macros/schema_tests/relationships_where.sql
2022-01-15 08:09:22.170528 (MainThread): Parsing macros/schema_tests/recency.sql
2022-01-15 08:09:22.172119 (MainThread): Parsing macros/schema_tests/not_constant.sql
2022-01-15 08:09:22.173244 (MainThread): Parsing macros/schema_tests/accepted_range.sql
2022-01-15 08:09:22.175547 (MainThread): Parsing macros/schema_tests/not_accepted_values.sql
2022-01-15 08:09:22.177527 (MainThread): Parsing macros/schema_tests/test_unique_where.sql
2022-01-15 08:09:22.178954 (MainThread): Parsing macros/schema_tests/at_least_one.sql
2022-01-15 08:09:22.180159 (MainThread): Parsing macros/schema_tests/unique_combination_of_columns.sql
2022-01-15 08:09:22.182833 (MainThread): Parsing macros/schema_tests/cardinality_equality.sql
2022-01-15 08:09:22.184632 (MainThread): Parsing macros/schema_tests/expression_is_true.sql
2022-01-15 08:09:22.186249 (MainThread): Parsing macros/schema_tests/sequential_values.sql
2022-01-15 08:09:22.189059 (MainThread): Parsing macros/schema_tests/test_not_null_where.sql
2022-01-15 08:09:22.190389 (MainThread): Parsing macros/schema_tests/equality.sql
2022-01-15 08:09:22.193623 (MainThread): Parsing macros/schema_tests/mutually_exclusive_ranges.sql
2022-01-15 08:09:22.202188 (MainThread): Parsing macros/sql/date_spine.sql
2022-01-15 08:09:22.206549 (MainThread): Parsing macros/sql/nullcheck_table.sql
2022-01-15 08:09:22.208034 (MainThread): Parsing macros/sql/get_relations_by_pattern.sql
2022-01-15 08:09:22.211422 (MainThread): Parsing macros/sql/generate_series.sql
2022-01-15 08:09:22.240287 (MainThread): Parsing macros/sql/get_relations_by_prefix.sql
2022-01-15 08:09:22.244752 (MainThread): Parsing macros/sql/get_tables_by_prefix_sql.sql
2022-01-15 08:09:22.246961 (MainThread): Parsing macros/sql/star.sql
2022-01-15 08:09:22.251188 (MainThread): Parsing macros/sql/unpivot.sql
2022-01-15 08:09:22.261109 (MainThread): Parsing macros/sql/union.sql
2022-01-15 08:09:22.270671 (MainThread): Parsing macros/sql/groupby.sql
2022-01-15 08:09:22.272201 (MainThread): Parsing macros/sql/surrogate_key.sql
2022-01-15 08:09:22.275996 (MainThread): Parsing macros/sql/safe_add.sql
2022-01-15 08:09:22.277831 (MainThread): Parsing macros/sql/nullcheck.sql
2022-01-15 08:09:22.279807 (MainThread): Parsing macros/sql/get_tables_by_pattern_sql.sql
2022-01-15 08:09:22.286665 (MainThread): Parsing macros/sql/get_column_values.sql
2022-01-15 08:09:22.291833 (MainThread): Parsing macros/sql/pivot.sql
2022-01-15 08:09:22.295941 (MainThread): Parsing macros/sql/get_query_results_as_dict.sql
2022-01-15 08:09:22.298084 (MainThread): Parsing macros/sql/haversine_distance.sql
2022-01-15 08:09:22.600762 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-15 08:09:22.612929 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-15 08:09:22.616436 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.film_test".
2022-01-15 08:09:22.619200 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-15 08:09:22.626911 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-15 08:09:22.630027 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-15 08:09:22.664412 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:09:22.666223 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:09:22.668128 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:09:22.670110 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:09:22.672772 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:09:22.674334 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:09:22.686530 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:09:22.686846 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:09:22.701004 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:09:22.702838 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:09:22.726511 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '94bb25e7-6369-4eab-93b4-205c71317730', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e9f10d0>]}
2022-01-15 08:09:22.734862 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-01-15 08:09:22.735392 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '94bb25e7-6369-4eab-93b4-205c71317730', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e9f1160>]}
2022-01-15 08:09:22.735689 (MainThread): Found 6 models, 9 tests, 0 snapshots, 0 analyses, 347 macros, 0 operations, 0 seed files, 12 sources, 0 exposures
2022-01-15 08:09:22.737036 (MainThread): 
2022-01-15 08:09:22.737381 (MainThread): Acquiring new postgres connection "master".
2022-01-15 08:09:22.738435 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_dwh".
2022-01-15 08:09:22.748094 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-15 08:09:22.748303 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: BEGIN
2022-01-15 08:09:22.748456 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2022-01-15 08:09:23.151301 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.40 seconds
2022-01-15 08:09:23.151697 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-15 08:09:23.151944 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_dwh"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dwh'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dwh'
  
2022-01-15 08:09:23.222274 (ThreadPoolExecutor-1_0): SQL status: SELECT 6 in 0.07 seconds
2022-01-15 08:09:23.224630 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: ROLLBACK
2022-01-15 08:09:23.285625 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: Close
2022-01-15 08:09:23.292573 (MainThread): Using postgres connection "master".
2022-01-15 08:09:23.292785 (MainThread): On master: BEGIN
2022-01-15 08:09:23.292959 (MainThread): Opening a new connection, currently in state init
2022-01-15 08:09:23.679922 (MainThread): SQL status: BEGIN in 0.39 seconds
2022-01-15 08:09:23.680255 (MainThread): Using postgres connection "master".
2022-01-15 08:09:23.680442 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-15 08:09:23.760942 (MainThread): SQL status: SELECT 47 in 0.08 seconds
2022-01-15 08:09:23.764195 (MainThread): On master: ROLLBACK
2022-01-15 08:09:23.824927 (MainThread): On master: Close
2022-01-15 08:09:23.825947 (MainThread): 13:39:23 | Concurrency: 1 threads (target='dev')
2022-01-15 08:09:23.826314 (MainThread): 13:39:23 | 
2022-01-15 08:09:23.828705 (Thread-1): Began running node test.sakila_dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
2022-01-15 08:09:23.829043 (Thread-1): 13:39:23 | 1 of 2 START test not_null_my_first_dbt_model_id..................... [RUN]
2022-01-15 08:09:23.829784 (Thread-1): Acquiring new postgres connection "test.sakila_dbt_project.not_null_my_first_dbt_model_id.5fb22c2710".
2022-01-15 08:09:23.830073 (Thread-1): Compiling test.sakila_dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
2022-01-15 08:09:23.836843 (Thread-1): Writing injected SQL for node "test.sakila_dbt_project.not_null_my_first_dbt_model_id.5fb22c2710"
2022-01-15 08:09:23.837627 (Thread-1): finished collecting timing info
2022-01-15 08:09:23.857024 (Thread-1): Writing runtime SQL for node "test.sakila_dbt_project.not_null_my_first_dbt_model_id.5fb22c2710"
2022-01-15 08:09:23.857778 (Thread-1): Using postgres connection "test.sakila_dbt_project.not_null_my_first_dbt_model_id.5fb22c2710".
2022-01-15 08:09:23.857960 (Thread-1): On test.sakila_dbt_project.not_null_my_first_dbt_model_id.5fb22c2710: BEGIN
2022-01-15 08:09:23.858131 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 08:09:24.232152 (Thread-1): SQL status: BEGIN in 0.37 seconds
2022-01-15 08:09:24.232584 (Thread-1): Using postgres connection "test.sakila_dbt_project.not_null_my_first_dbt_model_id.5fb22c2710".
2022-01-15 08:09:24.232858 (Thread-1): On test.sakila_dbt_project.not_null_my_first_dbt_model_id.5fb22c2710: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "test.sakila_dbt_project.not_null_my_first_dbt_model_id.5fb22c2710"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from "sakila_wh"."dwh"."my_first_dbt_model"
where id is null



      
    ) dbt_internal_test
2022-01-15 08:09:24.296543 (Thread-1): SQL status: SELECT 1 in 0.06 seconds
2022-01-15 08:09:24.299402 (Thread-1): finished collecting timing info
2022-01-15 08:09:24.299686 (Thread-1): On test.sakila_dbt_project.not_null_my_first_dbt_model_id.5fb22c2710: ROLLBACK
2022-01-15 08:09:24.360109 (Thread-1): On test.sakila_dbt_project.not_null_my_first_dbt_model_id.5fb22c2710: Close
2022-01-15 08:09:24.361164 (Thread-1): 13:39:24 | 1 of 2 PASS not_null_my_first_dbt_model_id........................... [PASS in 0.53s]
2022-01-15 08:09:24.361532 (Thread-1): Finished running node test.sakila_dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
2022-01-15 08:09:24.361874 (Thread-1): Began running node test.sakila_dbt_project.unique_my_first_dbt_model_id.16e066b321
2022-01-15 08:09:24.362298 (Thread-1): 13:39:24 | 2 of 2 START test unique_my_first_dbt_model_id....................... [RUN]
2022-01-15 08:09:24.362782 (Thread-1): Acquiring new postgres connection "test.sakila_dbt_project.unique_my_first_dbt_model_id.16e066b321".
2022-01-15 08:09:24.363047 (Thread-1): Compiling test.sakila_dbt_project.unique_my_first_dbt_model_id.16e066b321
2022-01-15 08:09:24.370718 (Thread-1): Writing injected SQL for node "test.sakila_dbt_project.unique_my_first_dbt_model_id.16e066b321"
2022-01-15 08:09:24.371432 (Thread-1): finished collecting timing info
2022-01-15 08:09:24.373584 (Thread-1): Writing runtime SQL for node "test.sakila_dbt_project.unique_my_first_dbt_model_id.16e066b321"
2022-01-15 08:09:24.374205 (Thread-1): Using postgres connection "test.sakila_dbt_project.unique_my_first_dbt_model_id.16e066b321".
2022-01-15 08:09:24.374388 (Thread-1): On test.sakila_dbt_project.unique_my_first_dbt_model_id.16e066b321: BEGIN
2022-01-15 08:09:24.374560 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 08:09:24.758662 (Thread-1): SQL status: BEGIN in 0.38 seconds
2022-01-15 08:09:24.759278 (Thread-1): Using postgres connection "test.sakila_dbt_project.unique_my_first_dbt_model_id.16e066b321".
2022-01-15 08:09:24.759538 (Thread-1): On test.sakila_dbt_project.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "test.sakila_dbt_project.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "sakila_wh"."dwh"."my_first_dbt_model"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
2022-01-15 08:09:24.824437 (Thread-1): SQL status: SELECT 1 in 0.06 seconds
2022-01-15 08:09:24.826583 (Thread-1): finished collecting timing info
2022-01-15 08:09:24.826869 (Thread-1): On test.sakila_dbt_project.unique_my_first_dbt_model_id.16e066b321: ROLLBACK
2022-01-15 08:09:24.891440 (Thread-1): On test.sakila_dbt_project.unique_my_first_dbt_model_id.16e066b321: Close
2022-01-15 08:09:24.892527 (Thread-1): 13:39:24 | 2 of 2 PASS unique_my_first_dbt_model_id............................. [PASS in 0.53s]
2022-01-15 08:09:24.892879 (Thread-1): Finished running node test.sakila_dbt_project.unique_my_first_dbt_model_id.16e066b321
2022-01-15 08:09:24.894403 (MainThread): Acquiring new postgres connection "master".
2022-01-15 08:09:24.894853 (MainThread): 13:39:24 | 
2022-01-15 08:09:24.895114 (MainThread): 13:39:24 | Finished running 2 tests in 2.16s.
2022-01-15 08:09:24.895352 (MainThread): Connection 'master' was properly closed.
2022-01-15 08:09:24.895549 (MainThread): Connection 'test.sakila_dbt_project.unique_my_first_dbt_model_id.16e066b321' was properly closed.
2022-01-15 08:09:24.904742 (MainThread): 
2022-01-15 08:09:24.905008 (MainThread): Completed successfully
2022-01-15 08:09:24.905224 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2022-01-15 08:09:24.905488 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ead1310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ead1cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ead1c10>]}
2022-01-15 08:09:24.905757 (MainThread): Flushing usage events
2022-01-15 08:09:58.185478 (MainThread): Running with dbt=0.21.1
2022-01-15 08:09:58.270793 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, data=False, schema=False, fail_fast=False, store_failures=False, greedy=False, threads=None, version_check=True, select=['example.film_test'], exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.test.TestTask'>, which='test', rpc_method='test')
2022-01-15 08:09:58.286660 (MainThread): Tracking: tracking
2022-01-15 08:09:58.305918 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ea4b8e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e4594c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ea37dc0>]}
2022-01-15 08:09:58.328268 (MainThread): Partial parsing not enabled
2022-01-15 08:09:58.368223 (MainThread): Parsing macros/catalog.sql
2022-01-15 08:09:58.371911 (MainThread): Parsing macros/relations.sql
2022-01-15 08:09:58.373507 (MainThread): Parsing macros/adapters.sql
2022-01-15 08:09:58.398223 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2022-01-15 08:09:58.400273 (MainThread): Parsing macros/core.sql
2022-01-15 08:09:58.404388 (MainThread): Parsing macros/materializations/test.sql
2022-01-15 08:09:58.411425 (MainThread): Parsing macros/materializations/helpers.sql
2022-01-15 08:09:58.420812 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2022-01-15 08:09:58.422524 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2022-01-15 08:09:58.438604 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2022-01-15 08:09:58.469347 (MainThread): Parsing macros/materializations/seed/seed.sql
2022-01-15 08:09:58.490793 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2022-01-15 08:09:58.492435 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2022-01-15 08:09:58.502082 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2022-01-15 08:09:58.520671 (MainThread): Parsing macros/materializations/common/merge.sql
2022-01-15 08:09:58.533875 (MainThread): Parsing macros/materializations/table/table.sql
2022-01-15 08:09:58.541350 (MainThread): Parsing macros/materializations/view/view.sql
2022-01-15 08:09:58.548105 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2022-01-15 08:09:58.551800 (MainThread): Parsing macros/etc/get_custom_alias.sql
2022-01-15 08:09:58.553270 (MainThread): Parsing macros/etc/query.sql
2022-01-15 08:09:58.554188 (MainThread): Parsing macros/etc/is_incremental.sql
2022-01-15 08:09:58.555590 (MainThread): Parsing macros/etc/datetime.sql
2022-01-15 08:09:58.563659 (MainThread): Parsing macros/etc/where_subquery.sql
2022-01-15 08:09:58.565348 (MainThread): Parsing macros/etc/get_custom_schema.sql
2022-01-15 08:09:58.567684 (MainThread): Parsing macros/etc/get_custom_database.sql
2022-01-15 08:09:58.569170 (MainThread): Parsing macros/adapters/common.sql
2022-01-15 08:09:58.621640 (MainThread): Parsing macros/schema_tests/relationships.sql
2022-01-15 08:09:58.623337 (MainThread): Parsing macros/schema_tests/not_null.sql
2022-01-15 08:09:58.624478 (MainThread): Parsing macros/schema_tests/unique.sql
2022-01-15 08:09:58.625726 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2022-01-15 08:09:58.627749 (MainThread): Parsing macros/cross_db_utils/except.sql
2022-01-15 08:09:58.628807 (MainThread): Parsing macros/cross_db_utils/replace.sql
2022-01-15 08:09:58.629977 (MainThread): Parsing macros/cross_db_utils/concat.sql
2022-01-15 08:09:58.630958 (MainThread): Parsing macros/cross_db_utils/datatypes.sql
2022-01-15 08:09:58.636750 (MainThread): Parsing macros/cross_db_utils/_is_relation.sql
2022-01-15 08:09:58.637888 (MainThread): Parsing macros/cross_db_utils/length.sql
2022-01-15 08:09:58.639110 (MainThread): Parsing macros/cross_db_utils/dateadd.sql
2022-01-15 08:09:58.642165 (MainThread): Parsing macros/cross_db_utils/intersect.sql
2022-01-15 08:09:58.643174 (MainThread): Parsing macros/cross_db_utils/right.sql
2022-01-15 08:09:58.645263 (MainThread): Parsing macros/cross_db_utils/datediff.sql
2022-01-15 08:09:58.655367 (MainThread): Parsing macros/cross_db_utils/safe_cast.sql
2022-01-15 08:09:58.657292 (MainThread): Parsing macros/cross_db_utils/hash.sql
2022-01-15 08:09:58.658616 (MainThread): Parsing macros/cross_db_utils/cast_bool_to_text.sql
2022-01-15 08:09:58.659935 (MainThread): Parsing macros/cross_db_utils/identifier.sql
2022-01-15 08:09:58.661545 (MainThread): Parsing macros/cross_db_utils/position.sql
2022-01-15 08:09:58.663138 (MainThread): Parsing macros/cross_db_utils/literal.sql
2022-01-15 08:09:58.664039 (MainThread): Parsing macros/cross_db_utils/current_timestamp.sql
2022-01-15 08:09:58.667611 (MainThread): Parsing macros/cross_db_utils/width_bucket.sql
2022-01-15 08:09:58.672450 (MainThread): Parsing macros/cross_db_utils/last_day.sql
2022-01-15 08:09:58.675693 (MainThread): Parsing macros/cross_db_utils/split_part.sql
2022-01-15 08:09:58.677394 (MainThread): Parsing macros/cross_db_utils/date_trunc.sql
2022-01-15 08:09:58.678889 (MainThread): Parsing macros/cross_db_utils/_is_ephemeral.sql
2022-01-15 08:09:58.680625 (MainThread): Parsing macros/materializations/insert_by_period_materialization.sql
2022-01-15 08:09:58.704470 (MainThread): Parsing macros/web/get_url_host.sql
2022-01-15 08:09:58.706344 (MainThread): Parsing macros/web/get_url_path.sql
2022-01-15 08:09:58.708887 (MainThread): Parsing macros/web/get_url_parameter.sql
2022-01-15 08:09:58.710340 (MainThread): Parsing macros/jinja_helpers/pretty_log_format.sql
2022-01-15 08:09:58.711368 (MainThread): Parsing macros/jinja_helpers/pretty_time.sql
2022-01-15 08:09:58.712485 (MainThread): Parsing macros/jinja_helpers/log_info.sql
2022-01-15 08:09:58.713564 (MainThread): Parsing macros/jinja_helpers/slugify.sql
2022-01-15 08:09:58.714694 (MainThread): Parsing macros/schema_tests/fewer_rows_than.sql
2022-01-15 08:09:58.716246 (MainThread): Parsing macros/schema_tests/equal_rowcount.sql
2022-01-15 08:09:58.717905 (MainThread): Parsing macros/schema_tests/relationships_where.sql
2022-01-15 08:09:58.720021 (MainThread): Parsing macros/schema_tests/recency.sql
2022-01-15 08:09:58.721624 (MainThread): Parsing macros/schema_tests/not_constant.sql
2022-01-15 08:09:58.722893 (MainThread): Parsing macros/schema_tests/accepted_range.sql
2022-01-15 08:09:58.725220 (MainThread): Parsing macros/schema_tests/not_accepted_values.sql
2022-01-15 08:09:58.727154 (MainThread): Parsing macros/schema_tests/test_unique_where.sql
2022-01-15 08:09:58.728705 (MainThread): Parsing macros/schema_tests/at_least_one.sql
2022-01-15 08:09:58.729885 (MainThread): Parsing macros/schema_tests/unique_combination_of_columns.sql
2022-01-15 08:09:58.732545 (MainThread): Parsing macros/schema_tests/cardinality_equality.sql
2022-01-15 08:09:58.734476 (MainThread): Parsing macros/schema_tests/expression_is_true.sql
2022-01-15 08:09:58.736256 (MainThread): Parsing macros/schema_tests/sequential_values.sql
2022-01-15 08:09:58.739058 (MainThread): Parsing macros/schema_tests/test_not_null_where.sql
2022-01-15 08:09:58.740503 (MainThread): Parsing macros/schema_tests/equality.sql
2022-01-15 08:09:58.743874 (MainThread): Parsing macros/schema_tests/mutually_exclusive_ranges.sql
2022-01-15 08:09:58.752296 (MainThread): Parsing macros/sql/date_spine.sql
2022-01-15 08:09:58.756528 (MainThread): Parsing macros/sql/nullcheck_table.sql
2022-01-15 08:09:58.758010 (MainThread): Parsing macros/sql/get_relations_by_pattern.sql
2022-01-15 08:09:58.761181 (MainThread): Parsing macros/sql/generate_series.sql
2022-01-15 08:09:58.790794 (MainThread): Parsing macros/sql/get_relations_by_prefix.sql
2022-01-15 08:09:58.795220 (MainThread): Parsing macros/sql/get_tables_by_prefix_sql.sql
2022-01-15 08:09:58.797361 (MainThread): Parsing macros/sql/star.sql
2022-01-15 08:09:58.801788 (MainThread): Parsing macros/sql/unpivot.sql
2022-01-15 08:09:58.811979 (MainThread): Parsing macros/sql/union.sql
2022-01-15 08:09:58.821729 (MainThread): Parsing macros/sql/groupby.sql
2022-01-15 08:09:58.823324 (MainThread): Parsing macros/sql/surrogate_key.sql
2022-01-15 08:09:58.827143 (MainThread): Parsing macros/sql/safe_add.sql
2022-01-15 08:09:58.829000 (MainThread): Parsing macros/sql/nullcheck.sql
2022-01-15 08:09:58.830853 (MainThread): Parsing macros/sql/get_tables_by_pattern_sql.sql
2022-01-15 08:09:58.838070 (MainThread): Parsing macros/sql/get_column_values.sql
2022-01-15 08:09:58.843495 (MainThread): Parsing macros/sql/pivot.sql
2022-01-15 08:09:58.847819 (MainThread): Parsing macros/sql/get_query_results_as_dict.sql
2022-01-15 08:09:58.850419 (MainThread): Parsing macros/sql/haversine_distance.sql
2022-01-15 08:09:59.153317 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-15 08:09:59.164719 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-15 08:09:59.168598 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.film_test".
2022-01-15 08:09:59.171481 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-15 08:09:59.179250 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-15 08:09:59.182465 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-15 08:09:59.216537 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:09:59.218479 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:09:59.220125 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:09:59.221768 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:09:59.224484 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:09:59.226081 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:09:59.238453 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:09:59.238772 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:09:59.252705 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:09:59.254374 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:09:59.276931 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e2134928-40c4-455f-a182-ce615c44c3c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eba50d0>]}
2022-01-15 08:09:59.285601 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-01-15 08:09:59.286090 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e2134928-40c4-455f-a182-ce615c44c3c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eba5160>]}
2022-01-15 08:09:59.286333 (MainThread): Found 6 models, 9 tests, 0 snapshots, 0 analyses, 347 macros, 0 operations, 0 seed files, 12 sources, 0 exposures
2022-01-15 08:09:59.287498 (MainThread): 
2022-01-15 08:09:59.287812 (MainThread): Acquiring new postgres connection "master".
2022-01-15 08:09:59.288715 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_dwh".
2022-01-15 08:09:59.297602 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-15 08:09:59.297763 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: BEGIN
2022-01-15 08:09:59.297917 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2022-01-15 08:09:59.704487 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.41 seconds
2022-01-15 08:09:59.704820 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-15 08:09:59.705032 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_dwh"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dwh'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dwh'
  
2022-01-15 08:09:59.770505 (ThreadPoolExecutor-1_0): SQL status: SELECT 6 in 0.07 seconds
2022-01-15 08:09:59.772852 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: ROLLBACK
2022-01-15 08:09:59.842059 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: Close
2022-01-15 08:09:59.848068 (MainThread): Using postgres connection "master".
2022-01-15 08:09:59.848333 (MainThread): On master: BEGIN
2022-01-15 08:09:59.848512 (MainThread): Opening a new connection, currently in state init
2022-01-15 08:10:00.223348 (MainThread): SQL status: BEGIN in 0.37 seconds
2022-01-15 08:10:00.242337 (MainThread): Using postgres connection "master".
2022-01-15 08:10:00.242766 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-15 08:10:00.322522 (MainThread): SQL status: SELECT 47 in 0.08 seconds
2022-01-15 08:10:00.325604 (MainThread): On master: ROLLBACK
2022-01-15 08:10:00.387604 (MainThread): On master: Close
2022-01-15 08:10:00.388603 (MainThread): 13:40:00 | Concurrency: 1 threads (target='dev')
2022-01-15 08:10:00.389020 (MainThread): 13:40:00 | 
2022-01-15 08:10:00.391166 (Thread-1): Began running node test.sakila_dbt_project.accepted_values_film_test_ratings_accepted_values__NC_17__PG_13__G__R__PG.5f23d90f6b
2022-01-15 08:10:00.391472 (Thread-1): 13:40:00 | 1 of 1 START test accepted_values_film_test_ratings_accepted_values__NC_17__PG_13__G__R__PG [RUN]
2022-01-15 08:10:00.391916 (Thread-1): Acquiring new postgres connection "test.sakila_dbt_project.accepted_values_film_test_ratings_accepted_values__NC_17__PG_13__G__R__PG.5f23d90f6b".
2022-01-15 08:10:00.392177 (Thread-1): Compiling test.sakila_dbt_project.accepted_values_film_test_ratings_accepted_values__NC_17__PG_13__G__R__PG.5f23d90f6b
2022-01-15 08:10:00.398780 (Thread-1): Writing injected SQL for node "test.sakila_dbt_project.accepted_values_film_test_ratings_accepted_values__NC_17__PG_13__G__R__PG.5f23d90f6b"
2022-01-15 08:10:00.399416 (Thread-1): finished collecting timing info
2022-01-15 08:10:00.417004 (Thread-1): Writing runtime SQL for node "test.sakila_dbt_project.accepted_values_film_test_ratings_accepted_values__NC_17__PG_13__G__R__PG.5f23d90f6b"
2022-01-15 08:10:00.417723 (Thread-1): Using postgres connection "test.sakila_dbt_project.accepted_values_film_test_ratings_accepted_values__NC_17__PG_13__G__R__PG.5f23d90f6b".
2022-01-15 08:10:00.417905 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_ratings_accepted_values__NC_17__PG_13__G__R__PG.5f23d90f6b: BEGIN
2022-01-15 08:10:00.418061 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 08:10:00.790223 (Thread-1): SQL status: BEGIN in 0.37 seconds
2022-01-15 08:10:00.790622 (Thread-1): Using postgres connection "test.sakila_dbt_project.accepted_values_film_test_ratings_accepted_values__NC_17__PG_13__G__R__PG.5f23d90f6b".
2022-01-15 08:10:00.790916 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_ratings_accepted_values__NC_17__PG_13__G__R__PG.5f23d90f6b: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "test.sakila_dbt_project.accepted_values_film_test_ratings_accepted_values__NC_17__PG_13__G__R__PG.5f23d90f6b"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        ratings_accepted values as value_field,
        count(*) as n_records

    from "sakila_wh"."dwh"."film_test"
    group by ratings_accepted values

)

select *
from all_values
where value_field not in (
    'NC-17','PG-13','G','R','PG'
)



      
    ) dbt_internal_test
2022-01-15 08:10:00.852532 (Thread-1): Postgres error: syntax error at or near "values"
LINE 14:         ratings_accepted values as value_field,
                                  ^

2022-01-15 08:10:00.852866 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_ratings_accepted_values__NC_17__PG_13__G__R__PG.5f23d90f6b: ROLLBACK
2022-01-15 08:10:00.916445 (Thread-1): finished collecting timing info
2022-01-15 08:10:00.916905 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_ratings_accepted_values__NC_17__PG_13__G__R__PG.5f23d90f6b: Close
2022-01-15 08:10:00.917580 (Thread-1): Database Error in test accepted_values_film_test_ratings_accepted_values__NC_17__PG_13__G__R__PG (models/example/schema.yml)
  syntax error at or near "values"
  LINE 14:         ratings_accepted values as value_field,
                                    ^
  compiled SQL at target/run/sakila_dbt_project/models/example/schema.yml/schema_test/accepted_values_film_test_151ffd162891540b2e8af8d20454e767.sql
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    yield
  File "/usr/local/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 80, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.SyntaxError: syntax error at or near "values"
LINE 14:         ratings_accepted values as value_field,
                                  ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/dbt/task/base.py", line 348, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.9/site-packages/dbt/task/base.py", line 291, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.9/site-packages/dbt/task/base.py", line 393, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.9/site-packages/dbt/task/test.py", line 132, in execute
    result = self.execute_test(test, manifest)
  File "/usr/local/lib/python3.9/site-packages/dbt/task/test.py", line 102, in execute_test
    macro_func()
  File "/usr/local/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 132, in macro
  File "/usr/local/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/dbt/clients/jinja.py", line 333, in __call__
    return self.call_macro(*args, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/dbt/clients/jinja.py", line 260, in call_macro
    return macro(*args, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/jinja2/runtime.py", line 675, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/lib/python3.9/site-packages/jinja2/runtime.py", line 679, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 41, in macro
  File "/usr/local/lib/python3.9/site-packages/jinja2/sandbox.py", line 462, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/jinja2/runtime.py", line 290, in call
    return __obj(*args, **kwargs)
  File "/usr/local/lib/python3.9/site-packages/dbt/adapters/base/impl.py", line 226, in execute
    return self.connections.execute(
  File "/usr/local/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 131, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/usr/local/lib/python3.9/site-packages/dbt/adapters/sql/connections.py", line 87, in add_query
    return connection, cursor
  File "/usr/local/Cellar/python@3.9/3.9.9/Frameworks/Python.framework/Versions/3.9/lib/python3.9/contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "/usr/local/lib/python3.9/site-packages/dbt/adapters/postgres/connections.py", line 67, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in test accepted_values_film_test_ratings_accepted_values__NC_17__PG_13__G__R__PG (models/example/schema.yml)
  syntax error at or near "values"
  LINE 14:         ratings_accepted values as value_field,
                                    ^
  compiled SQL at target/run/sakila_dbt_project/models/example/schema.yml/schema_test/accepted_values_film_test_151ffd162891540b2e8af8d20454e767.sql
2022-01-15 08:10:00.927643 (Thread-1): 13:40:00 | 1 of 1 ERROR accepted_values_film_test_ratings_accepted_values__NC_17__PG_13__G__R__PG [ERROR in 0.54s]
2022-01-15 08:10:00.927935 (Thread-1): Finished running node test.sakila_dbt_project.accepted_values_film_test_ratings_accepted_values__NC_17__PG_13__G__R__PG.5f23d90f6b
2022-01-15 08:10:00.929386 (MainThread): Acquiring new postgres connection "master".
2022-01-15 08:10:00.929844 (MainThread): 13:40:00 | 
2022-01-15 08:10:00.930127 (MainThread): 13:40:00 | Finished running 1 test in 1.64s.
2022-01-15 08:10:00.930318 (MainThread): Connection 'master' was properly closed.
2022-01-15 08:10:00.930490 (MainThread): Connection 'test.sakila_dbt_project.accepted_values_film_test_ratings_accepted_values__NC_17__PG_13__G__R__PG.5f23d90f6b' was properly closed.
2022-01-15 08:10:00.939707 (MainThread): 
2022-01-15 08:10:00.939955 (MainThread): Completed with 1 error and 0 warnings:
2022-01-15 08:10:00.940155 (MainThread): 
2022-01-15 08:10:00.940343 (MainThread): Database Error in test accepted_values_film_test_ratings_accepted_values__NC_17__PG_13__G__R__PG (models/example/schema.yml)
2022-01-15 08:10:00.940521 (MainThread):   syntax error at or near "values"
2022-01-15 08:10:00.940690 (MainThread):   LINE 14:         ratings_accepted values as value_field,
2022-01-15 08:10:00.940854 (MainThread):                                     ^
2022-01-15 08:10:00.941027 (MainThread):   compiled SQL at target/run/sakila_dbt_project/models/example/schema.yml/schema_test/accepted_values_film_test_151ffd162891540b2e8af8d20454e767.sql
2022-01-15 08:10:00.941205 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2022-01-15 08:10:00.941459 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ebf2550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ec51760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ec516a0>]}
2022-01-15 08:10:00.941723 (MainThread): Flushing usage events
2022-01-15 08:10:47.907335 (MainThread): Running with dbt=0.21.1
2022-01-15 08:10:47.987674 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, data=False, schema=False, fail_fast=False, store_failures=False, greedy=False, threads=None, version_check=True, select=['example.film_test'], exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.test.TestTask'>, which='test', rpc_method='test')
2022-01-15 08:10:47.989543 (MainThread): Tracking: tracking
2022-01-15 08:10:48.009420 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11267c8b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112088190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112655dc0>]}
2022-01-15 08:10:48.033303 (MainThread): Partial parsing not enabled
2022-01-15 08:10:48.072863 (MainThread): Parsing macros/catalog.sql
2022-01-15 08:10:48.076373 (MainThread): Parsing macros/relations.sql
2022-01-15 08:10:48.077840 (MainThread): Parsing macros/adapters.sql
2022-01-15 08:10:48.101763 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2022-01-15 08:10:48.103556 (MainThread): Parsing macros/core.sql
2022-01-15 08:10:48.107132 (MainThread): Parsing macros/materializations/test.sql
2022-01-15 08:10:48.113642 (MainThread): Parsing macros/materializations/helpers.sql
2022-01-15 08:10:48.123599 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2022-01-15 08:10:48.125306 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2022-01-15 08:10:48.141740 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2022-01-15 08:10:48.172372 (MainThread): Parsing macros/materializations/seed/seed.sql
2022-01-15 08:10:48.193948 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2022-01-15 08:10:48.195599 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2022-01-15 08:10:48.205284 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2022-01-15 08:10:48.224331 (MainThread): Parsing macros/materializations/common/merge.sql
2022-01-15 08:10:48.237722 (MainThread): Parsing macros/materializations/table/table.sql
2022-01-15 08:10:48.245212 (MainThread): Parsing macros/materializations/view/view.sql
2022-01-15 08:10:48.251988 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2022-01-15 08:10:48.255555 (MainThread): Parsing macros/etc/get_custom_alias.sql
2022-01-15 08:10:48.256930 (MainThread): Parsing macros/etc/query.sql
2022-01-15 08:10:48.257832 (MainThread): Parsing macros/etc/is_incremental.sql
2022-01-15 08:10:48.259225 (MainThread): Parsing macros/etc/datetime.sql
2022-01-15 08:10:48.267296 (MainThread): Parsing macros/etc/where_subquery.sql
2022-01-15 08:10:48.269093 (MainThread): Parsing macros/etc/get_custom_schema.sql
2022-01-15 08:10:48.271370 (MainThread): Parsing macros/etc/get_custom_database.sql
2022-01-15 08:10:48.272845 (MainThread): Parsing macros/adapters/common.sql
2022-01-15 08:10:48.324875 (MainThread): Parsing macros/schema_tests/relationships.sql
2022-01-15 08:10:48.326617 (MainThread): Parsing macros/schema_tests/not_null.sql
2022-01-15 08:10:48.327740 (MainThread): Parsing macros/schema_tests/unique.sql
2022-01-15 08:10:48.328986 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2022-01-15 08:10:48.331025 (MainThread): Parsing macros/cross_db_utils/except.sql
2022-01-15 08:10:48.332040 (MainThread): Parsing macros/cross_db_utils/replace.sql
2022-01-15 08:10:48.333224 (MainThread): Parsing macros/cross_db_utils/concat.sql
2022-01-15 08:10:48.334411 (MainThread): Parsing macros/cross_db_utils/datatypes.sql
2022-01-15 08:10:48.340044 (MainThread): Parsing macros/cross_db_utils/_is_relation.sql
2022-01-15 08:10:48.341100 (MainThread): Parsing macros/cross_db_utils/length.sql
2022-01-15 08:10:48.342421 (MainThread): Parsing macros/cross_db_utils/dateadd.sql
2022-01-15 08:10:48.345260 (MainThread): Parsing macros/cross_db_utils/intersect.sql
2022-01-15 08:10:48.346251 (MainThread): Parsing macros/cross_db_utils/right.sql
2022-01-15 08:10:48.348333 (MainThread): Parsing macros/cross_db_utils/datediff.sql
2022-01-15 08:10:48.357829 (MainThread): Parsing macros/cross_db_utils/safe_cast.sql
2022-01-15 08:10:48.359558 (MainThread): Parsing macros/cross_db_utils/hash.sql
2022-01-15 08:10:48.360854 (MainThread): Parsing macros/cross_db_utils/cast_bool_to_text.sql
2022-01-15 08:10:48.362179 (MainThread): Parsing macros/cross_db_utils/identifier.sql
2022-01-15 08:10:48.363880 (MainThread): Parsing macros/cross_db_utils/position.sql
2022-01-15 08:10:48.365392 (MainThread): Parsing macros/cross_db_utils/literal.sql
2022-01-15 08:10:48.366359 (MainThread): Parsing macros/cross_db_utils/current_timestamp.sql
2022-01-15 08:10:48.369988 (MainThread): Parsing macros/cross_db_utils/width_bucket.sql
2022-01-15 08:10:48.374879 (MainThread): Parsing macros/cross_db_utils/last_day.sql
2022-01-15 08:10:48.378134 (MainThread): Parsing macros/cross_db_utils/split_part.sql
2022-01-15 08:10:48.379845 (MainThread): Parsing macros/cross_db_utils/date_trunc.sql
2022-01-15 08:10:48.381354 (MainThread): Parsing macros/cross_db_utils/_is_ephemeral.sql
2022-01-15 08:10:48.383502 (MainThread): Parsing macros/materializations/insert_by_period_materialization.sql
2022-01-15 08:10:48.406996 (MainThread): Parsing macros/web/get_url_host.sql
2022-01-15 08:10:48.408799 (MainThread): Parsing macros/web/get_url_path.sql
2022-01-15 08:10:48.411241 (MainThread): Parsing macros/web/get_url_parameter.sql
2022-01-15 08:10:48.412697 (MainThread): Parsing macros/jinja_helpers/pretty_log_format.sql
2022-01-15 08:10:48.413850 (MainThread): Parsing macros/jinja_helpers/pretty_time.sql
2022-01-15 08:10:48.414973 (MainThread): Parsing macros/jinja_helpers/log_info.sql
2022-01-15 08:10:48.415996 (MainThread): Parsing macros/jinja_helpers/slugify.sql
2022-01-15 08:10:48.417360 (MainThread): Parsing macros/schema_tests/fewer_rows_than.sql
2022-01-15 08:10:48.418938 (MainThread): Parsing macros/schema_tests/equal_rowcount.sql
2022-01-15 08:10:48.420444 (MainThread): Parsing macros/schema_tests/relationships_where.sql
2022-01-15 08:10:48.422694 (MainThread): Parsing macros/schema_tests/recency.sql
2022-01-15 08:10:48.424395 (MainThread): Parsing macros/schema_tests/not_constant.sql
2022-01-15 08:10:48.425545 (MainThread): Parsing macros/schema_tests/accepted_range.sql
2022-01-15 08:10:48.427915 (MainThread): Parsing macros/schema_tests/not_accepted_values.sql
2022-01-15 08:10:48.429891 (MainThread): Parsing macros/schema_tests/test_unique_where.sql
2022-01-15 08:10:48.431219 (MainThread): Parsing macros/schema_tests/at_least_one.sql
2022-01-15 08:10:48.432446 (MainThread): Parsing macros/schema_tests/unique_combination_of_columns.sql
2022-01-15 08:10:48.435193 (MainThread): Parsing macros/schema_tests/cardinality_equality.sql
2022-01-15 08:10:48.437032 (MainThread): Parsing macros/schema_tests/expression_is_true.sql
2022-01-15 08:10:48.438687 (MainThread): Parsing macros/schema_tests/sequential_values.sql
2022-01-15 08:10:48.441469 (MainThread): Parsing macros/schema_tests/test_not_null_where.sql
2022-01-15 08:10:48.442890 (MainThread): Parsing macros/schema_tests/equality.sql
2022-01-15 08:10:48.446117 (MainThread): Parsing macros/schema_tests/mutually_exclusive_ranges.sql
2022-01-15 08:10:48.454914 (MainThread): Parsing macros/sql/date_spine.sql
2022-01-15 08:10:48.459227 (MainThread): Parsing macros/sql/nullcheck_table.sql
2022-01-15 08:10:48.460726 (MainThread): Parsing macros/sql/get_relations_by_pattern.sql
2022-01-15 08:10:48.464010 (MainThread): Parsing macros/sql/generate_series.sql
2022-01-15 08:10:48.493643 (MainThread): Parsing macros/sql/get_relations_by_prefix.sql
2022-01-15 08:10:48.497984 (MainThread): Parsing macros/sql/get_tables_by_prefix_sql.sql
2022-01-15 08:10:48.500105 (MainThread): Parsing macros/sql/star.sql
2022-01-15 08:10:48.504524 (MainThread): Parsing macros/sql/unpivot.sql
2022-01-15 08:10:48.514633 (MainThread): Parsing macros/sql/union.sql
2022-01-15 08:10:48.524305 (MainThread): Parsing macros/sql/groupby.sql
2022-01-15 08:10:48.525870 (MainThread): Parsing macros/sql/surrogate_key.sql
2022-01-15 08:10:48.529815 (MainThread): Parsing macros/sql/safe_add.sql
2022-01-15 08:10:48.531614 (MainThread): Parsing macros/sql/nullcheck.sql
2022-01-15 08:10:48.533465 (MainThread): Parsing macros/sql/get_tables_by_pattern_sql.sql
2022-01-15 08:10:48.540495 (MainThread): Parsing macros/sql/get_column_values.sql
2022-01-15 08:10:48.545767 (MainThread): Parsing macros/sql/pivot.sql
2022-01-15 08:10:48.550327 (MainThread): Parsing macros/sql/get_query_results_as_dict.sql
2022-01-15 08:10:48.552873 (MainThread): Parsing macros/sql/haversine_distance.sql
2022-01-15 08:10:48.858408 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-15 08:10:48.879652 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-15 08:10:48.883793 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.film_test".
2022-01-15 08:10:48.887080 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-15 08:10:48.896038 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-15 08:10:48.898939 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-15 08:10:48.932848 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:10:48.935015 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:10:48.936666 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:10:48.938332 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:10:48.940875 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:10:48.942638 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:10:48.954913 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:10:48.969208 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:10:48.970879 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:10:48.994211 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bad51626-97e9-48ce-a291-52dc3fa10ea4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1128040d0>]}
2022-01-15 08:10:49.002376 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-01-15 08:10:49.002931 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bad51626-97e9-48ce-a291-52dc3fa10ea4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112804160>]}
2022-01-15 08:10:49.003187 (MainThread): Found 6 models, 9 tests, 0 snapshots, 0 analyses, 347 macros, 0 operations, 0 seed files, 12 sources, 0 exposures
2022-01-15 08:10:49.004351 (MainThread): 
2022-01-15 08:10:49.004666 (MainThread): Acquiring new postgres connection "master".
2022-01-15 08:10:49.005558 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_dwh".
2022-01-15 08:10:49.014346 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-15 08:10:49.014530 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: BEGIN
2022-01-15 08:10:49.014678 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2022-01-15 08:10:49.424721 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.41 seconds
2022-01-15 08:10:49.425123 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-15 08:10:49.425379 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_dwh"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dwh'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dwh'
  
2022-01-15 08:10:49.493134 (ThreadPoolExecutor-1_0): SQL status: SELECT 6 in 0.07 seconds
2022-01-15 08:10:49.495469 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: ROLLBACK
2022-01-15 08:10:49.558234 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: Close
2022-01-15 08:10:49.564982 (MainThread): Using postgres connection "master".
2022-01-15 08:10:49.565196 (MainThread): On master: BEGIN
2022-01-15 08:10:49.565373 (MainThread): Opening a new connection, currently in state init
2022-01-15 08:10:49.942058 (MainThread): SQL status: BEGIN in 0.38 seconds
2022-01-15 08:10:49.942662 (MainThread): Using postgres connection "master".
2022-01-15 08:10:49.942972 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-15 08:10:50.021928 (MainThread): SQL status: SELECT 47 in 0.08 seconds
2022-01-15 08:10:50.024397 (MainThread): On master: ROLLBACK
2022-01-15 08:10:50.084248 (MainThread): On master: Close
2022-01-15 08:10:50.085049 (MainThread): 13:40:50 | Concurrency: 1 threads (target='dev')
2022-01-15 08:10:50.085332 (MainThread): 13:40:50 | 
2022-01-15 08:10:50.087226 (Thread-1): Began running node test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8
2022-01-15 08:10:50.087489 (Thread-1): 13:40:50 | 1 of 1 START test accepted_values_film_test_rating__NC_17__PG_13__G__R__PG [RUN]
2022-01-15 08:10:50.087890 (Thread-1): Acquiring new postgres connection "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8".
2022-01-15 08:10:50.088107 (Thread-1): Compiling test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8
2022-01-15 08:10:50.094294 (Thread-1): Writing injected SQL for node "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8"
2022-01-15 08:10:50.095180 (Thread-1): finished collecting timing info
2022-01-15 08:10:50.112877 (Thread-1): Writing runtime SQL for node "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8"
2022-01-15 08:10:50.113574 (Thread-1): Using postgres connection "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8".
2022-01-15 08:10:50.113744 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8: BEGIN
2022-01-15 08:10:50.113907 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 08:10:50.499329 (Thread-1): SQL status: BEGIN in 0.39 seconds
2022-01-15 08:10:50.499730 (Thread-1): Using postgres connection "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8".
2022-01-15 08:10:50.499991 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        rating as value_field,
        count(*) as n_records

    from "sakila_wh"."dwh"."film_test"
    group by rating

)

select *
from all_values
where value_field not in (
    'NC-17','PG-13','G','R','PG'
)



      
    ) dbt_internal_test
2022-01-15 08:10:50.566772 (Thread-1): SQL status: SELECT 1 in 0.07 seconds
2022-01-15 08:10:50.570098 (Thread-1): finished collecting timing info
2022-01-15 08:10:50.570398 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8: ROLLBACK
2022-01-15 08:10:50.634568 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8: Close
2022-01-15 08:10:50.635480 (Thread-1): 13:40:50 | 1 of 1 PASS accepted_values_film_test_rating__NC_17__PG_13__G__R__PG. [PASS in 0.55s]
2022-01-15 08:10:50.635884 (Thread-1): Finished running node test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8
2022-01-15 08:10:50.637193 (MainThread): Acquiring new postgres connection "master".
2022-01-15 08:10:50.637564 (MainThread): 13:40:50 | 
2022-01-15 08:10:50.637782 (MainThread): 13:40:50 | Finished running 1 test in 1.63s.
2022-01-15 08:10:50.637977 (MainThread): Connection 'master' was properly closed.
2022-01-15 08:10:50.638137 (MainThread): Connection 'test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8' was properly closed.
2022-01-15 08:10:50.646935 (MainThread): 
2022-01-15 08:10:50.647178 (MainThread): Completed successfully
2022-01-15 08:10:50.647394 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2022-01-15 08:10:50.647671 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1128d0940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1128d0cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1128d0310>]}
2022-01-15 08:10:50.647947 (MainThread): Flushing usage events
2022-01-15 08:11:05.341389 (MainThread): Running with dbt=0.21.1
2022-01-15 08:11:05.419728 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, data=False, schema=False, fail_fast=False, store_failures=False, greedy=False, threads=None, version_check=True, select=['example.film_test'], exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.test.TestTask'>, which='test', rpc_method='test')
2022-01-15 08:11:05.421666 (MainThread): Tracking: tracking
2022-01-15 08:11:05.440533 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fe1a8b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f826190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fe04dc0>]}
2022-01-15 08:11:05.464358 (MainThread): Partial parsing not enabled
2022-01-15 08:11:05.504243 (MainThread): Parsing macros/catalog.sql
2022-01-15 08:11:05.507732 (MainThread): Parsing macros/relations.sql
2022-01-15 08:11:05.509281 (MainThread): Parsing macros/adapters.sql
2022-01-15 08:11:05.531631 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2022-01-15 08:11:05.533276 (MainThread): Parsing macros/core.sql
2022-01-15 08:11:05.536907 (MainThread): Parsing macros/materializations/test.sql
2022-01-15 08:11:05.543648 (MainThread): Parsing macros/materializations/helpers.sql
2022-01-15 08:11:05.553651 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2022-01-15 08:11:05.555363 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2022-01-15 08:11:05.571986 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2022-01-15 08:11:05.602522 (MainThread): Parsing macros/materializations/seed/seed.sql
2022-01-15 08:11:05.624309 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2022-01-15 08:11:05.625930 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2022-01-15 08:11:05.635516 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2022-01-15 08:11:05.654597 (MainThread): Parsing macros/materializations/common/merge.sql
2022-01-15 08:11:05.667874 (MainThread): Parsing macros/materializations/table/table.sql
2022-01-15 08:11:05.675310 (MainThread): Parsing macros/materializations/view/view.sql
2022-01-15 08:11:05.681850 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2022-01-15 08:11:05.685854 (MainThread): Parsing macros/etc/get_custom_alias.sql
2022-01-15 08:11:05.687220 (MainThread): Parsing macros/etc/query.sql
2022-01-15 08:11:05.688110 (MainThread): Parsing macros/etc/is_incremental.sql
2022-01-15 08:11:05.689497 (MainThread): Parsing macros/etc/datetime.sql
2022-01-15 08:11:05.697279 (MainThread): Parsing macros/etc/where_subquery.sql
2022-01-15 08:11:05.698946 (MainThread): Parsing macros/etc/get_custom_schema.sql
2022-01-15 08:11:05.701573 (MainThread): Parsing macros/etc/get_custom_database.sql
2022-01-15 08:11:05.703375 (MainThread): Parsing macros/adapters/common.sql
2022-01-15 08:11:05.755749 (MainThread): Parsing macros/schema_tests/relationships.sql
2022-01-15 08:11:05.757311 (MainThread): Parsing macros/schema_tests/not_null.sql
2022-01-15 08:11:05.758407 (MainThread): Parsing macros/schema_tests/unique.sql
2022-01-15 08:11:05.759638 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2022-01-15 08:11:05.761654 (MainThread): Parsing macros/cross_db_utils/except.sql
2022-01-15 08:11:05.762644 (MainThread): Parsing macros/cross_db_utils/replace.sql
2022-01-15 08:11:05.763897 (MainThread): Parsing macros/cross_db_utils/concat.sql
2022-01-15 08:11:05.764833 (MainThread): Parsing macros/cross_db_utils/datatypes.sql
2022-01-15 08:11:05.770540 (MainThread): Parsing macros/cross_db_utils/_is_relation.sql
2022-01-15 08:11:05.771601 (MainThread): Parsing macros/cross_db_utils/length.sql
2022-01-15 08:11:05.772930 (MainThread): Parsing macros/cross_db_utils/dateadd.sql
2022-01-15 08:11:05.775719 (MainThread): Parsing macros/cross_db_utils/intersect.sql
2022-01-15 08:11:05.776696 (MainThread): Parsing macros/cross_db_utils/right.sql
2022-01-15 08:11:05.778831 (MainThread): Parsing macros/cross_db_utils/datediff.sql
2022-01-15 08:11:05.788523 (MainThread): Parsing macros/cross_db_utils/safe_cast.sql
2022-01-15 08:11:05.790340 (MainThread): Parsing macros/cross_db_utils/hash.sql
2022-01-15 08:11:05.791649 (MainThread): Parsing macros/cross_db_utils/cast_bool_to_text.sql
2022-01-15 08:11:05.792979 (MainThread): Parsing macros/cross_db_utils/identifier.sql
2022-01-15 08:11:05.794507 (MainThread): Parsing macros/cross_db_utils/position.sql
2022-01-15 08:11:05.795945 (MainThread): Parsing macros/cross_db_utils/literal.sql
2022-01-15 08:11:05.796841 (MainThread): Parsing macros/cross_db_utils/current_timestamp.sql
2022-01-15 08:11:05.800320 (MainThread): Parsing macros/cross_db_utils/width_bucket.sql
2022-01-15 08:11:05.805691 (MainThread): Parsing macros/cross_db_utils/last_day.sql
2022-01-15 08:11:05.809004 (MainThread): Parsing macros/cross_db_utils/split_part.sql
2022-01-15 08:11:05.810695 (MainThread): Parsing macros/cross_db_utils/date_trunc.sql
2022-01-15 08:11:05.812182 (MainThread): Parsing macros/cross_db_utils/_is_ephemeral.sql
2022-01-15 08:11:05.813910 (MainThread): Parsing macros/materializations/insert_by_period_materialization.sql
2022-01-15 08:11:05.837403 (MainThread): Parsing macros/web/get_url_host.sql
2022-01-15 08:11:05.839191 (MainThread): Parsing macros/web/get_url_path.sql
2022-01-15 08:11:05.841558 (MainThread): Parsing macros/web/get_url_parameter.sql
2022-01-15 08:11:05.843312 (MainThread): Parsing macros/jinja_helpers/pretty_log_format.sql
2022-01-15 08:11:05.844346 (MainThread): Parsing macros/jinja_helpers/pretty_time.sql
2022-01-15 08:11:05.845466 (MainThread): Parsing macros/jinja_helpers/log_info.sql
2022-01-15 08:11:05.846500 (MainThread): Parsing macros/jinja_helpers/slugify.sql
2022-01-15 08:11:05.847593 (MainThread): Parsing macros/schema_tests/fewer_rows_than.sql
2022-01-15 08:11:05.849302 (MainThread): Parsing macros/schema_tests/equal_rowcount.sql
2022-01-15 08:11:05.851116 (MainThread): Parsing macros/schema_tests/relationships_where.sql
2022-01-15 08:11:05.853233 (MainThread): Parsing macros/schema_tests/recency.sql
2022-01-15 08:11:05.854828 (MainThread): Parsing macros/schema_tests/not_constant.sql
2022-01-15 08:11:05.855962 (MainThread): Parsing macros/schema_tests/accepted_range.sql
2022-01-15 08:11:05.858418 (MainThread): Parsing macros/schema_tests/not_accepted_values.sql
2022-01-15 08:11:05.860369 (MainThread): Parsing macros/schema_tests/test_unique_where.sql
2022-01-15 08:11:05.861686 (MainThread): Parsing macros/schema_tests/at_least_one.sql
2022-01-15 08:11:05.862899 (MainThread): Parsing macros/schema_tests/unique_combination_of_columns.sql
2022-01-15 08:11:05.865481 (MainThread): Parsing macros/schema_tests/cardinality_equality.sql
2022-01-15 08:11:05.867602 (MainThread): Parsing macros/schema_tests/expression_is_true.sql
2022-01-15 08:11:05.869287 (MainThread): Parsing macros/schema_tests/sequential_values.sql
2022-01-15 08:11:05.872283 (MainThread): Parsing macros/schema_tests/test_not_null_where.sql
2022-01-15 08:11:05.873663 (MainThread): Parsing macros/schema_tests/equality.sql
2022-01-15 08:11:05.876954 (MainThread): Parsing macros/schema_tests/mutually_exclusive_ranges.sql
2022-01-15 08:11:05.886241 (MainThread): Parsing macros/sql/date_spine.sql
2022-01-15 08:11:05.890608 (MainThread): Parsing macros/sql/nullcheck_table.sql
2022-01-15 08:11:05.892102 (MainThread): Parsing macros/sql/get_relations_by_pattern.sql
2022-01-15 08:11:05.895288 (MainThread): Parsing macros/sql/generate_series.sql
2022-01-15 08:11:05.925973 (MainThread): Parsing macros/sql/get_relations_by_prefix.sql
2022-01-15 08:11:05.930397 (MainThread): Parsing macros/sql/get_tables_by_prefix_sql.sql
2022-01-15 08:11:05.932520 (MainThread): Parsing macros/sql/star.sql
2022-01-15 08:11:05.936802 (MainThread): Parsing macros/sql/unpivot.sql
2022-01-15 08:11:05.946968 (MainThread): Parsing macros/sql/union.sql
2022-01-15 08:11:05.956867 (MainThread): Parsing macros/sql/groupby.sql
2022-01-15 08:11:05.958388 (MainThread): Parsing macros/sql/surrogate_key.sql
2022-01-15 08:11:05.962231 (MainThread): Parsing macros/sql/safe_add.sql
2022-01-15 08:11:05.964176 (MainThread): Parsing macros/sql/nullcheck.sql
2022-01-15 08:11:05.966033 (MainThread): Parsing macros/sql/get_tables_by_pattern_sql.sql
2022-01-15 08:11:05.973148 (MainThread): Parsing macros/sql/get_column_values.sql
2022-01-15 08:11:05.978478 (MainThread): Parsing macros/sql/pivot.sql
2022-01-15 08:11:05.982762 (MainThread): Parsing macros/sql/get_query_results_as_dict.sql
2022-01-15 08:11:05.985122 (MainThread): Parsing macros/sql/haversine_distance.sql
2022-01-15 08:11:06.286626 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-15 08:11:06.297919 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-15 08:11:06.301477 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.film_test".
2022-01-15 08:11:06.304335 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-15 08:11:06.312212 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-15 08:11:06.314940 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-15 08:11:06.348433 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:11:06.350283 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:11:06.352261 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:11:06.353905 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:11:06.356456 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:11:06.358100 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:11:06.369835 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:11:06.383718 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:11:06.385608 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:11:06.407888 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5b1a70bc-b364-45a0-9099-a1f458ea57e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ffa30d0>]}
2022-01-15 08:11:06.415525 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-01-15 08:11:06.415995 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5b1a70bc-b364-45a0-9099-a1f458ea57e8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ffa3160>]}
2022-01-15 08:11:06.416237 (MainThread): Found 6 models, 9 tests, 0 snapshots, 0 analyses, 347 macros, 0 operations, 0 seed files, 12 sources, 0 exposures
2022-01-15 08:11:06.417507 (MainThread): 
2022-01-15 08:11:06.417918 (MainThread): Acquiring new postgres connection "master".
2022-01-15 08:11:06.418844 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_dwh".
2022-01-15 08:11:06.427289 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-15 08:11:06.427446 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: BEGIN
2022-01-15 08:11:06.427579 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2022-01-15 08:11:06.839555 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.41 seconds
2022-01-15 08:11:06.839984 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-15 08:11:06.840269 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_dwh"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dwh'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dwh'
  
2022-01-15 08:11:06.907619 (ThreadPoolExecutor-1_0): SQL status: SELECT 6 in 0.07 seconds
2022-01-15 08:11:06.910439 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: ROLLBACK
2022-01-15 08:11:06.970803 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: Close
2022-01-15 08:11:06.976797 (MainThread): Using postgres connection "master".
2022-01-15 08:11:06.977024 (MainThread): On master: BEGIN
2022-01-15 08:11:06.977201 (MainThread): Opening a new connection, currently in state init
2022-01-15 08:11:07.352380 (MainThread): SQL status: BEGIN in 0.38 seconds
2022-01-15 08:11:07.352710 (MainThread): Using postgres connection "master".
2022-01-15 08:11:07.352918 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-15 08:11:07.431857 (MainThread): SQL status: SELECT 47 in 0.08 seconds
2022-01-15 08:11:07.435490 (MainThread): On master: ROLLBACK
2022-01-15 08:11:07.501210 (MainThread): On master: Close
2022-01-15 08:11:07.501959 (MainThread): 13:41:07 | Concurrency: 1 threads (target='dev')
2022-01-15 08:11:07.502254 (MainThread): 13:41:07 | 
2022-01-15 08:11:07.504150 (Thread-1): Began running node test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__R__PG.9c49f99719
2022-01-15 08:11:07.504412 (Thread-1): 13:41:07 | 1 of 1 START test accepted_values_film_test_rating__NC_17__PG_13__R__PG [RUN]
2022-01-15 08:11:07.504983 (Thread-1): Acquiring new postgres connection "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__R__PG.9c49f99719".
2022-01-15 08:11:07.505207 (Thread-1): Compiling test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__R__PG.9c49f99719
2022-01-15 08:11:07.510865 (Thread-1): Writing injected SQL for node "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__R__PG.9c49f99719"
2022-01-15 08:11:07.511498 (Thread-1): finished collecting timing info
2022-01-15 08:11:07.530051 (Thread-1): Writing runtime SQL for node "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__R__PG.9c49f99719"
2022-01-15 08:11:07.530776 (Thread-1): Using postgres connection "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__R__PG.9c49f99719".
2022-01-15 08:11:07.530951 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__R__PG.9c49f99719: BEGIN
2022-01-15 08:11:07.531115 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 08:11:07.906798 (Thread-1): SQL status: BEGIN in 0.38 seconds
2022-01-15 08:11:07.907144 (Thread-1): Using postgres connection "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__R__PG.9c49f99719".
2022-01-15 08:11:07.907354 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__R__PG.9c49f99719: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__R__PG.9c49f99719"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        rating as value_field,
        count(*) as n_records

    from "sakila_wh"."dwh"."film_test"
    group by rating

)

select *
from all_values
where value_field not in (
    'NC-17','PG-13','R','PG'
)



      
    ) dbt_internal_test
2022-01-15 08:11:07.972873 (Thread-1): SQL status: SELECT 1 in 0.07 seconds
2022-01-15 08:11:07.975877 (Thread-1): finished collecting timing info
2022-01-15 08:11:07.976172 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__R__PG.9c49f99719: ROLLBACK
2022-01-15 08:11:08.041246 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__R__PG.9c49f99719: Close
2022-01-15 08:11:08.042103 (Thread-1): 13:41:08 | 1 of 1 FAIL 1 accepted_values_film_test_rating__NC_17__PG_13__R__PG.. [FAIL 1 in 0.54s]
2022-01-15 08:11:08.042466 (Thread-1): Finished running node test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__R__PG.9c49f99719
2022-01-15 08:11:08.044018 (MainThread): Acquiring new postgres connection "master".
2022-01-15 08:11:08.044458 (MainThread): 13:41:08 | 
2022-01-15 08:11:08.044718 (MainThread): 13:41:08 | Finished running 1 test in 1.63s.
2022-01-15 08:11:08.044949 (MainThread): Connection 'master' was properly closed.
2022-01-15 08:11:08.045150 (MainThread): Connection 'test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__R__PG.9c49f99719' was properly closed.
2022-01-15 08:11:08.054512 (MainThread): 
2022-01-15 08:11:08.054776 (MainThread): Completed with 1 error and 0 warnings:
2022-01-15 08:11:08.054985 (MainThread): 
2022-01-15 08:11:08.055195 (MainThread): Failure in test accepted_values_film_test_rating__NC_17__PG_13__R__PG (models/example/schema.yml)
2022-01-15 08:11:08.055387 (MainThread):   Got 1 result, configured to fail if != 0
2022-01-15 08:11:08.055579 (MainThread): 
2022-01-15 08:11:08.055768 (MainThread):   compiled SQL at target/compiled/sakila_dbt_project/models/example/schema.yml/schema_test/accepted_values_film_test_rating__NC_17__PG_13__R__PG.sql
2022-01-15 08:11:08.055962 (MainThread): 
Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
2022-01-15 08:11:08.056218 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ffbf1f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110069fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ff73700>]}
2022-01-15 08:11:08.056487 (MainThread): Flushing usage events
2022-01-15 08:11:31.014384 (MainThread): Running with dbt=0.21.1
2022-01-15 08:11:31.105495 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, data=False, schema=False, fail_fast=False, store_failures=False, greedy=False, threads=None, version_check=True, select=['example.film_test'], exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.test.TestTask'>, which='test', rpc_method='test')
2022-01-15 08:11:31.107164 (MainThread): Tracking: tracking
2022-01-15 08:11:31.125876 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e6c28e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e0ce190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e6acdc0>]}
2022-01-15 08:11:31.148551 (MainThread): Partial parsing not enabled
2022-01-15 08:11:31.191716 (MainThread): Parsing macros/catalog.sql
2022-01-15 08:11:31.195448 (MainThread): Parsing macros/relations.sql
2022-01-15 08:11:31.196987 (MainThread): Parsing macros/adapters.sql
2022-01-15 08:11:31.222095 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2022-01-15 08:11:31.224257 (MainThread): Parsing macros/core.sql
2022-01-15 08:11:31.229052 (MainThread): Parsing macros/materializations/test.sql
2022-01-15 08:11:31.237085 (MainThread): Parsing macros/materializations/helpers.sql
2022-01-15 08:11:31.248335 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2022-01-15 08:11:31.250299 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2022-01-15 08:11:31.269853 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2022-01-15 08:11:31.304185 (MainThread): Parsing macros/materializations/seed/seed.sql
2022-01-15 08:11:31.326545 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2022-01-15 08:11:31.328247 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2022-01-15 08:11:31.337825 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2022-01-15 08:11:31.356700 (MainThread): Parsing macros/materializations/common/merge.sql
2022-01-15 08:11:31.370010 (MainThread): Parsing macros/materializations/table/table.sql
2022-01-15 08:11:31.377557 (MainThread): Parsing macros/materializations/view/view.sql
2022-01-15 08:11:31.384870 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2022-01-15 08:11:31.388933 (MainThread): Parsing macros/etc/get_custom_alias.sql
2022-01-15 08:11:31.390405 (MainThread): Parsing macros/etc/query.sql
2022-01-15 08:11:31.391330 (MainThread): Parsing macros/etc/is_incremental.sql
2022-01-15 08:11:31.392730 (MainThread): Parsing macros/etc/datetime.sql
2022-01-15 08:11:31.400757 (MainThread): Parsing macros/etc/where_subquery.sql
2022-01-15 08:11:31.402612 (MainThread): Parsing macros/etc/get_custom_schema.sql
2022-01-15 08:11:31.405096 (MainThread): Parsing macros/etc/get_custom_database.sql
2022-01-15 08:11:31.406621 (MainThread): Parsing macros/adapters/common.sql
2022-01-15 08:11:31.460188 (MainThread): Parsing macros/schema_tests/relationships.sql
2022-01-15 08:11:31.461820 (MainThread): Parsing macros/schema_tests/not_null.sql
2022-01-15 08:11:31.463266 (MainThread): Parsing macros/schema_tests/unique.sql
2022-01-15 08:11:31.464777 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2022-01-15 08:11:31.466882 (MainThread): Parsing macros/cross_db_utils/except.sql
2022-01-15 08:11:31.467925 (MainThread): Parsing macros/cross_db_utils/replace.sql
2022-01-15 08:11:31.469187 (MainThread): Parsing macros/cross_db_utils/concat.sql
2022-01-15 08:11:31.470271 (MainThread): Parsing macros/cross_db_utils/datatypes.sql
2022-01-15 08:11:31.475950 (MainThread): Parsing macros/cross_db_utils/_is_relation.sql
2022-01-15 08:11:31.477069 (MainThread): Parsing macros/cross_db_utils/length.sql
2022-01-15 08:11:31.478319 (MainThread): Parsing macros/cross_db_utils/dateadd.sql
2022-01-15 08:11:31.481144 (MainThread): Parsing macros/cross_db_utils/intersect.sql
2022-01-15 08:11:31.482169 (MainThread): Parsing macros/cross_db_utils/right.sql
2022-01-15 08:11:31.484446 (MainThread): Parsing macros/cross_db_utils/datediff.sql
2022-01-15 08:11:31.494732 (MainThread): Parsing macros/cross_db_utils/safe_cast.sql
2022-01-15 08:11:31.496590 (MainThread): Parsing macros/cross_db_utils/hash.sql
2022-01-15 08:11:31.497975 (MainThread): Parsing macros/cross_db_utils/cast_bool_to_text.sql
2022-01-15 08:11:31.499363 (MainThread): Parsing macros/cross_db_utils/identifier.sql
2022-01-15 08:11:31.500988 (MainThread): Parsing macros/cross_db_utils/position.sql
2022-01-15 08:11:31.502658 (MainThread): Parsing macros/cross_db_utils/literal.sql
2022-01-15 08:11:31.503985 (MainThread): Parsing macros/cross_db_utils/current_timestamp.sql
2022-01-15 08:11:31.508069 (MainThread): Parsing macros/cross_db_utils/width_bucket.sql
2022-01-15 08:11:31.513963 (MainThread): Parsing macros/cross_db_utils/last_day.sql
2022-01-15 08:11:31.517869 (MainThread): Parsing macros/cross_db_utils/split_part.sql
2022-01-15 08:11:31.520021 (MainThread): Parsing macros/cross_db_utils/date_trunc.sql
2022-01-15 08:11:31.521887 (MainThread): Parsing macros/cross_db_utils/_is_ephemeral.sql
2022-01-15 08:11:31.524095 (MainThread): Parsing macros/materializations/insert_by_period_materialization.sql
2022-01-15 08:11:31.551082 (MainThread): Parsing macros/web/get_url_host.sql
2022-01-15 08:11:31.553314 (MainThread): Parsing macros/web/get_url_path.sql
2022-01-15 08:11:31.556131 (MainThread): Parsing macros/web/get_url_parameter.sql
2022-01-15 08:11:31.557859 (MainThread): Parsing macros/jinja_helpers/pretty_log_format.sql
2022-01-15 08:11:31.559086 (MainThread): Parsing macros/jinja_helpers/pretty_time.sql
2022-01-15 08:11:31.560399 (MainThread): Parsing macros/jinja_helpers/log_info.sql
2022-01-15 08:11:31.561608 (MainThread): Parsing macros/jinja_helpers/slugify.sql
2022-01-15 08:11:31.562882 (MainThread): Parsing macros/schema_tests/fewer_rows_than.sql
2022-01-15 08:11:31.564868 (MainThread): Parsing macros/schema_tests/equal_rowcount.sql
2022-01-15 08:11:31.566671 (MainThread): Parsing macros/schema_tests/relationships_where.sql
2022-01-15 08:11:31.569206 (MainThread): Parsing macros/schema_tests/recency.sql
2022-01-15 08:11:31.571255 (MainThread): Parsing macros/schema_tests/not_constant.sql
2022-01-15 08:11:31.572694 (MainThread): Parsing macros/schema_tests/accepted_range.sql
2022-01-15 08:11:31.575417 (MainThread): Parsing macros/schema_tests/not_accepted_values.sql
2022-01-15 08:11:31.577699 (MainThread): Parsing macros/schema_tests/test_unique_where.sql
2022-01-15 08:11:31.579254 (MainThread): Parsing macros/schema_tests/at_least_one.sql
2022-01-15 08:11:31.580623 (MainThread): Parsing macros/schema_tests/unique_combination_of_columns.sql
2022-01-15 08:11:31.583650 (MainThread): Parsing macros/schema_tests/cardinality_equality.sql
2022-01-15 08:11:31.585892 (MainThread): Parsing macros/schema_tests/expression_is_true.sql
2022-01-15 08:11:31.587929 (MainThread): Parsing macros/schema_tests/sequential_values.sql
2022-01-15 08:11:31.591218 (MainThread): Parsing macros/schema_tests/test_not_null_where.sql
2022-01-15 08:11:31.592800 (MainThread): Parsing macros/schema_tests/equality.sql
2022-01-15 08:11:31.596552 (MainThread): Parsing macros/schema_tests/mutually_exclusive_ranges.sql
2022-01-15 08:11:31.606380 (MainThread): Parsing macros/sql/date_spine.sql
2022-01-15 08:11:31.611450 (MainThread): Parsing macros/sql/nullcheck_table.sql
2022-01-15 08:11:31.613241 (MainThread): Parsing macros/sql/get_relations_by_pattern.sql
2022-01-15 08:11:31.616906 (MainThread): Parsing macros/sql/generate_series.sql
2022-01-15 08:11:31.650524 (MainThread): Parsing macros/sql/get_relations_by_prefix.sql
2022-01-15 08:11:31.654947 (MainThread): Parsing macros/sql/get_tables_by_prefix_sql.sql
2022-01-15 08:11:31.657109 (MainThread): Parsing macros/sql/star.sql
2022-01-15 08:11:31.661259 (MainThread): Parsing macros/sql/unpivot.sql
2022-01-15 08:11:31.671032 (MainThread): Parsing macros/sql/union.sql
2022-01-15 08:11:31.680415 (MainThread): Parsing macros/sql/groupby.sql
2022-01-15 08:11:31.681965 (MainThread): Parsing macros/sql/surrogate_key.sql
2022-01-15 08:11:31.685833 (MainThread): Parsing macros/sql/safe_add.sql
2022-01-15 08:11:31.687786 (MainThread): Parsing macros/sql/nullcheck.sql
2022-01-15 08:11:31.689655 (MainThread): Parsing macros/sql/get_tables_by_pattern_sql.sql
2022-01-15 08:11:31.696732 (MainThread): Parsing macros/sql/get_column_values.sql
2022-01-15 08:11:31.702229 (MainThread): Parsing macros/sql/pivot.sql
2022-01-15 08:11:31.706932 (MainThread): Parsing macros/sql/get_query_results_as_dict.sql
2022-01-15 08:11:31.709554 (MainThread): Parsing macros/sql/haversine_distance.sql
2022-01-15 08:11:32.030035 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-15 08:11:32.044311 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-15 08:11:32.048649 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.film_test".
2022-01-15 08:11:32.052202 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-15 08:11:32.062060 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-15 08:11:32.065715 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-15 08:11:32.106607 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:11:32.108752 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:11:32.110663 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:11:32.112658 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:11:32.115693 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:11:32.117615 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:11:32.131753 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:11:32.148212 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:11:32.150301 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:11:32.177707 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '408d8cb5-8a62-402f-92f4-c72ca0682df9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e87e0d0>]}
2022-01-15 08:11:32.187388 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-01-15 08:11:32.187992 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '408d8cb5-8a62-402f-92f4-c72ca0682df9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e87e160>]}
2022-01-15 08:11:32.188286 (MainThread): Found 6 models, 9 tests, 0 snapshots, 0 analyses, 347 macros, 0 operations, 0 seed files, 12 sources, 0 exposures
2022-01-15 08:11:32.189785 (MainThread): 
2022-01-15 08:11:32.190176 (MainThread): Acquiring new postgres connection "master".
2022-01-15 08:11:32.191286 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_dwh".
2022-01-15 08:11:32.201169 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-15 08:11:32.201412 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: BEGIN
2022-01-15 08:11:32.201662 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2022-01-15 08:11:32.599908 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.40 seconds
2022-01-15 08:11:32.600161 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-15 08:11:32.600312 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_dwh"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dwh'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dwh'
  
2022-01-15 08:11:32.669900 (ThreadPoolExecutor-1_0): SQL status: SELECT 6 in 0.07 seconds
2022-01-15 08:11:32.671420 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: ROLLBACK
2022-01-15 08:11:32.731562 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: Close
2022-01-15 08:11:32.736786 (MainThread): Using postgres connection "master".
2022-01-15 08:11:32.737035 (MainThread): On master: BEGIN
2022-01-15 08:11:32.737210 (MainThread): Opening a new connection, currently in state init
2022-01-15 08:11:33.106646 (MainThread): SQL status: BEGIN in 0.37 seconds
2022-01-15 08:11:33.106905 (MainThread): Using postgres connection "master".
2022-01-15 08:11:33.107059 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-15 08:11:33.187409 (MainThread): SQL status: SELECT 47 in 0.08 seconds
2022-01-15 08:11:33.189503 (MainThread): On master: ROLLBACK
2022-01-15 08:11:33.249492 (MainThread): On master: Close
2022-01-15 08:11:33.250111 (MainThread): 13:41:33 | Concurrency: 1 threads (target='dev')
2022-01-15 08:11:33.250337 (MainThread): 13:41:33 | 
2022-01-15 08:11:33.252003 (Thread-1): Began running node test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8
2022-01-15 08:11:33.252245 (Thread-1): 13:41:33 | 1 of 1 START test accepted_values_film_test_rating__NC_17__PG_13__G__R__PG [RUN]
2022-01-15 08:11:33.252608 (Thread-1): Acquiring new postgres connection "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8".
2022-01-15 08:11:33.252800 (Thread-1): Compiling test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8
2022-01-15 08:11:33.258391 (Thread-1): Writing injected SQL for node "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8"
2022-01-15 08:11:33.258912 (Thread-1): finished collecting timing info
2022-01-15 08:11:33.274345 (Thread-1): Writing runtime SQL for node "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8"
2022-01-15 08:11:33.275078 (Thread-1): Using postgres connection "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8".
2022-01-15 08:11:33.275266 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8: BEGIN
2022-01-15 08:11:33.275414 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 08:11:33.648879 (Thread-1): SQL status: BEGIN in 0.37 seconds
2022-01-15 08:11:33.649168 (Thread-1): Using postgres connection "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8".
2022-01-15 08:11:33.649338 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        rating as value_field,
        count(*) as n_records

    from "sakila_wh"."dwh"."film_test"
    group by rating

)

select *
from all_values
where value_field not in (
    'NC-17','PG-13','G','R','PG'
)



      
    ) dbt_internal_test
2022-01-15 08:11:33.716499 (Thread-1): SQL status: SELECT 1 in 0.07 seconds
2022-01-15 08:11:33.718733 (Thread-1): finished collecting timing info
2022-01-15 08:11:33.719003 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8: ROLLBACK
2022-01-15 08:11:33.779506 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8: Close
2022-01-15 08:11:33.780200 (Thread-1): 13:41:33 | 1 of 1 PASS accepted_values_film_test_rating__NC_17__PG_13__G__R__PG. [PASS in 0.53s]
2022-01-15 08:11:33.780468 (Thread-1): Finished running node test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8
2022-01-15 08:11:33.781652 (MainThread): Acquiring new postgres connection "master".
2022-01-15 08:11:33.782026 (MainThread): 13:41:33 | 
2022-01-15 08:11:33.782245 (MainThread): 13:41:33 | Finished running 1 test in 1.59s.
2022-01-15 08:11:33.782443 (MainThread): Connection 'master' was properly closed.
2022-01-15 08:11:33.782599 (MainThread): Connection 'test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8' was properly closed.
2022-01-15 08:11:33.792167 (MainThread): 
2022-01-15 08:11:33.792438 (MainThread): Completed successfully
2022-01-15 08:11:33.792653 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2022-01-15 08:11:33.792924 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e836550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e8c6760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e8c66a0>]}
2022-01-15 08:11:33.793205 (MainThread): Flushing usage events
2022-01-15 08:14:33.774689 (MainThread): Running with dbt=0.21.1
2022-01-15 08:14:33.857912 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, data=False, schema=False, fail_fast=False, store_failures=False, greedy=False, threads=None, version_check=True, select=['example.film_test'], exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.test.TestTask'>, which='test', rpc_method='test')
2022-01-15 08:14:33.859610 (MainThread): Tracking: tracking
2022-01-15 08:14:33.879052 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e1208e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10db2c250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e100dc0>]}
2022-01-15 08:14:33.901299 (MainThread): Partial parsing not enabled
2022-01-15 08:14:33.940999 (MainThread): Parsing macros/catalog.sql
2022-01-15 08:14:33.944403 (MainThread): Parsing macros/relations.sql
2022-01-15 08:14:33.945877 (MainThread): Parsing macros/adapters.sql
2022-01-15 08:14:33.968395 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2022-01-15 08:14:33.970009 (MainThread): Parsing macros/core.sql
2022-01-15 08:14:33.973457 (MainThread): Parsing macros/materializations/test.sql
2022-01-15 08:14:33.979814 (MainThread): Parsing macros/materializations/helpers.sql
2022-01-15 08:14:33.989914 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2022-01-15 08:14:33.991771 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2022-01-15 08:14:34.008688 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2022-01-15 08:14:34.038870 (MainThread): Parsing macros/materializations/seed/seed.sql
2022-01-15 08:14:34.060063 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2022-01-15 08:14:34.061699 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2022-01-15 08:14:34.070995 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2022-01-15 08:14:34.089501 (MainThread): Parsing macros/materializations/common/merge.sql
2022-01-15 08:14:34.102298 (MainThread): Parsing macros/materializations/table/table.sql
2022-01-15 08:14:34.110097 (MainThread): Parsing macros/materializations/view/view.sql
2022-01-15 08:14:34.116587 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2022-01-15 08:14:34.120009 (MainThread): Parsing macros/etc/get_custom_alias.sql
2022-01-15 08:14:34.121591 (MainThread): Parsing macros/etc/query.sql
2022-01-15 08:14:34.122468 (MainThread): Parsing macros/etc/is_incremental.sql
2022-01-15 08:14:34.123809 (MainThread): Parsing macros/etc/datetime.sql
2022-01-15 08:14:34.131564 (MainThread): Parsing macros/etc/where_subquery.sql
2022-01-15 08:14:34.133197 (MainThread): Parsing macros/etc/get_custom_schema.sql
2022-01-15 08:14:34.135409 (MainThread): Parsing macros/etc/get_custom_database.sql
2022-01-15 08:14:34.136889 (MainThread): Parsing macros/adapters/common.sql
2022-01-15 08:14:34.189497 (MainThread): Parsing macros/schema_tests/relationships.sql
2022-01-15 08:14:34.191068 (MainThread): Parsing macros/schema_tests/not_null.sql
2022-01-15 08:14:34.192165 (MainThread): Parsing macros/schema_tests/unique.sql
2022-01-15 08:14:34.193378 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2022-01-15 08:14:34.195461 (MainThread): Parsing macros/cross_db_utils/except.sql
2022-01-15 08:14:34.196449 (MainThread): Parsing macros/cross_db_utils/replace.sql
2022-01-15 08:14:34.197610 (MainThread): Parsing macros/cross_db_utils/concat.sql
2022-01-15 08:14:34.198538 (MainThread): Parsing macros/cross_db_utils/datatypes.sql
2022-01-15 08:14:34.204215 (MainThread): Parsing macros/cross_db_utils/_is_relation.sql
2022-01-15 08:14:34.205303 (MainThread): Parsing macros/cross_db_utils/length.sql
2022-01-15 08:14:34.206603 (MainThread): Parsing macros/cross_db_utils/dateadd.sql
2022-01-15 08:14:34.209285 (MainThread): Parsing macros/cross_db_utils/intersect.sql
2022-01-15 08:14:34.210239 (MainThread): Parsing macros/cross_db_utils/right.sql
2022-01-15 08:14:34.212280 (MainThread): Parsing macros/cross_db_utils/datediff.sql
2022-01-15 08:14:34.221521 (MainThread): Parsing macros/cross_db_utils/safe_cast.sql
2022-01-15 08:14:34.223243 (MainThread): Parsing macros/cross_db_utils/hash.sql
2022-01-15 08:14:34.224521 (MainThread): Parsing macros/cross_db_utils/cast_bool_to_text.sql
2022-01-15 08:14:34.225956 (MainThread): Parsing macros/cross_db_utils/identifier.sql
2022-01-15 08:14:34.227455 (MainThread): Parsing macros/cross_db_utils/position.sql
2022-01-15 08:14:34.228868 (MainThread): Parsing macros/cross_db_utils/literal.sql
2022-01-15 08:14:34.229745 (MainThread): Parsing macros/cross_db_utils/current_timestamp.sql
2022-01-15 08:14:34.232950 (MainThread): Parsing macros/cross_db_utils/width_bucket.sql
2022-01-15 08:14:34.237744 (MainThread): Parsing macros/cross_db_utils/last_day.sql
2022-01-15 08:14:34.241028 (MainThread): Parsing macros/cross_db_utils/split_part.sql
2022-01-15 08:14:34.242704 (MainThread): Parsing macros/cross_db_utils/date_trunc.sql
2022-01-15 08:14:34.244257 (MainThread): Parsing macros/cross_db_utils/_is_ephemeral.sql
2022-01-15 08:14:34.246082 (MainThread): Parsing macros/materializations/insert_by_period_materialization.sql
2022-01-15 08:14:34.269278 (MainThread): Parsing macros/web/get_url_host.sql
2022-01-15 08:14:34.271026 (MainThread): Parsing macros/web/get_url_path.sql
2022-01-15 08:14:34.273531 (MainThread): Parsing macros/web/get_url_parameter.sql
2022-01-15 08:14:34.274951 (MainThread): Parsing macros/jinja_helpers/pretty_log_format.sql
2022-01-15 08:14:34.275962 (MainThread): Parsing macros/jinja_helpers/pretty_time.sql
2022-01-15 08:14:34.277058 (MainThread): Parsing macros/jinja_helpers/log_info.sql
2022-01-15 08:14:34.278068 (MainThread): Parsing macros/jinja_helpers/slugify.sql
2022-01-15 08:14:34.279133 (MainThread): Parsing macros/schema_tests/fewer_rows_than.sql
2022-01-15 08:14:34.280675 (MainThread): Parsing macros/schema_tests/equal_rowcount.sql
2022-01-15 08:14:34.282183 (MainThread): Parsing macros/schema_tests/relationships_where.sql
2022-01-15 08:14:34.284248 (MainThread): Parsing macros/schema_tests/recency.sql
2022-01-15 08:14:34.286124 (MainThread): Parsing macros/schema_tests/not_constant.sql
2022-01-15 08:14:34.287333 (MainThread): Parsing macros/schema_tests/accepted_range.sql
2022-01-15 08:14:34.289842 (MainThread): Parsing macros/schema_tests/not_accepted_values.sql
2022-01-15 08:14:34.291770 (MainThread): Parsing macros/schema_tests/test_unique_where.sql
2022-01-15 08:14:34.293086 (MainThread): Parsing macros/schema_tests/at_least_one.sql
2022-01-15 08:14:34.294254 (MainThread): Parsing macros/schema_tests/unique_combination_of_columns.sql
2022-01-15 08:14:34.296823 (MainThread): Parsing macros/schema_tests/cardinality_equality.sql
2022-01-15 08:14:34.298629 (MainThread): Parsing macros/schema_tests/expression_is_true.sql
2022-01-15 08:14:34.300271 (MainThread): Parsing macros/schema_tests/sequential_values.sql
2022-01-15 08:14:34.303019 (MainThread): Parsing macros/schema_tests/test_not_null_where.sql
2022-01-15 08:14:34.304576 (MainThread): Parsing macros/schema_tests/equality.sql
2022-01-15 08:14:34.307754 (MainThread): Parsing macros/schema_tests/mutually_exclusive_ranges.sql
2022-01-15 08:14:34.316024 (MainThread): Parsing macros/sql/date_spine.sql
2022-01-15 08:14:34.320450 (MainThread): Parsing macros/sql/nullcheck_table.sql
2022-01-15 08:14:34.322190 (MainThread): Parsing macros/sql/get_relations_by_pattern.sql
2022-01-15 08:14:34.325386 (MainThread): Parsing macros/sql/generate_series.sql
2022-01-15 08:14:34.354084 (MainThread): Parsing macros/sql/get_relations_by_prefix.sql
2022-01-15 08:14:34.358410 (MainThread): Parsing macros/sql/get_tables_by_prefix_sql.sql
2022-01-15 08:14:34.360473 (MainThread): Parsing macros/sql/star.sql
2022-01-15 08:14:34.364579 (MainThread): Parsing macros/sql/unpivot.sql
2022-01-15 08:14:34.374375 (MainThread): Parsing macros/sql/union.sql
2022-01-15 08:14:34.383860 (MainThread): Parsing macros/sql/groupby.sql
2022-01-15 08:14:34.385373 (MainThread): Parsing macros/sql/surrogate_key.sql
2022-01-15 08:14:34.389163 (MainThread): Parsing macros/sql/safe_add.sql
2022-01-15 08:14:34.390958 (MainThread): Parsing macros/sql/nullcheck.sql
2022-01-15 08:14:34.392778 (MainThread): Parsing macros/sql/get_tables_by_pattern_sql.sql
2022-01-15 08:14:34.399705 (MainThread): Parsing macros/sql/get_column_values.sql
2022-01-15 08:14:34.404997 (MainThread): Parsing macros/sql/pivot.sql
2022-01-15 08:14:34.409293 (MainThread): Parsing macros/sql/get_query_results_as_dict.sql
2022-01-15 08:14:34.411653 (MainThread): Parsing macros/sql/haversine_distance.sql
2022-01-15 08:14:34.710806 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-15 08:14:34.722478 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-15 08:14:34.726014 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.film_test".
2022-01-15 08:14:34.728825 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-15 08:14:34.736543 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-15 08:14:34.739482 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-15 08:14:34.774163 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:14:34.775892 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:14:34.777554 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:14:34.779172 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:14:34.781813 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:14:34.783394 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:14:34.795563 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:14:34.799110 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:14:34.812901 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:14:34.814534 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:14:34.837432 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a9020971-b962-4eb2-8933-57c03d44ebf2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e2770d0>]}
2022-01-15 08:14:34.845410 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-01-15 08:14:34.845942 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a9020971-b962-4eb2-8933-57c03d44ebf2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e277160>]}
2022-01-15 08:14:34.846285 (MainThread): Found 6 models, 10 tests, 0 snapshots, 0 analyses, 347 macros, 0 operations, 0 seed files, 12 sources, 0 exposures
2022-01-15 08:14:34.847601 (MainThread): 
2022-01-15 08:14:34.847947 (MainThread): Acquiring new postgres connection "master".
2022-01-15 08:14:34.848890 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_dwh".
2022-01-15 08:14:34.857879 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-15 08:14:34.858069 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: BEGIN
2022-01-15 08:14:34.858206 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2022-01-15 08:14:35.265002 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.41 seconds
2022-01-15 08:14:35.265578 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-15 08:14:35.265839 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_dwh"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dwh'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dwh'
  
2022-01-15 08:14:35.333423 (ThreadPoolExecutor-1_0): SQL status: SELECT 6 in 0.07 seconds
2022-01-15 08:14:35.350055 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: ROLLBACK
2022-01-15 08:14:35.411256 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: Close
2022-01-15 08:14:35.418090 (MainThread): Using postgres connection "master".
2022-01-15 08:14:35.418294 (MainThread): On master: BEGIN
2022-01-15 08:14:35.418465 (MainThread): Opening a new connection, currently in state init
2022-01-15 08:14:35.795293 (MainThread): SQL status: BEGIN in 0.38 seconds
2022-01-15 08:14:35.795694 (MainThread): Using postgres connection "master".
2022-01-15 08:14:35.795949 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-15 08:14:35.878023 (MainThread): SQL status: SELECT 47 in 0.08 seconds
2022-01-15 08:14:35.881095 (MainThread): On master: ROLLBACK
2022-01-15 08:14:35.945783 (MainThread): On master: Close
2022-01-15 08:14:35.946592 (MainThread): 13:44:35 | Concurrency: 1 threads (target='dev')
2022-01-15 08:14:35.946893 (MainThread): 13:44:35 | 
2022-01-15 08:14:35.949005 (Thread-1): Began running node test.sakila_dbt_project.accepted_values_film_test_language_id__False__1__2.3b3d45ead6
2022-01-15 08:14:35.949301 (Thread-1): 13:44:35 | 1 of 2 START test accepted_values_film_test_language_id__False__1__2. [RUN]
2022-01-15 08:14:35.949943 (Thread-1): Acquiring new postgres connection "test.sakila_dbt_project.accepted_values_film_test_language_id__False__1__2.3b3d45ead6".
2022-01-15 08:14:35.950216 (Thread-1): Compiling test.sakila_dbt_project.accepted_values_film_test_language_id__False__1__2.3b3d45ead6
2022-01-15 08:14:35.954320 (Thread-1): Writing injected SQL for node "test.sakila_dbt_project.accepted_values_film_test_language_id__False__1__2.3b3d45ead6"
2022-01-15 08:14:35.955032 (Thread-1): finished collecting timing info
2022-01-15 08:14:35.973711 (Thread-1): Writing runtime SQL for node "test.sakila_dbt_project.accepted_values_film_test_language_id__False__1__2.3b3d45ead6"
2022-01-15 08:14:35.974436 (Thread-1): Using postgres connection "test.sakila_dbt_project.accepted_values_film_test_language_id__False__1__2.3b3d45ead6".
2022-01-15 08:14:35.974618 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_language_id__False__1__2.3b3d45ead6: BEGIN
2022-01-15 08:14:35.974784 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 08:14:36.350828 (Thread-1): SQL status: BEGIN in 0.38 seconds
2022-01-15 08:14:36.351509 (Thread-1): Using postgres connection "test.sakila_dbt_project.accepted_values_film_test_language_id__False__1__2.3b3d45ead6".
2022-01-15 08:14:36.351812 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_language_id__False__1__2.3b3d45ead6: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "test.sakila_dbt_project.accepted_values_film_test_language_id__False__1__2.3b3d45ead6"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        language_id as value_field,
        count(*) as n_records

    from "sakila_wh"."dwh"."film_test"
    group by language_id

)

select *
from all_values
where value_field not in (
    1,2
)



      
    ) dbt_internal_test
2022-01-15 08:14:36.416214 (Thread-1): SQL status: SELECT 1 in 0.06 seconds
2022-01-15 08:14:36.419042 (Thread-1): finished collecting timing info
2022-01-15 08:14:36.419320 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_language_id__False__1__2.3b3d45ead6: ROLLBACK
2022-01-15 08:14:36.479970 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_language_id__False__1__2.3b3d45ead6: Close
2022-01-15 08:14:36.480792 (Thread-1): 13:44:36 | 1 of 2 PASS accepted_values_film_test_language_id__False__1__2....... [PASS in 0.53s]
2022-01-15 08:14:36.481215 (Thread-1): Finished running node test.sakila_dbt_project.accepted_values_film_test_language_id__False__1__2.3b3d45ead6
2022-01-15 08:14:36.481545 (Thread-1): Began running node test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8
2022-01-15 08:14:36.481977 (Thread-1): 13:44:36 | 2 of 2 START test accepted_values_film_test_rating__NC_17__PG_13__G__R__PG [RUN]
2022-01-15 08:14:36.482413 (Thread-1): Acquiring new postgres connection "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8".
2022-01-15 08:14:36.482647 (Thread-1): Compiling test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8
2022-01-15 08:14:36.489540 (Thread-1): Writing injected SQL for node "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8"
2022-01-15 08:14:36.490265 (Thread-1): finished collecting timing info
2022-01-15 08:14:36.492480 (Thread-1): Writing runtime SQL for node "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8"
2022-01-15 08:14:36.493125 (Thread-1): Using postgres connection "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8".
2022-01-15 08:14:36.493315 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8: BEGIN
2022-01-15 08:14:36.493489 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 08:14:36.870350 (Thread-1): SQL status: BEGIN in 0.38 seconds
2022-01-15 08:14:36.870824 (Thread-1): Using postgres connection "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8".
2022-01-15 08:14:36.871079 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        rating as value_field,
        count(*) as n_records

    from "sakila_wh"."dwh"."film_test"
    group by rating

)

select *
from all_values
where value_field not in (
    'NC-17','PG-13','G','R','PG'
)



      
    ) dbt_internal_test
2022-01-15 08:14:36.941631 (Thread-1): SQL status: SELECT 1 in 0.07 seconds
2022-01-15 08:14:36.943825 (Thread-1): finished collecting timing info
2022-01-15 08:14:36.944183 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8: ROLLBACK
2022-01-15 08:14:37.004334 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8: Close
2022-01-15 08:14:37.005156 (Thread-1): 13:44:37 | 2 of 2 PASS accepted_values_film_test_rating__NC_17__PG_13__G__R__PG. [PASS in 0.52s]
2022-01-15 08:14:37.005507 (Thread-1): Finished running node test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8
2022-01-15 08:14:37.007133 (MainThread): Acquiring new postgres connection "master".
2022-01-15 08:14:37.007591 (MainThread): 13:44:37 | 
2022-01-15 08:14:37.007859 (MainThread): 13:44:37 | Finished running 2 tests in 2.16s.
2022-01-15 08:14:37.008091 (MainThread): Connection 'master' was properly closed.
2022-01-15 08:14:37.008285 (MainThread): Connection 'test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8' was properly closed.
2022-01-15 08:14:37.017541 (MainThread): 
2022-01-15 08:14:37.017774 (MainThread): Completed successfully
2022-01-15 08:14:37.017981 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2022-01-15 08:14:37.018239 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e35b1c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e44a4c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e34a520>]}
2022-01-15 08:14:37.018511 (MainThread): Flushing usage events
2022-01-15 08:14:45.371399 (MainThread): Running with dbt=0.21.1
2022-01-15 08:14:45.454502 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, data=False, schema=False, fail_fast=False, store_failures=False, greedy=False, threads=None, version_check=True, select=['example.film_test'], exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.test.TestTask'>, which='test', rpc_method='test')
2022-01-15 08:14:45.456371 (MainThread): Tracking: tracking
2022-01-15 08:14:45.476247 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11308f910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112a9c760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113065cd0>]}
2022-01-15 08:14:45.500081 (MainThread): Partial parsing not enabled
2022-01-15 08:14:45.544383 (MainThread): Parsing macros/catalog.sql
2022-01-15 08:14:45.547921 (MainThread): Parsing macros/relations.sql
2022-01-15 08:14:45.549409 (MainThread): Parsing macros/adapters.sql
2022-01-15 08:14:45.574455 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2022-01-15 08:14:45.576372 (MainThread): Parsing macros/core.sql
2022-01-15 08:14:45.580207 (MainThread): Parsing macros/materializations/test.sql
2022-01-15 08:14:45.587045 (MainThread): Parsing macros/materializations/helpers.sql
2022-01-15 08:14:45.596896 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2022-01-15 08:14:45.598596 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2022-01-15 08:14:45.614768 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2022-01-15 08:14:45.645127 (MainThread): Parsing macros/materializations/seed/seed.sql
2022-01-15 08:14:45.666484 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2022-01-15 08:14:45.668115 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2022-01-15 08:14:45.677805 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2022-01-15 08:14:45.696220 (MainThread): Parsing macros/materializations/common/merge.sql
2022-01-15 08:14:45.709194 (MainThread): Parsing macros/materializations/table/table.sql
2022-01-15 08:14:45.716464 (MainThread): Parsing macros/materializations/view/view.sql
2022-01-15 08:14:45.723167 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2022-01-15 08:14:45.726794 (MainThread): Parsing macros/etc/get_custom_alias.sql
2022-01-15 08:14:45.728171 (MainThread): Parsing macros/etc/query.sql
2022-01-15 08:14:45.729030 (MainThread): Parsing macros/etc/is_incremental.sql
2022-01-15 08:14:45.730548 (MainThread): Parsing macros/etc/datetime.sql
2022-01-15 08:14:45.738691 (MainThread): Parsing macros/etc/where_subquery.sql
2022-01-15 08:14:45.740373 (MainThread): Parsing macros/etc/get_custom_schema.sql
2022-01-15 08:14:45.742581 (MainThread): Parsing macros/etc/get_custom_database.sql
2022-01-15 08:14:45.744014 (MainThread): Parsing macros/adapters/common.sql
2022-01-15 08:14:45.795791 (MainThread): Parsing macros/schema_tests/relationships.sql
2022-01-15 08:14:45.797359 (MainThread): Parsing macros/schema_tests/not_null.sql
2022-01-15 08:14:45.798447 (MainThread): Parsing macros/schema_tests/unique.sql
2022-01-15 08:14:45.799673 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2022-01-15 08:14:45.801672 (MainThread): Parsing macros/cross_db_utils/except.sql
2022-01-15 08:14:45.802646 (MainThread): Parsing macros/cross_db_utils/replace.sql
2022-01-15 08:14:45.803825 (MainThread): Parsing macros/cross_db_utils/concat.sql
2022-01-15 08:14:45.804957 (MainThread): Parsing macros/cross_db_utils/datatypes.sql
2022-01-15 08:14:45.810506 (MainThread): Parsing macros/cross_db_utils/_is_relation.sql
2022-01-15 08:14:45.811599 (MainThread): Parsing macros/cross_db_utils/length.sql
2022-01-15 08:14:45.812789 (MainThread): Parsing macros/cross_db_utils/dateadd.sql
2022-01-15 08:14:45.815523 (MainThread): Parsing macros/cross_db_utils/intersect.sql
2022-01-15 08:14:45.816484 (MainThread): Parsing macros/cross_db_utils/right.sql
2022-01-15 08:14:45.818525 (MainThread): Parsing macros/cross_db_utils/datediff.sql
2022-01-15 08:14:45.828106 (MainThread): Parsing macros/cross_db_utils/safe_cast.sql
2022-01-15 08:14:45.829838 (MainThread): Parsing macros/cross_db_utils/hash.sql
2022-01-15 08:14:45.831119 (MainThread): Parsing macros/cross_db_utils/cast_bool_to_text.sql
2022-01-15 08:14:45.832626 (MainThread): Parsing macros/cross_db_utils/identifier.sql
2022-01-15 08:14:45.834143 (MainThread): Parsing macros/cross_db_utils/position.sql
2022-01-15 08:14:45.835566 (MainThread): Parsing macros/cross_db_utils/literal.sql
2022-01-15 08:14:45.836534 (MainThread): Parsing macros/cross_db_utils/current_timestamp.sql
2022-01-15 08:14:45.840073 (MainThread): Parsing macros/cross_db_utils/width_bucket.sql
2022-01-15 08:14:45.844785 (MainThread): Parsing macros/cross_db_utils/last_day.sql
2022-01-15 08:14:45.848012 (MainThread): Parsing macros/cross_db_utils/split_part.sql
2022-01-15 08:14:45.849670 (MainThread): Parsing macros/cross_db_utils/date_trunc.sql
2022-01-15 08:14:45.851602 (MainThread): Parsing macros/cross_db_utils/_is_ephemeral.sql
2022-01-15 08:14:45.853345 (MainThread): Parsing macros/materializations/insert_by_period_materialization.sql
2022-01-15 08:14:45.876954 (MainThread): Parsing macros/web/get_url_host.sql
2022-01-15 08:14:45.878676 (MainThread): Parsing macros/web/get_url_path.sql
2022-01-15 08:14:45.881029 (MainThread): Parsing macros/web/get_url_parameter.sql
2022-01-15 08:14:45.882453 (MainThread): Parsing macros/jinja_helpers/pretty_log_format.sql
2022-01-15 08:14:45.883474 (MainThread): Parsing macros/jinja_helpers/pretty_time.sql
2022-01-15 08:14:45.884583 (MainThread): Parsing macros/jinja_helpers/log_info.sql
2022-01-15 08:14:45.885690 (MainThread): Parsing macros/jinja_helpers/slugify.sql
2022-01-15 08:14:45.886783 (MainThread): Parsing macros/schema_tests/fewer_rows_than.sql
2022-01-15 08:14:45.888572 (MainThread): Parsing macros/schema_tests/equal_rowcount.sql
2022-01-15 08:14:45.890088 (MainThread): Parsing macros/schema_tests/relationships_where.sql
2022-01-15 08:14:45.892266 (MainThread): Parsing macros/schema_tests/recency.sql
2022-01-15 08:14:45.893865 (MainThread): Parsing macros/schema_tests/not_constant.sql
2022-01-15 08:14:45.894983 (MainThread): Parsing macros/schema_tests/accepted_range.sql
2022-01-15 08:14:45.897260 (MainThread): Parsing macros/schema_tests/not_accepted_values.sql
2022-01-15 08:14:45.899164 (MainThread): Parsing macros/schema_tests/test_unique_where.sql
2022-01-15 08:14:45.900454 (MainThread): Parsing macros/schema_tests/at_least_one.sql
2022-01-15 08:14:45.901586 (MainThread): Parsing macros/schema_tests/unique_combination_of_columns.sql
2022-01-15 08:14:45.904549 (MainThread): Parsing macros/schema_tests/cardinality_equality.sql
2022-01-15 08:14:45.906785 (MainThread): Parsing macros/schema_tests/expression_is_true.sql
2022-01-15 08:14:45.908458 (MainThread): Parsing macros/schema_tests/sequential_values.sql
2022-01-15 08:14:45.911204 (MainThread): Parsing macros/schema_tests/test_not_null_where.sql
2022-01-15 08:14:45.912630 (MainThread): Parsing macros/schema_tests/equality.sql
2022-01-15 08:14:45.915968 (MainThread): Parsing macros/schema_tests/mutually_exclusive_ranges.sql
2022-01-15 08:14:45.924408 (MainThread): Parsing macros/sql/date_spine.sql
2022-01-15 08:14:45.928917 (MainThread): Parsing macros/sql/nullcheck_table.sql
2022-01-15 08:14:45.930548 (MainThread): Parsing macros/sql/get_relations_by_pattern.sql
2022-01-15 08:14:45.933865 (MainThread): Parsing macros/sql/generate_series.sql
2022-01-15 08:14:45.962966 (MainThread): Parsing macros/sql/get_relations_by_prefix.sql
2022-01-15 08:14:45.967352 (MainThread): Parsing macros/sql/get_tables_by_prefix_sql.sql
2022-01-15 08:14:45.969472 (MainThread): Parsing macros/sql/star.sql
2022-01-15 08:14:45.973809 (MainThread): Parsing macros/sql/unpivot.sql
2022-01-15 08:14:45.983684 (MainThread): Parsing macros/sql/union.sql
2022-01-15 08:14:45.993508 (MainThread): Parsing macros/sql/groupby.sql
2022-01-15 08:14:45.995024 (MainThread): Parsing macros/sql/surrogate_key.sql
2022-01-15 08:14:45.998779 (MainThread): Parsing macros/sql/safe_add.sql
2022-01-15 08:14:46.000553 (MainThread): Parsing macros/sql/nullcheck.sql
2022-01-15 08:14:46.002339 (MainThread): Parsing macros/sql/get_tables_by_pattern_sql.sql
2022-01-15 08:14:46.009392 (MainThread): Parsing macros/sql/get_column_values.sql
2022-01-15 08:14:46.014661 (MainThread): Parsing macros/sql/pivot.sql
2022-01-15 08:14:46.018893 (MainThread): Parsing macros/sql/get_query_results_as_dict.sql
2022-01-15 08:14:46.021266 (MainThread): Parsing macros/sql/haversine_distance.sql
2022-01-15 08:14:46.320133 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-15 08:14:46.332129 (MainThread): 1699: statically parsed example/my_second_dbt_model.sql
2022-01-15 08:14:46.339105 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-15 08:14:46.341972 (MainThread): Sending event: {'category': 'dbt', 'action': 'experimental_parser', 'label': 'ea2e3eb8-c6cb-4506-93a1-36a4496c54eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1131d52e0>]}
2022-01-15 08:14:46.342993 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.film_test".
2022-01-15 08:14:46.345859 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-15 08:14:46.353347 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-15 08:14:46.356325 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-15 08:14:46.390921 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:14:46.392694 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:14:46.394455 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:14:46.396062 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:14:46.397668 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:14:46.399449 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:14:46.411548 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:14:46.415223 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:14:46.429154 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:14:46.430792 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:14:46.454607 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ea2e3eb8-c6cb-4506-93a1-36a4496c54eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113245220>]}
2022-01-15 08:14:46.463206 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-01-15 08:14:46.463687 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ea2e3eb8-c6cb-4506-93a1-36a4496c54eb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1132450d0>]}
2022-01-15 08:14:46.463928 (MainThread): Found 6 models, 10 tests, 0 snapshots, 0 analyses, 347 macros, 0 operations, 0 seed files, 12 sources, 0 exposures
2022-01-15 08:14:46.465131 (MainThread): 
2022-01-15 08:14:46.465577 (MainThread): Acquiring new postgres connection "master".
2022-01-15 08:14:46.466491 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_dwh".
2022-01-15 08:14:46.475377 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-15 08:14:46.475586 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: BEGIN
2022-01-15 08:14:46.475742 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2022-01-15 08:14:46.860554 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.38 seconds
2022-01-15 08:14:46.860952 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-15 08:14:46.861207 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_dwh"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dwh'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dwh'
  
2022-01-15 08:14:46.928555 (ThreadPoolExecutor-1_0): SQL status: SELECT 6 in 0.07 seconds
2022-01-15 08:14:46.930746 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: ROLLBACK
2022-01-15 08:14:46.990992 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: Close
2022-01-15 08:14:46.996951 (MainThread): Using postgres connection "master".
2022-01-15 08:14:46.997174 (MainThread): On master: BEGIN
2022-01-15 08:14:46.997355 (MainThread): Opening a new connection, currently in state init
2022-01-15 08:14:47.376592 (MainThread): SQL status: BEGIN in 0.38 seconds
2022-01-15 08:14:47.377008 (MainThread): Using postgres connection "master".
2022-01-15 08:14:47.377272 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-15 08:14:47.458411 (MainThread): SQL status: SELECT 47 in 0.08 seconds
2022-01-15 08:14:47.461335 (MainThread): On master: ROLLBACK
2022-01-15 08:14:47.521409 (MainThread): On master: Close
2022-01-15 08:14:47.522323 (MainThread): 13:44:47 | Concurrency: 1 threads (target='dev')
2022-01-15 08:14:47.522778 (MainThread): 13:44:47 | 
2022-01-15 08:14:47.525084 (Thread-1): Began running node test.sakila_dbt_project.accepted_values_film_test_language_id__False__1.f32314a19d
2022-01-15 08:14:47.525447 (Thread-1): 13:44:47 | 1 of 2 START test accepted_values_film_test_language_id__False__1.... [RUN]
2022-01-15 08:14:47.525890 (Thread-1): Acquiring new postgres connection "test.sakila_dbt_project.accepted_values_film_test_language_id__False__1.f32314a19d".
2022-01-15 08:14:47.526116 (Thread-1): Compiling test.sakila_dbt_project.accepted_values_film_test_language_id__False__1.f32314a19d
2022-01-15 08:14:47.530106 (Thread-1): Writing injected SQL for node "test.sakila_dbt_project.accepted_values_film_test_language_id__False__1.f32314a19d"
2022-01-15 08:14:47.530799 (Thread-1): finished collecting timing info
2022-01-15 08:14:47.549821 (Thread-1): Writing runtime SQL for node "test.sakila_dbt_project.accepted_values_film_test_language_id__False__1.f32314a19d"
2022-01-15 08:14:47.550540 (Thread-1): Using postgres connection "test.sakila_dbt_project.accepted_values_film_test_language_id__False__1.f32314a19d".
2022-01-15 08:14:47.550723 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_language_id__False__1.f32314a19d: BEGIN
2022-01-15 08:14:47.550894 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 08:14:47.922231 (Thread-1): SQL status: BEGIN in 0.37 seconds
2022-01-15 08:14:47.922636 (Thread-1): Using postgres connection "test.sakila_dbt_project.accepted_values_film_test_language_id__False__1.f32314a19d".
2022-01-15 08:14:47.922906 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_language_id__False__1.f32314a19d: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "test.sakila_dbt_project.accepted_values_film_test_language_id__False__1.f32314a19d"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        language_id as value_field,
        count(*) as n_records

    from "sakila_wh"."dwh"."film_test"
    group by language_id

)

select *
from all_values
where value_field not in (
    1
)



      
    ) dbt_internal_test
2022-01-15 08:14:47.988204 (Thread-1): SQL status: SELECT 1 in 0.07 seconds
2022-01-15 08:14:47.991130 (Thread-1): finished collecting timing info
2022-01-15 08:14:47.991488 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_language_id__False__1.f32314a19d: ROLLBACK
2022-01-15 08:14:48.051763 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_language_id__False__1.f32314a19d: Close
2022-01-15 08:14:48.052625 (Thread-1): 13:44:48 | 1 of 2 PASS accepted_values_film_test_language_id__False__1.......... [PASS in 0.53s]
2022-01-15 08:14:48.052986 (Thread-1): Finished running node test.sakila_dbt_project.accepted_values_film_test_language_id__False__1.f32314a19d
2022-01-15 08:14:48.053479 (Thread-1): Began running node test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8
2022-01-15 08:14:48.053897 (Thread-1): 13:44:48 | 2 of 2 START test accepted_values_film_test_rating__NC_17__PG_13__G__R__PG [RUN]
2022-01-15 08:14:48.054364 (Thread-1): Acquiring new postgres connection "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8".
2022-01-15 08:14:48.054604 (Thread-1): Compiling test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8
2022-01-15 08:14:48.061196 (Thread-1): Writing injected SQL for node "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8"
2022-01-15 08:14:48.061829 (Thread-1): finished collecting timing info
2022-01-15 08:14:48.064941 (Thread-1): Writing runtime SQL for node "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8"
2022-01-15 08:14:48.065554 (Thread-1): Using postgres connection "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8".
2022-01-15 08:14:48.065741 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8: BEGIN
2022-01-15 08:14:48.065915 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 08:14:48.438421 (Thread-1): SQL status: BEGIN in 0.37 seconds
2022-01-15 08:14:48.438858 (Thread-1): Using postgres connection "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8".
2022-01-15 08:14:48.439117 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        rating as value_field,
        count(*) as n_records

    from "sakila_wh"."dwh"."film_test"
    group by rating

)

select *
from all_values
where value_field not in (
    'NC-17','PG-13','G','R','PG'
)



      
    ) dbt_internal_test
2022-01-15 08:14:48.505148 (Thread-1): SQL status: SELECT 1 in 0.07 seconds
2022-01-15 08:14:48.507379 (Thread-1): finished collecting timing info
2022-01-15 08:14:48.507680 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8: ROLLBACK
2022-01-15 08:14:48.570011 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8: Close
2022-01-15 08:14:48.571093 (Thread-1): 13:44:48 | 2 of 2 PASS accepted_values_film_test_rating__NC_17__PG_13__G__R__PG. [PASS in 0.52s]
2022-01-15 08:14:48.571442 (Thread-1): Finished running node test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8
2022-01-15 08:14:48.572870 (MainThread): Acquiring new postgres connection "master".
2022-01-15 08:14:48.573330 (MainThread): 13:44:48 | 
2022-01-15 08:14:48.573589 (MainThread): 13:44:48 | Finished running 2 tests in 2.11s.
2022-01-15 08:14:48.573817 (MainThread): Connection 'master' was properly closed.
2022-01-15 08:14:48.574005 (MainThread): Connection 'test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8' was properly closed.
2022-01-15 08:14:48.583186 (MainThread): 
2022-01-15 08:14:48.583418 (MainThread): Completed successfully
2022-01-15 08:14:48.583625 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2022-01-15 08:14:48.583884 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113306af0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113306be0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113306ac0>]}
2022-01-15 08:14:48.584147 (MainThread): Flushing usage events
2022-01-15 08:15:02.539868 (MainThread): Running with dbt=0.21.1
2022-01-15 08:15:02.622664 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, data=False, schema=False, fail_fast=False, store_failures=False, greedy=False, threads=None, version_check=True, select=['example.film_test'], exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.test.TestTask'>, which='test', rpc_method='test')
2022-01-15 08:15:02.624257 (MainThread): Tracking: tracking
2022-01-15 08:15:02.645179 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1040b6940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103ac2790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1040a07f0>]}
2022-01-15 08:15:02.667778 (MainThread): Partial parsing not enabled
2022-01-15 08:15:02.708338 (MainThread): Parsing macros/catalog.sql
2022-01-15 08:15:02.711760 (MainThread): Parsing macros/relations.sql
2022-01-15 08:15:02.713191 (MainThread): Parsing macros/adapters.sql
2022-01-15 08:15:02.737697 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2022-01-15 08:15:02.739587 (MainThread): Parsing macros/core.sql
2022-01-15 08:15:02.743662 (MainThread): Parsing macros/materializations/test.sql
2022-01-15 08:15:02.750790 (MainThread): Parsing macros/materializations/helpers.sql
2022-01-15 08:15:02.761081 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2022-01-15 08:15:02.762944 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2022-01-15 08:15:02.780245 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2022-01-15 08:15:02.810750 (MainThread): Parsing macros/materializations/seed/seed.sql
2022-01-15 08:15:02.832208 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2022-01-15 08:15:02.833847 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2022-01-15 08:15:02.843366 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2022-01-15 08:15:02.862296 (MainThread): Parsing macros/materializations/common/merge.sql
2022-01-15 08:15:02.875523 (MainThread): Parsing macros/materializations/table/table.sql
2022-01-15 08:15:02.882915 (MainThread): Parsing macros/materializations/view/view.sql
2022-01-15 08:15:02.889977 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2022-01-15 08:15:02.893739 (MainThread): Parsing macros/etc/get_custom_alias.sql
2022-01-15 08:15:02.895260 (MainThread): Parsing macros/etc/query.sql
2022-01-15 08:15:02.896138 (MainThread): Parsing macros/etc/is_incremental.sql
2022-01-15 08:15:02.897488 (MainThread): Parsing macros/etc/datetime.sql
2022-01-15 08:15:02.905425 (MainThread): Parsing macros/etc/where_subquery.sql
2022-01-15 08:15:02.907267 (MainThread): Parsing macros/etc/get_custom_schema.sql
2022-01-15 08:15:02.909449 (MainThread): Parsing macros/etc/get_custom_database.sql
2022-01-15 08:15:02.910875 (MainThread): Parsing macros/adapters/common.sql
2022-01-15 08:15:02.962738 (MainThread): Parsing macros/schema_tests/relationships.sql
2022-01-15 08:15:02.964302 (MainThread): Parsing macros/schema_tests/not_null.sql
2022-01-15 08:15:02.965465 (MainThread): Parsing macros/schema_tests/unique.sql
2022-01-15 08:15:02.967177 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2022-01-15 08:15:02.969202 (MainThread): Parsing macros/cross_db_utils/except.sql
2022-01-15 08:15:02.970235 (MainThread): Parsing macros/cross_db_utils/replace.sql
2022-01-15 08:15:02.971507 (MainThread): Parsing macros/cross_db_utils/concat.sql
2022-01-15 08:15:02.972546 (MainThread): Parsing macros/cross_db_utils/datatypes.sql
2022-01-15 08:15:02.978030 (MainThread): Parsing macros/cross_db_utils/_is_relation.sql
2022-01-15 08:15:02.979077 (MainThread): Parsing macros/cross_db_utils/length.sql
2022-01-15 08:15:02.980257 (MainThread): Parsing macros/cross_db_utils/dateadd.sql
2022-01-15 08:15:02.982986 (MainThread): Parsing macros/cross_db_utils/intersect.sql
2022-01-15 08:15:02.983951 (MainThread): Parsing macros/cross_db_utils/right.sql
2022-01-15 08:15:02.986112 (MainThread): Parsing macros/cross_db_utils/datediff.sql
2022-01-15 08:15:02.995709 (MainThread): Parsing macros/cross_db_utils/safe_cast.sql
2022-01-15 08:15:02.997415 (MainThread): Parsing macros/cross_db_utils/hash.sql
2022-01-15 08:15:02.998704 (MainThread): Parsing macros/cross_db_utils/cast_bool_to_text.sql
2022-01-15 08:15:03.000008 (MainThread): Parsing macros/cross_db_utils/identifier.sql
2022-01-15 08:15:03.001513 (MainThread): Parsing macros/cross_db_utils/position.sql
2022-01-15 08:15:03.003022 (MainThread): Parsing macros/cross_db_utils/literal.sql
2022-01-15 08:15:03.003958 (MainThread): Parsing macros/cross_db_utils/current_timestamp.sql
2022-01-15 08:15:03.007696 (MainThread): Parsing macros/cross_db_utils/width_bucket.sql
2022-01-15 08:15:03.012598 (MainThread): Parsing macros/cross_db_utils/last_day.sql
2022-01-15 08:15:03.015840 (MainThread): Parsing macros/cross_db_utils/split_part.sql
2022-01-15 08:15:03.017535 (MainThread): Parsing macros/cross_db_utils/date_trunc.sql
2022-01-15 08:15:03.019019 (MainThread): Parsing macros/cross_db_utils/_is_ephemeral.sql
2022-01-15 08:15:03.020760 (MainThread): Parsing macros/materializations/insert_by_period_materialization.sql
2022-01-15 08:15:03.044501 (MainThread): Parsing macros/web/get_url_host.sql
2022-01-15 08:15:03.046270 (MainThread): Parsing macros/web/get_url_path.sql
2022-01-15 08:15:03.048684 (MainThread): Parsing macros/web/get_url_parameter.sql
2022-01-15 08:15:03.050123 (MainThread): Parsing macros/jinja_helpers/pretty_log_format.sql
2022-01-15 08:15:03.051136 (MainThread): Parsing macros/jinja_helpers/pretty_time.sql
2022-01-15 08:15:03.052345 (MainThread): Parsing macros/jinja_helpers/log_info.sql
2022-01-15 08:15:03.053376 (MainThread): Parsing macros/jinja_helpers/slugify.sql
2022-01-15 08:15:03.055016 (MainThread): Parsing macros/schema_tests/fewer_rows_than.sql
2022-01-15 08:15:03.056753 (MainThread): Parsing macros/schema_tests/equal_rowcount.sql
2022-01-15 08:15:03.058253 (MainThread): Parsing macros/schema_tests/relationships_where.sql
2022-01-15 08:15:03.060345 (MainThread): Parsing macros/schema_tests/recency.sql
2022-01-15 08:15:03.061922 (MainThread): Parsing macros/schema_tests/not_constant.sql
2022-01-15 08:15:03.063126 (MainThread): Parsing macros/schema_tests/accepted_range.sql
2022-01-15 08:15:03.065438 (MainThread): Parsing macros/schema_tests/not_accepted_values.sql
2022-01-15 08:15:03.067383 (MainThread): Parsing macros/schema_tests/test_unique_where.sql
2022-01-15 08:15:03.068682 (MainThread): Parsing macros/schema_tests/at_least_one.sql
2022-01-15 08:15:03.069826 (MainThread): Parsing macros/schema_tests/unique_combination_of_columns.sql
2022-01-15 08:15:03.072491 (MainThread): Parsing macros/schema_tests/cardinality_equality.sql
2022-01-15 08:15:03.074344 (MainThread): Parsing macros/schema_tests/expression_is_true.sql
2022-01-15 08:15:03.075979 (MainThread): Parsing macros/schema_tests/sequential_values.sql
2022-01-15 08:15:03.079012 (MainThread): Parsing macros/schema_tests/test_not_null_where.sql
2022-01-15 08:15:03.080384 (MainThread): Parsing macros/schema_tests/equality.sql
2022-01-15 08:15:03.083668 (MainThread): Parsing macros/schema_tests/mutually_exclusive_ranges.sql
2022-01-15 08:15:03.092436 (MainThread): Parsing macros/sql/date_spine.sql
2022-01-15 08:15:03.096758 (MainThread): Parsing macros/sql/nullcheck_table.sql
2022-01-15 08:15:03.098254 (MainThread): Parsing macros/sql/get_relations_by_pattern.sql
2022-01-15 08:15:03.101359 (MainThread): Parsing macros/sql/generate_series.sql
2022-01-15 08:15:03.131458 (MainThread): Parsing macros/sql/get_relations_by_prefix.sql
2022-01-15 08:15:03.135903 (MainThread): Parsing macros/sql/get_tables_by_prefix_sql.sql
2022-01-15 08:15:03.138003 (MainThread): Parsing macros/sql/star.sql
2022-01-15 08:15:03.142206 (MainThread): Parsing macros/sql/unpivot.sql
2022-01-15 08:15:03.152290 (MainThread): Parsing macros/sql/union.sql
2022-01-15 08:15:03.162171 (MainThread): Parsing macros/sql/groupby.sql
2022-01-15 08:15:03.163701 (MainThread): Parsing macros/sql/surrogate_key.sql
2022-01-15 08:15:03.167583 (MainThread): Parsing macros/sql/safe_add.sql
2022-01-15 08:15:03.169376 (MainThread): Parsing macros/sql/nullcheck.sql
2022-01-15 08:15:03.171196 (MainThread): Parsing macros/sql/get_tables_by_pattern_sql.sql
2022-01-15 08:15:03.178219 (MainThread): Parsing macros/sql/get_column_values.sql
2022-01-15 08:15:03.183566 (MainThread): Parsing macros/sql/pivot.sql
2022-01-15 08:15:03.188034 (MainThread): Parsing macros/sql/get_query_results_as_dict.sql
2022-01-15 08:15:03.190674 (MainThread): Parsing macros/sql/haversine_distance.sql
2022-01-15 08:15:03.492869 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-15 08:15:03.504529 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-15 08:15:03.508434 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.film_test".
2022-01-15 08:15:03.511276 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-15 08:15:03.518964 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-15 08:15:03.521916 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-15 08:15:03.556187 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:15:03.557916 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:15:03.559613 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:15:03.561284 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:15:03.563811 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:15:03.565437 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:15:03.577645 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:15:03.581186 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:15:03.595316 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:15:03.597043 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:15:03.619861 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'fbf8b576-29d8-4b1d-b6a9-dfab3cfa01f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10423f0d0>]}
2022-01-15 08:15:03.627873 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-01-15 08:15:03.628351 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'fbf8b576-29d8-4b1d-b6a9-dfab3cfa01f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10423f160>]}
2022-01-15 08:15:03.628624 (MainThread): Found 6 models, 10 tests, 0 snapshots, 0 analyses, 347 macros, 0 operations, 0 seed files, 12 sources, 0 exposures
2022-01-15 08:15:03.629848 (MainThread): 
2022-01-15 08:15:03.630157 (MainThread): Acquiring new postgres connection "master".
2022-01-15 08:15:03.631055 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_dwh".
2022-01-15 08:15:03.639546 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-15 08:15:03.639725 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: BEGIN
2022-01-15 08:15:03.639857 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2022-01-15 08:15:04.043723 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.40 seconds
2022-01-15 08:15:04.044131 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-15 08:15:04.044391 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_dwh"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dwh'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dwh'
  
2022-01-15 08:15:04.116407 (ThreadPoolExecutor-1_0): SQL status: SELECT 6 in 0.07 seconds
2022-01-15 08:15:04.118948 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: ROLLBACK
2022-01-15 08:15:04.179236 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: Close
2022-01-15 08:15:04.185971 (MainThread): Using postgres connection "master".
2022-01-15 08:15:04.186214 (MainThread): On master: BEGIN
2022-01-15 08:15:04.186407 (MainThread): Opening a new connection, currently in state init
2022-01-15 08:15:04.572666 (MainThread): SQL status: BEGIN in 0.39 seconds
2022-01-15 08:15:04.573067 (MainThread): Using postgres connection "master".
2022-01-15 08:15:04.573329 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-15 08:15:04.653812 (MainThread): SQL status: SELECT 47 in 0.08 seconds
2022-01-15 08:15:04.657331 (MainThread): On master: ROLLBACK
2022-01-15 08:15:04.719155 (MainThread): On master: Close
2022-01-15 08:15:04.720014 (MainThread): 13:45:04 | Concurrency: 1 threads (target='dev')
2022-01-15 08:15:04.720442 (MainThread): 13:45:04 | 
2022-01-15 08:15:04.722740 (Thread-1): Began running node test.sakila_dbt_project.accepted_values_film_test_language_id__False__1__2__55.635a7ce766
2022-01-15 08:15:04.723057 (Thread-1): 13:45:04 | 1 of 2 START test accepted_values_film_test_language_id__False__1__2__55 [RUN]
2022-01-15 08:15:04.723750 (Thread-1): Acquiring new postgres connection "test.sakila_dbt_project.accepted_values_film_test_language_id__False__1__2__55.635a7ce766".
2022-01-15 08:15:04.724019 (Thread-1): Compiling test.sakila_dbt_project.accepted_values_film_test_language_id__False__1__2__55.635a7ce766
2022-01-15 08:15:04.727975 (Thread-1): Writing injected SQL for node "test.sakila_dbt_project.accepted_values_film_test_language_id__False__1__2__55.635a7ce766"
2022-01-15 08:15:04.728599 (Thread-1): finished collecting timing info
2022-01-15 08:15:04.746727 (Thread-1): Writing runtime SQL for node "test.sakila_dbt_project.accepted_values_film_test_language_id__False__1__2__55.635a7ce766"
2022-01-15 08:15:04.747432 (Thread-1): Using postgres connection "test.sakila_dbt_project.accepted_values_film_test_language_id__False__1__2__55.635a7ce766".
2022-01-15 08:15:04.747622 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_language_id__False__1__2__55.635a7ce766: BEGIN
2022-01-15 08:15:04.747788 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 08:15:05.123408 (Thread-1): SQL status: BEGIN in 0.38 seconds
2022-01-15 08:15:05.123802 (Thread-1): Using postgres connection "test.sakila_dbt_project.accepted_values_film_test_language_id__False__1__2__55.635a7ce766".
2022-01-15 08:15:05.124006 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_language_id__False__1__2__55.635a7ce766: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "test.sakila_dbt_project.accepted_values_film_test_language_id__False__1__2__55.635a7ce766"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        language_id as value_field,
        count(*) as n_records

    from "sakila_wh"."dwh"."film_test"
    group by language_id

)

select *
from all_values
where value_field not in (
    1,2,55
)



      
    ) dbt_internal_test
2022-01-15 08:15:05.192312 (Thread-1): SQL status: SELECT 1 in 0.07 seconds
2022-01-15 08:15:05.195283 (Thread-1): finished collecting timing info
2022-01-15 08:15:05.195566 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_language_id__False__1__2__55.635a7ce766: ROLLBACK
2022-01-15 08:15:05.255403 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_language_id__False__1__2__55.635a7ce766: Close
2022-01-15 08:15:05.256286 (Thread-1): 13:45:05 | 1 of 2 PASS accepted_values_film_test_language_id__False__1__2__55... [PASS in 0.53s]
2022-01-15 08:15:05.256641 (Thread-1): Finished running node test.sakila_dbt_project.accepted_values_film_test_language_id__False__1__2__55.635a7ce766
2022-01-15 08:15:05.256973 (Thread-1): Began running node test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8
2022-01-15 08:15:05.257429 (Thread-1): 13:45:05 | 2 of 2 START test accepted_values_film_test_rating__NC_17__PG_13__G__R__PG [RUN]
2022-01-15 08:15:05.257920 (Thread-1): Acquiring new postgres connection "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8".
2022-01-15 08:15:05.258150 (Thread-1): Compiling test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8
2022-01-15 08:15:05.264882 (Thread-1): Writing injected SQL for node "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8"
2022-01-15 08:15:05.265572 (Thread-1): finished collecting timing info
2022-01-15 08:15:05.267679 (Thread-1): Writing runtime SQL for node "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8"
2022-01-15 08:15:05.268287 (Thread-1): Using postgres connection "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8".
2022-01-15 08:15:05.268484 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8: BEGIN
2022-01-15 08:15:05.268658 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 08:15:05.658435 (Thread-1): SQL status: BEGIN in 0.39 seconds
2022-01-15 08:15:05.658848 (Thread-1): Using postgres connection "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8".
2022-01-15 08:15:05.659103 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        rating as value_field,
        count(*) as n_records

    from "sakila_wh"."dwh"."film_test"
    group by rating

)

select *
from all_values
where value_field not in (
    'NC-17','PG-13','G','R','PG'
)



      
    ) dbt_internal_test
2022-01-15 08:15:05.724230 (Thread-1): SQL status: SELECT 1 in 0.06 seconds
2022-01-15 08:15:05.725864 (Thread-1): finished collecting timing info
2022-01-15 08:15:05.726120 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8: ROLLBACK
2022-01-15 08:15:05.786139 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8: Close
2022-01-15 08:15:05.787293 (Thread-1): 13:45:05 | 2 of 2 PASS accepted_values_film_test_rating__NC_17__PG_13__G__R__PG. [PASS in 0.53s]
2022-01-15 08:15:05.787662 (Thread-1): Finished running node test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8
2022-01-15 08:15:05.789015 (MainThread): Acquiring new postgres connection "master".
2022-01-15 08:15:05.789448 (MainThread): 13:45:05 | 
2022-01-15 08:15:05.789663 (MainThread): 13:45:05 | Finished running 2 tests in 2.16s.
2022-01-15 08:15:05.789852 (MainThread): Connection 'master' was properly closed.
2022-01-15 08:15:05.790002 (MainThread): Connection 'test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8' was properly closed.
2022-01-15 08:15:05.798972 (MainThread): 
2022-01-15 08:15:05.799210 (MainThread): Completed successfully
2022-01-15 08:15:05.799422 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2022-01-15 08:15:05.799702 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1042f2a00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1043df460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1042dfbb0>]}
2022-01-15 08:15:05.799985 (MainThread): Flushing usage events
2022-01-15 08:15:37.842861 (MainThread): Running with dbt=0.21.1
2022-01-15 08:15:37.924287 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, data=False, schema=False, fail_fast=False, store_failures=False, greedy=False, threads=None, version_check=True, select=['example.film_test'], exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.test.TestTask'>, which='test', rpc_method='test')
2022-01-15 08:15:37.926069 (MainThread): Tracking: tracking
2022-01-15 08:15:37.945686 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108eb98b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1088c52e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e97dc0>]}
2022-01-15 08:15:37.968286 (MainThread): Partial parsing not enabled
2022-01-15 08:15:38.007992 (MainThread): Parsing macros/catalog.sql
2022-01-15 08:15:38.011522 (MainThread): Parsing macros/relations.sql
2022-01-15 08:15:38.012983 (MainThread): Parsing macros/adapters.sql
2022-01-15 08:15:38.035229 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2022-01-15 08:15:38.036851 (MainThread): Parsing macros/core.sql
2022-01-15 08:15:38.040381 (MainThread): Parsing macros/materializations/test.sql
2022-01-15 08:15:38.046786 (MainThread): Parsing macros/materializations/helpers.sql
2022-01-15 08:15:38.056504 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2022-01-15 08:15:38.058227 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2022-01-15 08:15:38.074739 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2022-01-15 08:15:38.104784 (MainThread): Parsing macros/materializations/seed/seed.sql
2022-01-15 08:15:38.126258 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2022-01-15 08:15:38.127941 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2022-01-15 08:15:38.137373 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2022-01-15 08:15:38.156136 (MainThread): Parsing macros/materializations/common/merge.sql
2022-01-15 08:15:38.168981 (MainThread): Parsing macros/materializations/table/table.sql
2022-01-15 08:15:38.176700 (MainThread): Parsing macros/materializations/view/view.sql
2022-01-15 08:15:38.183262 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2022-01-15 08:15:38.186955 (MainThread): Parsing macros/etc/get_custom_alias.sql
2022-01-15 08:15:38.188454 (MainThread): Parsing macros/etc/query.sql
2022-01-15 08:15:38.189503 (MainThread): Parsing macros/etc/is_incremental.sql
2022-01-15 08:15:38.190891 (MainThread): Parsing macros/etc/datetime.sql
2022-01-15 08:15:38.198726 (MainThread): Parsing macros/etc/where_subquery.sql
2022-01-15 08:15:38.200365 (MainThread): Parsing macros/etc/get_custom_schema.sql
2022-01-15 08:15:38.202543 (MainThread): Parsing macros/etc/get_custom_database.sql
2022-01-15 08:15:38.203966 (MainThread): Parsing macros/adapters/common.sql
2022-01-15 08:15:38.256651 (MainThread): Parsing macros/schema_tests/relationships.sql
2022-01-15 08:15:38.258228 (MainThread): Parsing macros/schema_tests/not_null.sql
2022-01-15 08:15:38.259326 (MainThread): Parsing macros/schema_tests/unique.sql
2022-01-15 08:15:38.260556 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2022-01-15 08:15:38.262633 (MainThread): Parsing macros/cross_db_utils/except.sql
2022-01-15 08:15:38.263604 (MainThread): Parsing macros/cross_db_utils/replace.sql
2022-01-15 08:15:38.264756 (MainThread): Parsing macros/cross_db_utils/concat.sql
2022-01-15 08:15:38.265677 (MainThread): Parsing macros/cross_db_utils/datatypes.sql
2022-01-15 08:15:38.271377 (MainThread): Parsing macros/cross_db_utils/_is_relation.sql
2022-01-15 08:15:38.272636 (MainThread): Parsing macros/cross_db_utils/length.sql
2022-01-15 08:15:38.273841 (MainThread): Parsing macros/cross_db_utils/dateadd.sql
2022-01-15 08:15:38.276602 (MainThread): Parsing macros/cross_db_utils/intersect.sql
2022-01-15 08:15:38.277578 (MainThread): Parsing macros/cross_db_utils/right.sql
2022-01-15 08:15:38.279653 (MainThread): Parsing macros/cross_db_utils/datediff.sql
2022-01-15 08:15:38.289325 (MainThread): Parsing macros/cross_db_utils/safe_cast.sql
2022-01-15 08:15:38.291087 (MainThread): Parsing macros/cross_db_utils/hash.sql
2022-01-15 08:15:38.292425 (MainThread): Parsing macros/cross_db_utils/cast_bool_to_text.sql
2022-01-15 08:15:38.293774 (MainThread): Parsing macros/cross_db_utils/identifier.sql
2022-01-15 08:15:38.295425 (MainThread): Parsing macros/cross_db_utils/position.sql
2022-01-15 08:15:38.296850 (MainThread): Parsing macros/cross_db_utils/literal.sql
2022-01-15 08:15:38.297730 (MainThread): Parsing macros/cross_db_utils/current_timestamp.sql
2022-01-15 08:15:38.300951 (MainThread): Parsing macros/cross_db_utils/width_bucket.sql
2022-01-15 08:15:38.305936 (MainThread): Parsing macros/cross_db_utils/last_day.sql
2022-01-15 08:15:38.309341 (MainThread): Parsing macros/cross_db_utils/split_part.sql
2022-01-15 08:15:38.311096 (MainThread): Parsing macros/cross_db_utils/date_trunc.sql
2022-01-15 08:15:38.312708 (MainThread): Parsing macros/cross_db_utils/_is_ephemeral.sql
2022-01-15 08:15:38.314446 (MainThread): Parsing macros/materializations/insert_by_period_materialization.sql
2022-01-15 08:15:38.337494 (MainThread): Parsing macros/web/get_url_host.sql
2022-01-15 08:15:38.339385 (MainThread): Parsing macros/web/get_url_path.sql
2022-01-15 08:15:38.341861 (MainThread): Parsing macros/web/get_url_parameter.sql
2022-01-15 08:15:38.343324 (MainThread): Parsing macros/jinja_helpers/pretty_log_format.sql
2022-01-15 08:15:38.344410 (MainThread): Parsing macros/jinja_helpers/pretty_time.sql
2022-01-15 08:15:38.345559 (MainThread): Parsing macros/jinja_helpers/log_info.sql
2022-01-15 08:15:38.346687 (MainThread): Parsing macros/jinja_helpers/slugify.sql
2022-01-15 08:15:38.347810 (MainThread): Parsing macros/schema_tests/fewer_rows_than.sql
2022-01-15 08:15:38.349356 (MainThread): Parsing macros/schema_tests/equal_rowcount.sql
2022-01-15 08:15:38.350868 (MainThread): Parsing macros/schema_tests/relationships_where.sql
2022-01-15 08:15:38.353054 (MainThread): Parsing macros/schema_tests/recency.sql
2022-01-15 08:15:38.354715 (MainThread): Parsing macros/schema_tests/not_constant.sql
2022-01-15 08:15:38.356125 (MainThread): Parsing macros/schema_tests/accepted_range.sql
2022-01-15 08:15:38.358453 (MainThread): Parsing macros/schema_tests/not_accepted_values.sql
2022-01-15 08:15:38.360410 (MainThread): Parsing macros/schema_tests/test_unique_where.sql
2022-01-15 08:15:38.361725 (MainThread): Parsing macros/schema_tests/at_least_one.sql
2022-01-15 08:15:38.362957 (MainThread): Parsing macros/schema_tests/unique_combination_of_columns.sql
2022-01-15 08:15:38.365541 (MainThread): Parsing macros/schema_tests/cardinality_equality.sql
2022-01-15 08:15:38.367446 (MainThread): Parsing macros/schema_tests/expression_is_true.sql
2022-01-15 08:15:38.369109 (MainThread): Parsing macros/schema_tests/sequential_values.sql
2022-01-15 08:15:38.372038 (MainThread): Parsing macros/schema_tests/test_not_null_where.sql
2022-01-15 08:15:38.373525 (MainThread): Parsing macros/schema_tests/equality.sql
2022-01-15 08:15:38.376705 (MainThread): Parsing macros/schema_tests/mutually_exclusive_ranges.sql
2022-01-15 08:15:38.385104 (MainThread): Parsing macros/sql/date_spine.sql
2022-01-15 08:15:38.389751 (MainThread): Parsing macros/sql/nullcheck_table.sql
2022-01-15 08:15:38.391378 (MainThread): Parsing macros/sql/get_relations_by_pattern.sql
2022-01-15 08:15:38.394534 (MainThread): Parsing macros/sql/generate_series.sql
2022-01-15 08:15:38.423343 (MainThread): Parsing macros/sql/get_relations_by_prefix.sql
2022-01-15 08:15:38.427804 (MainThread): Parsing macros/sql/get_tables_by_prefix_sql.sql
2022-01-15 08:15:38.429912 (MainThread): Parsing macros/sql/star.sql
2022-01-15 08:15:38.434156 (MainThread): Parsing macros/sql/unpivot.sql
2022-01-15 08:15:38.444249 (MainThread): Parsing macros/sql/union.sql
2022-01-15 08:15:38.453645 (MainThread): Parsing macros/sql/groupby.sql
2022-01-15 08:15:38.455166 (MainThread): Parsing macros/sql/surrogate_key.sql
2022-01-15 08:15:38.459073 (MainThread): Parsing macros/sql/safe_add.sql
2022-01-15 08:15:38.460868 (MainThread): Parsing macros/sql/nullcheck.sql
2022-01-15 08:15:38.462671 (MainThread): Parsing macros/sql/get_tables_by_pattern_sql.sql
2022-01-15 08:15:38.469687 (MainThread): Parsing macros/sql/get_column_values.sql
2022-01-15 08:15:38.475040 (MainThread): Parsing macros/sql/pivot.sql
2022-01-15 08:15:38.479146 (MainThread): Parsing macros/sql/get_query_results_as_dict.sql
2022-01-15 08:15:38.481316 (MainThread): Parsing macros/sql/haversine_distance.sql
2022-01-15 08:15:38.783017 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-15 08:15:38.794970 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-15 08:15:38.798570 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.film_test".
2022-01-15 08:15:38.801293 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-15 08:15:38.809548 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-15 08:15:38.812477 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-15 08:15:38.846755 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:15:38.848456 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:15:38.850081 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:15:38.851675 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:15:38.854527 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:15:38.856345 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:15:38.868274 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:15:38.871840 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:15:38.885604 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:15:38.887260 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:15:38.910107 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b13020d5-98b8-4508-8b7c-bab414fef89b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10903bf10>]}
2022-01-15 08:15:38.917869 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-01-15 08:15:38.918325 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b13020d5-98b8-4508-8b7c-bab414fef89b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10903be50>]}
2022-01-15 08:15:38.918566 (MainThread): Found 6 models, 10 tests, 0 snapshots, 0 analyses, 347 macros, 0 operations, 0 seed files, 12 sources, 0 exposures
2022-01-15 08:15:38.919990 (MainThread): 
2022-01-15 08:15:38.920295 (MainThread): Acquiring new postgres connection "master".
2022-01-15 08:15:38.921283 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_dwh".
2022-01-15 08:15:38.929847 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-15 08:15:38.930017 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: BEGIN
2022-01-15 08:15:38.930151 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2022-01-15 08:15:40.339374 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 1.41 seconds
2022-01-15 08:15:40.339856 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-15 08:15:40.340212 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_dwh"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dwh'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dwh'
  
2022-01-15 08:15:40.409791 (ThreadPoolExecutor-1_0): SQL status: SELECT 6 in 0.07 seconds
2022-01-15 08:15:40.412024 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: ROLLBACK
2022-01-15 08:15:40.472522 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: Close
2022-01-15 08:15:40.479344 (MainThread): Using postgres connection "master".
2022-01-15 08:15:40.479570 (MainThread): On master: BEGIN
2022-01-15 08:15:40.479750 (MainThread): Opening a new connection, currently in state init
2022-01-15 08:15:40.859488 (MainThread): SQL status: BEGIN in 0.38 seconds
2022-01-15 08:15:40.859848 (MainThread): Using postgres connection "master".
2022-01-15 08:15:40.860080 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-15 08:15:40.936462 (MainThread): SQL status: SELECT 47 in 0.08 seconds
2022-01-15 08:15:40.940189 (MainThread): On master: ROLLBACK
2022-01-15 08:15:41.004094 (MainThread): On master: Close
2022-01-15 08:15:41.004906 (MainThread): 13:45:41 | Concurrency: 1 threads (target='dev')
2022-01-15 08:15:41.005259 (MainThread): 13:45:41 | 
2022-01-15 08:15:41.007809 (Thread-1): Began running node test.sakila_dbt_project.accepted_values_film_test_language_id__False__55__99.72dd5739b7
2022-01-15 08:15:41.008134 (Thread-1): 13:45:41 | 1 of 2 START test accepted_values_film_test_language_id__False__55__99 [RUN]
2022-01-15 08:15:41.008831 (Thread-1): Acquiring new postgres connection "test.sakila_dbt_project.accepted_values_film_test_language_id__False__55__99.72dd5739b7".
2022-01-15 08:15:41.009098 (Thread-1): Compiling test.sakila_dbt_project.accepted_values_film_test_language_id__False__55__99.72dd5739b7
2022-01-15 08:15:41.013198 (Thread-1): Writing injected SQL for node "test.sakila_dbt_project.accepted_values_film_test_language_id__False__55__99.72dd5739b7"
2022-01-15 08:15:41.013839 (Thread-1): finished collecting timing info
2022-01-15 08:15:41.031436 (Thread-1): Writing runtime SQL for node "test.sakila_dbt_project.accepted_values_film_test_language_id__False__55__99.72dd5739b7"
2022-01-15 08:15:41.032138 (Thread-1): Using postgres connection "test.sakila_dbt_project.accepted_values_film_test_language_id__False__55__99.72dd5739b7".
2022-01-15 08:15:41.032317 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_language_id__False__55__99.72dd5739b7: BEGIN
2022-01-15 08:15:41.032477 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 08:15:41.415151 (Thread-1): SQL status: BEGIN in 0.38 seconds
2022-01-15 08:15:41.415757 (Thread-1): Using postgres connection "test.sakila_dbt_project.accepted_values_film_test_language_id__False__55__99.72dd5739b7".
2022-01-15 08:15:41.416051 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_language_id__False__55__99.72dd5739b7: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "test.sakila_dbt_project.accepted_values_film_test_language_id__False__55__99.72dd5739b7"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        language_id as value_field,
        count(*) as n_records

    from "sakila_wh"."dwh"."film_test"
    group by language_id

)

select *
from all_values
where value_field not in (
    55,99
)



      
    ) dbt_internal_test
2022-01-15 08:15:41.505591 (Thread-1): SQL status: SELECT 1 in 0.09 seconds
2022-01-15 08:15:41.508819 (Thread-1): finished collecting timing info
2022-01-15 08:15:41.509135 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_language_id__False__55__99.72dd5739b7: ROLLBACK
2022-01-15 08:15:41.569819 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_language_id__False__55__99.72dd5739b7: Close
2022-01-15 08:15:41.570744 (Thread-1): 13:45:41 | 1 of 2 FAIL 1 accepted_values_film_test_language_id__False__55__99... [FAIL 1 in 0.56s]
2022-01-15 08:15:41.571126 (Thread-1): Finished running node test.sakila_dbt_project.accepted_values_film_test_language_id__False__55__99.72dd5739b7
2022-01-15 08:15:41.571474 (Thread-1): Began running node test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8
2022-01-15 08:15:41.571822 (Thread-1): 13:45:41 | 2 of 2 START test accepted_values_film_test_rating__NC_17__PG_13__G__R__PG [RUN]
2022-01-15 08:15:41.572331 (Thread-1): Acquiring new postgres connection "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8".
2022-01-15 08:15:41.572581 (Thread-1): Compiling test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8
2022-01-15 08:15:41.578969 (Thread-1): Writing injected SQL for node "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8"
2022-01-15 08:15:41.579662 (Thread-1): finished collecting timing info
2022-01-15 08:15:41.581765 (Thread-1): Writing runtime SQL for node "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8"
2022-01-15 08:15:41.582379 (Thread-1): Using postgres connection "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8".
2022-01-15 08:15:41.582566 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8: BEGIN
2022-01-15 08:15:41.582739 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 08:15:41.955936 (Thread-1): SQL status: BEGIN in 0.37 seconds
2022-01-15 08:15:41.956370 (Thread-1): Using postgres connection "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8".
2022-01-15 08:15:41.956693 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        rating as value_field,
        count(*) as n_records

    from "sakila_wh"."dwh"."film_test"
    group by rating

)

select *
from all_values
where value_field not in (
    'NC-17','PG-13','G','R','PG'
)



      
    ) dbt_internal_test
2022-01-15 08:15:42.023675 (Thread-1): SQL status: SELECT 1 in 0.07 seconds
2022-01-15 08:15:42.025747 (Thread-1): finished collecting timing info
2022-01-15 08:15:42.026189 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8: ROLLBACK
2022-01-15 08:15:42.088285 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8: Close
2022-01-15 08:15:42.089154 (Thread-1): 13:45:42 | 2 of 2 PASS accepted_values_film_test_rating__NC_17__PG_13__G__R__PG. [PASS in 0.52s]
2022-01-15 08:15:42.089519 (Thread-1): Finished running node test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8
2022-01-15 08:15:42.091027 (MainThread): Acquiring new postgres connection "master".
2022-01-15 08:15:42.091504 (MainThread): 13:45:42 | 
2022-01-15 08:15:42.091780 (MainThread): 13:45:42 | Finished running 2 tests in 3.17s.
2022-01-15 08:15:42.092099 (MainThread): Connection 'master' was properly closed.
2022-01-15 08:15:42.092326 (MainThread): Connection 'test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8' was properly closed.
2022-01-15 08:15:42.101595 (MainThread): 
2022-01-15 08:15:42.101828 (MainThread): Completed with 1 error and 0 warnings:
2022-01-15 08:15:42.102026 (MainThread): 
2022-01-15 08:15:42.102222 (MainThread): Failure in test accepted_values_film_test_language_id__False__55__99 (models/example/schema.yml)
2022-01-15 08:15:42.102403 (MainThread):   Got 1 result, configured to fail if != 0
2022-01-15 08:15:42.102579 (MainThread): 
2022-01-15 08:15:42.102757 (MainThread):   compiled SQL at target/compiled/sakila_dbt_project/models/example/schema.yml/schema_test/accepted_values_film_test_language_id__False__55__99.sql
2022-01-15 08:15:42.102959 (MainThread): 
Done. PASS=1 WARN=0 ERROR=1 SKIP=0 TOTAL=2
2022-01-15 08:15:42.103195 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1090f5970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1091e40a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1090e3850>]}
2022-01-15 08:15:42.103444 (MainThread): Flushing usage events
2022-01-15 08:15:56.167969 (MainThread): Running with dbt=0.21.1
2022-01-15 08:15:56.255298 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, data=False, schema=False, fail_fast=False, store_failures=False, greedy=False, threads=None, version_check=True, select=['example.film_test'], exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.test.TestTask'>, which='test', rpc_method='test')
2022-01-15 08:15:56.257215 (MainThread): Tracking: tracking
2022-01-15 08:15:56.275555 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a362910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109d6f310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a33bcd0>]}
2022-01-15 08:15:56.296848 (MainThread): Partial parsing not enabled
2022-01-15 08:15:56.334791 (MainThread): Parsing macros/catalog.sql
2022-01-15 08:15:56.337767 (MainThread): Parsing macros/relations.sql
2022-01-15 08:15:56.339033 (MainThread): Parsing macros/adapters.sql
2022-01-15 08:15:56.360378 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2022-01-15 08:15:56.362021 (MainThread): Parsing macros/core.sql
2022-01-15 08:15:56.365484 (MainThread): Parsing macros/materializations/test.sql
2022-01-15 08:15:56.372548 (MainThread): Parsing macros/materializations/helpers.sql
2022-01-15 08:15:56.381885 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2022-01-15 08:15:56.383495 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2022-01-15 08:15:56.399522 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2022-01-15 08:15:56.429940 (MainThread): Parsing macros/materializations/seed/seed.sql
2022-01-15 08:15:56.451946 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2022-01-15 08:15:56.453701 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2022-01-15 08:15:56.463786 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2022-01-15 08:15:56.485026 (MainThread): Parsing macros/materializations/common/merge.sql
2022-01-15 08:15:56.498202 (MainThread): Parsing macros/materializations/table/table.sql
2022-01-15 08:15:56.505606 (MainThread): Parsing macros/materializations/view/view.sql
2022-01-15 08:15:56.512345 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2022-01-15 08:15:56.515911 (MainThread): Parsing macros/etc/get_custom_alias.sql
2022-01-15 08:15:56.517303 (MainThread): Parsing macros/etc/query.sql
2022-01-15 08:15:56.518202 (MainThread): Parsing macros/etc/is_incremental.sql
2022-01-15 08:15:56.519605 (MainThread): Parsing macros/etc/datetime.sql
2022-01-15 08:15:56.527793 (MainThread): Parsing macros/etc/where_subquery.sql
2022-01-15 08:15:56.529486 (MainThread): Parsing macros/etc/get_custom_schema.sql
2022-01-15 08:15:56.531744 (MainThread): Parsing macros/etc/get_custom_database.sql
2022-01-15 08:15:56.533232 (MainThread): Parsing macros/adapters/common.sql
2022-01-15 08:15:56.585528 (MainThread): Parsing macros/schema_tests/relationships.sql
2022-01-15 08:15:56.587112 (MainThread): Parsing macros/schema_tests/not_null.sql
2022-01-15 08:15:56.588354 (MainThread): Parsing macros/schema_tests/unique.sql
2022-01-15 08:15:56.589579 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2022-01-15 08:15:56.591759 (MainThread): Parsing macros/cross_db_utils/except.sql
2022-01-15 08:15:56.592807 (MainThread): Parsing macros/cross_db_utils/replace.sql
2022-01-15 08:15:56.593967 (MainThread): Parsing macros/cross_db_utils/concat.sql
2022-01-15 08:15:56.594883 (MainThread): Parsing macros/cross_db_utils/datatypes.sql
2022-01-15 08:15:56.600250 (MainThread): Parsing macros/cross_db_utils/_is_relation.sql
2022-01-15 08:15:56.601285 (MainThread): Parsing macros/cross_db_utils/length.sql
2022-01-15 08:15:56.602471 (MainThread): Parsing macros/cross_db_utils/dateadd.sql
2022-01-15 08:15:56.605315 (MainThread): Parsing macros/cross_db_utils/intersect.sql
2022-01-15 08:15:56.606619 (MainThread): Parsing macros/cross_db_utils/right.sql
2022-01-15 08:15:56.608705 (MainThread): Parsing macros/cross_db_utils/datediff.sql
2022-01-15 08:15:56.618116 (MainThread): Parsing macros/cross_db_utils/safe_cast.sql
2022-01-15 08:15:56.619800 (MainThread): Parsing macros/cross_db_utils/hash.sql
2022-01-15 08:15:56.621117 (MainThread): Parsing macros/cross_db_utils/cast_bool_to_text.sql
2022-01-15 08:15:56.622559 (MainThread): Parsing macros/cross_db_utils/identifier.sql
2022-01-15 08:15:56.624344 (MainThread): Parsing macros/cross_db_utils/position.sql
2022-01-15 08:15:56.625788 (MainThread): Parsing macros/cross_db_utils/literal.sql
2022-01-15 08:15:56.626715 (MainThread): Parsing macros/cross_db_utils/current_timestamp.sql
2022-01-15 08:15:56.630121 (MainThread): Parsing macros/cross_db_utils/width_bucket.sql
2022-01-15 08:15:56.634829 (MainThread): Parsing macros/cross_db_utils/last_day.sql
2022-01-15 08:15:56.638152 (MainThread): Parsing macros/cross_db_utils/split_part.sql
2022-01-15 08:15:56.640103 (MainThread): Parsing macros/cross_db_utils/date_trunc.sql
2022-01-15 08:15:56.641590 (MainThread): Parsing macros/cross_db_utils/_is_ephemeral.sql
2022-01-15 08:15:56.643306 (MainThread): Parsing macros/materializations/insert_by_period_materialization.sql
2022-01-15 08:15:56.666835 (MainThread): Parsing macros/web/get_url_host.sql
2022-01-15 08:15:56.668550 (MainThread): Parsing macros/web/get_url_path.sql
2022-01-15 08:15:56.670899 (MainThread): Parsing macros/web/get_url_parameter.sql
2022-01-15 08:15:56.672520 (MainThread): Parsing macros/jinja_helpers/pretty_log_format.sql
2022-01-15 08:15:56.673703 (MainThread): Parsing macros/jinja_helpers/pretty_time.sql
2022-01-15 08:15:56.674889 (MainThread): Parsing macros/jinja_helpers/log_info.sql
2022-01-15 08:15:56.675917 (MainThread): Parsing macros/jinja_helpers/slugify.sql
2022-01-15 08:15:56.677002 (MainThread): Parsing macros/schema_tests/fewer_rows_than.sql
2022-01-15 08:15:56.678535 (MainThread): Parsing macros/schema_tests/equal_rowcount.sql
2022-01-15 08:15:56.680026 (MainThread): Parsing macros/schema_tests/relationships_where.sql
2022-01-15 08:15:56.682221 (MainThread): Parsing macros/schema_tests/recency.sql
2022-01-15 08:15:56.683821 (MainThread): Parsing macros/schema_tests/not_constant.sql
2022-01-15 08:15:56.684959 (MainThread): Parsing macros/schema_tests/accepted_range.sql
2022-01-15 08:15:56.687382 (MainThread): Parsing macros/schema_tests/not_accepted_values.sql
2022-01-15 08:15:56.689505 (MainThread): Parsing macros/schema_tests/test_unique_where.sql
2022-01-15 08:15:56.690820 (MainThread): Parsing macros/schema_tests/at_least_one.sql
2022-01-15 08:15:56.691962 (MainThread): Parsing macros/schema_tests/unique_combination_of_columns.sql
2022-01-15 08:15:56.694529 (MainThread): Parsing macros/schema_tests/cardinality_equality.sql
2022-01-15 08:15:56.696443 (MainThread): Parsing macros/schema_tests/expression_is_true.sql
2022-01-15 08:15:56.698065 (MainThread): Parsing macros/schema_tests/sequential_values.sql
2022-01-15 08:15:56.700761 (MainThread): Parsing macros/schema_tests/test_not_null_where.sql
2022-01-15 08:15:56.702044 (MainThread): Parsing macros/schema_tests/equality.sql
2022-01-15 08:15:56.705181 (MainThread): Parsing macros/schema_tests/mutually_exclusive_ranges.sql
2022-01-15 08:15:56.713933 (MainThread): Parsing macros/sql/date_spine.sql
2022-01-15 08:15:56.718266 (MainThread): Parsing macros/sql/nullcheck_table.sql
2022-01-15 08:15:56.719843 (MainThread): Parsing macros/sql/get_relations_by_pattern.sql
2022-01-15 08:15:56.723151 (MainThread): Parsing macros/sql/generate_series.sql
2022-01-15 08:15:56.751339 (MainThread): Parsing macros/sql/get_relations_by_prefix.sql
2022-01-15 08:15:56.755895 (MainThread): Parsing macros/sql/get_tables_by_prefix_sql.sql
2022-01-15 08:15:56.758153 (MainThread): Parsing macros/sql/star.sql
2022-01-15 08:15:56.762280 (MainThread): Parsing macros/sql/unpivot.sql
2022-01-15 08:15:56.771967 (MainThread): Parsing macros/sql/union.sql
2022-01-15 08:15:56.781517 (MainThread): Parsing macros/sql/groupby.sql
2022-01-15 08:15:56.783060 (MainThread): Parsing macros/sql/surrogate_key.sql
2022-01-15 08:15:56.786934 (MainThread): Parsing macros/sql/safe_add.sql
2022-01-15 08:15:56.788731 (MainThread): Parsing macros/sql/nullcheck.sql
2022-01-15 08:15:56.790654 (MainThread): Parsing macros/sql/get_tables_by_pattern_sql.sql
2022-01-15 08:15:56.797587 (MainThread): Parsing macros/sql/get_column_values.sql
2022-01-15 08:15:56.802763 (MainThread): Parsing macros/sql/pivot.sql
2022-01-15 08:15:56.807008 (MainThread): Parsing macros/sql/get_query_results_as_dict.sql
2022-01-15 08:15:56.809188 (MainThread): Parsing macros/sql/haversine_distance.sql
2022-01-15 08:15:57.109939 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-15 08:15:57.121447 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-15 08:15:57.125263 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.film_test".
2022-01-15 08:15:57.128247 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-15 08:15:57.136116 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-15 08:15:57.138860 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-15 08:15:57.173682 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:15:57.175429 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:15:57.177039 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:15:57.178615 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:15:57.181099 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:15:57.182663 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:15:57.194684 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:15:57.198275 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:15:57.211867 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:15:57.213578 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:15:57.236910 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd7b38d62-f670-4cd8-9aca-846a2357bd78', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a4ba0d0>]}
2022-01-15 08:15:57.244874 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-01-15 08:15:57.245348 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd7b38d62-f670-4cd8-9aca-846a2357bd78', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a4ba160>]}
2022-01-15 08:15:57.245589 (MainThread): Found 6 models, 10 tests, 0 snapshots, 0 analyses, 347 macros, 0 operations, 0 seed files, 12 sources, 0 exposures
2022-01-15 08:15:57.246900 (MainThread): 
2022-01-15 08:15:57.247265 (MainThread): Acquiring new postgres connection "master".
2022-01-15 08:15:57.248414 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_dwh".
2022-01-15 08:15:57.256933 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-15 08:15:57.257111 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: BEGIN
2022-01-15 08:15:57.257246 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2022-01-15 08:15:57.673195 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.42 seconds
2022-01-15 08:15:57.673578 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-15 08:15:57.673807 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_dwh"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dwh'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dwh'
  
2022-01-15 08:15:57.739221 (ThreadPoolExecutor-1_0): SQL status: SELECT 6 in 0.07 seconds
2022-01-15 08:15:57.741612 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: ROLLBACK
2022-01-15 08:15:57.803969 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: Close
2022-01-15 08:15:57.810542 (MainThread): Using postgres connection "master".
2022-01-15 08:15:57.810781 (MainThread): On master: BEGIN
2022-01-15 08:15:57.810961 (MainThread): Opening a new connection, currently in state init
2022-01-15 08:15:58.197323 (MainThread): SQL status: BEGIN in 0.39 seconds
2022-01-15 08:15:58.197910 (MainThread): Using postgres connection "master".
2022-01-15 08:15:58.198159 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-15 08:15:58.279673 (MainThread): SQL status: SELECT 47 in 0.08 seconds
2022-01-15 08:15:58.282882 (MainThread): On master: ROLLBACK
2022-01-15 08:15:58.347573 (MainThread): On master: Close
2022-01-15 08:15:58.348211 (MainThread): 13:45:58 | Concurrency: 1 threads (target='dev')
2022-01-15 08:15:58.348492 (MainThread): 13:45:58 | 
2022-01-15 08:15:58.350638 (Thread-1): Began running node test.sakila_dbt_project.accepted_values_film_test_language_id__False__1__2.3b3d45ead6
2022-01-15 08:15:58.350924 (Thread-1): 13:45:58 | 1 of 2 START test accepted_values_film_test_language_id__False__1__2. [RUN]
2022-01-15 08:15:58.351476 (Thread-1): Acquiring new postgres connection "test.sakila_dbt_project.accepted_values_film_test_language_id__False__1__2.3b3d45ead6".
2022-01-15 08:15:58.351695 (Thread-1): Compiling test.sakila_dbt_project.accepted_values_film_test_language_id__False__1__2.3b3d45ead6
2022-01-15 08:15:58.355629 (Thread-1): Writing injected SQL for node "test.sakila_dbt_project.accepted_values_film_test_language_id__False__1__2.3b3d45ead6"
2022-01-15 08:15:58.356289 (Thread-1): finished collecting timing info
2022-01-15 08:15:58.374308 (Thread-1): Writing runtime SQL for node "test.sakila_dbt_project.accepted_values_film_test_language_id__False__1__2.3b3d45ead6"
2022-01-15 08:15:58.375010 (Thread-1): Using postgres connection "test.sakila_dbt_project.accepted_values_film_test_language_id__False__1__2.3b3d45ead6".
2022-01-15 08:15:58.375188 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_language_id__False__1__2.3b3d45ead6: BEGIN
2022-01-15 08:15:58.375348 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 08:15:58.755996 (Thread-1): SQL status: BEGIN in 0.38 seconds
2022-01-15 08:15:58.756388 (Thread-1): Using postgres connection "test.sakila_dbt_project.accepted_values_film_test_language_id__False__1__2.3b3d45ead6".
2022-01-15 08:15:58.756640 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_language_id__False__1__2.3b3d45ead6: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "test.sakila_dbt_project.accepted_values_film_test_language_id__False__1__2.3b3d45ead6"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        language_id as value_field,
        count(*) as n_records

    from "sakila_wh"."dwh"."film_test"
    group by language_id

)

select *
from all_values
where value_field not in (
    1,2
)



      
    ) dbt_internal_test
2022-01-15 08:15:58.823920 (Thread-1): SQL status: SELECT 1 in 0.07 seconds
2022-01-15 08:15:58.826710 (Thread-1): finished collecting timing info
2022-01-15 08:15:58.827023 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_language_id__False__1__2.3b3d45ead6: ROLLBACK
2022-01-15 08:15:58.890161 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_language_id__False__1__2.3b3d45ead6: Close
2022-01-15 08:15:58.891030 (Thread-1): 13:45:58 | 1 of 2 PASS accepted_values_film_test_language_id__False__1__2....... [PASS in 0.54s]
2022-01-15 08:15:58.891409 (Thread-1): Finished running node test.sakila_dbt_project.accepted_values_film_test_language_id__False__1__2.3b3d45ead6
2022-01-15 08:15:58.891734 (Thread-1): Began running node test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8
2022-01-15 08:15:58.892108 (Thread-1): 13:45:58 | 2 of 2 START test accepted_values_film_test_rating__NC_17__PG_13__G__R__PG [RUN]
2022-01-15 08:15:58.892636 (Thread-1): Acquiring new postgres connection "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8".
2022-01-15 08:15:58.892875 (Thread-1): Compiling test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8
2022-01-15 08:15:58.899482 (Thread-1): Writing injected SQL for node "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8"
2022-01-15 08:15:58.900102 (Thread-1): finished collecting timing info
2022-01-15 08:15:58.902159 (Thread-1): Writing runtime SQL for node "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8"
2022-01-15 08:15:58.902736 (Thread-1): Using postgres connection "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8".
2022-01-15 08:15:58.902917 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8: BEGIN
2022-01-15 08:15:58.903088 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 08:15:59.284627 (Thread-1): SQL status: BEGIN in 0.38 seconds
2022-01-15 08:15:59.285045 (Thread-1): Using postgres connection "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8".
2022-01-15 08:15:59.285308 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        rating as value_field,
        count(*) as n_records

    from "sakila_wh"."dwh"."film_test"
    group by rating

)

select *
from all_values
where value_field not in (
    'NC-17','PG-13','G','R','PG'
)



      
    ) dbt_internal_test
2022-01-15 08:15:59.355000 (Thread-1): SQL status: SELECT 1 in 0.07 seconds
2022-01-15 08:15:59.357438 (Thread-1): finished collecting timing info
2022-01-15 08:15:59.357786 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8: ROLLBACK
2022-01-15 08:15:59.419334 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8: Close
2022-01-15 08:15:59.420477 (Thread-1): 13:45:59 | 2 of 2 PASS accepted_values_film_test_rating__NC_17__PG_13__G__R__PG. [PASS in 0.53s]
2022-01-15 08:15:59.420835 (Thread-1): Finished running node test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8
2022-01-15 08:15:59.422215 (MainThread): Acquiring new postgres connection "master".
2022-01-15 08:15:59.422706 (MainThread): 13:45:59 | 
2022-01-15 08:15:59.422982 (MainThread): 13:45:59 | Finished running 2 tests in 2.18s.
2022-01-15 08:15:59.423221 (MainThread): Connection 'master' was properly closed.
2022-01-15 08:15:59.423414 (MainThread): Connection 'test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8' was properly closed.
2022-01-15 08:15:59.432808 (MainThread): 
2022-01-15 08:15:59.433060 (MainThread): Completed successfully
2022-01-15 08:15:59.433271 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2022-01-15 08:15:59.433535 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a5ab9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a68b8e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a589790>]}
2022-01-15 08:15:59.433807 (MainThread): Flushing usage events
2022-01-15 08:16:42.013461 (MainThread): Running with dbt=0.21.1
2022-01-15 08:16:42.104786 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, data=False, schema=False, fail_fast=False, store_failures=False, greedy=False, threads=None, version_check=True, select=['example.film_test'], exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.test.TestTask'>, which='test', rpc_method='test')
2022-01-15 08:16:42.106636 (MainThread): Tracking: tracking
2022-01-15 08:16:42.126878 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1045a98e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103fb5250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104587dc0>]}
2022-01-15 08:16:42.149467 (MainThread): Partial parsing not enabled
2022-01-15 08:16:42.188555 (MainThread): Parsing macros/catalog.sql
2022-01-15 08:16:42.192125 (MainThread): Parsing macros/relations.sql
2022-01-15 08:16:42.193623 (MainThread): Parsing macros/adapters.sql
2022-01-15 08:16:42.217455 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2022-01-15 08:16:42.219083 (MainThread): Parsing macros/core.sql
2022-01-15 08:16:42.222490 (MainThread): Parsing macros/materializations/test.sql
2022-01-15 08:16:42.228989 (MainThread): Parsing macros/materializations/helpers.sql
2022-01-15 08:16:42.238179 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2022-01-15 08:16:42.240280 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2022-01-15 08:16:42.259323 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2022-01-15 08:16:42.293238 (MainThread): Parsing macros/materializations/seed/seed.sql
2022-01-15 08:16:42.315289 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2022-01-15 08:16:42.316929 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2022-01-15 08:16:42.326492 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2022-01-15 08:16:42.345116 (MainThread): Parsing macros/materializations/common/merge.sql
2022-01-15 08:16:42.358442 (MainThread): Parsing macros/materializations/table/table.sql
2022-01-15 08:16:42.365842 (MainThread): Parsing macros/materializations/view/view.sql
2022-01-15 08:16:42.372559 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2022-01-15 08:16:42.376171 (MainThread): Parsing macros/etc/get_custom_alias.sql
2022-01-15 08:16:42.377548 (MainThread): Parsing macros/etc/query.sql
2022-01-15 08:16:42.378443 (MainThread): Parsing macros/etc/is_incremental.sql
2022-01-15 08:16:42.379815 (MainThread): Parsing macros/etc/datetime.sql
2022-01-15 08:16:42.387718 (MainThread): Parsing macros/etc/where_subquery.sql
2022-01-15 08:16:42.389440 (MainThread): Parsing macros/etc/get_custom_schema.sql
2022-01-15 08:16:42.391768 (MainThread): Parsing macros/etc/get_custom_database.sql
2022-01-15 08:16:42.393419 (MainThread): Parsing macros/adapters/common.sql
2022-01-15 08:16:42.445842 (MainThread): Parsing macros/schema_tests/relationships.sql
2022-01-15 08:16:42.447513 (MainThread): Parsing macros/schema_tests/not_null.sql
2022-01-15 08:16:42.448653 (MainThread): Parsing macros/schema_tests/unique.sql
2022-01-15 08:16:42.449914 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2022-01-15 08:16:42.451964 (MainThread): Parsing macros/cross_db_utils/except.sql
2022-01-15 08:16:42.452963 (MainThread): Parsing macros/cross_db_utils/replace.sql
2022-01-15 08:16:42.454137 (MainThread): Parsing macros/cross_db_utils/concat.sql
2022-01-15 08:16:42.455169 (MainThread): Parsing macros/cross_db_utils/datatypes.sql
2022-01-15 08:16:42.460823 (MainThread): Parsing macros/cross_db_utils/_is_relation.sql
2022-01-15 08:16:42.461911 (MainThread): Parsing macros/cross_db_utils/length.sql
2022-01-15 08:16:42.463135 (MainThread): Parsing macros/cross_db_utils/dateadd.sql
2022-01-15 08:16:42.465909 (MainThread): Parsing macros/cross_db_utils/intersect.sql
2022-01-15 08:16:42.467012 (MainThread): Parsing macros/cross_db_utils/right.sql
2022-01-15 08:16:42.469103 (MainThread): Parsing macros/cross_db_utils/datediff.sql
2022-01-15 08:16:42.478692 (MainThread): Parsing macros/cross_db_utils/safe_cast.sql
2022-01-15 08:16:42.480530 (MainThread): Parsing macros/cross_db_utils/hash.sql
2022-01-15 08:16:42.481840 (MainThread): Parsing macros/cross_db_utils/cast_bool_to_text.sql
2022-01-15 08:16:42.483159 (MainThread): Parsing macros/cross_db_utils/identifier.sql
2022-01-15 08:16:42.484683 (MainThread): Parsing macros/cross_db_utils/position.sql
2022-01-15 08:16:42.486123 (MainThread): Parsing macros/cross_db_utils/literal.sql
2022-01-15 08:16:42.487314 (MainThread): Parsing macros/cross_db_utils/current_timestamp.sql
2022-01-15 08:16:42.490790 (MainThread): Parsing macros/cross_db_utils/width_bucket.sql
2022-01-15 08:16:42.495627 (MainThread): Parsing macros/cross_db_utils/last_day.sql
2022-01-15 08:16:42.498949 (MainThread): Parsing macros/cross_db_utils/split_part.sql
2022-01-15 08:16:42.500635 (MainThread): Parsing macros/cross_db_utils/date_trunc.sql
2022-01-15 08:16:42.502117 (MainThread): Parsing macros/cross_db_utils/_is_ephemeral.sql
2022-01-15 08:16:42.503921 (MainThread): Parsing macros/materializations/insert_by_period_materialization.sql
2022-01-15 08:16:42.530439 (MainThread): Parsing macros/web/get_url_host.sql
2022-01-15 08:16:42.532240 (MainThread): Parsing macros/web/get_url_path.sql
2022-01-15 08:16:42.534638 (MainThread): Parsing macros/web/get_url_parameter.sql
2022-01-15 08:16:42.536094 (MainThread): Parsing macros/jinja_helpers/pretty_log_format.sql
2022-01-15 08:16:42.537186 (MainThread): Parsing macros/jinja_helpers/pretty_time.sql
2022-01-15 08:16:42.538332 (MainThread): Parsing macros/jinja_helpers/log_info.sql
2022-01-15 08:16:42.539477 (MainThread): Parsing macros/jinja_helpers/slugify.sql
2022-01-15 08:16:42.540619 (MainThread): Parsing macros/schema_tests/fewer_rows_than.sql
2022-01-15 08:16:42.542152 (MainThread): Parsing macros/schema_tests/equal_rowcount.sql
2022-01-15 08:16:42.543628 (MainThread): Parsing macros/schema_tests/relationships_where.sql
2022-01-15 08:16:42.545699 (MainThread): Parsing macros/schema_tests/recency.sql
2022-01-15 08:16:42.547489 (MainThread): Parsing macros/schema_tests/not_constant.sql
2022-01-15 08:16:42.548635 (MainThread): Parsing macros/schema_tests/accepted_range.sql
2022-01-15 08:16:42.550975 (MainThread): Parsing macros/schema_tests/not_accepted_values.sql
2022-01-15 08:16:42.552899 (MainThread): Parsing macros/schema_tests/test_unique_where.sql
2022-01-15 08:16:42.554209 (MainThread): Parsing macros/schema_tests/at_least_one.sql
2022-01-15 08:16:42.555377 (MainThread): Parsing macros/schema_tests/unique_combination_of_columns.sql
2022-01-15 08:16:42.558236 (MainThread): Parsing macros/schema_tests/cardinality_equality.sql
2022-01-15 08:16:42.560293 (MainThread): Parsing macros/schema_tests/expression_is_true.sql
2022-01-15 08:16:42.561925 (MainThread): Parsing macros/schema_tests/sequential_values.sql
2022-01-15 08:16:42.564773 (MainThread): Parsing macros/schema_tests/test_not_null_where.sql
2022-01-15 08:16:42.566089 (MainThread): Parsing macros/schema_tests/equality.sql
2022-01-15 08:16:42.569544 (MainThread): Parsing macros/schema_tests/mutually_exclusive_ranges.sql
2022-01-15 08:16:42.578023 (MainThread): Parsing macros/sql/date_spine.sql
2022-01-15 08:16:42.582294 (MainThread): Parsing macros/sql/nullcheck_table.sql
2022-01-15 08:16:42.583809 (MainThread): Parsing macros/sql/get_relations_by_pattern.sql
2022-01-15 08:16:42.587110 (MainThread): Parsing macros/sql/generate_series.sql
2022-01-15 08:16:42.616464 (MainThread): Parsing macros/sql/get_relations_by_prefix.sql
2022-01-15 08:16:42.620808 (MainThread): Parsing macros/sql/get_tables_by_prefix_sql.sql
2022-01-15 08:16:42.623019 (MainThread): Parsing macros/sql/star.sql
2022-01-15 08:16:42.627259 (MainThread): Parsing macros/sql/unpivot.sql
2022-01-15 08:16:42.637213 (MainThread): Parsing macros/sql/union.sql
2022-01-15 08:16:42.646810 (MainThread): Parsing macros/sql/groupby.sql
2022-01-15 08:16:42.648344 (MainThread): Parsing macros/sql/surrogate_key.sql
2022-01-15 08:16:42.652099 (MainThread): Parsing macros/sql/safe_add.sql
2022-01-15 08:16:42.653863 (MainThread): Parsing macros/sql/nullcheck.sql
2022-01-15 08:16:42.655731 (MainThread): Parsing macros/sql/get_tables_by_pattern_sql.sql
2022-01-15 08:16:42.662911 (MainThread): Parsing macros/sql/get_column_values.sql
2022-01-15 08:16:42.668380 (MainThread): Parsing macros/sql/pivot.sql
2022-01-15 08:16:42.672716 (MainThread): Parsing macros/sql/get_query_results_as_dict.sql
2022-01-15 08:16:42.675329 (MainThread): Parsing macros/sql/haversine_distance.sql
2022-01-15 08:16:42.981848 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-15 08:16:42.993795 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-15 08:16:42.997497 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.film_test".
2022-01-15 08:16:43.000276 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-15 08:16:43.008406 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-15 08:16:43.011357 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-15 08:16:43.047827 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:16:43.049788 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:16:43.051522 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:16:43.053208 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:16:43.056299 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:16:43.058064 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:16:43.070258 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:16:43.074254 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:16:43.088103 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:16:43.089874 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:16:43.113464 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cd4737a3-9101-40ba-9b1d-4b3eb7fbbea1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047030d0>]}
2022-01-15 08:16:43.121593 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-01-15 08:16:43.122122 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cd4737a3-9101-40ba-9b1d-4b3eb7fbbea1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104703160>]}
2022-01-15 08:16:43.122387 (MainThread): Found 6 models, 10 tests, 0 snapshots, 0 analyses, 347 macros, 0 operations, 0 seed files, 12 sources, 0 exposures
2022-01-15 08:16:43.123684 (MainThread): 
2022-01-15 08:16:43.124011 (MainThread): Acquiring new postgres connection "master".
2022-01-15 08:16:43.124979 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_dwh".
2022-01-15 08:16:43.134348 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-15 08:16:43.134526 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: BEGIN
2022-01-15 08:16:43.134675 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2022-01-15 08:16:43.536665 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.40 seconds
2022-01-15 08:16:43.537141 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-15 08:16:43.537396 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_dwh"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dwh'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dwh'
  
2022-01-15 08:16:43.604006 (ThreadPoolExecutor-1_0): SQL status: SELECT 6 in 0.07 seconds
2022-01-15 08:16:43.606452 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: ROLLBACK
2022-01-15 08:16:43.667919 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: Close
2022-01-15 08:16:43.677489 (MainThread): Using postgres connection "master".
2022-01-15 08:16:43.677768 (MainThread): On master: BEGIN
2022-01-15 08:16:43.677976 (MainThread): Opening a new connection, currently in state init
2022-01-15 08:16:44.060505 (MainThread): SQL status: BEGIN in 0.38 seconds
2022-01-15 08:16:44.060910 (MainThread): Using postgres connection "master".
2022-01-15 08:16:44.061172 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-15 08:16:44.139172 (MainThread): SQL status: SELECT 47 in 0.08 seconds
2022-01-15 08:16:44.142106 (MainThread): On master: ROLLBACK
2022-01-15 08:16:44.202648 (MainThread): On master: Close
2022-01-15 08:16:44.203456 (MainThread): 13:46:44 | Concurrency: 1 threads (target='dev')
2022-01-15 08:16:44.203832 (MainThread): 13:46:44 | 
2022-01-15 08:16:44.206082 (Thread-1): Began running node test.sakila_dbt_project.accepted_values_film_test_language_id__False__2.342d69cbc5
2022-01-15 08:16:44.206399 (Thread-1): 13:46:44 | 1 of 2 START test accepted_values_film_test_language_id__False__2.... [RUN]
2022-01-15 08:16:44.207339 (Thread-1): Acquiring new postgres connection "test.sakila_dbt_project.accepted_values_film_test_language_id__False__2.342d69cbc5".
2022-01-15 08:16:44.207639 (Thread-1): Compiling test.sakila_dbt_project.accepted_values_film_test_language_id__False__2.342d69cbc5
2022-01-15 08:16:44.211744 (Thread-1): Writing injected SQL for node "test.sakila_dbt_project.accepted_values_film_test_language_id__False__2.342d69cbc5"
2022-01-15 08:16:44.212452 (Thread-1): finished collecting timing info
2022-01-15 08:16:44.230958 (Thread-1): Writing runtime SQL for node "test.sakila_dbt_project.accepted_values_film_test_language_id__False__2.342d69cbc5"
2022-01-15 08:16:44.231676 (Thread-1): Using postgres connection "test.sakila_dbt_project.accepted_values_film_test_language_id__False__2.342d69cbc5".
2022-01-15 08:16:44.231863 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_language_id__False__2.342d69cbc5: BEGIN
2022-01-15 08:16:44.232037 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 08:16:44.601133 (Thread-1): SQL status: BEGIN in 0.37 seconds
2022-01-15 08:16:44.601562 (Thread-1): Using postgres connection "test.sakila_dbt_project.accepted_values_film_test_language_id__False__2.342d69cbc5".
2022-01-15 08:16:44.601851 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_language_id__False__2.342d69cbc5: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "test.sakila_dbt_project.accepted_values_film_test_language_id__False__2.342d69cbc5"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        language_id as value_field,
        count(*) as n_records

    from "sakila_wh"."dwh"."film_test"
    group by language_id

)

select *
from all_values
where value_field not in (
    2
)



      
    ) dbt_internal_test
2022-01-15 08:16:44.666804 (Thread-1): SQL status: SELECT 1 in 0.06 seconds
2022-01-15 08:16:44.670307 (Thread-1): finished collecting timing info
2022-01-15 08:16:44.670606 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_language_id__False__2.342d69cbc5: ROLLBACK
2022-01-15 08:16:44.732814 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_language_id__False__2.342d69cbc5: Close
2022-01-15 08:16:44.733728 (Thread-1): 13:46:44 | 1 of 2 FAIL 1 accepted_values_film_test_language_id__False__2........ [FAIL 1 in 0.53s]
2022-01-15 08:16:44.734016 (Thread-1): Finished running node test.sakila_dbt_project.accepted_values_film_test_language_id__False__2.342d69cbc5
2022-01-15 08:16:44.734244 (Thread-1): Began running node test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8
2022-01-15 08:16:44.734676 (Thread-1): 13:46:44 | 2 of 2 START test accepted_values_film_test_rating__NC_17__PG_13__G__R__PG [RUN]
2022-01-15 08:16:44.735041 (Thread-1): Acquiring new postgres connection "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8".
2022-01-15 08:16:44.735243 (Thread-1): Compiling test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8
2022-01-15 08:16:44.741619 (Thread-1): Writing injected SQL for node "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8"
2022-01-15 08:16:44.742316 (Thread-1): finished collecting timing info
2022-01-15 08:16:44.744507 (Thread-1): Writing runtime SQL for node "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8"
2022-01-15 08:16:44.745141 (Thread-1): Using postgres connection "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8".
2022-01-15 08:16:44.745324 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8: BEGIN
2022-01-15 08:16:44.745500 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 08:16:45.151752 (Thread-1): SQL status: BEGIN in 0.41 seconds
2022-01-15 08:16:45.152317 (Thread-1): Using postgres connection "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8".
2022-01-15 08:16:45.152697 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        rating as value_field,
        count(*) as n_records

    from "sakila_wh"."dwh"."film_test"
    group by rating

)

select *
from all_values
where value_field not in (
    'NC-17','PG-13','G','R','PG'
)



      
    ) dbt_internal_test
2022-01-15 08:16:45.223849 (Thread-1): SQL status: SELECT 1 in 0.07 seconds
2022-01-15 08:16:45.226086 (Thread-1): finished collecting timing info
2022-01-15 08:16:45.226385 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8: ROLLBACK
2022-01-15 08:16:45.288898 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8: Close
2022-01-15 08:16:45.289828 (Thread-1): 13:46:45 | 2 of 2 PASS accepted_values_film_test_rating__NC_17__PG_13__G__R__PG. [PASS in 0.55s]
2022-01-15 08:16:45.290199 (Thread-1): Finished running node test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8
2022-01-15 08:16:45.291406 (MainThread): Acquiring new postgres connection "master".
2022-01-15 08:16:45.291784 (MainThread): 13:46:45 | 
2022-01-15 08:16:45.292000 (MainThread): 13:46:45 | Finished running 2 tests in 2.17s.
2022-01-15 08:16:45.292193 (MainThread): Connection 'master' was properly closed.
2022-01-15 08:16:45.292349 (MainThread): Connection 'test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8' was properly closed.
2022-01-15 08:16:45.301546 (MainThread): 
2022-01-15 08:16:45.301805 (MainThread): Completed with 1 error and 0 warnings:
2022-01-15 08:16:45.302010 (MainThread): 
2022-01-15 08:16:45.302212 (MainThread): Failure in test accepted_values_film_test_language_id__False__2 (models/example/schema.yml)
2022-01-15 08:16:45.302399 (MainThread):   Got 1 result, configured to fail if != 0
2022-01-15 08:16:45.302580 (MainThread): 
2022-01-15 08:16:45.302765 (MainThread):   compiled SQL at target/compiled/sakila_dbt_project/models/example/schema.yml/schema_test/accepted_values_film_test_language_id__False__2.sql
2022-01-15 08:16:45.302960 (MainThread): 
Done. PASS=1 WARN=0 ERROR=1 SKIP=0 TOTAL=2
2022-01-15 08:16:45.303218 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1047f89a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1048d1910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1048d50a0>]}
2022-01-15 08:16:45.303500 (MainThread): Flushing usage events
2022-01-15 08:17:01.909871 (MainThread): Running with dbt=0.21.1
2022-01-15 08:17:01.991175 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, data=False, schema=False, fail_fast=False, store_failures=False, greedy=False, threads=None, version_check=True, select=['example.film_test'], exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.test.TestTask'>, which='test', rpc_method='test')
2022-01-15 08:17:01.993515 (MainThread): Tracking: tracking
2022-01-15 08:17:02.013529 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d26b8e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cc79250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d245dc0>]}
2022-01-15 08:17:02.036240 (MainThread): Partial parsing not enabled
2022-01-15 08:17:02.075751 (MainThread): Parsing macros/catalog.sql
2022-01-15 08:17:02.079200 (MainThread): Parsing macros/relations.sql
2022-01-15 08:17:02.080638 (MainThread): Parsing macros/adapters.sql
2022-01-15 08:17:02.104675 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2022-01-15 08:17:02.106333 (MainThread): Parsing macros/core.sql
2022-01-15 08:17:02.109932 (MainThread): Parsing macros/materializations/test.sql
2022-01-15 08:17:02.116478 (MainThread): Parsing macros/materializations/helpers.sql
2022-01-15 08:17:02.126788 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2022-01-15 08:17:02.128823 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2022-01-15 08:17:02.147789 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2022-01-15 08:17:02.179819 (MainThread): Parsing macros/materializations/seed/seed.sql
2022-01-15 08:17:02.201250 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2022-01-15 08:17:02.202892 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2022-01-15 08:17:02.212588 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2022-01-15 08:17:02.231435 (MainThread): Parsing macros/materializations/common/merge.sql
2022-01-15 08:17:02.244588 (MainThread): Parsing macros/materializations/table/table.sql
2022-01-15 08:17:02.252206 (MainThread): Parsing macros/materializations/view/view.sql
2022-01-15 08:17:02.259023 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2022-01-15 08:17:02.262557 (MainThread): Parsing macros/etc/get_custom_alias.sql
2022-01-15 08:17:02.263920 (MainThread): Parsing macros/etc/query.sql
2022-01-15 08:17:02.264805 (MainThread): Parsing macros/etc/is_incremental.sql
2022-01-15 08:17:02.266186 (MainThread): Parsing macros/etc/datetime.sql
2022-01-15 08:17:02.274293 (MainThread): Parsing macros/etc/where_subquery.sql
2022-01-15 08:17:02.276022 (MainThread): Parsing macros/etc/get_custom_schema.sql
2022-01-15 08:17:02.278298 (MainThread): Parsing macros/etc/get_custom_database.sql
2022-01-15 08:17:02.279772 (MainThread): Parsing macros/adapters/common.sql
2022-01-15 08:17:02.334071 (MainThread): Parsing macros/schema_tests/relationships.sql
2022-01-15 08:17:02.336053 (MainThread): Parsing macros/schema_tests/not_null.sql
2022-01-15 08:17:02.337165 (MainThread): Parsing macros/schema_tests/unique.sql
2022-01-15 08:17:02.338430 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2022-01-15 08:17:02.340603 (MainThread): Parsing macros/cross_db_utils/except.sql
2022-01-15 08:17:02.341730 (MainThread): Parsing macros/cross_db_utils/replace.sql
2022-01-15 08:17:02.342889 (MainThread): Parsing macros/cross_db_utils/concat.sql
2022-01-15 08:17:02.343812 (MainThread): Parsing macros/cross_db_utils/datatypes.sql
2022-01-15 08:17:02.349431 (MainThread): Parsing macros/cross_db_utils/_is_relation.sql
2022-01-15 08:17:02.350490 (MainThread): Parsing macros/cross_db_utils/length.sql
2022-01-15 08:17:02.351697 (MainThread): Parsing macros/cross_db_utils/dateadd.sql
2022-01-15 08:17:02.354461 (MainThread): Parsing macros/cross_db_utils/intersect.sql
2022-01-15 08:17:02.355526 (MainThread): Parsing macros/cross_db_utils/right.sql
2022-01-15 08:17:02.357908 (MainThread): Parsing macros/cross_db_utils/datediff.sql
2022-01-15 08:17:02.367535 (MainThread): Parsing macros/cross_db_utils/safe_cast.sql
2022-01-15 08:17:02.369235 (MainThread): Parsing macros/cross_db_utils/hash.sql
2022-01-15 08:17:02.370524 (MainThread): Parsing macros/cross_db_utils/cast_bool_to_text.sql
2022-01-15 08:17:02.371841 (MainThread): Parsing macros/cross_db_utils/identifier.sql
2022-01-15 08:17:02.373563 (MainThread): Parsing macros/cross_db_utils/position.sql
2022-01-15 08:17:02.375100 (MainThread): Parsing macros/cross_db_utils/literal.sql
2022-01-15 08:17:02.375991 (MainThread): Parsing macros/cross_db_utils/current_timestamp.sql
2022-01-15 08:17:02.379484 (MainThread): Parsing macros/cross_db_utils/width_bucket.sql
2022-01-15 08:17:02.384375 (MainThread): Parsing macros/cross_db_utils/last_day.sql
2022-01-15 08:17:02.387768 (MainThread): Parsing macros/cross_db_utils/split_part.sql
2022-01-15 08:17:02.389523 (MainThread): Parsing macros/cross_db_utils/date_trunc.sql
2022-01-15 08:17:02.391160 (MainThread): Parsing macros/cross_db_utils/_is_ephemeral.sql
2022-01-15 08:17:02.393001 (MainThread): Parsing macros/materializations/insert_by_period_materialization.sql
2022-01-15 08:17:02.416653 (MainThread): Parsing macros/web/get_url_host.sql
2022-01-15 08:17:02.418430 (MainThread): Parsing macros/web/get_url_path.sql
2022-01-15 08:17:02.420873 (MainThread): Parsing macros/web/get_url_parameter.sql
2022-01-15 08:17:02.422380 (MainThread): Parsing macros/jinja_helpers/pretty_log_format.sql
2022-01-15 08:17:02.423594 (MainThread): Parsing macros/jinja_helpers/pretty_time.sql
2022-01-15 08:17:02.424817 (MainThread): Parsing macros/jinja_helpers/log_info.sql
2022-01-15 08:17:02.425880 (MainThread): Parsing macros/jinja_helpers/slugify.sql
2022-01-15 08:17:02.427103 (MainThread): Parsing macros/schema_tests/fewer_rows_than.sql
2022-01-15 08:17:02.428699 (MainThread): Parsing macros/schema_tests/equal_rowcount.sql
2022-01-15 08:17:02.430212 (MainThread): Parsing macros/schema_tests/relationships_where.sql
2022-01-15 08:17:02.432337 (MainThread): Parsing macros/schema_tests/recency.sql
2022-01-15 08:17:02.434026 (MainThread): Parsing macros/schema_tests/not_constant.sql
2022-01-15 08:17:02.435188 (MainThread): Parsing macros/schema_tests/accepted_range.sql
2022-01-15 08:17:02.437563 (MainThread): Parsing macros/schema_tests/not_accepted_values.sql
2022-01-15 08:17:02.439595 (MainThread): Parsing macros/schema_tests/test_unique_where.sql
2022-01-15 08:17:02.441044 (MainThread): Parsing macros/schema_tests/at_least_one.sql
2022-01-15 08:17:02.442241 (MainThread): Parsing macros/schema_tests/unique_combination_of_columns.sql
2022-01-15 08:17:02.444886 (MainThread): Parsing macros/schema_tests/cardinality_equality.sql
2022-01-15 08:17:02.446747 (MainThread): Parsing macros/schema_tests/expression_is_true.sql
2022-01-15 08:17:02.448544 (MainThread): Parsing macros/schema_tests/sequential_values.sql
2022-01-15 08:17:02.451412 (MainThread): Parsing macros/schema_tests/test_not_null_where.sql
2022-01-15 08:17:02.452758 (MainThread): Parsing macros/schema_tests/equality.sql
2022-01-15 08:17:02.456086 (MainThread): Parsing macros/schema_tests/mutually_exclusive_ranges.sql
2022-01-15 08:17:02.464475 (MainThread): Parsing macros/sql/date_spine.sql
2022-01-15 08:17:02.469121 (MainThread): Parsing macros/sql/nullcheck_table.sql
2022-01-15 08:17:02.470662 (MainThread): Parsing macros/sql/get_relations_by_pattern.sql
2022-01-15 08:17:02.474098 (MainThread): Parsing macros/sql/generate_series.sql
2022-01-15 08:17:02.503226 (MainThread): Parsing macros/sql/get_relations_by_prefix.sql
2022-01-15 08:17:02.508020 (MainThread): Parsing macros/sql/get_tables_by_prefix_sql.sql
2022-01-15 08:17:02.510167 (MainThread): Parsing macros/sql/star.sql
2022-01-15 08:17:02.514666 (MainThread): Parsing macros/sql/unpivot.sql
2022-01-15 08:17:02.524645 (MainThread): Parsing macros/sql/union.sql
2022-01-15 08:17:02.534779 (MainThread): Parsing macros/sql/groupby.sql
2022-01-15 08:17:02.536397 (MainThread): Parsing macros/sql/surrogate_key.sql
2022-01-15 08:17:02.540259 (MainThread): Parsing macros/sql/safe_add.sql
2022-01-15 08:17:02.542191 (MainThread): Parsing macros/sql/nullcheck.sql
2022-01-15 08:17:02.544013 (MainThread): Parsing macros/sql/get_tables_by_pattern_sql.sql
2022-01-15 08:17:02.550988 (MainThread): Parsing macros/sql/get_column_values.sql
2022-01-15 08:17:02.556313 (MainThread): Parsing macros/sql/pivot.sql
2022-01-15 08:17:02.560735 (MainThread): Parsing macros/sql/get_query_results_as_dict.sql
2022-01-15 08:17:02.563194 (MainThread): Parsing macros/sql/haversine_distance.sql
2022-01-15 08:17:02.870065 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-15 08:17:02.882073 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-15 08:17:02.885607 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.film_test".
2022-01-15 08:17:02.888563 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-15 08:17:02.896741 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-15 08:17:02.899660 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-15 08:17:02.934472 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:17:02.936257 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:17:02.937957 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:17:02.939653 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:17:02.942355 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:17:02.944004 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:17:02.956183 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:17:02.960130 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:17:02.974080 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:17:02.975815 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:17:02.999052 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '04b2b0f5-1384-43a9-8b86-c7fd45018420', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d3f70d0>]}
2022-01-15 08:17:03.007452 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-01-15 08:17:03.008091 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '04b2b0f5-1384-43a9-8b86-c7fd45018420', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d3f7160>]}
2022-01-15 08:17:03.008345 (MainThread): Found 6 models, 10 tests, 0 snapshots, 0 analyses, 347 macros, 0 operations, 0 seed files, 12 sources, 0 exposures
2022-01-15 08:17:03.009620 (MainThread): 
2022-01-15 08:17:03.009937 (MainThread): Acquiring new postgres connection "master".
2022-01-15 08:17:03.010840 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_dwh".
2022-01-15 08:17:03.019961 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-15 08:17:03.020140 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: BEGIN
2022-01-15 08:17:03.020292 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2022-01-15 08:17:03.418037 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.40 seconds
2022-01-15 08:17:03.418436 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-15 08:17:03.418710 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_dwh"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dwh'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dwh'
  
2022-01-15 08:17:03.485679 (ThreadPoolExecutor-1_0): SQL status: SELECT 6 in 0.07 seconds
2022-01-15 08:17:03.488391 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: ROLLBACK
2022-01-15 08:17:03.550223 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: Close
2022-01-15 08:17:03.557014 (MainThread): Using postgres connection "master".
2022-01-15 08:17:03.557298 (MainThread): On master: BEGIN
2022-01-15 08:17:03.557497 (MainThread): Opening a new connection, currently in state init
2022-01-15 08:17:03.930480 (MainThread): SQL status: BEGIN in 0.37 seconds
2022-01-15 08:17:03.930766 (MainThread): Using postgres connection "master".
2022-01-15 08:17:03.930936 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-15 08:17:04.011395 (MainThread): SQL status: SELECT 47 in 0.08 seconds
2022-01-15 08:17:04.014489 (MainThread): On master: ROLLBACK
2022-01-15 08:17:04.074709 (MainThread): On master: Close
2022-01-15 08:17:04.075560 (MainThread): 13:47:04 | Concurrency: 1 threads (target='dev')
2022-01-15 08:17:04.075892 (MainThread): 13:47:04 | 
2022-01-15 08:17:04.077787 (Thread-1): Began running node test.sakila_dbt_project.accepted_values_film_test_language_id__False__2__1.c6efaacf18
2022-01-15 08:17:04.078039 (Thread-1): 13:47:04 | 1 of 2 START test accepted_values_film_test_language_id__False__2__1. [RUN]
2022-01-15 08:17:04.078611 (Thread-1): Acquiring new postgres connection "test.sakila_dbt_project.accepted_values_film_test_language_id__False__2__1.c6efaacf18".
2022-01-15 08:17:04.078839 (Thread-1): Compiling test.sakila_dbt_project.accepted_values_film_test_language_id__False__2__1.c6efaacf18
2022-01-15 08:17:04.082743 (Thread-1): Writing injected SQL for node "test.sakila_dbt_project.accepted_values_film_test_language_id__False__2__1.c6efaacf18"
2022-01-15 08:17:04.083358 (Thread-1): finished collecting timing info
2022-01-15 08:17:04.101588 (Thread-1): Writing runtime SQL for node "test.sakila_dbt_project.accepted_values_film_test_language_id__False__2__1.c6efaacf18"
2022-01-15 08:17:04.102533 (Thread-1): Using postgres connection "test.sakila_dbt_project.accepted_values_film_test_language_id__False__2__1.c6efaacf18".
2022-01-15 08:17:04.102736 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_language_id__False__2__1.c6efaacf18: BEGIN
2022-01-15 08:17:04.102926 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 08:17:04.487536 (Thread-1): SQL status: BEGIN in 0.38 seconds
2022-01-15 08:17:04.488038 (Thread-1): Using postgres connection "test.sakila_dbt_project.accepted_values_film_test_language_id__False__2__1.c6efaacf18".
2022-01-15 08:17:04.488310 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_language_id__False__2__1.c6efaacf18: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "test.sakila_dbt_project.accepted_values_film_test_language_id__False__2__1.c6efaacf18"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        language_id as value_field,
        count(*) as n_records

    from "sakila_wh"."dwh"."film_test"
    group by language_id

)

select *
from all_values
where value_field not in (
    2,1
)



      
    ) dbt_internal_test
2022-01-15 08:17:04.553341 (Thread-1): SQL status: SELECT 1 in 0.06 seconds
2022-01-15 08:17:04.556443 (Thread-1): finished collecting timing info
2022-01-15 08:17:04.556767 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_language_id__False__2__1.c6efaacf18: ROLLBACK
2022-01-15 08:17:04.616910 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_language_id__False__2__1.c6efaacf18: Close
2022-01-15 08:17:04.617914 (Thread-1): 13:47:04 | 1 of 2 PASS accepted_values_film_test_language_id__False__2__1....... [PASS in 0.54s]
2022-01-15 08:17:04.618379 (Thread-1): Finished running node test.sakila_dbt_project.accepted_values_film_test_language_id__False__2__1.c6efaacf18
2022-01-15 08:17:04.618773 (Thread-1): Began running node test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8
2022-01-15 08:17:04.619198 (Thread-1): 13:47:04 | 2 of 2 START test accepted_values_film_test_rating__NC_17__PG_13__G__R__PG [RUN]
2022-01-15 08:17:04.619689 (Thread-1): Acquiring new postgres connection "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8".
2022-01-15 08:17:04.619935 (Thread-1): Compiling test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8
2022-01-15 08:17:04.626660 (Thread-1): Writing injected SQL for node "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8"
2022-01-15 08:17:04.627349 (Thread-1): finished collecting timing info
2022-01-15 08:17:04.629504 (Thread-1): Writing runtime SQL for node "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8"
2022-01-15 08:17:04.630074 (Thread-1): Using postgres connection "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8".
2022-01-15 08:17:04.630257 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8: BEGIN
2022-01-15 08:17:04.630431 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 08:17:04.997339 (Thread-1): SQL status: BEGIN in 0.37 seconds
2022-01-15 08:17:04.997724 (Thread-1): Using postgres connection "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8".
2022-01-15 08:17:04.997986 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        rating as value_field,
        count(*) as n_records

    from "sakila_wh"."dwh"."film_test"
    group by rating

)

select *
from all_values
where value_field not in (
    'NC-17','PG-13','G','R','PG'
)



      
    ) dbt_internal_test
2022-01-15 08:17:05.064077 (Thread-1): SQL status: SELECT 1 in 0.07 seconds
2022-01-15 08:17:05.066108 (Thread-1): finished collecting timing info
2022-01-15 08:17:05.066415 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8: ROLLBACK
2022-01-15 08:17:05.129197 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8: Close
2022-01-15 08:17:05.130026 (Thread-1): 13:47:05 | 2 of 2 PASS accepted_values_film_test_rating__NC_17__PG_13__G__R__PG. [PASS in 0.51s]
2022-01-15 08:17:05.130317 (Thread-1): Finished running node test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8
2022-01-15 08:17:05.131530 (MainThread): Acquiring new postgres connection "master".
2022-01-15 08:17:05.131910 (MainThread): 13:47:05 | 
2022-01-15 08:17:05.132125 (MainThread): 13:47:05 | Finished running 2 tests in 2.12s.
2022-01-15 08:17:05.132319 (MainThread): Connection 'master' was properly closed.
2022-01-15 08:17:05.132474 (MainThread): Connection 'test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8' was properly closed.
2022-01-15 08:17:05.141460 (MainThread): 
2022-01-15 08:17:05.141709 (MainThread): Completed successfully
2022-01-15 08:17:05.141917 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2022-01-15 08:17:05.142179 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d4bb1c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d599b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d498520>]}
2022-01-15 08:17:05.142444 (MainThread): Flushing usage events
2022-01-15 08:23:30.769246 (MainThread): Running with dbt=0.21.1
2022-01-15 08:23:30.861698 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, data=False, schema=False, fail_fast=False, store_failures=False, greedy=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.test.TestTask'>, which='test', rpc_method='test')
2022-01-15 08:23:30.863559 (MainThread): Tracking: tracking
2022-01-15 08:23:30.882039 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107205640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107801e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107801340>]}
2022-01-15 08:23:30.904109 (MainThread): Partial parsing not enabled
2022-01-15 08:23:30.944583 (MainThread): Parsing macros/catalog.sql
2022-01-15 08:23:30.948065 (MainThread): Parsing macros/relations.sql
2022-01-15 08:23:30.949533 (MainThread): Parsing macros/adapters.sql
2022-01-15 08:23:30.974426 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2022-01-15 08:23:30.976379 (MainThread): Parsing macros/core.sql
2022-01-15 08:23:30.980604 (MainThread): Parsing macros/materializations/test.sql
2022-01-15 08:23:30.988164 (MainThread): Parsing macros/materializations/helpers.sql
2022-01-15 08:23:30.998740 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2022-01-15 08:23:31.000543 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2022-01-15 08:23:31.017081 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2022-01-15 08:23:31.048235 (MainThread): Parsing macros/materializations/seed/seed.sql
2022-01-15 08:23:31.070074 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2022-01-15 08:23:31.071792 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2022-01-15 08:23:31.081457 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2022-01-15 08:23:31.100696 (MainThread): Parsing macros/materializations/common/merge.sql
2022-01-15 08:23:31.114538 (MainThread): Parsing macros/materializations/table/table.sql
2022-01-15 08:23:31.122150 (MainThread): Parsing macros/materializations/view/view.sql
2022-01-15 08:23:31.129379 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2022-01-15 08:23:31.132940 (MainThread): Parsing macros/etc/get_custom_alias.sql
2022-01-15 08:23:31.134670 (MainThread): Parsing macros/etc/query.sql
2022-01-15 08:23:31.135690 (MainThread): Parsing macros/etc/is_incremental.sql
2022-01-15 08:23:31.137215 (MainThread): Parsing macros/etc/datetime.sql
2022-01-15 08:23:31.145210 (MainThread): Parsing macros/etc/where_subquery.sql
2022-01-15 08:23:31.146903 (MainThread): Parsing macros/etc/get_custom_schema.sql
2022-01-15 08:23:31.149156 (MainThread): Parsing macros/etc/get_custom_database.sql
2022-01-15 08:23:31.150637 (MainThread): Parsing macros/adapters/common.sql
2022-01-15 08:23:31.203722 (MainThread): Parsing macros/schema_tests/relationships.sql
2022-01-15 08:23:31.205358 (MainThread): Parsing macros/schema_tests/not_null.sql
2022-01-15 08:23:31.206542 (MainThread): Parsing macros/schema_tests/unique.sql
2022-01-15 08:23:31.207800 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2022-01-15 08:23:31.209856 (MainThread): Parsing macros/cross_db_utils/except.sql
2022-01-15 08:23:31.210845 (MainThread): Parsing macros/cross_db_utils/replace.sql
2022-01-15 08:23:31.212011 (MainThread): Parsing macros/cross_db_utils/concat.sql
2022-01-15 08:23:31.212954 (MainThread): Parsing macros/cross_db_utils/datatypes.sql
2022-01-15 08:23:31.218763 (MainThread): Parsing macros/cross_db_utils/_is_relation.sql
2022-01-15 08:23:31.219855 (MainThread): Parsing macros/cross_db_utils/length.sql
2022-01-15 08:23:31.221111 (MainThread): Parsing macros/cross_db_utils/dateadd.sql
2022-01-15 08:23:31.223949 (MainThread): Parsing macros/cross_db_utils/intersect.sql
2022-01-15 08:23:31.224982 (MainThread): Parsing macros/cross_db_utils/right.sql
2022-01-15 08:23:31.227181 (MainThread): Parsing macros/cross_db_utils/datediff.sql
2022-01-15 08:23:31.236816 (MainThread): Parsing macros/cross_db_utils/safe_cast.sql
2022-01-15 08:23:31.238647 (MainThread): Parsing macros/cross_db_utils/hash.sql
2022-01-15 08:23:31.239993 (MainThread): Parsing macros/cross_db_utils/cast_bool_to_text.sql
2022-01-15 08:23:31.241418 (MainThread): Parsing macros/cross_db_utils/identifier.sql
2022-01-15 08:23:31.243160 (MainThread): Parsing macros/cross_db_utils/position.sql
2022-01-15 08:23:31.245284 (MainThread): Parsing macros/cross_db_utils/literal.sql
2022-01-15 08:23:31.248191 (MainThread): Parsing macros/cross_db_utils/current_timestamp.sql
2022-01-15 08:23:31.252572 (MainThread): Parsing macros/cross_db_utils/width_bucket.sql
2022-01-15 08:23:31.260134 (MainThread): Parsing macros/cross_db_utils/last_day.sql
2022-01-15 08:23:31.265087 (MainThread): Parsing macros/cross_db_utils/split_part.sql
2022-01-15 08:23:31.267753 (MainThread): Parsing macros/cross_db_utils/date_trunc.sql
2022-01-15 08:23:31.269765 (MainThread): Parsing macros/cross_db_utils/_is_ephemeral.sql
2022-01-15 08:23:31.272334 (MainThread): Parsing macros/materializations/insert_by_period_materialization.sql
2022-01-15 08:23:31.302556 (MainThread): Parsing macros/web/get_url_host.sql
2022-01-15 08:23:31.305279 (MainThread): Parsing macros/web/get_url_path.sql
2022-01-15 08:23:31.308480 (MainThread): Parsing macros/web/get_url_parameter.sql
2022-01-15 08:23:31.310286 (MainThread): Parsing macros/jinja_helpers/pretty_log_format.sql
2022-01-15 08:23:31.311608 (MainThread): Parsing macros/jinja_helpers/pretty_time.sql
2022-01-15 08:23:31.313105 (MainThread): Parsing macros/jinja_helpers/log_info.sql
2022-01-15 08:23:31.314617 (MainThread): Parsing macros/jinja_helpers/slugify.sql
2022-01-15 08:23:31.316030 (MainThread): Parsing macros/schema_tests/fewer_rows_than.sql
2022-01-15 08:23:31.318330 (MainThread): Parsing macros/schema_tests/equal_rowcount.sql
2022-01-15 08:23:31.320616 (MainThread): Parsing macros/schema_tests/relationships_where.sql
2022-01-15 08:23:31.323338 (MainThread): Parsing macros/schema_tests/recency.sql
2022-01-15 08:23:31.325582 (MainThread): Parsing macros/schema_tests/not_constant.sql
2022-01-15 08:23:31.327114 (MainThread): Parsing macros/schema_tests/accepted_range.sql
2022-01-15 08:23:31.329917 (MainThread): Parsing macros/schema_tests/not_accepted_values.sql
2022-01-15 08:23:31.332220 (MainThread): Parsing macros/schema_tests/test_unique_where.sql
2022-01-15 08:23:31.333796 (MainThread): Parsing macros/schema_tests/at_least_one.sql
2022-01-15 08:23:31.335371 (MainThread): Parsing macros/schema_tests/unique_combination_of_columns.sql
2022-01-15 08:23:31.338535 (MainThread): Parsing macros/schema_tests/cardinality_equality.sql
2022-01-15 08:23:31.340829 (MainThread): Parsing macros/schema_tests/expression_is_true.sql
2022-01-15 08:23:31.343090 (MainThread): Parsing macros/schema_tests/sequential_values.sql
2022-01-15 08:23:31.346438 (MainThread): Parsing macros/schema_tests/test_not_null_where.sql
2022-01-15 08:23:31.348019 (MainThread): Parsing macros/schema_tests/equality.sql
2022-01-15 08:23:31.352182 (MainThread): Parsing macros/schema_tests/mutually_exclusive_ranges.sql
2022-01-15 08:23:31.362224 (MainThread): Parsing macros/sql/date_spine.sql
2022-01-15 08:23:31.367267 (MainThread): Parsing macros/sql/nullcheck_table.sql
2022-01-15 08:23:31.369044 (MainThread): Parsing macros/sql/get_relations_by_pattern.sql
2022-01-15 08:23:31.373032 (MainThread): Parsing macros/sql/generate_series.sql
2022-01-15 08:23:31.406922 (MainThread): Parsing macros/sql/get_relations_by_prefix.sql
2022-01-15 08:23:31.411569 (MainThread): Parsing macros/sql/get_tables_by_prefix_sql.sql
2022-01-15 08:23:31.413713 (MainThread): Parsing macros/sql/star.sql
2022-01-15 08:23:31.417954 (MainThread): Parsing macros/sql/unpivot.sql
2022-01-15 08:23:31.428329 (MainThread): Parsing macros/sql/union.sql
2022-01-15 08:23:31.438679 (MainThread): Parsing macros/sql/groupby.sql
2022-01-15 08:23:31.440446 (MainThread): Parsing macros/sql/surrogate_key.sql
2022-01-15 08:23:31.444314 (MainThread): Parsing macros/sql/safe_add.sql
2022-01-15 08:23:31.446948 (MainThread): Parsing macros/sql/nullcheck.sql
2022-01-15 08:23:31.448931 (MainThread): Parsing macros/sql/get_tables_by_pattern_sql.sql
2022-01-15 08:23:31.456559 (MainThread): Parsing macros/sql/get_column_values.sql
2022-01-15 08:23:31.462100 (MainThread): Parsing macros/sql/pivot.sql
2022-01-15 08:23:31.466688 (MainThread): Parsing macros/sql/get_query_results_as_dict.sql
2022-01-15 08:23:31.469398 (MainThread): Parsing macros/sql/haversine_distance.sql
2022-01-15 08:23:31.785368 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-15 08:23:31.798535 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-15 08:23:31.802692 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.film_test".
2022-01-15 08:23:31.806002 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-15 08:23:31.815147 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-15 08:23:31.818194 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-15 08:23:31.829557 (MainThread): Acquiring new postgres connection "test.sakila_dbt_project.film_replacementcost_30".
2022-01-15 08:23:31.831377 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:23:31.863234 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:23:31.864979 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:23:31.866663 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:23:31.868665 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:23:31.870334 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:23:31.872006 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:23:31.884180 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:23:31.888219 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:23:31.902207 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:23:31.903880 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:23:31.927300 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '434b11fd-347b-4468-8d8a-92fa9f8938ad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a23fa0>]}
2022-01-15 08:23:31.935594 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-01-15 08:23:31.936162 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '434b11fd-347b-4468-8d8a-92fa9f8938ad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10787d580>]}
2022-01-15 08:23:31.936424 (MainThread): Found 6 models, 11 tests, 0 snapshots, 0 analyses, 347 macros, 0 operations, 0 seed files, 12 sources, 0 exposures
2022-01-15 08:23:31.938181 (MainThread): 
2022-01-15 08:23:31.938524 (MainThread): Acquiring new postgres connection "master".
2022-01-15 08:23:31.939479 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_dwh".
2022-01-15 08:23:31.948802 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-15 08:23:31.949009 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: BEGIN
2022-01-15 08:23:31.949167 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2022-01-15 08:23:32.361987 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.41 seconds
2022-01-15 08:23:32.362321 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-15 08:23:32.362529 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_dwh"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dwh'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dwh'
  
2022-01-15 08:23:32.428451 (ThreadPoolExecutor-1_0): SQL status: SELECT 6 in 0.07 seconds
2022-01-15 08:23:32.430015 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: ROLLBACK
2022-01-15 08:23:32.490777 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: Close
2022-01-15 08:23:32.495807 (MainThread): Using postgres connection "master".
2022-01-15 08:23:32.496029 (MainThread): On master: BEGIN
2022-01-15 08:23:32.496197 (MainThread): Opening a new connection, currently in state init
2022-01-15 08:23:32.866806 (MainThread): SQL status: BEGIN in 0.37 seconds
2022-01-15 08:23:32.867205 (MainThread): Using postgres connection "master".
2022-01-15 08:23:32.867455 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-15 08:23:32.951662 (MainThread): SQL status: SELECT 47 in 0.08 seconds
2022-01-15 08:23:32.954904 (MainThread): On master: ROLLBACK
2022-01-15 08:23:33.016693 (MainThread): On master: Close
2022-01-15 08:23:33.017528 (MainThread): 13:53:33 | Concurrency: 1 threads (target='dev')
2022-01-15 08:23:33.017868 (MainThread): 13:53:33 | 
2022-01-15 08:23:33.020383 (Thread-1): Began running node test.sakila_dbt_project.accepted_values_film_test_language_id__False__2__1.c6efaacf18
2022-01-15 08:23:33.020662 (Thread-1): 13:53:33 | 1 of 11 START test accepted_values_film_test_language_id__False__2__1 [RUN]
2022-01-15 08:23:33.021057 (Thread-1): Acquiring new postgres connection "test.sakila_dbt_project.accepted_values_film_test_language_id__False__2__1.c6efaacf18".
2022-01-15 08:23:33.021267 (Thread-1): Compiling test.sakila_dbt_project.accepted_values_film_test_language_id__False__2__1.c6efaacf18
2022-01-15 08:23:33.024995 (Thread-1): Writing injected SQL for node "test.sakila_dbt_project.accepted_values_film_test_language_id__False__2__1.c6efaacf18"
2022-01-15 08:23:33.025549 (Thread-1): finished collecting timing info
2022-01-15 08:23:33.042407 (Thread-1): Writing runtime SQL for node "test.sakila_dbt_project.accepted_values_film_test_language_id__False__2__1.c6efaacf18"
2022-01-15 08:23:33.043120 (Thread-1): Using postgres connection "test.sakila_dbt_project.accepted_values_film_test_language_id__False__2__1.c6efaacf18".
2022-01-15 08:23:33.043294 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_language_id__False__2__1.c6efaacf18: BEGIN
2022-01-15 08:23:33.043451 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 08:23:33.421706 (Thread-1): SQL status: BEGIN in 0.38 seconds
2022-01-15 08:23:33.422060 (Thread-1): Using postgres connection "test.sakila_dbt_project.accepted_values_film_test_language_id__False__2__1.c6efaacf18".
2022-01-15 08:23:33.422277 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_language_id__False__2__1.c6efaacf18: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "test.sakila_dbt_project.accepted_values_film_test_language_id__False__2__1.c6efaacf18"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        language_id as value_field,
        count(*) as n_records

    from "sakila_wh"."dwh"."film_test"
    group by language_id

)

select *
from all_values
where value_field not in (
    2,1
)



      
    ) dbt_internal_test
2022-01-15 08:23:33.490704 (Thread-1): SQL status: SELECT 1 in 0.07 seconds
2022-01-15 08:23:33.493734 (Thread-1): finished collecting timing info
2022-01-15 08:23:33.494093 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_language_id__False__2__1.c6efaacf18: ROLLBACK
2022-01-15 08:23:33.558232 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_language_id__False__2__1.c6efaacf18: Close
2022-01-15 08:23:33.559008 (Thread-1): 13:53:33 | 1 of 11 PASS accepted_values_film_test_language_id__False__2__1...... [PASS in 0.54s]
2022-01-15 08:23:33.559334 (Thread-1): Finished running node test.sakila_dbt_project.accepted_values_film_test_language_id__False__2__1.c6efaacf18
2022-01-15 08:23:33.559611 (Thread-1): Began running node test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8
2022-01-15 08:23:33.559978 (Thread-1): 13:53:33 | 2 of 11 START test accepted_values_film_test_rating__NC_17__PG_13__G__R__PG [RUN]
2022-01-15 08:23:33.560421 (Thread-1): Acquiring new postgres connection "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8".
2022-01-15 08:23:33.560614 (Thread-1): Compiling test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8
2022-01-15 08:23:33.567509 (Thread-1): Writing injected SQL for node "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8"
2022-01-15 08:23:33.568254 (Thread-1): finished collecting timing info
2022-01-15 08:23:33.570429 (Thread-1): Writing runtime SQL for node "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8"
2022-01-15 08:23:33.571047 (Thread-1): Using postgres connection "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8".
2022-01-15 08:23:33.571233 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8: BEGIN
2022-01-15 08:23:33.571413 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 08:23:33.942836 (Thread-1): SQL status: BEGIN in 0.37 seconds
2022-01-15 08:23:33.943247 (Thread-1): Using postgres connection "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8".
2022-01-15 08:23:33.943507 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        rating as value_field,
        count(*) as n_records

    from "sakila_wh"."dwh"."film_test"
    group by rating

)

select *
from all_values
where value_field not in (
    'NC-17','PG-13','G','R','PG'
)



      
    ) dbt_internal_test
2022-01-15 08:23:34.009303 (Thread-1): SQL status: SELECT 1 in 0.07 seconds
2022-01-15 08:23:34.011534 (Thread-1): finished collecting timing info
2022-01-15 08:23:34.011828 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8: ROLLBACK
2022-01-15 08:23:34.072255 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8: Close
2022-01-15 08:23:34.073158 (Thread-1): 13:53:34 | 2 of 11 PASS accepted_values_film_test_rating__NC_17__PG_13__G__R__PG [PASS in 0.51s]
2022-01-15 08:23:34.073557 (Thread-1): Finished running node test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8
2022-01-15 08:23:34.073840 (Thread-1): Began running node test.sakila_dbt_project.film_replacementcost_30
2022-01-15 08:23:34.074199 (Thread-1): 13:53:34 | 3 of 11 START test film_replacementcost_30........................... [RUN]
2022-01-15 08:23:34.074585 (Thread-1): Acquiring new postgres connection "test.sakila_dbt_project.film_replacementcost_30".
2022-01-15 08:23:34.074780 (Thread-1): Compiling test.sakila_dbt_project.film_replacementcost_30
2022-01-15 08:23:34.076421 (Thread-1): Writing injected SQL for node "test.sakila_dbt_project.film_replacementcost_30"
2022-01-15 08:23:34.077257 (Thread-1): finished collecting timing info
2022-01-15 08:23:34.079364 (Thread-1): Writing runtime SQL for node "test.sakila_dbt_project.film_replacementcost_30"
2022-01-15 08:23:34.080190 (Thread-1): Using postgres connection "test.sakila_dbt_project.film_replacementcost_30".
2022-01-15 08:23:34.080373 (Thread-1): On test.sakila_dbt_project.film_replacementcost_30: BEGIN
2022-01-15 08:23:34.080544 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 08:23:34.449405 (Thread-1): SQL status: BEGIN in 0.37 seconds
2022-01-15 08:23:34.450021 (Thread-1): Using postgres connection "test.sakila_dbt_project.film_replacementcost_30".
2022-01-15 08:23:34.450369 (Thread-1): On test.sakila_dbt_project.film_replacementcost_30: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "test.sakila_dbt_project.film_replacementcost_30"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      select * from 
dwh.film_test  
where replacement_cost > 29
      
    ) dbt_internal_test
2022-01-15 08:23:34.514797 (Thread-1): SQL status: SELECT 1 in 0.06 seconds
2022-01-15 08:23:34.517210 (Thread-1): finished collecting timing info
2022-01-15 08:23:34.517577 (Thread-1): On test.sakila_dbt_project.film_replacementcost_30: ROLLBACK
2022-01-15 08:23:34.581555 (Thread-1): On test.sakila_dbt_project.film_replacementcost_30: Close
2022-01-15 08:23:34.582379 (Thread-1): 13:53:34 | 3 of 11 FAIL 53 film_replacementcost_30.............................. [FAIL 53 in 0.51s]
2022-01-15 08:23:34.582740 (Thread-1): Finished running node test.sakila_dbt_project.film_replacementcost_30
2022-01-15 08:23:34.583071 (Thread-1): Began running node test.sakila_dbt_project.not_null_dim_date_date_dim_id.b5878fcef1
2022-01-15 08:23:34.583538 (Thread-1): 13:53:34 | 4 of 11 START test not_null_dim_date_date_dim_id..................... [RUN]
2022-01-15 08:23:34.584138 (Thread-1): Acquiring new postgres connection "test.sakila_dbt_project.not_null_dim_date_date_dim_id.b5878fcef1".
2022-01-15 08:23:34.584408 (Thread-1): Compiling test.sakila_dbt_project.not_null_dim_date_date_dim_id.b5878fcef1
2022-01-15 08:23:34.591953 (Thread-1): Writing injected SQL for node "test.sakila_dbt_project.not_null_dim_date_date_dim_id.b5878fcef1"
2022-01-15 08:23:34.592954 (Thread-1): finished collecting timing info
2022-01-15 08:23:34.595282 (Thread-1): Writing runtime SQL for node "test.sakila_dbt_project.not_null_dim_date_date_dim_id.b5878fcef1"
2022-01-15 08:23:34.596242 (Thread-1): Using postgres connection "test.sakila_dbt_project.not_null_dim_date_date_dim_id.b5878fcef1".
2022-01-15 08:23:34.596453 (Thread-1): On test.sakila_dbt_project.not_null_dim_date_date_dim_id.b5878fcef1: BEGIN
2022-01-15 08:23:34.596657 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 08:23:34.967026 (Thread-1): SQL status: BEGIN in 0.37 seconds
2022-01-15 08:23:34.967428 (Thread-1): Using postgres connection "test.sakila_dbt_project.not_null_dim_date_date_dim_id.b5878fcef1".
2022-01-15 08:23:34.967711 (Thread-1): On test.sakila_dbt_project.not_null_dim_date_date_dim_id.b5878fcef1: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "test.sakila_dbt_project.not_null_dim_date_date_dim_id.b5878fcef1"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from "sakila_wh"."dwh"."dim_date"
where date_dim_id is null



      
    ) dbt_internal_test
2022-01-15 08:23:35.032186 (Thread-1): SQL status: SELECT 1 in 0.06 seconds
2022-01-15 08:23:35.034512 (Thread-1): finished collecting timing info
2022-01-15 08:23:35.034864 (Thread-1): On test.sakila_dbt_project.not_null_dim_date_date_dim_id.b5878fcef1: ROLLBACK
2022-01-15 08:23:35.095072 (Thread-1): On test.sakila_dbt_project.not_null_dim_date_date_dim_id.b5878fcef1: Close
2022-01-15 08:23:35.095767 (Thread-1): 13:53:35 | 4 of 11 PASS not_null_dim_date_date_dim_id........................... [PASS in 0.51s]
2022-01-15 08:23:35.096063 (Thread-1): Finished running node test.sakila_dbt_project.not_null_dim_date_date_dim_id.b5878fcef1
2022-01-15 08:23:35.096330 (Thread-1): Began running node test.sakila_dbt_project.not_null_hello_world_customer_id.2c9ffec564
2022-01-15 08:23:35.096693 (Thread-1): 13:53:35 | 5 of 11 START test not_null_hello_world_customer_id.................. [RUN]
2022-01-15 08:23:35.097106 (Thread-1): Acquiring new postgres connection "test.sakila_dbt_project.not_null_hello_world_customer_id.2c9ffec564".
2022-01-15 08:23:35.097337 (Thread-1): Compiling test.sakila_dbt_project.not_null_hello_world_customer_id.2c9ffec564
2022-01-15 08:23:35.101874 (Thread-1): Writing injected SQL for node "test.sakila_dbt_project.not_null_hello_world_customer_id.2c9ffec564"
2022-01-15 08:23:35.102718 (Thread-1): finished collecting timing info
2022-01-15 08:23:35.104913 (Thread-1): Writing runtime SQL for node "test.sakila_dbt_project.not_null_hello_world_customer_id.2c9ffec564"
2022-01-15 08:23:35.105520 (Thread-1): Using postgres connection "test.sakila_dbt_project.not_null_hello_world_customer_id.2c9ffec564".
2022-01-15 08:23:35.105701 (Thread-1): On test.sakila_dbt_project.not_null_hello_world_customer_id.2c9ffec564: BEGIN
2022-01-15 08:23:35.105883 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 08:23:35.476898 (Thread-1): SQL status: BEGIN in 0.37 seconds
2022-01-15 08:23:35.477297 (Thread-1): Using postgres connection "test.sakila_dbt_project.not_null_hello_world_customer_id.2c9ffec564".
2022-01-15 08:23:35.477631 (Thread-1): On test.sakila_dbt_project.not_null_hello_world_customer_id.2c9ffec564: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "test.sakila_dbt_project.not_null_hello_world_customer_id.2c9ffec564"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from "sakila_wh"."dwh"."hello_world"
where customer_id is null



      
    ) dbt_internal_test
2022-01-15 08:23:35.553433 (Thread-1): SQL status: SELECT 1 in 0.08 seconds
2022-01-15 08:23:35.555371 (Thread-1): finished collecting timing info
2022-01-15 08:23:35.555656 (Thread-1): On test.sakila_dbt_project.not_null_hello_world_customer_id.2c9ffec564: ROLLBACK
2022-01-15 08:23:35.615983 (Thread-1): On test.sakila_dbt_project.not_null_hello_world_customer_id.2c9ffec564: Close
2022-01-15 08:23:35.616981 (Thread-1): 13:53:35 | 5 of 11 PASS not_null_hello_world_customer_id........................ [PASS in 0.52s]
2022-01-15 08:23:35.617377 (Thread-1): Finished running node test.sakila_dbt_project.not_null_hello_world_customer_id.2c9ffec564
2022-01-15 08:23:35.617664 (Thread-1): Began running node test.sakila_dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
2022-01-15 08:23:35.618040 (Thread-1): 13:53:35 | 6 of 11 START test not_null_my_first_dbt_model_id.................... [RUN]
2022-01-15 08:23:35.618613 (Thread-1): Acquiring new postgres connection "test.sakila_dbt_project.not_null_my_first_dbt_model_id.5fb22c2710".
2022-01-15 08:23:35.618924 (Thread-1): Compiling test.sakila_dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
2022-01-15 08:23:35.623147 (Thread-1): Writing injected SQL for node "test.sakila_dbt_project.not_null_my_first_dbt_model_id.5fb22c2710"
2022-01-15 08:23:35.623856 (Thread-1): finished collecting timing info
2022-01-15 08:23:35.627311 (Thread-1): Writing runtime SQL for node "test.sakila_dbt_project.not_null_my_first_dbt_model_id.5fb22c2710"
2022-01-15 08:23:35.627918 (Thread-1): Using postgres connection "test.sakila_dbt_project.not_null_my_first_dbt_model_id.5fb22c2710".
2022-01-15 08:23:35.628095 (Thread-1): On test.sakila_dbt_project.not_null_my_first_dbt_model_id.5fb22c2710: BEGIN
2022-01-15 08:23:35.628282 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 08:23:36.015683 (Thread-1): SQL status: BEGIN in 0.39 seconds
2022-01-15 08:23:36.016158 (Thread-1): Using postgres connection "test.sakila_dbt_project.not_null_my_first_dbt_model_id.5fb22c2710".
2022-01-15 08:23:36.016429 (Thread-1): On test.sakila_dbt_project.not_null_my_first_dbt_model_id.5fb22c2710: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "test.sakila_dbt_project.not_null_my_first_dbt_model_id.5fb22c2710"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from "sakila_wh"."dwh"."my_first_dbt_model"
where id is null



      
    ) dbt_internal_test
2022-01-15 08:23:36.089281 (Thread-1): SQL status: SELECT 1 in 0.07 seconds
2022-01-15 08:23:36.091102 (Thread-1): finished collecting timing info
2022-01-15 08:23:36.091381 (Thread-1): On test.sakila_dbt_project.not_null_my_first_dbt_model_id.5fb22c2710: ROLLBACK
2022-01-15 08:23:36.152292 (Thread-1): On test.sakila_dbt_project.not_null_my_first_dbt_model_id.5fb22c2710: Close
2022-01-15 08:23:36.153356 (Thread-1): 13:53:36 | 6 of 11 PASS not_null_my_first_dbt_model_id.......................... [PASS in 0.53s]
2022-01-15 08:23:36.153885 (Thread-1): Finished running node test.sakila_dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
2022-01-15 08:23:36.154301 (Thread-1): Began running node test.sakila_dbt_project.not_null_my_second_dbt_model_id.151b76d778
2022-01-15 08:23:36.154669 (Thread-1): 13:53:36 | 7 of 11 START test not_null_my_second_dbt_model_id................... [RUN]
2022-01-15 08:23:36.155184 (Thread-1): Acquiring new postgres connection "test.sakila_dbt_project.not_null_my_second_dbt_model_id.151b76d778".
2022-01-15 08:23:36.155395 (Thread-1): Compiling test.sakila_dbt_project.not_null_my_second_dbt_model_id.151b76d778
2022-01-15 08:23:36.159344 (Thread-1): Writing injected SQL for node "test.sakila_dbt_project.not_null_my_second_dbt_model_id.151b76d778"
2022-01-15 08:23:36.160069 (Thread-1): finished collecting timing info
2022-01-15 08:23:36.162365 (Thread-1): Writing runtime SQL for node "test.sakila_dbt_project.not_null_my_second_dbt_model_id.151b76d778"
2022-01-15 08:23:36.163006 (Thread-1): Using postgres connection "test.sakila_dbt_project.not_null_my_second_dbt_model_id.151b76d778".
2022-01-15 08:23:36.163187 (Thread-1): On test.sakila_dbt_project.not_null_my_second_dbt_model_id.151b76d778: BEGIN
2022-01-15 08:23:36.163359 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 08:23:36.535561 (Thread-1): SQL status: BEGIN in 0.37 seconds
2022-01-15 08:23:36.535993 (Thread-1): Using postgres connection "test.sakila_dbt_project.not_null_my_second_dbt_model_id.151b76d778".
2022-01-15 08:23:36.536246 (Thread-1): On test.sakila_dbt_project.not_null_my_second_dbt_model_id.151b76d778: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "test.sakila_dbt_project.not_null_my_second_dbt_model_id.151b76d778"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from "sakila_wh"."dwh"."my_second_dbt_model"
where id is null



      
    ) dbt_internal_test
2022-01-15 08:23:36.598427 (Thread-1): SQL status: SELECT 1 in 0.06 seconds
2022-01-15 08:23:36.600657 (Thread-1): finished collecting timing info
2022-01-15 08:23:36.600947 (Thread-1): On test.sakila_dbt_project.not_null_my_second_dbt_model_id.151b76d778: ROLLBACK
2022-01-15 08:23:36.662021 (Thread-1): On test.sakila_dbt_project.not_null_my_second_dbt_model_id.151b76d778: Close
2022-01-15 08:23:36.663018 (Thread-1): 13:53:36 | 7 of 11 PASS not_null_my_second_dbt_model_id......................... [PASS in 0.51s]
2022-01-15 08:23:36.663382 (Thread-1): Finished running node test.sakila_dbt_project.not_null_my_second_dbt_model_id.151b76d778
2022-01-15 08:23:36.663738 (Thread-1): Began running node test.sakila_dbt_project.unique_dim_date_date_dim_id.8ef810b6d3
2022-01-15 08:23:36.663985 (Thread-1): 13:53:36 | 8 of 11 START test unique_dim_date_date_dim_id....................... [RUN]
2022-01-15 08:23:36.664501 (Thread-1): Acquiring new postgres connection "test.sakila_dbt_project.unique_dim_date_date_dim_id.8ef810b6d3".
2022-01-15 08:23:36.664747 (Thread-1): Compiling test.sakila_dbt_project.unique_dim_date_date_dim_id.8ef810b6d3
2022-01-15 08:23:36.672246 (Thread-1): Writing injected SQL for node "test.sakila_dbt_project.unique_dim_date_date_dim_id.8ef810b6d3"
2022-01-15 08:23:36.672979 (Thread-1): finished collecting timing info
2022-01-15 08:23:36.675317 (Thread-1): Writing runtime SQL for node "test.sakila_dbt_project.unique_dim_date_date_dim_id.8ef810b6d3"
2022-01-15 08:23:36.676007 (Thread-1): Using postgres connection "test.sakila_dbt_project.unique_dim_date_date_dim_id.8ef810b6d3".
2022-01-15 08:23:36.676196 (Thread-1): On test.sakila_dbt_project.unique_dim_date_date_dim_id.8ef810b6d3: BEGIN
2022-01-15 08:23:36.676382 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 08:23:37.053930 (Thread-1): SQL status: BEGIN in 0.38 seconds
2022-01-15 08:23:37.054422 (Thread-1): Using postgres connection "test.sakila_dbt_project.unique_dim_date_date_dim_id.8ef810b6d3".
2022-01-15 08:23:37.054695 (Thread-1): On test.sakila_dbt_project.unique_dim_date_date_dim_id.8ef810b6d3: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "test.sakila_dbt_project.unique_dim_date_date_dim_id.8ef810b6d3"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    date_dim_id as unique_field,
    count(*) as n_records

from "sakila_wh"."dwh"."dim_date"
where date_dim_id is not null
group by date_dim_id
having count(*) > 1



      
    ) dbt_internal_test
2022-01-15 08:23:37.126364 (Thread-1): SQL status: SELECT 1 in 0.07 seconds
2022-01-15 08:23:37.128833 (Thread-1): finished collecting timing info
2022-01-15 08:23:37.129187 (Thread-1): On test.sakila_dbt_project.unique_dim_date_date_dim_id.8ef810b6d3: ROLLBACK
2022-01-15 08:23:37.191936 (Thread-1): On test.sakila_dbt_project.unique_dim_date_date_dim_id.8ef810b6d3: Close
2022-01-15 08:23:37.192883 (Thread-1): 13:53:37 | 8 of 11 PASS unique_dim_date_date_dim_id............................. [PASS in 0.53s]
2022-01-15 08:23:37.193204 (Thread-1): Finished running node test.sakila_dbt_project.unique_dim_date_date_dim_id.8ef810b6d3
2022-01-15 08:23:37.193463 (Thread-1): Began running node test.sakila_dbt_project.unique_hello_world_customer_id.ec99a3c2de
2022-01-15 08:23:37.193883 (Thread-1): 13:53:37 | 9 of 11 START test unique_hello_world_customer_id.................... [RUN]
2022-01-15 08:23:37.194259 (Thread-1): Acquiring new postgres connection "test.sakila_dbt_project.unique_hello_world_customer_id.ec99a3c2de".
2022-01-15 08:23:37.194491 (Thread-1): Compiling test.sakila_dbt_project.unique_hello_world_customer_id.ec99a3c2de
2022-01-15 08:23:37.198464 (Thread-1): Writing injected SQL for node "test.sakila_dbt_project.unique_hello_world_customer_id.ec99a3c2de"
2022-01-15 08:23:37.199134 (Thread-1): finished collecting timing info
2022-01-15 08:23:37.201328 (Thread-1): Writing runtime SQL for node "test.sakila_dbt_project.unique_hello_world_customer_id.ec99a3c2de"
2022-01-15 08:23:37.201989 (Thread-1): Using postgres connection "test.sakila_dbt_project.unique_hello_world_customer_id.ec99a3c2de".
2022-01-15 08:23:37.202170 (Thread-1): On test.sakila_dbt_project.unique_hello_world_customer_id.ec99a3c2de: BEGIN
2022-01-15 08:23:37.202338 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 08:23:37.578522 (Thread-1): SQL status: BEGIN in 0.38 seconds
2022-01-15 08:23:37.578905 (Thread-1): Using postgres connection "test.sakila_dbt_project.unique_hello_world_customer_id.ec99a3c2de".
2022-01-15 08:23:37.579151 (Thread-1): On test.sakila_dbt_project.unique_hello_world_customer_id.ec99a3c2de: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "test.sakila_dbt_project.unique_hello_world_customer_id.ec99a3c2de"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    customer_id as unique_field,
    count(*) as n_records

from "sakila_wh"."dwh"."hello_world"
where customer_id is not null
group by customer_id
having count(*) > 1



      
    ) dbt_internal_test
2022-01-15 08:23:37.642612 (Thread-1): SQL status: SELECT 1 in 0.06 seconds
2022-01-15 08:23:37.644830 (Thread-1): finished collecting timing info
2022-01-15 08:23:37.645103 (Thread-1): On test.sakila_dbt_project.unique_hello_world_customer_id.ec99a3c2de: ROLLBACK
2022-01-15 08:23:37.705237 (Thread-1): On test.sakila_dbt_project.unique_hello_world_customer_id.ec99a3c2de: Close
2022-01-15 08:23:37.705920 (Thread-1): 13:53:37 | 9 of 11 PASS unique_hello_world_customer_id.......................... [PASS in 0.51s]
2022-01-15 08:23:37.706211 (Thread-1): Finished running node test.sakila_dbt_project.unique_hello_world_customer_id.ec99a3c2de
2022-01-15 08:23:37.706482 (Thread-1): Began running node test.sakila_dbt_project.unique_my_first_dbt_model_id.16e066b321
2022-01-15 08:23:37.706817 (Thread-1): 13:53:37 | 10 of 11 START test unique_my_first_dbt_model_id..................... [RUN]
2022-01-15 08:23:37.707232 (Thread-1): Acquiring new postgres connection "test.sakila_dbt_project.unique_my_first_dbt_model_id.16e066b321".
2022-01-15 08:23:37.707458 (Thread-1): Compiling test.sakila_dbt_project.unique_my_first_dbt_model_id.16e066b321
2022-01-15 08:23:37.711358 (Thread-1): Writing injected SQL for node "test.sakila_dbt_project.unique_my_first_dbt_model_id.16e066b321"
2022-01-15 08:23:37.711995 (Thread-1): finished collecting timing info
2022-01-15 08:23:37.714207 (Thread-1): Writing runtime SQL for node "test.sakila_dbt_project.unique_my_first_dbt_model_id.16e066b321"
2022-01-15 08:23:37.714826 (Thread-1): Using postgres connection "test.sakila_dbt_project.unique_my_first_dbt_model_id.16e066b321".
2022-01-15 08:23:37.715000 (Thread-1): On test.sakila_dbt_project.unique_my_first_dbt_model_id.16e066b321: BEGIN
2022-01-15 08:23:37.715169 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 08:23:38.089677 (Thread-1): SQL status: BEGIN in 0.37 seconds
2022-01-15 08:23:38.090090 (Thread-1): Using postgres connection "test.sakila_dbt_project.unique_my_first_dbt_model_id.16e066b321".
2022-01-15 08:23:38.090349 (Thread-1): On test.sakila_dbt_project.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "test.sakila_dbt_project.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "sakila_wh"."dwh"."my_first_dbt_model"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
2022-01-15 08:23:38.156352 (Thread-1): SQL status: SELECT 1 in 0.07 seconds
2022-01-15 08:23:38.158372 (Thread-1): finished collecting timing info
2022-01-15 08:23:38.158647 (Thread-1): On test.sakila_dbt_project.unique_my_first_dbt_model_id.16e066b321: ROLLBACK
2022-01-15 08:23:38.222085 (Thread-1): On test.sakila_dbt_project.unique_my_first_dbt_model_id.16e066b321: Close
2022-01-15 08:23:38.222965 (Thread-1): 13:53:38 | 10 of 11 PASS unique_my_first_dbt_model_id........................... [PASS in 0.52s]
2022-01-15 08:23:38.223345 (Thread-1): Finished running node test.sakila_dbt_project.unique_my_first_dbt_model_id.16e066b321
2022-01-15 08:23:38.223674 (Thread-1): Began running node test.sakila_dbt_project.unique_my_second_dbt_model_id.57a0f8c493
2022-01-15 08:23:38.224095 (Thread-1): 13:53:38 | 11 of 11 START test unique_my_second_dbt_model_id.................... [RUN]
2022-01-15 08:23:38.224566 (Thread-1): Acquiring new postgres connection "test.sakila_dbt_project.unique_my_second_dbt_model_id.57a0f8c493".
2022-01-15 08:23:38.224798 (Thread-1): Compiling test.sakila_dbt_project.unique_my_second_dbt_model_id.57a0f8c493
2022-01-15 08:23:38.230374 (Thread-1): Writing injected SQL for node "test.sakila_dbt_project.unique_my_second_dbt_model_id.57a0f8c493"
2022-01-15 08:23:38.230981 (Thread-1): finished collecting timing info
2022-01-15 08:23:38.232964 (Thread-1): Writing runtime SQL for node "test.sakila_dbt_project.unique_my_second_dbt_model_id.57a0f8c493"
2022-01-15 08:23:38.233559 (Thread-1): Using postgres connection "test.sakila_dbt_project.unique_my_second_dbt_model_id.57a0f8c493".
2022-01-15 08:23:38.233804 (Thread-1): On test.sakila_dbt_project.unique_my_second_dbt_model_id.57a0f8c493: BEGIN
2022-01-15 08:23:38.233994 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 08:23:38.606442 (Thread-1): SQL status: BEGIN in 0.37 seconds
2022-01-15 08:23:38.606763 (Thread-1): Using postgres connection "test.sakila_dbt_project.unique_my_second_dbt_model_id.57a0f8c493".
2022-01-15 08:23:38.606968 (Thread-1): On test.sakila_dbt_project.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "test.sakila_dbt_project.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "sakila_wh"."dwh"."my_second_dbt_model"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
2022-01-15 08:23:38.670989 (Thread-1): SQL status: SELECT 1 in 0.06 seconds
2022-01-15 08:23:38.673080 (Thread-1): finished collecting timing info
2022-01-15 08:23:38.673373 (Thread-1): On test.sakila_dbt_project.unique_my_second_dbt_model_id.57a0f8c493: ROLLBACK
2022-01-15 08:23:38.733503 (Thread-1): On test.sakila_dbt_project.unique_my_second_dbt_model_id.57a0f8c493: Close
2022-01-15 08:23:38.734604 (Thread-1): 13:53:38 | 11 of 11 PASS unique_my_second_dbt_model_id.......................... [PASS in 0.51s]
2022-01-15 08:23:38.734970 (Thread-1): Finished running node test.sakila_dbt_project.unique_my_second_dbt_model_id.57a0f8c493
2022-01-15 08:23:38.736572 (MainThread): Acquiring new postgres connection "master".
2022-01-15 08:23:38.737027 (MainThread): 13:53:38 | 
2022-01-15 08:23:38.737281 (MainThread): 13:53:38 | Finished running 11 tests in 6.80s.
2022-01-15 08:23:38.737576 (MainThread): Connection 'master' was properly closed.
2022-01-15 08:23:38.737831 (MainThread): Connection 'test.sakila_dbt_project.unique_my_second_dbt_model_id.57a0f8c493' was properly closed.
2022-01-15 08:23:38.747385 (MainThread): 
2022-01-15 08:23:38.747623 (MainThread): Completed with 1 error and 0 warnings:
2022-01-15 08:23:38.747823 (MainThread): 
2022-01-15 08:23:38.748027 (MainThread): Failure in test film_replacementcost_30 (tests/film_replacementcost_30.sql)
2022-01-15 08:23:38.748216 (MainThread):   Got 53 results, configured to fail if != 0
2022-01-15 08:23:38.748397 (MainThread): 
2022-01-15 08:23:38.748579 (MainThread):   compiled SQL at target/compiled/sakila_dbt_project/tests/film_replacementcost_30.sql
2022-01-15 08:23:38.748780 (MainThread): 
Done. PASS=10 WARN=0 ERROR=1 SKIP=0 TOTAL=11
2022-01-15 08:23:38.749034 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b78220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107abb670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107abb550>]}
2022-01-15 08:23:38.749294 (MainThread): Flushing usage events
2022-01-15 08:32:35.511654 (MainThread): Running with dbt=0.21.1
2022-01-15 08:32:35.594092 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, defer=None, state=None, cls=<class 'dbt.task.clean.CleanTask'>, which='clean', rpc_method=None)
2022-01-15 08:32:35.594727 (MainThread): Tracking: tracking
2022-01-15 08:32:35.615073 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f5e6ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f5e6280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f5d3be0>]}
2022-01-15 08:32:35.616784 (MainThread): Checking target/*
2022-01-15 08:32:35.634437 (MainThread):  Cleaned target/*
2022-01-15 08:32:35.634724 (MainThread): Checking dbt_modules/*
2022-01-15 08:32:35.683586 (MainThread):  Cleaned dbt_modules/*
2022-01-15 08:32:35.683973 (MainThread): Finished cleaning all paths.
2022-01-15 08:32:35.684549 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f5e6280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f5e6ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f5d3310>]}
2022-01-15 08:32:35.684836 (MainThread): Flushing usage events
2022-01-15 08:33:08.354703 (MainThread): Running with dbt=0.21.1
2022-01-15 08:33:08.453285 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, data=False, schema=False, fail_fast=False, store_failures=False, greedy=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.test.TestTask'>, which='test', rpc_method='test')
2022-01-15 08:33:08.455126 (MainThread): Tracking: tracking
2022-01-15 08:33:08.476418 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107cb9640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1082c27c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1082c23a0>]}
2022-01-15 08:33:08.478793 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1082d54f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1082c2a60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1082c2d60>]}
2022-01-15 08:33:08.479123 (MainThread): Flushing usage events
2022-01-15 08:33:10.028718 (MainThread): Encountered an error:
2022-01-15 08:33:10.029063 (MainThread): Compilation Error
  dbt found 1 package(s) specified in packages.yml, but only 0 package(s) installed in dbt_modules. Run "dbt deps" to install package dependencies.
2022-01-15 08:33:10.035514 (MainThread): Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/dbt/main.py", line 127, in main
    results, succeeded = handle_and_check(args)
  File "/usr/local/lib/python3.9/site-packages/dbt/main.py", line 205, in handle_and_check
    task, res = run_from_args(parsed)
  File "/usr/local/lib/python3.9/site-packages/dbt/main.py", line 258, in run_from_args
    results = task.run()
  File "/usr/local/lib/python3.9/site-packages/dbt/task/runnable.py", line 438, in run
    self._runtime_initialize()
  File "/usr/local/lib/python3.9/site-packages/dbt/task/runnable.py", line 154, in _runtime_initialize
    super()._runtime_initialize()
  File "/usr/local/lib/python3.9/site-packages/dbt/task/runnable.py", line 92, in _runtime_initialize
    self.load_manifest()
  File "/usr/local/lib/python3.9/site-packages/dbt/task/runnable.py", line 79, in load_manifest
    self.manifest = ManifestLoader.get_full_manifest(self.config)
  File "/usr/local/lib/python3.9/site-packages/dbt/parser/manifest.py", line 179, in get_full_manifest
    projects = config.load_dependencies()
  File "/usr/local/lib/python3.9/site-packages/dbt/config/runtime.py", line 336, in load_dependencies
    raise_compiler_error(
  File "/usr/local/lib/python3.9/site-packages/dbt/exceptions.py", line 447, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error
  dbt found 1 package(s) specified in packages.yml, but only 0 package(s) installed in dbt_modules. Run "dbt deps" to install package dependencies.

2022-01-15 08:33:20.895482 (MainThread): Running with dbt=0.21.1
2022-01-15 08:33:20.971089 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, defer=None, state=None, cls=<class 'dbt.task.deps.DepsTask'>, which='deps', rpc_method='deps')
2022-01-15 08:33:20.971658 (MainThread): Tracking: tracking
2022-01-15 08:33:20.991306 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076db7c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076db340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076c7c10>]}
2022-01-15 08:33:20.994406 (MainThread): Set downloads directory='/var/folders/ht/55m1kf9529v8n85gyrn0hzcc0000gp/T/dbt-downloads-h_eboclm'
2022-01-15 08:33:20.995409 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/index.json
2022-01-15 08:33:21.822900 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/index.json 200
2022-01-15 08:33:21.823354 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
2022-01-15 08:33:22.255231 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
2022-01-15 08:33:22.277395 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils/0.7.1.json
2022-01-15 08:33:22.902810 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils/0.7.1.json 200
2022-01-15 08:33:22.903236 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
2022-01-15 08:33:23.317287 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
2022-01-15 08:33:23.339173 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils/0.7.1.json
2022-01-15 08:33:24.264307 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils/0.7.1.json 200
2022-01-15 08:33:24.264806 (MainThread): Installing dbt-labs/dbt_utils@0.7.1
2022-01-15 08:33:25.315848 (MainThread):   Installed from version 0.7.1
2022-01-15 08:33:25.316244 (MainThread):   Updated version available: 0.8.0
2022-01-15 08:33:25.316628 (MainThread): Sending event: {'category': 'dbt', 'action': 'package', 'label': '08ea99e7-5447-4d0a-8e45-a17b906cfcdf', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076c7f40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076c7940>]}
2022-01-15 08:33:25.317024 (MainThread): 
Updates available for packages: ['dbt-labs/dbt_utils']                 
Update your versions in packages.yml, then run dbt deps
2022-01-15 08:33:25.318612 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076c78b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076c7fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076c7e50>]}
2022-01-15 08:33:25.319047 (MainThread): Flushing usage events
2022-01-15 08:34:02.652709 (MainThread): Running with dbt=0.21.1
2022-01-15 08:34:02.766646 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, defer=None, state=None, cls=<class 'dbt.task.clean.CleanTask'>, which='clean', rpc_method=None)
2022-01-15 08:34:02.767582 (MainThread): Tracking: tracking
2022-01-15 08:34:02.790089 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104cb3ee0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104cb3340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c8fc10>]}
2022-01-15 08:34:02.791665 (MainThread): Checking target/*
2022-01-15 08:34:02.793010 (MainThread):  Cleaned target/*
2022-01-15 08:34:02.793240 (MainThread): Checking dbt_modules/*
2022-01-15 08:34:02.834708 (MainThread):  Cleaned dbt_modules/*
2022-01-15 08:34:02.835051 (MainThread): Finished cleaning all paths.
2022-01-15 08:34:02.835470 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104cb3340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104cb39a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c8f400>]}
2022-01-15 08:34:02.835731 (MainThread): Flushing usage events
2022-01-15 08:34:13.160908 (MainThread): Running with dbt=0.21.1
2022-01-15 08:34:13.238038 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, defer=None, state=None, cls=<class 'dbt.task.deps.DepsTask'>, which='deps', rpc_method='deps')
2022-01-15 08:34:13.238604 (MainThread): Tracking: tracking
2022-01-15 08:34:13.258785 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1092490a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1092492e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109225c10>]}
2022-01-15 08:34:13.262431 (MainThread): Set downloads directory='/var/folders/ht/55m1kf9529v8n85gyrn0hzcc0000gp/T/dbt-downloads-3iph4v37'
2022-01-15 08:34:13.263548 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/index.json
2022-01-15 08:34:14.167233 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/index.json 200
2022-01-15 08:34:14.167676 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
2022-01-15 08:34:14.599683 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
2022-01-15 08:34:14.620061 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils/0.8.0.json
2022-01-15 08:34:15.027843 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils/0.8.0.json 200
2022-01-15 08:34:15.028360 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
2022-01-15 08:34:15.444502 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
2022-01-15 08:34:15.465950 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils/0.8.0.json
2022-01-15 08:34:15.896397 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils/0.8.0.json 200
2022-01-15 08:34:15.896875 (MainThread): Installing dbt-labs/dbt_utils@0.8.0
2022-01-15 08:34:16.755920 (MainThread):   Installed from version 0.8.0
2022-01-15 08:34:16.756311 (MainThread):   Up to date!
2022-01-15 08:34:16.756707 (MainThread): Sending event: {'category': 'dbt', 'action': 'package', 'label': '565ac803-f135-44fe-b42e-780cb1d9430c', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1092252e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1092257f0>]}
2022-01-15 08:34:16.758449 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109225940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109225fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1092258b0>]}
2022-01-15 08:34:16.758915 (MainThread): Flushing usage events
2022-01-15 08:34:24.036599 (MainThread): Running with dbt=0.21.1
2022-01-15 08:34:24.119443 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, data=False, schema=False, fail_fast=False, store_failures=False, greedy=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.test.TestTask'>, which='test', rpc_method='test')
2022-01-15 08:34:24.121134 (MainThread): Tracking: tracking
2022-01-15 08:34:24.142483 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10578d640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d957c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d953a0>]}
2022-01-15 08:34:24.163278 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e05220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e051c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e05c70>]}
2022-01-15 08:34:24.163596 (MainThread): Flushing usage events
2022-01-15 08:34:25.809983 (MainThread): Encountered an error:
2022-01-15 08:34:25.810330 (MainThread): Runtime Error
  Failed to read package: Runtime Error
    This version of dbt is not supported with the 'dbt_utils' package.
      Installed version of dbt: =0.21.1
      Required version of dbt for 'dbt_utils': ['>=1.0.0', '<2.0.0']
    Check the requirements for the 'dbt_utils' package, or run dbt again with --no-version-check
    
  
  Error encountered in /Users/nijoshi/Desktop/dbt_proj/dbt_modules/dbt_utils/dbt_project.yml

Error encountered in /Users/nijoshi/Desktop/dbt_proj/dbt_modules/dbt_utils
2022-01-15 08:34:25.816536 (MainThread): Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/dbt/config/runtime.py", line 367, in load_projects
    project = self.new_project(str(path))
  File "/usr/local/lib/python3.9/site-packages/dbt/config/runtime.py", line 144, in new_project
    project = Project.from_project_root(
  File "/usr/local/lib/python3.9/site-packages/dbt/config/project.py", line 643, in from_project_root
    return partial.render(renderer)
  File "/usr/local/lib/python3.9/site-packages/dbt/config/project.py", line 289, in render
    return self.create_project(rendered)
  File "/usr/local/lib/python3.9/site-packages/dbt/config/project.py", line 301, in create_project
    dbt_version = _get_required_version(
  File "/usr/local/lib/python3.9/site-packages/dbt/config/project.py", line 226, in _get_required_version
    validate_version(dbt_version, project_dict['name'])
  File "/usr/local/lib/python3.9/site-packages/dbt/config/project.py", line 203, in validate_version
    raise DbtProjectError(msg)
dbt.exceptions.DbtProjectError: Runtime Error
  This version of dbt is not supported with the 'dbt_utils' package.
    Installed version of dbt: =0.21.1
    Required version of dbt for 'dbt_utils': ['>=1.0.0', '<2.0.0']
  Check the requirements for the 'dbt_utils' package, or run dbt again with --no-version-check
  

Error encountered in /Users/nijoshi/Desktop/dbt_proj/dbt_modules/dbt_utils/dbt_project.yml

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/dbt/main.py", line 127, in main
    results, succeeded = handle_and_check(args)
  File "/usr/local/lib/python3.9/site-packages/dbt/main.py", line 205, in handle_and_check
    task, res = run_from_args(parsed)
  File "/usr/local/lib/python3.9/site-packages/dbt/main.py", line 258, in run_from_args
    results = task.run()
  File "/usr/local/lib/python3.9/site-packages/dbt/task/runnable.py", line 438, in run
    self._runtime_initialize()
  File "/usr/local/lib/python3.9/site-packages/dbt/task/runnable.py", line 154, in _runtime_initialize
    super()._runtime_initialize()
  File "/usr/local/lib/python3.9/site-packages/dbt/task/runnable.py", line 92, in _runtime_initialize
    self.load_manifest()
  File "/usr/local/lib/python3.9/site-packages/dbt/task/runnable.py", line 79, in load_manifest
    self.manifest = ManifestLoader.get_full_manifest(self.config)
  File "/usr/local/lib/python3.9/site-packages/dbt/parser/manifest.py", line 179, in get_full_manifest
    projects = config.load_dependencies()
  File "/usr/local/lib/python3.9/site-packages/dbt/config/runtime.py", line 347, in load_dependencies
    for project_name, project in self.load_projects(project_paths):
  File "/usr/local/lib/python3.9/site-packages/dbt/config/runtime.py", line 369, in load_projects
    raise DbtProjectError(
dbt.exceptions.DbtProjectError: Runtime Error
  Failed to read package: Runtime Error
    This version of dbt is not supported with the 'dbt_utils' package.
      Installed version of dbt: =0.21.1
      Required version of dbt for 'dbt_utils': ['>=1.0.0', '<2.0.0']
    Check the requirements for the 'dbt_utils' package, or run dbt again with --no-version-check
    
  
  Error encountered in /Users/nijoshi/Desktop/dbt_proj/dbt_modules/dbt_utils/dbt_project.yml

Error encountered in /Users/nijoshi/Desktop/dbt_proj/dbt_modules/dbt_utils

2022-01-15 08:35:22.136584 (MainThread): Running with dbt=0.21.1
2022-01-15 08:35:22.215284 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, data=False, schema=False, fail_fast=False, store_failures=False, greedy=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.test.TestTask'>, which='test', rpc_method='test')
2022-01-15 08:35:22.217083 (MainThread): Tracking: tracking
2022-01-15 08:35:22.237103 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f0e1640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f6de7c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f6de3a0>]}
2022-01-15 08:35:22.257435 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f75a220>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f75a1c0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f75ac70>]}
2022-01-15 08:35:22.257769 (MainThread): Flushing usage events
2022-01-15 08:35:24.091161 (MainThread): Encountered an error:
2022-01-15 08:35:24.091492 (MainThread): Runtime Error
  Failed to read package: Runtime Error
    This version of dbt is not supported with the 'dbt_utils' package.
      Installed version of dbt: =0.21.1
      Required version of dbt for 'dbt_utils': ['>=1.0.0', '<2.0.0']
    Check the requirements for the 'dbt_utils' package, or run dbt again with --no-version-check
    
  
  Error encountered in /Users/nijoshi/Desktop/dbt_proj/dbt_modules/dbt_utils/dbt_project.yml

Error encountered in /Users/nijoshi/Desktop/dbt_proj/dbt_modules/dbt_utils
2022-01-15 08:35:24.093644 (MainThread): Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/dbt/config/runtime.py", line 367, in load_projects
    project = self.new_project(str(path))
  File "/usr/local/lib/python3.9/site-packages/dbt/config/runtime.py", line 144, in new_project
    project = Project.from_project_root(
  File "/usr/local/lib/python3.9/site-packages/dbt/config/project.py", line 643, in from_project_root
    return partial.render(renderer)
  File "/usr/local/lib/python3.9/site-packages/dbt/config/project.py", line 289, in render
    return self.create_project(rendered)
  File "/usr/local/lib/python3.9/site-packages/dbt/config/project.py", line 301, in create_project
    dbt_version = _get_required_version(
  File "/usr/local/lib/python3.9/site-packages/dbt/config/project.py", line 226, in _get_required_version
    validate_version(dbt_version, project_dict['name'])
  File "/usr/local/lib/python3.9/site-packages/dbt/config/project.py", line 203, in validate_version
    raise DbtProjectError(msg)
dbt.exceptions.DbtProjectError: Runtime Error
  This version of dbt is not supported with the 'dbt_utils' package.
    Installed version of dbt: =0.21.1
    Required version of dbt for 'dbt_utils': ['>=1.0.0', '<2.0.0']
  Check the requirements for the 'dbt_utils' package, or run dbt again with --no-version-check
  

Error encountered in /Users/nijoshi/Desktop/dbt_proj/dbt_modules/dbt_utils/dbt_project.yml

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/dbt/main.py", line 127, in main
    results, succeeded = handle_and_check(args)
  File "/usr/local/lib/python3.9/site-packages/dbt/main.py", line 205, in handle_and_check
    task, res = run_from_args(parsed)
  File "/usr/local/lib/python3.9/site-packages/dbt/main.py", line 258, in run_from_args
    results = task.run()
  File "/usr/local/lib/python3.9/site-packages/dbt/task/runnable.py", line 438, in run
    self._runtime_initialize()
  File "/usr/local/lib/python3.9/site-packages/dbt/task/runnable.py", line 154, in _runtime_initialize
    super()._runtime_initialize()
  File "/usr/local/lib/python3.9/site-packages/dbt/task/runnable.py", line 92, in _runtime_initialize
    self.load_manifest()
  File "/usr/local/lib/python3.9/site-packages/dbt/task/runnable.py", line 79, in load_manifest
    self.manifest = ManifestLoader.get_full_manifest(self.config)
  File "/usr/local/lib/python3.9/site-packages/dbt/parser/manifest.py", line 179, in get_full_manifest
    projects = config.load_dependencies()
  File "/usr/local/lib/python3.9/site-packages/dbt/config/runtime.py", line 347, in load_dependencies
    for project_name, project in self.load_projects(project_paths):
  File "/usr/local/lib/python3.9/site-packages/dbt/config/runtime.py", line 369, in load_projects
    raise DbtProjectError(
dbt.exceptions.DbtProjectError: Runtime Error
  Failed to read package: Runtime Error
    This version of dbt is not supported with the 'dbt_utils' package.
      Installed version of dbt: =0.21.1
      Required version of dbt for 'dbt_utils': ['>=1.0.0', '<2.0.0']
    Check the requirements for the 'dbt_utils' package, or run dbt again with --no-version-check
    
  
  Error encountered in /Users/nijoshi/Desktop/dbt_proj/dbt_modules/dbt_utils/dbt_project.yml

Error encountered in /Users/nijoshi/Desktop/dbt_proj/dbt_modules/dbt_utils

2022-01-15 08:35:51.748643 (MainThread): Running with dbt=0.21.1
2022-01-15 08:35:51.824267 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, defer=None, state=None, cls=<class 'dbt.task.clean.CleanTask'>, which='clean', rpc_method=None)
2022-01-15 08:35:51.824821 (MainThread): Tracking: tracking
2022-01-15 08:35:51.844494 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c3900a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c390340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c36cc10>]}
2022-01-15 08:35:51.846069 (MainThread): Checking target/*
2022-01-15 08:35:51.847281 (MainThread):  Cleaned target/*
2022-01-15 08:35:51.847503 (MainThread): Checking dbt_modules/*
2022-01-15 08:35:51.890841 (MainThread):  Cleaned dbt_modules/*
2022-01-15 08:35:51.891091 (MainThread): Finished cleaning all paths.
2022-01-15 08:35:51.891450 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c390340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c390a30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c36c400>]}
2022-01-15 08:35:51.891701 (MainThread): Flushing usage events
2022-01-15 08:35:57.772612 (MainThread): Running with dbt=0.21.1
2022-01-15 08:35:57.851816 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, defer=None, state=None, cls=<class 'dbt.task.deps.DepsTask'>, which='deps', rpc_method='deps')
2022-01-15 08:35:57.852424 (MainThread): Tracking: tracking
2022-01-15 08:35:57.871881 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067d9970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067d92e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067b4c10>]}
2022-01-15 08:35:57.875109 (MainThread): Set downloads directory='/var/folders/ht/55m1kf9529v8n85gyrn0hzcc0000gp/T/dbt-downloads-pobr49dh'
2022-01-15 08:35:57.875982 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/index.json
2022-01-15 08:35:58.482271 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/index.json 200
2022-01-15 08:35:58.482735 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
2022-01-15 08:35:58.936263 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
2022-01-15 08:35:58.958212 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils/0.7.1.json
2022-01-15 08:35:59.366672 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils/0.7.1.json 200
2022-01-15 08:35:59.367185 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
2022-01-15 08:35:59.776202 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
2022-01-15 08:35:59.799044 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils/0.7.1.json
2022-01-15 08:36:00.231181 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils/0.7.1.json 200
2022-01-15 08:36:00.231737 (MainThread): Installing dbt-labs/dbt_utils@0.7.1
2022-01-15 08:36:01.383052 (MainThread):   Installed from version 0.7.1
2022-01-15 08:36:01.383368 (MainThread):   Updated version available: 0.8.0
2022-01-15 08:36:01.383745 (MainThread): Sending event: {'category': 'dbt', 'action': 'package', 'label': 'd11489e5-a5cf-48c3-9e9b-32995717ef6f', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067b4f40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067b4940>]}
2022-01-15 08:36:01.384139 (MainThread): 
Updates available for packages: ['dbt-labs/dbt_utils']                 
Update your versions in packages.yml, then run dbt deps
2022-01-15 08:36:01.385771 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067b48b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067b4fa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067b4e50>]}
2022-01-15 08:36:01.386230 (MainThread): Flushing usage events
2022-01-15 08:36:14.231758 (MainThread): Running with dbt=0.21.1
2022-01-15 08:36:14.312943 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, data=False, schema=False, fail_fast=False, store_failures=False, greedy=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, cls=<class 'dbt.task.test.TestTask'>, which='test', rpc_method='test')
2022-01-15 08:36:14.315092 (MainThread): Tracking: tracking
2022-01-15 08:36:14.335912 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1104c2640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110ac0e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110ac0340>]}
2022-01-15 08:36:14.358299 (MainThread): Partial parsing not enabled
2022-01-15 08:36:14.405915 (MainThread): Parsing macros/catalog.sql
2022-01-15 08:36:14.409465 (MainThread): Parsing macros/relations.sql
2022-01-15 08:36:14.410742 (MainThread): Parsing macros/adapters.sql
2022-01-15 08:36:14.432356 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2022-01-15 08:36:14.434021 (MainThread): Parsing macros/core.sql
2022-01-15 08:36:14.437531 (MainThread): Parsing macros/materializations/test.sql
2022-01-15 08:36:14.444097 (MainThread): Parsing macros/materializations/helpers.sql
2022-01-15 08:36:14.453874 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2022-01-15 08:36:14.455525 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2022-01-15 08:36:14.472154 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2022-01-15 08:36:14.502766 (MainThread): Parsing macros/materializations/seed/seed.sql
2022-01-15 08:36:14.523965 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2022-01-15 08:36:14.525631 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2022-01-15 08:36:14.535168 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2022-01-15 08:36:14.553614 (MainThread): Parsing macros/materializations/common/merge.sql
2022-01-15 08:36:14.566778 (MainThread): Parsing macros/materializations/table/table.sql
2022-01-15 08:36:14.574117 (MainThread): Parsing macros/materializations/view/view.sql
2022-01-15 08:36:14.580802 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2022-01-15 08:36:14.584523 (MainThread): Parsing macros/etc/get_custom_alias.sql
2022-01-15 08:36:14.585889 (MainThread): Parsing macros/etc/query.sql
2022-01-15 08:36:14.586816 (MainThread): Parsing macros/etc/is_incremental.sql
2022-01-15 08:36:14.588180 (MainThread): Parsing macros/etc/datetime.sql
2022-01-15 08:36:14.596042 (MainThread): Parsing macros/etc/where_subquery.sql
2022-01-15 08:36:14.597970 (MainThread): Parsing macros/etc/get_custom_schema.sql
2022-01-15 08:36:14.600152 (MainThread): Parsing macros/etc/get_custom_database.sql
2022-01-15 08:36:14.601575 (MainThread): Parsing macros/adapters/common.sql
2022-01-15 08:36:14.654286 (MainThread): Parsing macros/schema_tests/relationships.sql
2022-01-15 08:36:14.655866 (MainThread): Parsing macros/schema_tests/not_null.sql
2022-01-15 08:36:14.656976 (MainThread): Parsing macros/schema_tests/unique.sql
2022-01-15 08:36:14.658221 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2022-01-15 08:36:14.660259 (MainThread): Parsing macros/cross_db_utils/except.sql
2022-01-15 08:36:14.661253 (MainThread): Parsing macros/cross_db_utils/replace.sql
2022-01-15 08:36:14.662600 (MainThread): Parsing macros/cross_db_utils/concat.sql
2022-01-15 08:36:14.664030 (MainThread): Parsing macros/cross_db_utils/datatypes.sql
2022-01-15 08:36:14.669629 (MainThread): Parsing macros/cross_db_utils/_is_relation.sql
2022-01-15 08:36:14.670688 (MainThread): Parsing macros/cross_db_utils/length.sql
2022-01-15 08:36:14.671909 (MainThread): Parsing macros/cross_db_utils/dateadd.sql
2022-01-15 08:36:14.674811 (MainThread): Parsing macros/cross_db_utils/intersect.sql
2022-01-15 08:36:14.675789 (MainThread): Parsing macros/cross_db_utils/right.sql
2022-01-15 08:36:14.677836 (MainThread): Parsing macros/cross_db_utils/datediff.sql
2022-01-15 08:36:14.687561 (MainThread): Parsing macros/cross_db_utils/safe_cast.sql
2022-01-15 08:36:14.689295 (MainThread): Parsing macros/cross_db_utils/hash.sql
2022-01-15 08:36:14.690689 (MainThread): Parsing macros/cross_db_utils/cast_bool_to_text.sql
2022-01-15 08:36:14.692011 (MainThread): Parsing macros/cross_db_utils/identifier.sql
2022-01-15 08:36:14.693529 (MainThread): Parsing macros/cross_db_utils/position.sql
2022-01-15 08:36:14.694950 (MainThread): Parsing macros/cross_db_utils/literal.sql
2022-01-15 08:36:14.695843 (MainThread): Parsing macros/cross_db_utils/current_timestamp.sql
2022-01-15 08:36:14.699426 (MainThread): Parsing macros/cross_db_utils/width_bucket.sql
2022-01-15 08:36:14.704360 (MainThread): Parsing macros/cross_db_utils/last_day.sql
2022-01-15 08:36:14.707624 (MainThread): Parsing macros/cross_db_utils/split_part.sql
2022-01-15 08:36:14.709333 (MainThread): Parsing macros/cross_db_utils/date_trunc.sql
2022-01-15 08:36:14.710830 (MainThread): Parsing macros/cross_db_utils/_is_ephemeral.sql
2022-01-15 08:36:14.712708 (MainThread): Parsing macros/materializations/insert_by_period_materialization.sql
2022-01-15 08:36:14.736054 (MainThread): Parsing macros/web/get_url_host.sql
2022-01-15 08:36:14.737740 (MainThread): Parsing macros/web/get_url_path.sql
2022-01-15 08:36:14.740139 (MainThread): Parsing macros/web/get_url_parameter.sql
2022-01-15 08:36:14.741568 (MainThread): Parsing macros/jinja_helpers/pretty_log_format.sql
2022-01-15 08:36:14.742727 (MainThread): Parsing macros/jinja_helpers/pretty_time.sql
2022-01-15 08:36:14.743858 (MainThread): Parsing macros/jinja_helpers/log_info.sql
2022-01-15 08:36:14.744894 (MainThread): Parsing macros/jinja_helpers/slugify.sql
2022-01-15 08:36:14.745981 (MainThread): Parsing macros/schema_tests/fewer_rows_than.sql
2022-01-15 08:36:14.747715 (MainThread): Parsing macros/schema_tests/equal_rowcount.sql
2022-01-15 08:36:14.749251 (MainThread): Parsing macros/schema_tests/relationships_where.sql
2022-01-15 08:36:14.751385 (MainThread): Parsing macros/schema_tests/recency.sql
2022-01-15 08:36:14.753009 (MainThread): Parsing macros/schema_tests/not_constant.sql
2022-01-15 08:36:14.754171 (MainThread): Parsing macros/schema_tests/accepted_range.sql
2022-01-15 08:36:14.756493 (MainThread): Parsing macros/schema_tests/not_accepted_values.sql
2022-01-15 08:36:14.758438 (MainThread): Parsing macros/schema_tests/test_unique_where.sql
2022-01-15 08:36:14.759759 (MainThread): Parsing macros/schema_tests/at_least_one.sql
2022-01-15 08:36:14.760917 (MainThread): Parsing macros/schema_tests/unique_combination_of_columns.sql
2022-01-15 08:36:14.764035 (MainThread): Parsing macros/schema_tests/cardinality_equality.sql
2022-01-15 08:36:14.765904 (MainThread): Parsing macros/schema_tests/expression_is_true.sql
2022-01-15 08:36:14.767565 (MainThread): Parsing macros/schema_tests/sequential_values.sql
2022-01-15 08:36:14.770440 (MainThread): Parsing macros/schema_tests/test_not_null_where.sql
2022-01-15 08:36:14.771771 (MainThread): Parsing macros/schema_tests/equality.sql
2022-01-15 08:36:14.775038 (MainThread): Parsing macros/schema_tests/mutually_exclusive_ranges.sql
2022-01-15 08:36:14.783638 (MainThread): Parsing macros/sql/date_spine.sql
2022-01-15 08:36:14.788206 (MainThread): Parsing macros/sql/nullcheck_table.sql
2022-01-15 08:36:14.789807 (MainThread): Parsing macros/sql/get_relations_by_pattern.sql
2022-01-15 08:36:14.792974 (MainThread): Parsing macros/sql/generate_series.sql
2022-01-15 08:36:14.822009 (MainThread): Parsing macros/sql/get_relations_by_prefix.sql
2022-01-15 08:36:14.826387 (MainThread): Parsing macros/sql/get_tables_by_prefix_sql.sql
2022-01-15 08:36:14.828606 (MainThread): Parsing macros/sql/star.sql
2022-01-15 08:36:14.832931 (MainThread): Parsing macros/sql/unpivot.sql
2022-01-15 08:36:14.842853 (MainThread): Parsing macros/sql/union.sql
2022-01-15 08:36:14.852645 (MainThread): Parsing macros/sql/groupby.sql
2022-01-15 08:36:14.854184 (MainThread): Parsing macros/sql/surrogate_key.sql
2022-01-15 08:36:14.858004 (MainThread): Parsing macros/sql/safe_add.sql
2022-01-15 08:36:14.859833 (MainThread): Parsing macros/sql/nullcheck.sql
2022-01-15 08:36:14.861673 (MainThread): Parsing macros/sql/get_tables_by_pattern_sql.sql
2022-01-15 08:36:14.868829 (MainThread): Parsing macros/sql/get_column_values.sql
2022-01-15 08:36:14.874172 (MainThread): Parsing macros/sql/pivot.sql
2022-01-15 08:36:14.878521 (MainThread): Parsing macros/sql/get_query_results_as_dict.sql
2022-01-15 08:36:14.880997 (MainThread): Parsing macros/sql/haversine_distance.sql
2022-01-15 08:36:15.183121 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-15 08:36:15.194683 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-15 08:36:15.198209 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.film_test".
2022-01-15 08:36:15.201077 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-15 08:36:15.208922 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-15 08:36:15.211691 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-15 08:36:15.222909 (MainThread): Acquiring new postgres connection "test.sakila_dbt_project.film_replacementcost_30".
2022-01-15 08:36:15.224659 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:36:15.256054 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:36:15.257742 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:36:15.259363 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:36:15.261122 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:36:15.262761 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:36:15.264630 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:36:15.276256 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:36:15.280178 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:36:15.293953 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:36:15.295649 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 08:36:15.319711 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6ad6d688-a9a2-4af6-b775-790185d76048', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110cddfa0>]}
2022-01-15 08:36:15.328549 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-01-15 08:36:15.329279 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6ad6d688-a9a2-4af6-b775-790185d76048', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110b3a550>]}
2022-01-15 08:36:15.329536 (MainThread): Found 6 models, 11 tests, 0 snapshots, 0 analyses, 347 macros, 0 operations, 0 seed files, 12 sources, 0 exposures
2022-01-15 08:36:15.331507 (MainThread): 
2022-01-15 08:36:15.331943 (MainThread): Acquiring new postgres connection "master".
2022-01-15 08:36:15.332889 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_dwh".
2022-01-15 08:36:15.341888 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-15 08:36:15.342057 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: BEGIN
2022-01-15 08:36:15.342258 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2022-01-15 08:36:15.814548 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.47 seconds
2022-01-15 08:36:15.815046 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-15 08:36:15.815414 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_dwh"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dwh'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dwh'
  
2022-01-15 08:36:15.886563 (ThreadPoolExecutor-1_0): SQL status: SELECT 6 in 0.07 seconds
2022-01-15 08:36:15.888645 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: ROLLBACK
2022-01-15 08:36:15.948837 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: Close
2022-01-15 08:36:15.954286 (MainThread): Using postgres connection "master".
2022-01-15 08:36:15.954514 (MainThread): On master: BEGIN
2022-01-15 08:36:15.954686 (MainThread): Opening a new connection, currently in state init
2022-01-15 08:36:16.333440 (MainThread): SQL status: BEGIN in 0.38 seconds
2022-01-15 08:36:16.333762 (MainThread): Using postgres connection "master".
2022-01-15 08:36:16.333961 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-15 08:36:16.420864 (MainThread): SQL status: SELECT 47 in 0.09 seconds
2022-01-15 08:36:16.424398 (MainThread): On master: ROLLBACK
2022-01-15 08:36:16.485363 (MainThread): On master: Close
2022-01-15 08:36:16.486194 (MainThread): 14:06:16 | Concurrency: 1 threads (target='dev')
2022-01-15 08:36:16.486567 (MainThread): 14:06:16 | 
2022-01-15 08:36:16.489996 (Thread-1): Began running node test.sakila_dbt_project.accepted_values_film_test_language_id__False__2__1.c6efaacf18
2022-01-15 08:36:16.490290 (Thread-1): 14:06:16 | 1 of 11 START test accepted_values_film_test_language_id__False__2__1 [RUN]
2022-01-15 08:36:16.490733 (Thread-1): Acquiring new postgres connection "test.sakila_dbt_project.accepted_values_film_test_language_id__False__2__1.c6efaacf18".
2022-01-15 08:36:16.490981 (Thread-1): Compiling test.sakila_dbt_project.accepted_values_film_test_language_id__False__2__1.c6efaacf18
2022-01-15 08:36:16.494954 (Thread-1): Writing injected SQL for node "test.sakila_dbt_project.accepted_values_film_test_language_id__False__2__1.c6efaacf18"
2022-01-15 08:36:16.496527 (Thread-1): finished collecting timing info
2022-01-15 08:36:16.515341 (Thread-1): Writing runtime SQL for node "test.sakila_dbt_project.accepted_values_film_test_language_id__False__2__1.c6efaacf18"
2022-01-15 08:36:16.516858 (Thread-1): Using postgres connection "test.sakila_dbt_project.accepted_values_film_test_language_id__False__2__1.c6efaacf18".
2022-01-15 08:36:16.517050 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_language_id__False__2__1.c6efaacf18: BEGIN
2022-01-15 08:36:16.517214 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 08:36:16.890854 (Thread-1): SQL status: BEGIN in 0.37 seconds
2022-01-15 08:36:16.891263 (Thread-1): Using postgres connection "test.sakila_dbt_project.accepted_values_film_test_language_id__False__2__1.c6efaacf18".
2022-01-15 08:36:16.891528 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_language_id__False__2__1.c6efaacf18: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "test.sakila_dbt_project.accepted_values_film_test_language_id__False__2__1.c6efaacf18"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        language_id as value_field,
        count(*) as n_records

    from "sakila_wh"."dwh"."film_test"
    group by language_id

)

select *
from all_values
where value_field not in (
    2,1
)



      
    ) dbt_internal_test
2022-01-15 08:36:16.956512 (Thread-1): SQL status: SELECT 1 in 0.06 seconds
2022-01-15 08:36:16.959601 (Thread-1): finished collecting timing info
2022-01-15 08:36:16.959891 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_language_id__False__2__1.c6efaacf18: ROLLBACK
2022-01-15 08:36:17.019950 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_language_id__False__2__1.c6efaacf18: Close
2022-01-15 08:36:17.020794 (Thread-1): 14:06:17 | 1 of 11 PASS accepted_values_film_test_language_id__False__2__1...... [PASS in 0.53s]
2022-01-15 08:36:17.021161 (Thread-1): Finished running node test.sakila_dbt_project.accepted_values_film_test_language_id__False__2__1.c6efaacf18
2022-01-15 08:36:17.021506 (Thread-1): Began running node test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8
2022-01-15 08:36:17.021914 (Thread-1): 14:06:17 | 2 of 11 START test accepted_values_film_test_rating__NC_17__PG_13__G__R__PG [RUN]
2022-01-15 08:36:17.022372 (Thread-1): Acquiring new postgres connection "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8".
2022-01-15 08:36:17.022601 (Thread-1): Compiling test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8
2022-01-15 08:36:17.029781 (Thread-1): Writing injected SQL for node "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8"
2022-01-15 08:36:17.030472 (Thread-1): finished collecting timing info
2022-01-15 08:36:17.032726 (Thread-1): Writing runtime SQL for node "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8"
2022-01-15 08:36:17.033401 (Thread-1): Using postgres connection "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8".
2022-01-15 08:36:17.033601 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8: BEGIN
2022-01-15 08:36:17.033780 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 08:36:17.404004 (Thread-1): SQL status: BEGIN in 0.37 seconds
2022-01-15 08:36:17.404379 (Thread-1): Using postgres connection "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8".
2022-01-15 08:36:17.404651 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

with all_values as (

    select
        rating as value_field,
        count(*) as n_records

    from "sakila_wh"."dwh"."film_test"
    group by rating

)

select *
from all_values
where value_field not in (
    'NC-17','PG-13','G','R','PG'
)



      
    ) dbt_internal_test
2022-01-15 08:36:17.479127 (Thread-1): SQL status: SELECT 1 in 0.07 seconds
2022-01-15 08:36:17.481574 (Thread-1): finished collecting timing info
2022-01-15 08:36:17.481915 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8: ROLLBACK
2022-01-15 08:36:17.543814 (Thread-1): On test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8: Close
2022-01-15 08:36:17.544766 (Thread-1): 14:06:17 | 2 of 11 PASS accepted_values_film_test_rating__NC_17__PG_13__G__R__PG [PASS in 0.52s]
2022-01-15 08:36:17.545161 (Thread-1): Finished running node test.sakila_dbt_project.accepted_values_film_test_rating__NC_17__PG_13__G__R__PG.c6439407a8
2022-01-15 08:36:17.545426 (Thread-1): Began running node test.sakila_dbt_project.film_replacementcost_30
2022-01-15 08:36:17.545785 (Thread-1): 14:06:17 | 3 of 11 START test film_replacementcost_30........................... [RUN]
2022-01-15 08:36:17.546224 (Thread-1): Acquiring new postgres connection "test.sakila_dbt_project.film_replacementcost_30".
2022-01-15 08:36:17.546452 (Thread-1): Compiling test.sakila_dbt_project.film_replacementcost_30
2022-01-15 08:36:17.548538 (Thread-1): Writing injected SQL for node "test.sakila_dbt_project.film_replacementcost_30"
2022-01-15 08:36:17.549332 (Thread-1): finished collecting timing info
2022-01-15 08:36:17.551448 (Thread-1): Writing runtime SQL for node "test.sakila_dbt_project.film_replacementcost_30"
2022-01-15 08:36:17.552123 (Thread-1): Using postgres connection "test.sakila_dbt_project.film_replacementcost_30".
2022-01-15 08:36:17.552295 (Thread-1): On test.sakila_dbt_project.film_replacementcost_30: BEGIN
2022-01-15 08:36:17.552459 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 08:36:17.930406 (Thread-1): SQL status: BEGIN in 0.38 seconds
2022-01-15 08:36:17.930791 (Thread-1): Using postgres connection "test.sakila_dbt_project.film_replacementcost_30".
2022-01-15 08:36:17.931035 (Thread-1): On test.sakila_dbt_project.film_replacementcost_30: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "test.sakila_dbt_project.film_replacementcost_30"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      select * from 
dwh.film_test  
where replacement_cost > 29
      
    ) dbt_internal_test
2022-01-15 08:36:17.996323 (Thread-1): SQL status: SELECT 1 in 0.06 seconds
2022-01-15 08:36:17.998672 (Thread-1): finished collecting timing info
2022-01-15 08:36:17.999040 (Thread-1): On test.sakila_dbt_project.film_replacementcost_30: ROLLBACK
2022-01-15 08:36:18.060145 (Thread-1): On test.sakila_dbt_project.film_replacementcost_30: Close
2022-01-15 08:36:18.061271 (Thread-1): 14:06:18 | 3 of 11 FAIL 53 film_replacementcost_30.............................. [FAIL 53 in 0.52s]
2022-01-15 08:36:18.061639 (Thread-1): Finished running node test.sakila_dbt_project.film_replacementcost_30
2022-01-15 08:36:18.062017 (Thread-1): Began running node test.sakila_dbt_project.not_null_dim_date_date_dim_id.b5878fcef1
2022-01-15 08:36:18.062408 (Thread-1): 14:06:18 | 4 of 11 START test not_null_dim_date_date_dim_id..................... [RUN]
2022-01-15 08:36:18.062857 (Thread-1): Acquiring new postgres connection "test.sakila_dbt_project.not_null_dim_date_date_dim_id.b5878fcef1".
2022-01-15 08:36:18.063086 (Thread-1): Compiling test.sakila_dbt_project.not_null_dim_date_date_dim_id.b5878fcef1
2022-01-15 08:36:18.069968 (Thread-1): Writing injected SQL for node "test.sakila_dbt_project.not_null_dim_date_date_dim_id.b5878fcef1"
2022-01-15 08:36:18.071033 (Thread-1): finished collecting timing info
2022-01-15 08:36:18.073208 (Thread-1): Writing runtime SQL for node "test.sakila_dbt_project.not_null_dim_date_date_dim_id.b5878fcef1"
2022-01-15 08:36:18.074231 (Thread-1): Using postgres connection "test.sakila_dbt_project.not_null_dim_date_date_dim_id.b5878fcef1".
2022-01-15 08:36:18.074417 (Thread-1): On test.sakila_dbt_project.not_null_dim_date_date_dim_id.b5878fcef1: BEGIN
2022-01-15 08:36:18.074586 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 08:36:18.447367 (Thread-1): SQL status: BEGIN in 0.37 seconds
2022-01-15 08:36:18.447752 (Thread-1): Using postgres connection "test.sakila_dbt_project.not_null_dim_date_date_dim_id.b5878fcef1".
2022-01-15 08:36:18.447996 (Thread-1): On test.sakila_dbt_project.not_null_dim_date_date_dim_id.b5878fcef1: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "test.sakila_dbt_project.not_null_dim_date_date_dim_id.b5878fcef1"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from "sakila_wh"."dwh"."dim_date"
where date_dim_id is null



      
    ) dbt_internal_test
2022-01-15 08:36:18.512917 (Thread-1): SQL status: SELECT 1 in 0.06 seconds
2022-01-15 08:36:18.514655 (Thread-1): finished collecting timing info
2022-01-15 08:36:18.514899 (Thread-1): On test.sakila_dbt_project.not_null_dim_date_date_dim_id.b5878fcef1: ROLLBACK
2022-01-15 08:36:18.576336 (Thread-1): On test.sakila_dbt_project.not_null_dim_date_date_dim_id.b5878fcef1: Close
2022-01-15 08:36:18.577303 (Thread-1): 14:06:18 | 4 of 11 PASS not_null_dim_date_date_dim_id........................... [PASS in 0.51s]
2022-01-15 08:36:18.577706 (Thread-1): Finished running node test.sakila_dbt_project.not_null_dim_date_date_dim_id.b5878fcef1
2022-01-15 08:36:18.578041 (Thread-1): Began running node test.sakila_dbt_project.not_null_hello_world_customer_id.2c9ffec564
2022-01-15 08:36:18.578396 (Thread-1): 14:06:18 | 5 of 11 START test not_null_hello_world_customer_id.................. [RUN]
2022-01-15 08:36:18.578838 (Thread-1): Acquiring new postgres connection "test.sakila_dbt_project.not_null_hello_world_customer_id.2c9ffec564".
2022-01-15 08:36:18.579078 (Thread-1): Compiling test.sakila_dbt_project.not_null_hello_world_customer_id.2c9ffec564
2022-01-15 08:36:18.583219 (Thread-1): Writing injected SQL for node "test.sakila_dbt_project.not_null_hello_world_customer_id.2c9ffec564"
2022-01-15 08:36:18.583887 (Thread-1): finished collecting timing info
2022-01-15 08:36:18.586089 (Thread-1): Writing runtime SQL for node "test.sakila_dbt_project.not_null_hello_world_customer_id.2c9ffec564"
2022-01-15 08:36:18.586718 (Thread-1): Using postgres connection "test.sakila_dbt_project.not_null_hello_world_customer_id.2c9ffec564".
2022-01-15 08:36:18.586892 (Thread-1): On test.sakila_dbt_project.not_null_hello_world_customer_id.2c9ffec564: BEGIN
2022-01-15 08:36:18.587059 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 08:36:18.957483 (Thread-1): SQL status: BEGIN in 0.37 seconds
2022-01-15 08:36:18.958040 (Thread-1): Using postgres connection "test.sakila_dbt_project.not_null_hello_world_customer_id.2c9ffec564".
2022-01-15 08:36:18.958291 (Thread-1): On test.sakila_dbt_project.not_null_hello_world_customer_id.2c9ffec564: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "test.sakila_dbt_project.not_null_hello_world_customer_id.2c9ffec564"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from "sakila_wh"."dwh"."hello_world"
where customer_id is null



      
    ) dbt_internal_test
2022-01-15 08:36:19.025270 (Thread-1): SQL status: SELECT 1 in 0.07 seconds
2022-01-15 08:36:19.026868 (Thread-1): finished collecting timing info
2022-01-15 08:36:19.027100 (Thread-1): On test.sakila_dbt_project.not_null_hello_world_customer_id.2c9ffec564: ROLLBACK
2022-01-15 08:36:19.087100 (Thread-1): On test.sakila_dbt_project.not_null_hello_world_customer_id.2c9ffec564: Close
2022-01-15 08:36:19.087896 (Thread-1): 14:06:19 | 5 of 11 PASS not_null_hello_world_customer_id........................ [PASS in 0.51s]
2022-01-15 08:36:19.088176 (Thread-1): Finished running node test.sakila_dbt_project.not_null_hello_world_customer_id.2c9ffec564
2022-01-15 08:36:19.088573 (Thread-1): Began running node test.sakila_dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
2022-01-15 08:36:19.088961 (Thread-1): 14:06:19 | 6 of 11 START test not_null_my_first_dbt_model_id.................... [RUN]
2022-01-15 08:36:19.089401 (Thread-1): Acquiring new postgres connection "test.sakila_dbt_project.not_null_my_first_dbt_model_id.5fb22c2710".
2022-01-15 08:36:19.089600 (Thread-1): Compiling test.sakila_dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
2022-01-15 08:36:19.093457 (Thread-1): Writing injected SQL for node "test.sakila_dbt_project.not_null_my_first_dbt_model_id.5fb22c2710"
2022-01-15 08:36:19.094050 (Thread-1): finished collecting timing info
2022-01-15 08:36:19.097030 (Thread-1): Writing runtime SQL for node "test.sakila_dbt_project.not_null_my_first_dbt_model_id.5fb22c2710"
2022-01-15 08:36:19.097642 (Thread-1): Using postgres connection "test.sakila_dbt_project.not_null_my_first_dbt_model_id.5fb22c2710".
2022-01-15 08:36:19.097810 (Thread-1): On test.sakila_dbt_project.not_null_my_first_dbt_model_id.5fb22c2710: BEGIN
2022-01-15 08:36:19.097965 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 08:36:19.468422 (Thread-1): SQL status: BEGIN in 0.37 seconds
2022-01-15 08:36:19.468800 (Thread-1): Using postgres connection "test.sakila_dbt_project.not_null_my_first_dbt_model_id.5fb22c2710".
2022-01-15 08:36:19.469055 (Thread-1): On test.sakila_dbt_project.not_null_my_first_dbt_model_id.5fb22c2710: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "test.sakila_dbt_project.not_null_my_first_dbt_model_id.5fb22c2710"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from "sakila_wh"."dwh"."my_first_dbt_model"
where id is null



      
    ) dbt_internal_test
2022-01-15 08:36:19.531895 (Thread-1): SQL status: SELECT 1 in 0.06 seconds
2022-01-15 08:36:19.533793 (Thread-1): finished collecting timing info
2022-01-15 08:36:19.534071 (Thread-1): On test.sakila_dbt_project.not_null_my_first_dbt_model_id.5fb22c2710: ROLLBACK
2022-01-15 08:36:19.595344 (Thread-1): On test.sakila_dbt_project.not_null_my_first_dbt_model_id.5fb22c2710: Close
2022-01-15 08:36:19.596240 (Thread-1): 14:06:19 | 6 of 11 PASS not_null_my_first_dbt_model_id.......................... [PASS in 0.51s]
2022-01-15 08:36:19.596619 (Thread-1): Finished running node test.sakila_dbt_project.not_null_my_first_dbt_model_id.5fb22c2710
2022-01-15 08:36:19.596892 (Thread-1): Began running node test.sakila_dbt_project.not_null_my_second_dbt_model_id.151b76d778
2022-01-15 08:36:19.597236 (Thread-1): 14:06:19 | 7 of 11 START test not_null_my_second_dbt_model_id................... [RUN]
2022-01-15 08:36:19.597774 (Thread-1): Acquiring new postgres connection "test.sakila_dbt_project.not_null_my_second_dbt_model_id.151b76d778".
2022-01-15 08:36:19.598048 (Thread-1): Compiling test.sakila_dbt_project.not_null_my_second_dbt_model_id.151b76d778
2022-01-15 08:36:19.602171 (Thread-1): Writing injected SQL for node "test.sakila_dbt_project.not_null_my_second_dbt_model_id.151b76d778"
2022-01-15 08:36:19.602855 (Thread-1): finished collecting timing info
2022-01-15 08:36:19.605126 (Thread-1): Writing runtime SQL for node "test.sakila_dbt_project.not_null_my_second_dbt_model_id.151b76d778"
2022-01-15 08:36:19.605748 (Thread-1): Using postgres connection "test.sakila_dbt_project.not_null_my_second_dbt_model_id.151b76d778".
2022-01-15 08:36:19.605928 (Thread-1): On test.sakila_dbt_project.not_null_my_second_dbt_model_id.151b76d778: BEGIN
2022-01-15 08:36:19.606103 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 08:36:19.988338 (Thread-1): SQL status: BEGIN in 0.38 seconds
2022-01-15 08:36:19.988796 (Thread-1): Using postgres connection "test.sakila_dbt_project.not_null_my_second_dbt_model_id.151b76d778".
2022-01-15 08:36:19.989059 (Thread-1): On test.sakila_dbt_project.not_null_my_second_dbt_model_id.151b76d778: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "test.sakila_dbt_project.not_null_my_second_dbt_model_id.151b76d778"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select *
from "sakila_wh"."dwh"."my_second_dbt_model"
where id is null



      
    ) dbt_internal_test
2022-01-15 08:36:20.053917 (Thread-1): SQL status: SELECT 1 in 0.06 seconds
2022-01-15 08:36:20.056490 (Thread-1): finished collecting timing info
2022-01-15 08:36:20.056860 (Thread-1): On test.sakila_dbt_project.not_null_my_second_dbt_model_id.151b76d778: ROLLBACK
2022-01-15 08:36:20.119144 (Thread-1): On test.sakila_dbt_project.not_null_my_second_dbt_model_id.151b76d778: Close
2022-01-15 08:36:20.120194 (Thread-1): 14:06:20 | 7 of 11 PASS not_null_my_second_dbt_model_id......................... [PASS in 0.52s]
2022-01-15 08:36:20.120512 (Thread-1): Finished running node test.sakila_dbt_project.not_null_my_second_dbt_model_id.151b76d778
2022-01-15 08:36:20.120773 (Thread-1): Began running node test.sakila_dbt_project.unique_dim_date_date_dim_id.8ef810b6d3
2022-01-15 08:36:20.121137 (Thread-1): 14:06:20 | 8 of 11 START test unique_dim_date_date_dim_id....................... [RUN]
2022-01-15 08:36:20.121566 (Thread-1): Acquiring new postgres connection "test.sakila_dbt_project.unique_dim_date_date_dim_id.8ef810b6d3".
2022-01-15 08:36:20.121792 (Thread-1): Compiling test.sakila_dbt_project.unique_dim_date_date_dim_id.8ef810b6d3
2022-01-15 08:36:20.129042 (Thread-1): Writing injected SQL for node "test.sakila_dbt_project.unique_dim_date_date_dim_id.8ef810b6d3"
2022-01-15 08:36:20.129702 (Thread-1): finished collecting timing info
2022-01-15 08:36:20.131895 (Thread-1): Writing runtime SQL for node "test.sakila_dbt_project.unique_dim_date_date_dim_id.8ef810b6d3"
2022-01-15 08:36:20.132501 (Thread-1): Using postgres connection "test.sakila_dbt_project.unique_dim_date_date_dim_id.8ef810b6d3".
2022-01-15 08:36:20.132674 (Thread-1): On test.sakila_dbt_project.unique_dim_date_date_dim_id.8ef810b6d3: BEGIN
2022-01-15 08:36:20.132840 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 08:36:20.516792 (Thread-1): SQL status: BEGIN in 0.38 seconds
2022-01-15 08:36:20.517211 (Thread-1): Using postgres connection "test.sakila_dbt_project.unique_dim_date_date_dim_id.8ef810b6d3".
2022-01-15 08:36:20.517455 (Thread-1): On test.sakila_dbt_project.unique_dim_date_date_dim_id.8ef810b6d3: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "test.sakila_dbt_project.unique_dim_date_date_dim_id.8ef810b6d3"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    date_dim_id as unique_field,
    count(*) as n_records

from "sakila_wh"."dwh"."dim_date"
where date_dim_id is not null
group by date_dim_id
having count(*) > 1



      
    ) dbt_internal_test
2022-01-15 08:36:20.593893 (Thread-1): SQL status: SELECT 1 in 0.08 seconds
2022-01-15 08:36:20.596406 (Thread-1): finished collecting timing info
2022-01-15 08:36:20.596761 (Thread-1): On test.sakila_dbt_project.unique_dim_date_date_dim_id.8ef810b6d3: ROLLBACK
2022-01-15 08:36:20.658866 (Thread-1): On test.sakila_dbt_project.unique_dim_date_date_dim_id.8ef810b6d3: Close
2022-01-15 08:36:20.659912 (Thread-1): 14:06:20 | 8 of 11 PASS unique_dim_date_date_dim_id............................. [PASS in 0.54s]
2022-01-15 08:36:20.660262 (Thread-1): Finished running node test.sakila_dbt_project.unique_dim_date_date_dim_id.8ef810b6d3
2022-01-15 08:36:20.660584 (Thread-1): Began running node test.sakila_dbt_project.unique_hello_world_customer_id.ec99a3c2de
2022-01-15 08:36:20.661017 (Thread-1): 14:06:20 | 9 of 11 START test unique_hello_world_customer_id.................... [RUN]
2022-01-15 08:36:20.661599 (Thread-1): Acquiring new postgres connection "test.sakila_dbt_project.unique_hello_world_customer_id.ec99a3c2de".
2022-01-15 08:36:20.661885 (Thread-1): Compiling test.sakila_dbt_project.unique_hello_world_customer_id.ec99a3c2de
2022-01-15 08:36:20.666396 (Thread-1): Writing injected SQL for node "test.sakila_dbt_project.unique_hello_world_customer_id.ec99a3c2de"
2022-01-15 08:36:20.667036 (Thread-1): finished collecting timing info
2022-01-15 08:36:20.669171 (Thread-1): Writing runtime SQL for node "test.sakila_dbt_project.unique_hello_world_customer_id.ec99a3c2de"
2022-01-15 08:36:20.669777 (Thread-1): Using postgres connection "test.sakila_dbt_project.unique_hello_world_customer_id.ec99a3c2de".
2022-01-15 08:36:20.669956 (Thread-1): On test.sakila_dbt_project.unique_hello_world_customer_id.ec99a3c2de: BEGIN
2022-01-15 08:36:20.670124 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 08:36:21.042997 (Thread-1): SQL status: BEGIN in 0.37 seconds
2022-01-15 08:36:21.043424 (Thread-1): Using postgres connection "test.sakila_dbt_project.unique_hello_world_customer_id.ec99a3c2de".
2022-01-15 08:36:21.043677 (Thread-1): On test.sakila_dbt_project.unique_hello_world_customer_id.ec99a3c2de: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "test.sakila_dbt_project.unique_hello_world_customer_id.ec99a3c2de"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    customer_id as unique_field,
    count(*) as n_records

from "sakila_wh"."dwh"."hello_world"
where customer_id is not null
group by customer_id
having count(*) > 1



      
    ) dbt_internal_test
2022-01-15 08:36:21.109488 (Thread-1): SQL status: SELECT 1 in 0.07 seconds
2022-01-15 08:36:21.111717 (Thread-1): finished collecting timing info
2022-01-15 08:36:21.112000 (Thread-1): On test.sakila_dbt_project.unique_hello_world_customer_id.ec99a3c2de: ROLLBACK
2022-01-15 08:36:21.172416 (Thread-1): On test.sakila_dbt_project.unique_hello_world_customer_id.ec99a3c2de: Close
2022-01-15 08:36:21.173229 (Thread-1): 14:06:21 | 9 of 11 PASS unique_hello_world_customer_id.......................... [PASS in 0.51s]
2022-01-15 08:36:21.173600 (Thread-1): Finished running node test.sakila_dbt_project.unique_hello_world_customer_id.ec99a3c2de
2022-01-15 08:36:21.173928 (Thread-1): Began running node test.sakila_dbt_project.unique_my_first_dbt_model_id.16e066b321
2022-01-15 08:36:21.174396 (Thread-1): 14:06:21 | 10 of 11 START test unique_my_first_dbt_model_id..................... [RUN]
2022-01-15 08:36:21.174896 (Thread-1): Acquiring new postgres connection "test.sakila_dbt_project.unique_my_first_dbt_model_id.16e066b321".
2022-01-15 08:36:21.175125 (Thread-1): Compiling test.sakila_dbt_project.unique_my_first_dbt_model_id.16e066b321
2022-01-15 08:36:21.179602 (Thread-1): Writing injected SQL for node "test.sakila_dbt_project.unique_my_first_dbt_model_id.16e066b321"
2022-01-15 08:36:21.180273 (Thread-1): finished collecting timing info
2022-01-15 08:36:21.182609 (Thread-1): Writing runtime SQL for node "test.sakila_dbt_project.unique_my_first_dbt_model_id.16e066b321"
2022-01-15 08:36:21.183234 (Thread-1): Using postgres connection "test.sakila_dbt_project.unique_my_first_dbt_model_id.16e066b321".
2022-01-15 08:36:21.183418 (Thread-1): On test.sakila_dbt_project.unique_my_first_dbt_model_id.16e066b321: BEGIN
2022-01-15 08:36:21.183588 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 08:36:21.566892 (Thread-1): SQL status: BEGIN in 0.38 seconds
2022-01-15 08:36:21.567275 (Thread-1): Using postgres connection "test.sakila_dbt_project.unique_my_first_dbt_model_id.16e066b321".
2022-01-15 08:36:21.567526 (Thread-1): On test.sakila_dbt_project.unique_my_first_dbt_model_id.16e066b321: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "test.sakila_dbt_project.unique_my_first_dbt_model_id.16e066b321"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "sakila_wh"."dwh"."my_first_dbt_model"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
2022-01-15 08:36:21.632155 (Thread-1): SQL status: SELECT 1 in 0.06 seconds
2022-01-15 08:36:21.634184 (Thread-1): finished collecting timing info
2022-01-15 08:36:21.634464 (Thread-1): On test.sakila_dbt_project.unique_my_first_dbt_model_id.16e066b321: ROLLBACK
2022-01-15 08:36:21.695914 (Thread-1): On test.sakila_dbt_project.unique_my_first_dbt_model_id.16e066b321: Close
2022-01-15 08:36:21.696940 (Thread-1): 14:06:21 | 10 of 11 PASS unique_my_first_dbt_model_id........................... [PASS in 0.52s]
2022-01-15 08:36:21.697298 (Thread-1): Finished running node test.sakila_dbt_project.unique_my_first_dbt_model_id.16e066b321
2022-01-15 08:36:21.697656 (Thread-1): Began running node test.sakila_dbt_project.unique_my_second_dbt_model_id.57a0f8c493
2022-01-15 08:36:21.698122 (Thread-1): 14:06:21 | 11 of 11 START test unique_my_second_dbt_model_id.................... [RUN]
2022-01-15 08:36:21.698736 (Thread-1): Acquiring new postgres connection "test.sakila_dbt_project.unique_my_second_dbt_model_id.57a0f8c493".
2022-01-15 08:36:21.698995 (Thread-1): Compiling test.sakila_dbt_project.unique_my_second_dbt_model_id.57a0f8c493
2022-01-15 08:36:21.704477 (Thread-1): Writing injected SQL for node "test.sakila_dbt_project.unique_my_second_dbt_model_id.57a0f8c493"
2022-01-15 08:36:21.705180 (Thread-1): finished collecting timing info
2022-01-15 08:36:21.707365 (Thread-1): Writing runtime SQL for node "test.sakila_dbt_project.unique_my_second_dbt_model_id.57a0f8c493"
2022-01-15 08:36:21.707947 (Thread-1): Using postgres connection "test.sakila_dbt_project.unique_my_second_dbt_model_id.57a0f8c493".
2022-01-15 08:36:21.708122 (Thread-1): On test.sakila_dbt_project.unique_my_second_dbt_model_id.57a0f8c493: BEGIN
2022-01-15 08:36:21.708291 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 08:36:22.100130 (Thread-1): SQL status: BEGIN in 0.39 seconds
2022-01-15 08:36:22.100524 (Thread-1): Using postgres connection "test.sakila_dbt_project.unique_my_second_dbt_model_id.57a0f8c493".
2022-01-15 08:36:22.100724 (Thread-1): On test.sakila_dbt_project.unique_my_second_dbt_model_id.57a0f8c493: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "test.sakila_dbt_project.unique_my_second_dbt_model_id.57a0f8c493"} */
select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
    

select
    id as unique_field,
    count(*) as n_records

from "sakila_wh"."dwh"."my_second_dbt_model"
where id is not null
group by id
having count(*) > 1



      
    ) dbt_internal_test
2022-01-15 08:36:22.165685 (Thread-1): SQL status: SELECT 1 in 0.06 seconds
2022-01-15 08:36:22.167547 (Thread-1): finished collecting timing info
2022-01-15 08:36:22.167830 (Thread-1): On test.sakila_dbt_project.unique_my_second_dbt_model_id.57a0f8c493: ROLLBACK
2022-01-15 08:36:22.227761 (Thread-1): On test.sakila_dbt_project.unique_my_second_dbt_model_id.57a0f8c493: Close
2022-01-15 08:36:22.228644 (Thread-1): 14:06:22 | 11 of 11 PASS unique_my_second_dbt_model_id.......................... [PASS in 0.53s]
2022-01-15 08:36:22.228913 (Thread-1): Finished running node test.sakila_dbt_project.unique_my_second_dbt_model_id.57a0f8c493
2022-01-15 08:36:22.230100 (MainThread): Acquiring new postgres connection "master".
2022-01-15 08:36:22.230485 (MainThread): 14:06:22 | 
2022-01-15 08:36:22.230703 (MainThread): 14:06:22 | Finished running 11 tests in 6.90s.
2022-01-15 08:36:22.230892 (MainThread): Connection 'master' was properly closed.
2022-01-15 08:36:22.231044 (MainThread): Connection 'test.sakila_dbt_project.unique_my_second_dbt_model_id.57a0f8c493' was properly closed.
2022-01-15 08:36:22.240503 (MainThread): 
2022-01-15 08:36:22.240735 (MainThread): Completed with 1 error and 0 warnings:
2022-01-15 08:36:22.240932 (MainThread): 
2022-01-15 08:36:22.241131 (MainThread): Failure in test film_replacementcost_30 (tests/film_replacementcost_30.sql)
2022-01-15 08:36:22.241313 (MainThread):   Got 53 results, configured to fail if != 0
2022-01-15 08:36:22.241498 (MainThread): 
2022-01-15 08:36:22.241686 (MainThread):   compiled SQL at target/compiled/sakila_dbt_project/tests/film_replacementcost_30.sql
2022-01-15 08:36:22.241892 (MainThread): 
Done. PASS=10 WARN=0 ERROR=1 SKIP=0 TOTAL=11
2022-01-15 08:36:22.242146 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110ec6f40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110d77670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110d77550>]}
2022-01-15 08:36:22.242419 (MainThread): Flushing usage events
2022-01-15 10:15:52.827415 (MainThread): Running with dbt=0.21.1
2022-01-15 10:15:52.940139 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=['example.customer_test'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2022-01-15 10:15:52.942036 (MainThread): Tracking: tracking
2022-01-15 10:15:52.966732 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1129808e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11238e250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11296ddc0>]}
2022-01-15 10:15:52.989737 (MainThread): Partial parsing not enabled
2022-01-15 10:15:53.044807 (MainThread): Parsing macros/catalog.sql
2022-01-15 10:15:53.048715 (MainThread): Parsing macros/relations.sql
2022-01-15 10:15:53.050206 (MainThread): Parsing macros/adapters.sql
2022-01-15 10:15:53.076197 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2022-01-15 10:15:53.078111 (MainThread): Parsing macros/core.sql
2022-01-15 10:15:53.082173 (MainThread): Parsing macros/materializations/test.sql
2022-01-15 10:15:53.089707 (MainThread): Parsing macros/materializations/helpers.sql
2022-01-15 10:15:53.100357 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2022-01-15 10:15:53.102212 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2022-01-15 10:15:53.119340 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2022-01-15 10:15:53.149244 (MainThread): Parsing macros/materializations/seed/seed.sql
2022-01-15 10:15:53.170849 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2022-01-15 10:15:53.172633 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2022-01-15 10:15:53.181764 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2022-01-15 10:15:53.200498 (MainThread): Parsing macros/materializations/common/merge.sql
2022-01-15 10:15:53.213460 (MainThread): Parsing macros/materializations/table/table.sql
2022-01-15 10:15:53.220940 (MainThread): Parsing macros/materializations/view/view.sql
2022-01-15 10:15:53.227464 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2022-01-15 10:15:53.230982 (MainThread): Parsing macros/etc/get_custom_alias.sql
2022-01-15 10:15:53.232426 (MainThread): Parsing macros/etc/query.sql
2022-01-15 10:15:53.233585 (MainThread): Parsing macros/etc/is_incremental.sql
2022-01-15 10:15:53.235017 (MainThread): Parsing macros/etc/datetime.sql
2022-01-15 10:15:53.242742 (MainThread): Parsing macros/etc/where_subquery.sql
2022-01-15 10:15:53.244456 (MainThread): Parsing macros/etc/get_custom_schema.sql
2022-01-15 10:15:53.246635 (MainThread): Parsing macros/etc/get_custom_database.sql
2022-01-15 10:15:53.248057 (MainThread): Parsing macros/adapters/common.sql
2022-01-15 10:15:53.299835 (MainThread): Parsing macros/schema_tests/relationships.sql
2022-01-15 10:15:53.301422 (MainThread): Parsing macros/schema_tests/not_null.sql
2022-01-15 10:15:53.302520 (MainThread): Parsing macros/schema_tests/unique.sql
2022-01-15 10:15:53.303835 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2022-01-15 10:15:53.305869 (MainThread): Parsing macros/cross_db_utils/except.sql
2022-01-15 10:15:53.306858 (MainThread): Parsing macros/cross_db_utils/replace.sql
2022-01-15 10:15:53.308013 (MainThread): Parsing macros/cross_db_utils/concat.sql
2022-01-15 10:15:53.308936 (MainThread): Parsing macros/cross_db_utils/datatypes.sql
2022-01-15 10:15:53.314482 (MainThread): Parsing macros/cross_db_utils/_is_relation.sql
2022-01-15 10:15:53.315724 (MainThread): Parsing macros/cross_db_utils/length.sql
2022-01-15 10:15:53.317253 (MainThread): Parsing macros/cross_db_utils/dateadd.sql
2022-01-15 10:15:53.320021 (MainThread): Parsing macros/cross_db_utils/intersect.sql
2022-01-15 10:15:53.321001 (MainThread): Parsing macros/cross_db_utils/right.sql
2022-01-15 10:15:53.323093 (MainThread): Parsing macros/cross_db_utils/datediff.sql
2022-01-15 10:15:53.332690 (MainThread): Parsing macros/cross_db_utils/safe_cast.sql
2022-01-15 10:15:53.334607 (MainThread): Parsing macros/cross_db_utils/hash.sql
2022-01-15 10:15:53.335932 (MainThread): Parsing macros/cross_db_utils/cast_bool_to_text.sql
2022-01-15 10:15:53.337256 (MainThread): Parsing macros/cross_db_utils/identifier.sql
2022-01-15 10:15:53.338791 (MainThread): Parsing macros/cross_db_utils/position.sql
2022-01-15 10:15:53.340231 (MainThread): Parsing macros/cross_db_utils/literal.sql
2022-01-15 10:15:53.341137 (MainThread): Parsing macros/cross_db_utils/current_timestamp.sql
2022-01-15 10:15:53.344447 (MainThread): Parsing macros/cross_db_utils/width_bucket.sql
2022-01-15 10:15:53.349305 (MainThread): Parsing macros/cross_db_utils/last_day.sql
2022-01-15 10:15:53.352813 (MainThread): Parsing macros/cross_db_utils/split_part.sql
2022-01-15 10:15:53.354531 (MainThread): Parsing macros/cross_db_utils/date_trunc.sql
2022-01-15 10:15:53.356029 (MainThread): Parsing macros/cross_db_utils/_is_ephemeral.sql
2022-01-15 10:15:53.357763 (MainThread): Parsing macros/materializations/insert_by_period_materialization.sql
2022-01-15 10:15:53.381067 (MainThread): Parsing macros/web/get_url_host.sql
2022-01-15 10:15:53.382871 (MainThread): Parsing macros/web/get_url_path.sql
2022-01-15 10:15:53.385551 (MainThread): Parsing macros/web/get_url_parameter.sql
2022-01-15 10:15:53.387020 (MainThread): Parsing macros/jinja_helpers/pretty_log_format.sql
2022-01-15 10:15:53.388049 (MainThread): Parsing macros/jinja_helpers/pretty_time.sql
2022-01-15 10:15:53.389165 (MainThread): Parsing macros/jinja_helpers/log_info.sql
2022-01-15 10:15:53.390205 (MainThread): Parsing macros/jinja_helpers/slugify.sql
2022-01-15 10:15:53.391286 (MainThread): Parsing macros/schema_tests/fewer_rows_than.sql
2022-01-15 10:15:53.392891 (MainThread): Parsing macros/schema_tests/equal_rowcount.sql
2022-01-15 10:15:53.394406 (MainThread): Parsing macros/schema_tests/relationships_where.sql
2022-01-15 10:15:53.396636 (MainThread): Parsing macros/schema_tests/recency.sql
2022-01-15 10:15:53.398228 (MainThread): Parsing macros/schema_tests/not_constant.sql
2022-01-15 10:15:53.399430 (MainThread): Parsing macros/schema_tests/accepted_range.sql
2022-01-15 10:15:53.401839 (MainThread): Parsing macros/schema_tests/not_accepted_values.sql
2022-01-15 10:15:53.403828 (MainThread): Parsing macros/schema_tests/test_unique_where.sql
2022-01-15 10:15:53.405154 (MainThread): Parsing macros/schema_tests/at_least_one.sql
2022-01-15 10:15:53.406314 (MainThread): Parsing macros/schema_tests/unique_combination_of_columns.sql
2022-01-15 10:15:53.408898 (MainThread): Parsing macros/schema_tests/cardinality_equality.sql
2022-01-15 10:15:53.410726 (MainThread): Parsing macros/schema_tests/expression_is_true.sql
2022-01-15 10:15:53.412420 (MainThread): Parsing macros/schema_tests/sequential_values.sql
2022-01-15 10:15:53.415309 (MainThread): Parsing macros/schema_tests/test_not_null_where.sql
2022-01-15 10:15:53.416811 (MainThread): Parsing macros/schema_tests/equality.sql
2022-01-15 10:15:53.420075 (MainThread): Parsing macros/schema_tests/mutually_exclusive_ranges.sql
2022-01-15 10:15:53.428354 (MainThread): Parsing macros/sql/date_spine.sql
2022-01-15 10:15:53.432708 (MainThread): Parsing macros/sql/nullcheck_table.sql
2022-01-15 10:15:53.434327 (MainThread): Parsing macros/sql/get_relations_by_pattern.sql
2022-01-15 10:15:53.437469 (MainThread): Parsing macros/sql/generate_series.sql
2022-01-15 10:15:53.467641 (MainThread): Parsing macros/sql/get_relations_by_prefix.sql
2022-01-15 10:15:53.472134 (MainThread): Parsing macros/sql/get_tables_by_prefix_sql.sql
2022-01-15 10:15:53.474293 (MainThread): Parsing macros/sql/star.sql
2022-01-15 10:15:53.478512 (MainThread): Parsing macros/sql/unpivot.sql
2022-01-15 10:15:53.488754 (MainThread): Parsing macros/sql/union.sql
2022-01-15 10:15:53.498456 (MainThread): Parsing macros/sql/groupby.sql
2022-01-15 10:15:53.500062 (MainThread): Parsing macros/sql/surrogate_key.sql
2022-01-15 10:15:53.504077 (MainThread): Parsing macros/sql/safe_add.sql
2022-01-15 10:15:53.505905 (MainThread): Parsing macros/sql/nullcheck.sql
2022-01-15 10:15:53.507738 (MainThread): Parsing macros/sql/get_tables_by_pattern_sql.sql
2022-01-15 10:15:53.514781 (MainThread): Parsing macros/sql/get_column_values.sql
2022-01-15 10:15:53.520306 (MainThread): Parsing macros/sql/pivot.sql
2022-01-15 10:15:53.524761 (MainThread): Parsing macros/sql/get_query_results_as_dict.sql
2022-01-15 10:15:53.527283 (MainThread): Parsing macros/sql/haversine_distance.sql
2022-01-15 10:15:53.829192 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-15 10:15:53.840889 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.customer_test".
2022-01-15 10:15:53.844889 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-15 10:15:53.848362 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.film_test".
2022-01-15 10:15:53.851932 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-15 10:15:53.859444 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-15 10:15:53.862131 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-15 10:15:53.873927 (MainThread): Acquiring new postgres connection "test.sakila_dbt_project.film_replacementcost_30".
2022-01-15 10:15:53.875877 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 10:15:53.908105 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 10:15:53.909796 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 10:15:53.911529 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 10:15:53.913144 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 10:15:53.914797 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 10:15:53.917076 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 10:15:53.928985 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 10:15:53.932967 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 10:15:53.946624 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 10:15:53.948449 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 10:15:53.971885 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd3bbedd8-2e35-405d-9e8a-fa549c04be43', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112b2e670>]}
2022-01-15 10:15:53.980225 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-01-15 10:15:53.980727 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd3bbedd8-2e35-405d-9e8a-fa549c04be43', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112b2e670>]}
2022-01-15 10:15:53.980968 (MainThread): Found 7 models, 11 tests, 0 snapshots, 0 analyses, 347 macros, 0 operations, 0 seed files, 12 sources, 0 exposures
2022-01-15 10:15:53.982239 (MainThread): 
2022-01-15 10:15:53.982562 (MainThread): Acquiring new postgres connection "master".
2022-01-15 10:15:53.983414 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_sakila_wh".
2022-01-15 10:15:53.992503 (ThreadPoolExecutor-0_0): Using postgres connection "list_sakila_wh".
2022-01-15 10:15:53.992710 (ThreadPoolExecutor-0_0): On list_sakila_wh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh"} */

    select distinct nspname from pg_namespace
  
2022-01-15 10:15:53.992870 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2022-01-15 10:15:54.406522 (ThreadPoolExecutor-0_0): SQL status: SELECT 12 in 0.41 seconds
2022-01-15 10:15:54.408669 (ThreadPoolExecutor-0_0): On list_sakila_wh: Close
2022-01-15 10:15:54.410400 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_dwh".
2022-01-15 10:15:54.417169 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-15 10:15:54.417407 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: BEGIN
2022-01-15 10:15:54.417590 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2022-01-15 10:15:54.788580 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.37 seconds
2022-01-15 10:15:54.789024 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-15 10:15:54.789341 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_dwh"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dwh'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dwh'
  
2022-01-15 10:15:54.855060 (ThreadPoolExecutor-1_0): SQL status: SELECT 6 in 0.07 seconds
2022-01-15 10:15:54.856937 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: ROLLBACK
2022-01-15 10:15:54.917286 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: Close
2022-01-15 10:15:54.923195 (MainThread): Using postgres connection "master".
2022-01-15 10:15:54.923424 (MainThread): On master: BEGIN
2022-01-15 10:15:54.923607 (MainThread): Opening a new connection, currently in state init
2022-01-15 10:15:55.298333 (MainThread): SQL status: BEGIN in 0.37 seconds
2022-01-15 10:15:55.298739 (MainThread): Using postgres connection "master".
2022-01-15 10:15:55.298997 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-15 10:15:55.375538 (MainThread): SQL status: SELECT 47 in 0.08 seconds
2022-01-15 10:15:55.378634 (MainThread): On master: ROLLBACK
2022-01-15 10:15:55.439769 (MainThread): Using postgres connection "master".
2022-01-15 10:15:55.440250 (MainThread): On master: BEGIN
2022-01-15 10:15:55.562664 (MainThread): SQL status: BEGIN in 0.12 seconds
2022-01-15 10:15:55.563294 (MainThread): On master: COMMIT
2022-01-15 10:15:55.563686 (MainThread): Using postgres connection "master".
2022-01-15 10:15:55.563950 (MainThread): On master: COMMIT
2022-01-15 10:15:55.626764 (MainThread): SQL status: COMMIT in 0.06 seconds
2022-01-15 10:15:55.627414 (MainThread): On master: Close
2022-01-15 10:15:55.628057 (MainThread): 15:45:55 | Concurrency: 1 threads (target='dev')
2022-01-15 10:15:55.628402 (MainThread): 15:45:55 | 
2022-01-15 10:15:55.632039 (Thread-1): Began running node model.sakila_dbt_project.customer_test
2022-01-15 10:15:55.632481 (Thread-1): 15:45:55 | 1 of 1 START table model dwh.customer_test........................... [RUN]
2022-01-15 10:15:55.632969 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.customer_test".
2022-01-15 10:15:55.633230 (Thread-1): Compiling model.sakila_dbt_project.customer_test
2022-01-15 10:15:55.637329 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.customer_test"
2022-01-15 10:15:55.637960 (Thread-1): finished collecting timing info
2022-01-15 10:15:55.665552 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.customer_test"
2022-01-15 10:15:55.666296 (Thread-1): Using postgres connection "model.sakila_dbt_project.customer_test".
2022-01-15 10:15:55.666505 (Thread-1): On model.sakila_dbt_project.customer_test: BEGIN
2022-01-15 10:15:55.666671 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 10:15:56.045857 (Thread-1): SQL status: BEGIN in 0.38 seconds
2022-01-15 10:15:56.046272 (Thread-1): Using postgres connection "model.sakila_dbt_project.customer_test".
2022-01-15 10:15:56.046545 (Thread-1): On model.sakila_dbt_project.customer_test: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.customer_test"} */


  create  table "sakila_wh"."dwh"."customer_test__dbt_tmp"
  as (
    select * from 
"sakila_wh"."dwh"."hello_world"
where customer_id < 10
  );
2022-01-15 10:15:56.121640 (Thread-1): SQL status: SELECT 9 in 0.07 seconds
2022-01-15 10:15:56.129645 (Thread-1): Using postgres connection "model.sakila_dbt_project.customer_test".
2022-01-15 10:15:56.129869 (Thread-1): On model.sakila_dbt_project.customer_test: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.customer_test"} */
alter table "sakila_wh"."dwh"."customer_test__dbt_tmp" rename to "customer_test"
2022-01-15 10:15:56.190924 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-15 10:15:56.204505 (Thread-1): On model.sakila_dbt_project.customer_test: COMMIT
2022-01-15 10:15:56.204765 (Thread-1): Using postgres connection "model.sakila_dbt_project.customer_test".
2022-01-15 10:15:56.204941 (Thread-1): On model.sakila_dbt_project.customer_test: COMMIT
2022-01-15 10:15:56.265901 (Thread-1): SQL status: COMMIT in 0.06 seconds
2022-01-15 10:15:56.272565 (Thread-1): Using postgres connection "model.sakila_dbt_project.customer_test".
2022-01-15 10:15:56.272799 (Thread-1): On model.sakila_dbt_project.customer_test: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.customer_test"} */
drop table if exists "sakila_wh"."dwh"."customer_test__dbt_backup" cascade
2022-01-15 10:15:56.334263 (Thread-1): SQL status: DROP TABLE in 0.06 seconds
2022-01-15 10:15:56.335988 (Thread-1): finished collecting timing info
2022-01-15 10:15:56.336272 (Thread-1): On model.sakila_dbt_project.customer_test: Close
2022-01-15 10:15:56.336835 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd3bbedd8-2e35-405d-9e8a-fa549c04be43', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112acd520>]}
2022-01-15 10:15:56.337293 (Thread-1): 15:45:56 | 1 of 1 OK created table model dwh.customer_test...................... [SELECT 9 in 0.70s]
2022-01-15 10:15:56.337563 (Thread-1): Finished running node model.sakila_dbt_project.customer_test
2022-01-15 10:15:56.338801 (MainThread): Acquiring new postgres connection "master".
2022-01-15 10:15:56.339038 (MainThread): Using postgres connection "master".
2022-01-15 10:15:56.339226 (MainThread): On master: BEGIN
2022-01-15 10:15:56.339395 (MainThread): Opening a new connection, currently in state closed
2022-01-15 10:15:56.709729 (MainThread): SQL status: BEGIN in 0.37 seconds
2022-01-15 10:15:56.710183 (MainThread): On master: COMMIT
2022-01-15 10:15:56.710469 (MainThread): Using postgres connection "master".
2022-01-15 10:15:56.710728 (MainThread): On master: COMMIT
2022-01-15 10:15:56.770857 (MainThread): SQL status: COMMIT in 0.06 seconds
2022-01-15 10:15:56.771254 (MainThread): On master: Close
2022-01-15 10:15:56.771944 (MainThread): 15:45:56 | 
2022-01-15 10:15:56.772296 (MainThread): 15:45:56 | Finished running 1 table model in 2.79s.
2022-01-15 10:15:56.772547 (MainThread): Connection 'master' was properly closed.
2022-01-15 10:15:56.772742 (MainThread): Connection 'model.sakila_dbt_project.customer_test' was properly closed.
2022-01-15 10:15:56.782221 (MainThread): 
2022-01-15 10:15:56.782493 (MainThread): Completed successfully
2022-01-15 10:15:56.782710 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2022-01-15 10:15:56.782981 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1129d6d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112c38880>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112c38a30>]}
2022-01-15 10:15:56.783323 (MainThread): Flushing usage events
2022-01-15 10:29:17.757901 (MainThread): Running with dbt=0.21.1
2022-01-15 10:29:17.868643 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=['example.customer_test'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2022-01-15 10:29:17.870737 (MainThread): Tracking: tracking
2022-01-15 10:29:17.894779 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f441910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f43b880>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f43b820>]}
2022-01-15 10:29:17.946319 (MainThread): Partial parsing not enabled
2022-01-15 10:29:18.039119 (MainThread): Parsing macros/catalog.sql
2022-01-15 10:29:18.044138 (MainThread): Parsing macros/relations.sql
2022-01-15 10:29:18.046227 (MainThread): Parsing macros/adapters.sql
2022-01-15 10:29:18.074657 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2022-01-15 10:29:18.076787 (MainThread): Parsing macros/core.sql
2022-01-15 10:29:18.081666 (MainThread): Parsing macros/materializations/test.sql
2022-01-15 10:29:18.089942 (MainThread): Parsing macros/materializations/helpers.sql
2022-01-15 10:29:18.101367 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2022-01-15 10:29:18.103284 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2022-01-15 10:29:18.122717 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2022-01-15 10:29:18.158566 (MainThread): Parsing macros/materializations/seed/seed.sql
2022-01-15 10:29:18.183847 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2022-01-15 10:29:18.185830 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2022-01-15 10:29:18.196973 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2022-01-15 10:29:18.218315 (MainThread): Parsing macros/materializations/common/merge.sql
2022-01-15 10:29:18.232810 (MainThread): Parsing macros/materializations/table/table.sql
2022-01-15 10:29:18.240448 (MainThread): Parsing macros/materializations/view/view.sql
2022-01-15 10:29:18.247484 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2022-01-15 10:29:18.251229 (MainThread): Parsing macros/etc/get_custom_alias.sql
2022-01-15 10:29:18.252617 (MainThread): Parsing macros/etc/query.sql
2022-01-15 10:29:18.253510 (MainThread): Parsing macros/etc/is_incremental.sql
2022-01-15 10:29:18.254923 (MainThread): Parsing macros/etc/datetime.sql
2022-01-15 10:29:18.263132 (MainThread): Parsing macros/etc/where_subquery.sql
2022-01-15 10:29:18.264884 (MainThread): Parsing macros/etc/get_custom_schema.sql
2022-01-15 10:29:18.267131 (MainThread): Parsing macros/etc/get_custom_database.sql
2022-01-15 10:29:18.268613 (MainThread): Parsing macros/adapters/common.sql
2022-01-15 10:29:18.320894 (MainThread): Parsing macros/schema_tests/relationships.sql
2022-01-15 10:29:18.322612 (MainThread): Parsing macros/schema_tests/not_null.sql
2022-01-15 10:29:18.324090 (MainThread): Parsing macros/schema_tests/unique.sql
2022-01-15 10:29:18.325495 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2022-01-15 10:29:18.327584 (MainThread): Parsing macros/cross_db_utils/except.sql
2022-01-15 10:29:18.328617 (MainThread): Parsing macros/cross_db_utils/replace.sql
2022-01-15 10:29:18.329952 (MainThread): Parsing macros/cross_db_utils/concat.sql
2022-01-15 10:29:18.331012 (MainThread): Parsing macros/cross_db_utils/datatypes.sql
2022-01-15 10:29:18.337311 (MainThread): Parsing macros/cross_db_utils/_is_relation.sql
2022-01-15 10:29:18.338461 (MainThread): Parsing macros/cross_db_utils/length.sql
2022-01-15 10:29:18.339722 (MainThread): Parsing macros/cross_db_utils/dateadd.sql
2022-01-15 10:29:18.342978 (MainThread): Parsing macros/cross_db_utils/intersect.sql
2022-01-15 10:29:18.344137 (MainThread): Parsing macros/cross_db_utils/right.sql
2022-01-15 10:29:18.346544 (MainThread): Parsing macros/cross_db_utils/datediff.sql
2022-01-15 10:29:18.356227 (MainThread): Parsing macros/cross_db_utils/safe_cast.sql
2022-01-15 10:29:18.358062 (MainThread): Parsing macros/cross_db_utils/hash.sql
2022-01-15 10:29:18.359399 (MainThread): Parsing macros/cross_db_utils/cast_bool_to_text.sql
2022-01-15 10:29:18.360750 (MainThread): Parsing macros/cross_db_utils/identifier.sql
2022-01-15 10:29:18.362310 (MainThread): Parsing macros/cross_db_utils/position.sql
2022-01-15 10:29:18.363769 (MainThread): Parsing macros/cross_db_utils/literal.sql
2022-01-15 10:29:18.364687 (MainThread): Parsing macros/cross_db_utils/current_timestamp.sql
2022-01-15 10:29:18.368027 (MainThread): Parsing macros/cross_db_utils/width_bucket.sql
2022-01-15 10:29:18.373168 (MainThread): Parsing macros/cross_db_utils/last_day.sql
2022-01-15 10:29:18.376534 (MainThread): Parsing macros/cross_db_utils/split_part.sql
2022-01-15 10:29:18.378257 (MainThread): Parsing macros/cross_db_utils/date_trunc.sql
2022-01-15 10:29:18.379776 (MainThread): Parsing macros/cross_db_utils/_is_ephemeral.sql
2022-01-15 10:29:18.381543 (MainThread): Parsing macros/materializations/insert_by_period_materialization.sql
2022-01-15 10:29:18.404905 (MainThread): Parsing macros/web/get_url_host.sql
2022-01-15 10:29:18.406796 (MainThread): Parsing macros/web/get_url_path.sql
2022-01-15 10:29:18.409348 (MainThread): Parsing macros/web/get_url_parameter.sql
2022-01-15 10:29:18.410841 (MainThread): Parsing macros/jinja_helpers/pretty_log_format.sql
2022-01-15 10:29:18.411896 (MainThread): Parsing macros/jinja_helpers/pretty_time.sql
2022-01-15 10:29:18.413038 (MainThread): Parsing macros/jinja_helpers/log_info.sql
2022-01-15 10:29:18.414094 (MainThread): Parsing macros/jinja_helpers/slugify.sql
2022-01-15 10:29:18.415203 (MainThread): Parsing macros/schema_tests/fewer_rows_than.sql
2022-01-15 10:29:18.416849 (MainThread): Parsing macros/schema_tests/equal_rowcount.sql
2022-01-15 10:29:18.418368 (MainThread): Parsing macros/schema_tests/relationships_where.sql
2022-01-15 10:29:18.420602 (MainThread): Parsing macros/schema_tests/recency.sql
2022-01-15 10:29:18.422237 (MainThread): Parsing macros/schema_tests/not_constant.sql
2022-01-15 10:29:18.423633 (MainThread): Parsing macros/schema_tests/accepted_range.sql
2022-01-15 10:29:18.426089 (MainThread): Parsing macros/schema_tests/not_accepted_values.sql
2022-01-15 10:29:18.428074 (MainThread): Parsing macros/schema_tests/test_unique_where.sql
2022-01-15 10:29:18.429503 (MainThread): Parsing macros/schema_tests/at_least_one.sql
2022-01-15 10:29:18.430685 (MainThread): Parsing macros/schema_tests/unique_combination_of_columns.sql
2022-01-15 10:29:18.433372 (MainThread): Parsing macros/schema_tests/cardinality_equality.sql
2022-01-15 10:29:18.435222 (MainThread): Parsing macros/schema_tests/expression_is_true.sql
2022-01-15 10:29:18.436889 (MainThread): Parsing macros/schema_tests/sequential_values.sql
2022-01-15 10:29:18.439724 (MainThread): Parsing macros/schema_tests/test_not_null_where.sql
2022-01-15 10:29:18.441270 (MainThread): Parsing macros/schema_tests/equality.sql
2022-01-15 10:29:18.444795 (MainThread): Parsing macros/schema_tests/mutually_exclusive_ranges.sql
2022-01-15 10:29:18.453231 (MainThread): Parsing macros/sql/date_spine.sql
2022-01-15 10:29:18.458350 (MainThread): Parsing macros/sql/nullcheck_table.sql
2022-01-15 10:29:18.459954 (MainThread): Parsing macros/sql/get_relations_by_pattern.sql
2022-01-15 10:29:18.463138 (MainThread): Parsing macros/sql/generate_series.sql
2022-01-15 10:29:18.493704 (MainThread): Parsing macros/sql/get_relations_by_prefix.sql
2022-01-15 10:29:18.498163 (MainThread): Parsing macros/sql/get_tables_by_prefix_sql.sql
2022-01-15 10:29:18.500330 (MainThread): Parsing macros/sql/star.sql
2022-01-15 10:29:18.504463 (MainThread): Parsing macros/sql/unpivot.sql
2022-01-15 10:29:18.514796 (MainThread): Parsing macros/sql/union.sql
2022-01-15 10:29:18.524884 (MainThread): Parsing macros/sql/groupby.sql
2022-01-15 10:29:18.526532 (MainThread): Parsing macros/sql/surrogate_key.sql
2022-01-15 10:29:18.530625 (MainThread): Parsing macros/sql/safe_add.sql
2022-01-15 10:29:18.532459 (MainThread): Parsing macros/sql/nullcheck.sql
2022-01-15 10:29:18.534298 (MainThread): Parsing macros/sql/get_tables_by_pattern_sql.sql
2022-01-15 10:29:18.541486 (MainThread): Parsing macros/sql/get_column_values.sql
2022-01-15 10:29:18.546903 (MainThread): Parsing macros/sql/pivot.sql
2022-01-15 10:29:18.551353 (MainThread): Parsing macros/sql/get_query_results_as_dict.sql
2022-01-15 10:29:18.553862 (MainThread): Parsing macros/sql/haversine_distance.sql
2022-01-15 10:29:18.860597 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-15 10:29:18.872706 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.customer_test".
2022-01-15 10:29:18.876169 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 10:29:18.877150 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-15 10:29:18.880730 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.film_test".
2022-01-15 10:29:18.884092 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-15 10:29:18.891672 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-15 10:29:18.894473 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-15 10:29:18.905642 (MainThread): Acquiring new postgres connection "test.sakila_dbt_project.film_replacementcost_30".
2022-01-15 10:29:18.907561 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 10:29:18.940758 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 10:29:18.942835 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 10:29:18.944899 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 10:29:18.946790 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 10:29:18.948656 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 10:29:18.950710 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 10:29:18.964923 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 10:29:18.969155 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 10:29:18.985518 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 10:29:18.987445 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 10:29:19.016659 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8cd83544-bfcd-40f8-8a3e-c35e05b46c61', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f5cc790>]}
2022-01-15 10:29:19.027522 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-01-15 10:29:19.028168 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8cd83544-bfcd-40f8-8a3e-c35e05b46c61', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f5cc700>]}
2022-01-15 10:29:19.028505 (MainThread): Found 7 models, 11 tests, 0 snapshots, 0 analyses, 347 macros, 0 operations, 0 seed files, 12 sources, 0 exposures
2022-01-15 10:29:19.030356 (MainThread): 
2022-01-15 10:29:19.030852 (MainThread): Acquiring new postgres connection "master".
2022-01-15 10:29:19.031682 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_sakila_wh".
2022-01-15 10:29:19.043507 (ThreadPoolExecutor-0_0): Using postgres connection "list_sakila_wh".
2022-01-15 10:29:19.043790 (ThreadPoolExecutor-0_0): On list_sakila_wh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh"} */

    select distinct nspname from pg_namespace
  
2022-01-15 10:29:19.044009 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2022-01-15 10:29:19.438926 (ThreadPoolExecutor-0_0): SQL status: SELECT 12 in 0.39 seconds
2022-01-15 10:29:19.441354 (ThreadPoolExecutor-0_0): On list_sakila_wh: Close
2022-01-15 10:29:19.443244 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_dwh".
2022-01-15 10:29:19.450276 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-15 10:29:19.450530 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: BEGIN
2022-01-15 10:29:19.450711 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2022-01-15 10:29:19.809883 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.36 seconds
2022-01-15 10:29:19.810216 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-15 10:29:19.810427 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_dwh"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dwh'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dwh'
  
2022-01-15 10:29:19.874400 (ThreadPoolExecutor-1_0): SQL status: SELECT 7 in 0.06 seconds
2022-01-15 10:29:19.876324 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: ROLLBACK
2022-01-15 10:29:19.934789 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: Close
2022-01-15 10:29:19.941201 (MainThread): Using postgres connection "master".
2022-01-15 10:29:19.941535 (MainThread): On master: BEGIN
2022-01-15 10:29:19.941712 (MainThread): Opening a new connection, currently in state init
2022-01-15 10:29:20.299743 (MainThread): SQL status: BEGIN in 0.36 seconds
2022-01-15 10:29:20.300378 (MainThread): Using postgres connection "master".
2022-01-15 10:29:20.300748 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-15 10:29:20.375001 (MainThread): SQL status: SELECT 47 in 0.07 seconds
2022-01-15 10:29:20.377865 (MainThread): On master: ROLLBACK
2022-01-15 10:29:20.438432 (MainThread): Using postgres connection "master".
2022-01-15 10:29:20.438769 (MainThread): On master: BEGIN
2022-01-15 10:29:20.558757 (MainThread): SQL status: BEGIN in 0.12 seconds
2022-01-15 10:29:20.559195 (MainThread): On master: COMMIT
2022-01-15 10:29:20.559430 (MainThread): Using postgres connection "master".
2022-01-15 10:29:20.559628 (MainThread): On master: COMMIT
2022-01-15 10:29:20.618705 (MainThread): SQL status: COMMIT in 0.06 seconds
2022-01-15 10:29:20.619323 (MainThread): On master: Close
2022-01-15 10:29:20.619989 (MainThread): 15:59:20 | Concurrency: 1 threads (target='dev')
2022-01-15 10:29:20.620326 (MainThread): 15:59:20 | 
2022-01-15 10:29:20.623407 (Thread-1): Began running node model.sakila_dbt_project.customer_test
2022-01-15 10:29:20.623865 (Thread-1): 15:59:20 | 1 of 1 START table model dwh.customer_alias.......................... [RUN]
2022-01-15 10:29:20.624341 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.customer_test".
2022-01-15 10:29:20.624577 (Thread-1): Compiling model.sakila_dbt_project.customer_test
2022-01-15 10:29:20.628712 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.customer_test"
2022-01-15 10:29:20.629414 (Thread-1): finished collecting timing info
2022-01-15 10:29:20.657180 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.customer_test"
2022-01-15 10:29:20.657892 (Thread-1): Using postgres connection "model.sakila_dbt_project.customer_test".
2022-01-15 10:29:20.658079 (Thread-1): On model.sakila_dbt_project.customer_test: BEGIN
2022-01-15 10:29:20.658249 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 10:29:21.020109 (Thread-1): SQL status: BEGIN in 0.36 seconds
2022-01-15 10:29:21.020757 (Thread-1): Using postgres connection "model.sakila_dbt_project.customer_test".
2022-01-15 10:29:21.021013 (Thread-1): On model.sakila_dbt_project.customer_test: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.customer_test"} */


  create  table "sakila_wh"."dwh"."customer_test__dbt_tmp"
  as (
    

select * from 
"sakila_wh"."dwh"."hello_world"
where customer_id < 10
  );
2022-01-15 10:29:21.097009 (Thread-1): SQL status: SELECT 9 in 0.08 seconds
2022-01-15 10:29:21.105780 (Thread-1): Using postgres connection "model.sakila_dbt_project.customer_test".
2022-01-15 10:29:21.106020 (Thread-1): On model.sakila_dbt_project.customer_test: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.customer_test"} */
alter table "sakila_wh"."dwh"."customer_test__dbt_tmp" rename to "customer_alias"
2022-01-15 10:29:21.165850 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-15 10:29:21.178893 (Thread-1): On model.sakila_dbt_project.customer_test: COMMIT
2022-01-15 10:29:21.179150 (Thread-1): Using postgres connection "model.sakila_dbt_project.customer_test".
2022-01-15 10:29:21.179318 (Thread-1): On model.sakila_dbt_project.customer_test: COMMIT
2022-01-15 10:29:21.238770 (Thread-1): SQL status: COMMIT in 0.06 seconds
2022-01-15 10:29:21.245346 (Thread-1): Using postgres connection "model.sakila_dbt_project.customer_test".
2022-01-15 10:29:21.245599 (Thread-1): On model.sakila_dbt_project.customer_test: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.customer_test"} */
drop table if exists "sakila_wh"."dwh"."customer_test__dbt_backup" cascade
2022-01-15 10:29:21.305886 (Thread-1): SQL status: DROP TABLE in 0.06 seconds
2022-01-15 10:29:21.322752 (Thread-1): finished collecting timing info
2022-01-15 10:29:21.323331 (Thread-1): On model.sakila_dbt_project.customer_test: Close
2022-01-15 10:29:21.345500 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8cd83544-bfcd-40f8-8a3e-c35e05b46c61', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f5b40d0>]}
2022-01-15 10:29:21.346217 (Thread-1): 15:59:21 | 1 of 1 OK created table model dwh.customer_alias..................... [SELECT 9 in 0.72s]
2022-01-15 10:29:21.346564 (Thread-1): Finished running node model.sakila_dbt_project.customer_test
2022-01-15 10:29:21.348081 (MainThread): Acquiring new postgres connection "master".
2022-01-15 10:29:21.348358 (MainThread): Using postgres connection "master".
2022-01-15 10:29:21.348561 (MainThread): On master: BEGIN
2022-01-15 10:29:21.348761 (MainThread): Opening a new connection, currently in state closed
2022-01-15 10:29:21.706830 (MainThread): SQL status: BEGIN in 0.36 seconds
2022-01-15 10:29:21.707239 (MainThread): On master: COMMIT
2022-01-15 10:29:21.707499 (MainThread): Using postgres connection "master".
2022-01-15 10:29:21.707736 (MainThread): On master: COMMIT
2022-01-15 10:29:21.767028 (MainThread): SQL status: COMMIT in 0.06 seconds
2022-01-15 10:29:21.767613 (MainThread): On master: Close
2022-01-15 10:29:21.768289 (MainThread): 15:59:21 | 
2022-01-15 10:29:21.768627 (MainThread): 15:59:21 | Finished running 1 table model in 2.74s.
2022-01-15 10:29:21.768915 (MainThread): Connection 'master' was properly closed.
2022-01-15 10:29:21.769099 (MainThread): Connection 'model.sakila_dbt_project.customer_test' was properly closed.
2022-01-15 10:29:21.779377 (MainThread): 
2022-01-15 10:29:21.779658 (MainThread): Completed successfully
2022-01-15 10:29:21.779905 (MainThread): 
Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
2022-01-15 10:29:21.780234 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f4187f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f71aa30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f71a730>]}
2022-01-15 10:29:21.780517 (MainThread): Flushing usage events
2022-01-15 16:15:02.392063 (MainThread): Running with dbt=0.21.1
2022-01-15 16:15:02.525283 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, defer=None, state=None, cls=<class 'dbt.task.deps.DepsTask'>, which='deps', rpc_method='deps')
2022-01-15 16:15:02.526839 (MainThread): Tracking: tracking
2022-01-15 16:15:02.556685 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107cb40d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107cb4b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c8ec10>]}
2022-01-15 16:15:02.560865 (MainThread): Set downloads directory='/var/folders/ht/55m1kf9529v8n85gyrn0hzcc0000gp/T/dbt-downloads-cvd8b_9e'
2022-01-15 16:15:02.561755 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/index.json
2022-01-15 16:15:03.317012 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/index.json 200
2022-01-15 16:15:03.317413 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
2022-01-15 16:15:03.695728 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
2022-01-15 16:15:03.716841 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils/0.8.0.json
2022-01-15 16:15:04.098382 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils/0.8.0.json 200
2022-01-15 16:15:04.098854 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
2022-01-15 16:15:04.498640 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
2022-01-15 16:15:04.520288 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils/0.8.0.json
2022-01-15 16:15:04.897844 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils/0.8.0.json 200
2022-01-15 16:15:04.898318 (MainThread): Installing dbt-labs/dbt_utils@0.8.0
2022-01-15 16:15:06.041779 (MainThread):   Installed from version 0.8.0
2022-01-15 16:15:06.042181 (MainThread):   Up to date!
2022-01-15 16:15:06.042575 (MainThread): Sending event: {'category': 'dbt', 'action': 'package', 'label': '60ab668b-880d-4e7c-adfd-cd208ac2e8d2', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c8e2e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c8e7f0>]}
2022-01-15 16:15:06.044306 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c8e940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c8efa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107c8e8b0>]}
2022-01-15 16:15:06.044769 (MainThread): Flushing usage events
2022-01-15 16:15:15.912644 (MainThread): Running with dbt=0.21.1
2022-01-15 16:15:15.994215 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=['example.customer_test'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2022-01-15 16:15:15.996051 (MainThread): Tracking: tracking
2022-01-15 16:15:16.016153 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b5a48e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10afaf0d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b583dc0>]}
2022-01-15 16:15:16.036241 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b5e3e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b5e3910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b5e37c0>]}
2022-01-15 16:15:16.036554 (MainThread): Flushing usage events
2022-01-15 16:15:17.511065 (MainThread): Encountered an error:
2022-01-15 16:15:17.511453 (MainThread): Runtime Error
  Failed to read package: Runtime Error
    This version of dbt is not supported with the 'dbt_utils' package.
      Installed version of dbt: =0.21.1
      Required version of dbt for 'dbt_utils': ['>=1.0.0', '<2.0.0']
    Check the requirements for the 'dbt_utils' package, or run dbt again with --no-version-check
    
  
  Error encountered in /Users/nijoshi/Desktop/dbt_proj/dbt_modules/dbt_utils/dbt_project.yml

Error encountered in /Users/nijoshi/Desktop/dbt_proj/dbt_modules/dbt_utils
2022-01-15 16:15:17.518457 (MainThread): Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/dbt/config/runtime.py", line 367, in load_projects
    project = self.new_project(str(path))
  File "/usr/local/lib/python3.9/site-packages/dbt/config/runtime.py", line 144, in new_project
    project = Project.from_project_root(
  File "/usr/local/lib/python3.9/site-packages/dbt/config/project.py", line 643, in from_project_root
    return partial.render(renderer)
  File "/usr/local/lib/python3.9/site-packages/dbt/config/project.py", line 289, in render
    return self.create_project(rendered)
  File "/usr/local/lib/python3.9/site-packages/dbt/config/project.py", line 301, in create_project
    dbt_version = _get_required_version(
  File "/usr/local/lib/python3.9/site-packages/dbt/config/project.py", line 226, in _get_required_version
    validate_version(dbt_version, project_dict['name'])
  File "/usr/local/lib/python3.9/site-packages/dbt/config/project.py", line 203, in validate_version
    raise DbtProjectError(msg)
dbt.exceptions.DbtProjectError: Runtime Error
  This version of dbt is not supported with the 'dbt_utils' package.
    Installed version of dbt: =0.21.1
    Required version of dbt for 'dbt_utils': ['>=1.0.0', '<2.0.0']
  Check the requirements for the 'dbt_utils' package, or run dbt again with --no-version-check
  

Error encountered in /Users/nijoshi/Desktop/dbt_proj/dbt_modules/dbt_utils/dbt_project.yml

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/dbt/main.py", line 127, in main
    results, succeeded = handle_and_check(args)
  File "/usr/local/lib/python3.9/site-packages/dbt/main.py", line 205, in handle_and_check
    task, res = run_from_args(parsed)
  File "/usr/local/lib/python3.9/site-packages/dbt/main.py", line 258, in run_from_args
    results = task.run()
  File "/usr/local/lib/python3.9/site-packages/dbt/task/runnable.py", line 438, in run
    self._runtime_initialize()
  File "/usr/local/lib/python3.9/site-packages/dbt/task/runnable.py", line 154, in _runtime_initialize
    super()._runtime_initialize()
  File "/usr/local/lib/python3.9/site-packages/dbt/task/runnable.py", line 92, in _runtime_initialize
    self.load_manifest()
  File "/usr/local/lib/python3.9/site-packages/dbt/task/runnable.py", line 79, in load_manifest
    self.manifest = ManifestLoader.get_full_manifest(self.config)
  File "/usr/local/lib/python3.9/site-packages/dbt/parser/manifest.py", line 179, in get_full_manifest
    projects = config.load_dependencies()
  File "/usr/local/lib/python3.9/site-packages/dbt/config/runtime.py", line 347, in load_dependencies
    for project_name, project in self.load_projects(project_paths):
  File "/usr/local/lib/python3.9/site-packages/dbt/config/runtime.py", line 369, in load_projects
    raise DbtProjectError(
dbt.exceptions.DbtProjectError: Runtime Error
  Failed to read package: Runtime Error
    This version of dbt is not supported with the 'dbt_utils' package.
      Installed version of dbt: =0.21.1
      Required version of dbt for 'dbt_utils': ['>=1.0.0', '<2.0.0']
    Check the requirements for the 'dbt_utils' package, or run dbt again with --no-version-check
    
  
  Error encountered in /Users/nijoshi/Desktop/dbt_proj/dbt_modules/dbt_utils/dbt_project.yml

Error encountered in /Users/nijoshi/Desktop/dbt_proj/dbt_modules/dbt_utils

2022-01-15 16:17:29.883402 (MainThread): Running with dbt=0.21.1
2022-01-15 16:17:29.960833 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=['example.customer_test'], exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2022-01-15 16:17:29.962864 (MainThread): Tracking: tracking
2022-01-15 16:17:29.982637 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c79b8b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c1a7460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c774dc0>]}
2022-01-15 16:17:30.001678 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c7db880>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c7dbdf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c7dbe80>]}
2022-01-15 16:17:30.001993 (MainThread): Flushing usage events
2022-01-15 16:17:31.858379 (MainThread): Encountered an error:
2022-01-15 16:17:31.858775 (MainThread): Runtime Error
  Failed to read package: Runtime Error
    This version of dbt is not supported with the 'dbt_utils' package.
      Installed version of dbt: =0.21.1
      Required version of dbt for 'dbt_utils': ['>=1.0.0', '<2.0.0']
    Check the requirements for the 'dbt_utils' package, or run dbt again with --no-version-check
    
  
  Error encountered in /Users/nijoshi/Desktop/dbt_proj/dbt_modules/dbt_utils/dbt_project.yml

Error encountered in /Users/nijoshi/Desktop/dbt_proj/dbt_modules/dbt_utils
2022-01-15 16:17:31.861522 (MainThread): Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/dbt/config/runtime.py", line 367, in load_projects
    project = self.new_project(str(path))
  File "/usr/local/lib/python3.9/site-packages/dbt/config/runtime.py", line 144, in new_project
    project = Project.from_project_root(
  File "/usr/local/lib/python3.9/site-packages/dbt/config/project.py", line 643, in from_project_root
    return partial.render(renderer)
  File "/usr/local/lib/python3.9/site-packages/dbt/config/project.py", line 289, in render
    return self.create_project(rendered)
  File "/usr/local/lib/python3.9/site-packages/dbt/config/project.py", line 301, in create_project
    dbt_version = _get_required_version(
  File "/usr/local/lib/python3.9/site-packages/dbt/config/project.py", line 226, in _get_required_version
    validate_version(dbt_version, project_dict['name'])
  File "/usr/local/lib/python3.9/site-packages/dbt/config/project.py", line 203, in validate_version
    raise DbtProjectError(msg)
dbt.exceptions.DbtProjectError: Runtime Error
  This version of dbt is not supported with the 'dbt_utils' package.
    Installed version of dbt: =0.21.1
    Required version of dbt for 'dbt_utils': ['>=1.0.0', '<2.0.0']
  Check the requirements for the 'dbt_utils' package, or run dbt again with --no-version-check
  

Error encountered in /Users/nijoshi/Desktop/dbt_proj/dbt_modules/dbt_utils/dbt_project.yml

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/dbt/main.py", line 127, in main
    results, succeeded = handle_and_check(args)
  File "/usr/local/lib/python3.9/site-packages/dbt/main.py", line 205, in handle_and_check
    task, res = run_from_args(parsed)
  File "/usr/local/lib/python3.9/site-packages/dbt/main.py", line 258, in run_from_args
    results = task.run()
  File "/usr/local/lib/python3.9/site-packages/dbt/task/runnable.py", line 438, in run
    self._runtime_initialize()
  File "/usr/local/lib/python3.9/site-packages/dbt/task/runnable.py", line 154, in _runtime_initialize
    super()._runtime_initialize()
  File "/usr/local/lib/python3.9/site-packages/dbt/task/runnable.py", line 92, in _runtime_initialize
    self.load_manifest()
  File "/usr/local/lib/python3.9/site-packages/dbt/task/runnable.py", line 79, in load_manifest
    self.manifest = ManifestLoader.get_full_manifest(self.config)
  File "/usr/local/lib/python3.9/site-packages/dbt/parser/manifest.py", line 179, in get_full_manifest
    projects = config.load_dependencies()
  File "/usr/local/lib/python3.9/site-packages/dbt/config/runtime.py", line 347, in load_dependencies
    for project_name, project in self.load_projects(project_paths):
  File "/usr/local/lib/python3.9/site-packages/dbt/config/runtime.py", line 369, in load_projects
    raise DbtProjectError(
dbt.exceptions.DbtProjectError: Runtime Error
  Failed to read package: Runtime Error
    This version of dbt is not supported with the 'dbt_utils' package.
      Installed version of dbt: =0.21.1
      Required version of dbt for 'dbt_utils': ['>=1.0.0', '<2.0.0']
    Check the requirements for the 'dbt_utils' package, or run dbt again with --no-version-check
    
  
  Error encountered in /Users/nijoshi/Desktop/dbt_proj/dbt_modules/dbt_utils/dbt_project.yml

Error encountered in /Users/nijoshi/Desktop/dbt_proj/dbt_modules/dbt_utils

2022-01-15 16:25:49.094549 (MainThread): Running with dbt=0.21.1
2022-01-15 16:25:49.197824 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2022-01-15 16:25:49.199696 (MainThread): Tracking: tracking
2022-01-15 16:25:49.221976 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1055244f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105b23e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105b23370>]}
2022-01-15 16:25:49.241772 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105b9a880>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105b9aa30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105b81250>]}
2022-01-15 16:25:49.242079 (MainThread): Flushing usage events
2022-01-15 16:25:50.834899 (MainThread): Encountered an error:
2022-01-15 16:25:50.835308 (MainThread): Runtime Error
  Failed to read package: Runtime Error
    This version of dbt is not supported with the 'dbt_utils' package.
      Installed version of dbt: =0.21.1
      Required version of dbt for 'dbt_utils': ['>=1.0.0', '<2.0.0']
    Check the requirements for the 'dbt_utils' package, or run dbt again with --no-version-check
    
  
  Error encountered in /Users/nijoshi/Desktop/dbt_proj/dbt_modules/dbt_utils/dbt_project.yml

Error encountered in /Users/nijoshi/Desktop/dbt_proj/dbt_modules/dbt_utils
2022-01-15 16:25:50.842360 (MainThread): Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/dbt/config/runtime.py", line 367, in load_projects
    project = self.new_project(str(path))
  File "/usr/local/lib/python3.9/site-packages/dbt/config/runtime.py", line 144, in new_project
    project = Project.from_project_root(
  File "/usr/local/lib/python3.9/site-packages/dbt/config/project.py", line 643, in from_project_root
    return partial.render(renderer)
  File "/usr/local/lib/python3.9/site-packages/dbt/config/project.py", line 289, in render
    return self.create_project(rendered)
  File "/usr/local/lib/python3.9/site-packages/dbt/config/project.py", line 301, in create_project
    dbt_version = _get_required_version(
  File "/usr/local/lib/python3.9/site-packages/dbt/config/project.py", line 226, in _get_required_version
    validate_version(dbt_version, project_dict['name'])
  File "/usr/local/lib/python3.9/site-packages/dbt/config/project.py", line 203, in validate_version
    raise DbtProjectError(msg)
dbt.exceptions.DbtProjectError: Runtime Error
  This version of dbt is not supported with the 'dbt_utils' package.
    Installed version of dbt: =0.21.1
    Required version of dbt for 'dbt_utils': ['>=1.0.0', '<2.0.0']
  Check the requirements for the 'dbt_utils' package, or run dbt again with --no-version-check
  

Error encountered in /Users/nijoshi/Desktop/dbt_proj/dbt_modules/dbt_utils/dbt_project.yml

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/dbt/main.py", line 127, in main
    results, succeeded = handle_and_check(args)
  File "/usr/local/lib/python3.9/site-packages/dbt/main.py", line 205, in handle_and_check
    task, res = run_from_args(parsed)
  File "/usr/local/lib/python3.9/site-packages/dbt/main.py", line 258, in run_from_args
    results = task.run()
  File "/usr/local/lib/python3.9/site-packages/dbt/task/runnable.py", line 438, in run
    self._runtime_initialize()
  File "/usr/local/lib/python3.9/site-packages/dbt/task/runnable.py", line 154, in _runtime_initialize
    super()._runtime_initialize()
  File "/usr/local/lib/python3.9/site-packages/dbt/task/runnable.py", line 92, in _runtime_initialize
    self.load_manifest()
  File "/usr/local/lib/python3.9/site-packages/dbt/task/runnable.py", line 79, in load_manifest
    self.manifest = ManifestLoader.get_full_manifest(self.config)
  File "/usr/local/lib/python3.9/site-packages/dbt/parser/manifest.py", line 179, in get_full_manifest
    projects = config.load_dependencies()
  File "/usr/local/lib/python3.9/site-packages/dbt/config/runtime.py", line 347, in load_dependencies
    for project_name, project in self.load_projects(project_paths):
  File "/usr/local/lib/python3.9/site-packages/dbt/config/runtime.py", line 369, in load_projects
    raise DbtProjectError(
dbt.exceptions.DbtProjectError: Runtime Error
  Failed to read package: Runtime Error
    This version of dbt is not supported with the 'dbt_utils' package.
      Installed version of dbt: =0.21.1
      Required version of dbt for 'dbt_utils': ['>=1.0.0', '<2.0.0']
    Check the requirements for the 'dbt_utils' package, or run dbt again with --no-version-check
    
  
  Error encountered in /Users/nijoshi/Desktop/dbt_proj/dbt_modules/dbt_utils/dbt_project.yml

Error encountered in /Users/nijoshi/Desktop/dbt_proj/dbt_modules/dbt_utils

2022-01-15 16:26:51.557344 (MainThread): Running with dbt=0.21.1
2022-01-15 16:26:51.638080 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2022-01-15 16:26:51.639903 (MainThread): Tracking: tracking
2022-01-15 16:26:51.660499 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dc5d640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e250e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e250340>]}
2022-01-15 16:26:51.679573 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e2d3850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e2d3940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e2ba490>]}
2022-01-15 16:26:51.679875 (MainThread): Flushing usage events
2022-01-15 16:26:53.104906 (MainThread): Encountered an error:
2022-01-15 16:26:53.105306 (MainThread): Runtime Error
  Failed to read package: Runtime Error
    This version of dbt is not supported with the 'dbt_utils' package.
      Installed version of dbt: =0.21.1
      Required version of dbt for 'dbt_utils': ['>=1.0.0', '<2.0.0']
    Check the requirements for the 'dbt_utils' package, or run dbt again with --no-version-check
    
  
  Error encountered in /Users/nijoshi/Desktop/dbt_proj/dbt_modules/dbt_utils/dbt_project.yml

Error encountered in /Users/nijoshi/Desktop/dbt_proj/dbt_modules/dbt_utils
2022-01-15 16:26:53.107786 (MainThread): Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/dbt/config/runtime.py", line 367, in load_projects
    project = self.new_project(str(path))
  File "/usr/local/lib/python3.9/site-packages/dbt/config/runtime.py", line 144, in new_project
    project = Project.from_project_root(
  File "/usr/local/lib/python3.9/site-packages/dbt/config/project.py", line 643, in from_project_root
    return partial.render(renderer)
  File "/usr/local/lib/python3.9/site-packages/dbt/config/project.py", line 289, in render
    return self.create_project(rendered)
  File "/usr/local/lib/python3.9/site-packages/dbt/config/project.py", line 301, in create_project
    dbt_version = _get_required_version(
  File "/usr/local/lib/python3.9/site-packages/dbt/config/project.py", line 226, in _get_required_version
    validate_version(dbt_version, project_dict['name'])
  File "/usr/local/lib/python3.9/site-packages/dbt/config/project.py", line 203, in validate_version
    raise DbtProjectError(msg)
dbt.exceptions.DbtProjectError: Runtime Error
  This version of dbt is not supported with the 'dbt_utils' package.
    Installed version of dbt: =0.21.1
    Required version of dbt for 'dbt_utils': ['>=1.0.0', '<2.0.0']
  Check the requirements for the 'dbt_utils' package, or run dbt again with --no-version-check
  

Error encountered in /Users/nijoshi/Desktop/dbt_proj/dbt_modules/dbt_utils/dbt_project.yml

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/dbt/main.py", line 127, in main
    results, succeeded = handle_and_check(args)
  File "/usr/local/lib/python3.9/site-packages/dbt/main.py", line 205, in handle_and_check
    task, res = run_from_args(parsed)
  File "/usr/local/lib/python3.9/site-packages/dbt/main.py", line 258, in run_from_args
    results = task.run()
  File "/usr/local/lib/python3.9/site-packages/dbt/task/runnable.py", line 438, in run
    self._runtime_initialize()
  File "/usr/local/lib/python3.9/site-packages/dbt/task/runnable.py", line 154, in _runtime_initialize
    super()._runtime_initialize()
  File "/usr/local/lib/python3.9/site-packages/dbt/task/runnable.py", line 92, in _runtime_initialize
    self.load_manifest()
  File "/usr/local/lib/python3.9/site-packages/dbt/task/runnable.py", line 79, in load_manifest
    self.manifest = ManifestLoader.get_full_manifest(self.config)
  File "/usr/local/lib/python3.9/site-packages/dbt/parser/manifest.py", line 179, in get_full_manifest
    projects = config.load_dependencies()
  File "/usr/local/lib/python3.9/site-packages/dbt/config/runtime.py", line 347, in load_dependencies
    for project_name, project in self.load_projects(project_paths):
  File "/usr/local/lib/python3.9/site-packages/dbt/config/runtime.py", line 369, in load_projects
    raise DbtProjectError(
dbt.exceptions.DbtProjectError: Runtime Error
  Failed to read package: Runtime Error
    This version of dbt is not supported with the 'dbt_utils' package.
      Installed version of dbt: =0.21.1
      Required version of dbt for 'dbt_utils': ['>=1.0.0', '<2.0.0']
    Check the requirements for the 'dbt_utils' package, or run dbt again with --no-version-check
    
  
  Error encountered in /Users/nijoshi/Desktop/dbt_proj/dbt_modules/dbt_utils/dbt_project.yml

Error encountered in /Users/nijoshi/Desktop/dbt_proj/dbt_modules/dbt_utils

2022-01-15 16:27:15.946437 (MainThread): Running with dbt=0.21.1
2022-01-15 16:27:16.024025 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, defer=None, state=None, cls=<class 'dbt.task.clean.CleanTask'>, which='clean', rpc_method=None)
2022-01-15 16:27:16.024618 (MainThread): Tracking: tracking
2022-01-15 16:27:16.042282 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10980ac70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10980ab80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1097e6c40>]}
2022-01-15 16:27:16.043912 (MainThread): Checking target/*
2022-01-15 16:27:16.059224 (MainThread):  Cleaned target/*
2022-01-15 16:27:16.059478 (MainThread): Checking dbt_modules/*
2022-01-15 16:27:16.105738 (MainThread):  Cleaned dbt_modules/*
2022-01-15 16:27:16.105989 (MainThread): Finished cleaning all paths.
2022-01-15 16:27:16.106365 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10980ab80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10980ac70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1097e6370>]}
2022-01-15 16:27:16.106614 (MainThread): Flushing usage events
2022-01-15 16:27:39.472046 (MainThread): Running with dbt=0.21.1
2022-01-15 16:27:39.545735 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, defer=None, state=None, cls=<class 'dbt.task.deps.DepsTask'>, which='deps', rpc_method='deps')
2022-01-15 16:27:39.546277 (MainThread): Tracking: tracking
2022-01-15 16:27:39.567363 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e2f8b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e2f670>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e3e940>]}
2022-01-15 16:27:39.570754 (MainThread): Set downloads directory='/var/folders/ht/55m1kf9529v8n85gyrn0hzcc0000gp/T/dbt-downloads-29hi_961'
2022-01-15 16:27:39.571881 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/index.json
2022-01-15 16:27:40.203096 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/index.json 200
2022-01-15 16:27:40.203550 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
2022-01-15 16:27:40.592693 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
2022-01-15 16:27:40.614081 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils/0.7.1.json
2022-01-15 16:27:41.333123 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils/0.7.1.json 200
2022-01-15 16:27:41.333590 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
2022-01-15 16:27:42.102930 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
2022-01-15 16:27:42.124798 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils/0.7.1.json
2022-01-15 16:27:42.544060 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils/0.7.1.json 200
2022-01-15 16:27:42.544542 (MainThread): Installing dbt-labs/dbt_utils@0.7.1
2022-01-15 16:27:43.531713 (MainThread):   Installed from version 0.7.1
2022-01-15 16:27:43.532106 (MainThread):   Updated version available: 0.8.0
2022-01-15 16:27:43.532496 (MainThread): Sending event: {'category': 'dbt', 'action': 'package', 'label': 'bd24937e-223e-4f52-84a5-41eb609854b3', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e2fd60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e2fe20>]}
2022-01-15 16:27:43.532880 (MainThread): 
Updates available for packages: ['dbt-labs/dbt_utils']                 
Update your versions in packages.yml, then run dbt deps
2022-01-15 16:27:43.534626 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e3ad00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e2fac0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e2fee0>]}
2022-01-15 16:27:43.535162 (MainThread): Flushing usage events
2022-01-15 16:27:51.577510 (MainThread): Running with dbt=0.21.1
2022-01-15 16:27:51.659723 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2022-01-15 16:27:51.661410 (MainThread): Tracking: tracking
2022-01-15 16:27:51.681283 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1108f85b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110eefca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110eef310>]}
2022-01-15 16:27:51.703284 (MainThread): Partial parsing not enabled
2022-01-15 16:27:51.754135 (MainThread): Parsing macros/catalog.sql
2022-01-15 16:27:51.758012 (MainThread): Parsing macros/relations.sql
2022-01-15 16:27:51.759316 (MainThread): Parsing macros/adapters.sql
2022-01-15 16:27:51.783200 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2022-01-15 16:27:51.785179 (MainThread): Parsing macros/core.sql
2022-01-15 16:27:51.789088 (MainThread): Parsing macros/materializations/test.sql
2022-01-15 16:27:51.796182 (MainThread): Parsing macros/materializations/helpers.sql
2022-01-15 16:27:51.806166 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2022-01-15 16:27:51.807805 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2022-01-15 16:27:51.824283 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2022-01-15 16:27:51.855119 (MainThread): Parsing macros/materializations/seed/seed.sql
2022-01-15 16:27:51.876593 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2022-01-15 16:27:51.878309 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2022-01-15 16:27:51.887892 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2022-01-15 16:27:51.906499 (MainThread): Parsing macros/materializations/common/merge.sql
2022-01-15 16:27:51.919809 (MainThread): Parsing macros/materializations/table/table.sql
2022-01-15 16:27:51.927129 (MainThread): Parsing macros/materializations/view/view.sql
2022-01-15 16:27:51.933746 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2022-01-15 16:27:51.937451 (MainThread): Parsing macros/etc/get_custom_alias.sql
2022-01-15 16:27:51.938835 (MainThread): Parsing macros/etc/query.sql
2022-01-15 16:27:51.939718 (MainThread): Parsing macros/etc/is_incremental.sql
2022-01-15 16:27:51.941149 (MainThread): Parsing macros/etc/datetime.sql
2022-01-15 16:27:51.949127 (MainThread): Parsing macros/etc/where_subquery.sql
2022-01-15 16:27:51.950821 (MainThread): Parsing macros/etc/get_custom_schema.sql
2022-01-15 16:27:51.953243 (MainThread): Parsing macros/etc/get_custom_database.sql
2022-01-15 16:27:51.954695 (MainThread): Parsing macros/adapters/common.sql
2022-01-15 16:27:52.007216 (MainThread): Parsing macros/schema_tests/relationships.sql
2022-01-15 16:27:52.008973 (MainThread): Parsing macros/schema_tests/not_null.sql
2022-01-15 16:27:52.010077 (MainThread): Parsing macros/schema_tests/unique.sql
2022-01-15 16:27:52.011306 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2022-01-15 16:27:52.013397 (MainThread): Parsing macros/cross_db_utils/except.sql
2022-01-15 16:27:52.014370 (MainThread): Parsing macros/cross_db_utils/replace.sql
2022-01-15 16:27:52.015515 (MainThread): Parsing macros/cross_db_utils/concat.sql
2022-01-15 16:27:52.016428 (MainThread): Parsing macros/cross_db_utils/datatypes.sql
2022-01-15 16:27:52.022133 (MainThread): Parsing macros/cross_db_utils/_is_relation.sql
2022-01-15 16:27:52.023215 (MainThread): Parsing macros/cross_db_utils/length.sql
2022-01-15 16:27:52.024419 (MainThread): Parsing macros/cross_db_utils/dateadd.sql
2022-01-15 16:27:52.027121 (MainThread): Parsing macros/cross_db_utils/intersect.sql
2022-01-15 16:27:52.028432 (MainThread): Parsing macros/cross_db_utils/right.sql
2022-01-15 16:27:52.030560 (MainThread): Parsing macros/cross_db_utils/datediff.sql
2022-01-15 16:27:52.039961 (MainThread): Parsing macros/cross_db_utils/safe_cast.sql
2022-01-15 16:27:52.041674 (MainThread): Parsing macros/cross_db_utils/hash.sql
2022-01-15 16:27:52.042977 (MainThread): Parsing macros/cross_db_utils/cast_bool_to_text.sql
2022-01-15 16:27:52.044298 (MainThread): Parsing macros/cross_db_utils/identifier.sql
2022-01-15 16:27:52.045834 (MainThread): Parsing macros/cross_db_utils/position.sql
2022-01-15 16:27:52.047249 (MainThread): Parsing macros/cross_db_utils/literal.sql
2022-01-15 16:27:52.048139 (MainThread): Parsing macros/cross_db_utils/current_timestamp.sql
2022-01-15 16:27:52.051519 (MainThread): Parsing macros/cross_db_utils/width_bucket.sql
2022-01-15 16:27:52.056377 (MainThread): Parsing macros/cross_db_utils/last_day.sql
2022-01-15 16:27:52.059610 (MainThread): Parsing macros/cross_db_utils/split_part.sql
2022-01-15 16:27:52.061380 (MainThread): Parsing macros/cross_db_utils/date_trunc.sql
2022-01-15 16:27:52.062848 (MainThread): Parsing macros/cross_db_utils/_is_ephemeral.sql
2022-01-15 16:27:52.064579 (MainThread): Parsing macros/materializations/insert_by_period_materialization.sql
2022-01-15 16:27:52.088463 (MainThread): Parsing macros/web/get_url_host.sql
2022-01-15 16:27:52.090264 (MainThread): Parsing macros/web/get_url_path.sql
2022-01-15 16:27:52.092657 (MainThread): Parsing macros/web/get_url_parameter.sql
2022-01-15 16:27:52.094121 (MainThread): Parsing macros/jinja_helpers/pretty_log_format.sql
2022-01-15 16:27:52.095167 (MainThread): Parsing macros/jinja_helpers/pretty_time.sql
2022-01-15 16:27:52.096301 (MainThread): Parsing macros/jinja_helpers/log_info.sql
2022-01-15 16:27:52.097335 (MainThread): Parsing macros/jinja_helpers/slugify.sql
2022-01-15 16:27:52.098490 (MainThread): Parsing macros/schema_tests/fewer_rows_than.sql
2022-01-15 16:27:52.100058 (MainThread): Parsing macros/schema_tests/equal_rowcount.sql
2022-01-15 16:27:52.101894 (MainThread): Parsing macros/schema_tests/relationships_where.sql
2022-01-15 16:27:52.104027 (MainThread): Parsing macros/schema_tests/recency.sql
2022-01-15 16:27:52.105627 (MainThread): Parsing macros/schema_tests/not_constant.sql
2022-01-15 16:27:52.106762 (MainThread): Parsing macros/schema_tests/accepted_range.sql
2022-01-15 16:27:52.109367 (MainThread): Parsing macros/schema_tests/not_accepted_values.sql
2022-01-15 16:27:52.111279 (MainThread): Parsing macros/schema_tests/test_unique_where.sql
2022-01-15 16:27:52.112580 (MainThread): Parsing macros/schema_tests/at_least_one.sql
2022-01-15 16:27:52.113720 (MainThread): Parsing macros/schema_tests/unique_combination_of_columns.sql
2022-01-15 16:27:52.116705 (MainThread): Parsing macros/schema_tests/cardinality_equality.sql
2022-01-15 16:27:52.118759 (MainThread): Parsing macros/schema_tests/expression_is_true.sql
2022-01-15 16:27:52.120543 (MainThread): Parsing macros/schema_tests/sequential_values.sql
2022-01-15 16:27:52.123328 (MainThread): Parsing macros/schema_tests/test_not_null_where.sql
2022-01-15 16:27:52.124658 (MainThread): Parsing macros/schema_tests/equality.sql
2022-01-15 16:27:52.127846 (MainThread): Parsing macros/schema_tests/mutually_exclusive_ranges.sql
2022-01-15 16:27:52.136296 (MainThread): Parsing macros/sql/date_spine.sql
2022-01-15 16:27:52.140639 (MainThread): Parsing macros/sql/nullcheck_table.sql
2022-01-15 16:27:52.142145 (MainThread): Parsing macros/sql/get_relations_by_pattern.sql
2022-01-15 16:27:52.145300 (MainThread): Parsing macros/sql/generate_series.sql
2022-01-15 16:27:52.174606 (MainThread): Parsing macros/sql/get_relations_by_prefix.sql
2022-01-15 16:27:52.178996 (MainThread): Parsing macros/sql/get_tables_by_prefix_sql.sql
2022-01-15 16:27:52.181229 (MainThread): Parsing macros/sql/star.sql
2022-01-15 16:27:52.185548 (MainThread): Parsing macros/sql/unpivot.sql
2022-01-15 16:27:52.195686 (MainThread): Parsing macros/sql/union.sql
2022-01-15 16:27:52.205627 (MainThread): Parsing macros/sql/groupby.sql
2022-01-15 16:27:52.207165 (MainThread): Parsing macros/sql/surrogate_key.sql
2022-01-15 16:27:52.211153 (MainThread): Parsing macros/sql/safe_add.sql
2022-01-15 16:27:52.212958 (MainThread): Parsing macros/sql/nullcheck.sql
2022-01-15 16:27:52.214759 (MainThread): Parsing macros/sql/get_tables_by_pattern_sql.sql
2022-01-15 16:27:52.222033 (MainThread): Parsing macros/sql/get_column_values.sql
2022-01-15 16:27:52.227450 (MainThread): Parsing macros/sql/pivot.sql
2022-01-15 16:27:52.231874 (MainThread): Parsing macros/sql/get_query_results_as_dict.sql
2022-01-15 16:27:52.234391 (MainThread): Parsing macros/sql/haversine_distance.sql
2022-01-15 16:27:52.538612 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-15 16:27:52.550363 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.customer_test".
2022-01-15 16:27:52.553750 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 16:27:52.554702 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-15 16:27:52.558110 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.film_test".
2022-01-15 16:27:52.561320 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-15 16:27:52.568864 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-15 16:27:52.571649 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-15 16:27:52.582773 (MainThread): Acquiring new postgres connection "test.sakila_dbt_project.film_replacementcost_30".
2022-01-15 16:27:52.584478 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 16:27:52.616539 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 16:27:52.618456 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 16:27:52.620323 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 16:27:52.622196 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 16:27:52.623834 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 16:27:52.625606 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 16:27:52.637734 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 16:27:52.641392 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 16:27:52.655326 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 16:27:52.657010 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-15 16:27:52.680564 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '291477e8-d627-4b4f-806c-4375696da087', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1110ce1c0>]}
2022-01-15 16:27:52.690055 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-01-15 16:27:52.690585 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '291477e8-d627-4b4f-806c-4375696da087', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111087c70>]}
2022-01-15 16:27:52.690826 (MainThread): Found 7 models, 11 tests, 0 snapshots, 0 analyses, 347 macros, 0 operations, 0 seed files, 12 sources, 0 exposures
2022-01-15 16:27:52.692550 (MainThread): 
2022-01-15 16:27:52.692896 (MainThread): Acquiring new postgres connection "master".
2022-01-15 16:27:52.693836 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_sakila_wh".
2022-01-15 16:27:52.703409 (ThreadPoolExecutor-0_0): Using postgres connection "list_sakila_wh".
2022-01-15 16:27:52.703630 (ThreadPoolExecutor-0_0): On list_sakila_wh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh"} */

    select distinct nspname from pg_namespace
  
2022-01-15 16:27:52.703792 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2022-01-15 16:27:53.170984 (ThreadPoolExecutor-0_0): SQL status: SELECT 12 in 0.47 seconds
2022-01-15 16:27:53.172995 (ThreadPoolExecutor-0_0): On list_sakila_wh: Close
2022-01-15 16:27:53.174741 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_dwh".
2022-01-15 16:27:53.181515 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-15 16:27:53.181719 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: BEGIN
2022-01-15 16:27:53.181897 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2022-01-15 16:27:53.531632 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.35 seconds
2022-01-15 16:27:53.532061 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-15 16:27:53.532371 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_dwh"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dwh'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dwh'
  
2022-01-15 16:27:53.596463 (ThreadPoolExecutor-1_0): SQL status: SELECT 8 in 0.06 seconds
2022-01-15 16:27:53.599009 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: ROLLBACK
2022-01-15 16:27:53.656848 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: Close
2022-01-15 16:27:53.662766 (MainThread): Using postgres connection "master".
2022-01-15 16:27:53.663004 (MainThread): On master: BEGIN
2022-01-15 16:27:53.663186 (MainThread): Opening a new connection, currently in state init
2022-01-15 16:27:54.024256 (MainThread): SQL status: BEGIN in 0.36 seconds
2022-01-15 16:27:54.024647 (MainThread): Using postgres connection "master".
2022-01-15 16:27:54.024902 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-15 16:27:54.099470 (MainThread): SQL status: SELECT 47 in 0.07 seconds
2022-01-15 16:27:54.102930 (MainThread): On master: ROLLBACK
2022-01-15 16:27:54.159624 (MainThread): Using postgres connection "master".
2022-01-15 16:27:54.160198 (MainThread): On master: BEGIN
2022-01-15 16:27:54.274548 (MainThread): SQL status: BEGIN in 0.11 seconds
2022-01-15 16:27:54.275145 (MainThread): On master: COMMIT
2022-01-15 16:27:54.275508 (MainThread): Using postgres connection "master".
2022-01-15 16:27:54.275756 (MainThread): On master: COMMIT
2022-01-15 16:27:54.332946 (MainThread): SQL status: COMMIT in 0.06 seconds
2022-01-15 16:27:54.333571 (MainThread): On master: Close
2022-01-15 16:27:54.334324 (MainThread): 21:57:54 | Concurrency: 1 threads (target='dev')
2022-01-15 16:27:54.334711 (MainThread): 21:57:54 | 
2022-01-15 16:27:54.338110 (Thread-1): Began running node model.sakila_dbt_project.dim_date
2022-01-15 16:27:54.338528 (Thread-1): 21:57:54 | 1 of 7 START table model dwh.dim_date................................ [RUN]
2022-01-15 16:27:54.339004 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-15 16:27:54.339267 (Thread-1): Compiling model.sakila_dbt_project.dim_date
2022-01-15 16:27:54.342031 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_date"
2022-01-15 16:27:54.343309 (Thread-1): finished collecting timing info
2022-01-15 16:27:54.370709 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_date"
2022-01-15 16:27:54.372007 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-15 16:27:54.372239 (Thread-1): On model.sakila_dbt_project.dim_date: BEGIN
2022-01-15 16:27:54.372410 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 16:27:54.727432 (Thread-1): SQL status: BEGIN in 0.35 seconds
2022-01-15 16:27:54.728076 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-15 16:27:54.728375 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */


  create  table "sakila_wh"."dwh"."dim_date__dbt_tmp"
  as (
    with dates as (
SELECT
       TO_CHAR(datum, 'yyyymmdd')::INT AS date_dim_id,
       datum AS date_key,
       EXTRACT(EPOCH FROM datum) AS epoch,
       TO_CHAR(datum, 'TMDay') AS day_name,
       EXTRACT(ISODOW FROM datum) AS day_of_week,
       EXTRACT(DAY FROM datum) AS day_of_month,
       datum - DATE_TRUNC('quarter', datum)::DATE + 1 AS day_of_quarter,
       EXTRACT(DOY FROM datum) AS day_of_year,
       TO_CHAR(datum, 'W')::INT AS week_of_month,
       EXTRACT(WEEK FROM datum) AS week_of_year,
       EXTRACT(MONTH FROM datum) AS month_actual,
       TO_CHAR(datum, 'TMMonth') AS month_name,
       TO_CHAR(datum, 'Mon') AS month_name_abbreviated,
       EXTRACT(QUARTER FROM datum) AS quarter_actual,
       CASE
           WHEN EXTRACT(QUARTER FROM datum) = 1 THEN 'First'
           WHEN EXTRACT(QUARTER FROM datum) = 2 THEN 'Second'
           WHEN EXTRACT(QUARTER FROM datum) = 3 THEN 'Third'
           WHEN EXTRACT(QUARTER FROM datum) = 4 THEN 'Fourth'
           END AS quarter_name,
       EXTRACT(YEAR FROM datum) AS year_actual,
       datum + (1 - EXTRACT(ISODOW FROM datum))::INT AS first_day_of_week,
       datum + (7 - EXTRACT(ISODOW FROM datum))::INT AS last_day_of_week,
       datum + (1 - EXTRACT(DAY FROM datum))::INT AS first_day_of_month,
       (DATE_TRUNC('MONTH', datum) + INTERVAL '1 MONTH - 1 day')::DATE AS last_day_of_month,
       DATE_TRUNC('quarter', datum)::DATE AS first_day_of_quarter,
       (DATE_TRUNC('quarter', datum) + INTERVAL '3 MONTH - 1 day')::DATE AS last_day_of_quarter,
       TO_DATE(EXTRACT(YEAR FROM datum) || '-01-01', 'YYYY-MM-DD') AS first_day_of_year,
       TO_DATE(EXTRACT(YEAR FROM datum) || '-12-31', 'YYYY-MM-DD') AS last_day_of_year,
       TO_CHAR(datum, 'yyyymm') AS yyyymm,
       CASE
           WHEN EXTRACT(ISODOW FROM datum) IN (6, 7) THEN TRUE
           ELSE FALSE
           END AS weekend_indr
FROM (SELECT '2000-01-01'::DATE + SEQUENCE.DAY AS datum
      FROM GENERATE_SERIES(0, 29219) AS SEQUENCE (DAY)
      GROUP BY SEQUENCE.DAY) DQ
)
select
*
from
dates
where
date_key <= CURRENT_DATE
order by date_dim_id asc
  );
2022-01-15 16:27:55.768654 (Thread-1): SQL status: SELECT 8051 in 1.04 seconds
2022-01-15 16:27:55.776391 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-15 16:27:55.776617 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
alter table "sakila_wh"."dwh"."dim_date" rename to "dim_date__dbt_backup"
2022-01-15 16:27:55.835090 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-15 16:27:55.838807 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-15 16:27:55.839056 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
alter table "sakila_wh"."dwh"."dim_date__dbt_tmp" rename to "dim_date"
2022-01-15 16:27:55.897033 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-15 16:27:55.909805 (Thread-1): On model.sakila_dbt_project.dim_date: COMMIT
2022-01-15 16:27:55.910067 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-15 16:27:55.910244 (Thread-1): On model.sakila_dbt_project.dim_date: COMMIT
2022-01-15 16:27:55.969661 (Thread-1): SQL status: COMMIT in 0.06 seconds
2022-01-15 16:27:55.975972 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-15 16:27:55.976188 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
drop table if exists "sakila_wh"."dwh"."dim_date__dbt_backup" cascade
2022-01-15 16:27:56.041913 (Thread-1): SQL status: DROP TABLE in 0.07 seconds
2022-01-15 16:27:56.043743 (Thread-1): finished collecting timing info
2022-01-15 16:27:56.044019 (Thread-1): On model.sakila_dbt_project.dim_date: Close
2022-01-15 16:27:56.044602 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '291477e8-d627-4b4f-806c-4375696da087', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11105c940>]}
2022-01-15 16:27:56.045052 (Thread-1): 21:57:56 | 1 of 7 OK created table model dwh.dim_date........................... [SELECT 8051 in 1.71s]
2022-01-15 16:27:56.045323 (Thread-1): Finished running node model.sakila_dbt_project.dim_date
2022-01-15 16:27:56.045581 (Thread-1): Began running node model.sakila_dbt_project.film_test
2022-01-15 16:27:56.046022 (Thread-1): 21:57:56 | 2 of 7 START table model dwh.film_test............................... [RUN]
2022-01-15 16:27:56.046470 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.film_test".
2022-01-15 16:27:56.046709 (Thread-1): Compiling model.sakila_dbt_project.film_test
2022-01-15 16:27:56.048497 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.film_test"
2022-01-15 16:27:56.049243 (Thread-1): finished collecting timing info
2022-01-15 16:27:56.052001 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.film_test"
2022-01-15 16:27:56.052834 (Thread-1): Using postgres connection "model.sakila_dbt_project.film_test".
2022-01-15 16:27:56.053026 (Thread-1): On model.sakila_dbt_project.film_test: BEGIN
2022-01-15 16:27:56.053208 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 16:27:56.411390 (Thread-1): SQL status: BEGIN in 0.36 seconds
2022-01-15 16:27:56.411778 (Thread-1): Using postgres connection "model.sakila_dbt_project.film_test".
2022-01-15 16:27:56.412046 (Thread-1): On model.sakila_dbt_project.film_test: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.film_test"} */


  create  table "sakila_wh"."dwh"."film_test__dbt_tmp"
  as (
    select * from 
stg.film
  );
2022-01-15 16:27:56.483363 (Thread-1): SQL status: SELECT 1000 in 0.07 seconds
2022-01-15 16:27:56.487351 (Thread-1): Using postgres connection "model.sakila_dbt_project.film_test".
2022-01-15 16:27:56.487600 (Thread-1): On model.sakila_dbt_project.film_test: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.film_test"} */
alter table "sakila_wh"."dwh"."film_test" rename to "film_test__dbt_backup"
2022-01-15 16:27:56.545436 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-15 16:27:56.550640 (Thread-1): Using postgres connection "model.sakila_dbt_project.film_test".
2022-01-15 16:27:56.551036 (Thread-1): On model.sakila_dbt_project.film_test: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.film_test"} */
alter table "sakila_wh"."dwh"."film_test__dbt_tmp" rename to "film_test"
2022-01-15 16:27:56.610964 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-15 16:27:56.613102 (Thread-1): On model.sakila_dbt_project.film_test: COMMIT
2022-01-15 16:27:56.613343 (Thread-1): Using postgres connection "model.sakila_dbt_project.film_test".
2022-01-15 16:27:56.613544 (Thread-1): On model.sakila_dbt_project.film_test: COMMIT
2022-01-15 16:27:56.671807 (Thread-1): SQL status: COMMIT in 0.06 seconds
2022-01-15 16:27:56.674317 (Thread-1): Using postgres connection "model.sakila_dbt_project.film_test".
2022-01-15 16:27:56.675455 (Thread-1): On model.sakila_dbt_project.film_test: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.film_test"} */
drop table if exists "sakila_wh"."dwh"."film_test__dbt_backup" cascade
2022-01-15 16:27:56.736390 (Thread-1): SQL status: DROP TABLE in 0.06 seconds
2022-01-15 16:27:56.737979 (Thread-1): finished collecting timing info
2022-01-15 16:27:56.738258 (Thread-1): On model.sakila_dbt_project.film_test: Close
2022-01-15 16:27:56.738832 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '291477e8-d627-4b4f-806c-4375696da087', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1112c5a60>]}
2022-01-15 16:27:56.739262 (Thread-1): 21:57:56 | 2 of 7 OK created table model dwh.film_test.......................... [SELECT 1000 in 0.69s]
2022-01-15 16:27:56.739493 (Thread-1): Finished running node model.sakila_dbt_project.film_test
2022-01-15 16:27:56.739750 (Thread-1): Began running node model.sakila_dbt_project.hello_world
2022-01-15 16:27:56.740129 (Thread-1): 21:57:56 | 3 of 7 START table model dwh.hello_world............................. [RUN]
2022-01-15 16:27:56.740510 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-15 16:27:56.740710 (Thread-1): Compiling model.sakila_dbt_project.hello_world
2022-01-15 16:27:56.742453 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.hello_world"
2022-01-15 16:27:56.743095 (Thread-1): finished collecting timing info
2022-01-15 16:27:56.745829 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.hello_world"
2022-01-15 16:27:56.746399 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-15 16:27:56.746579 (Thread-1): On model.sakila_dbt_project.hello_world: BEGIN
2022-01-15 16:27:56.746750 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 16:27:57.096056 (Thread-1): SQL status: BEGIN in 0.35 seconds
2022-01-15 16:27:57.096476 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-15 16:27:57.096761 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */


  create  table "sakila_wh"."dwh"."hello_world__dbt_tmp"
  as (
    select
	customer.customer_id::int,
	customer.store_id::int,
	customer.first_name,
	customer.last_name,
	concat(customer.first_name,' ',customer.last_name) as full_name,
	substring(email from POSITION('@' in email)+1 for char_length(email)-POSITION('@' in email)) as domain,
	customer.email,
	customer.active::int,
	customer.address_id::int,
	address.address,
	city.city_id::int,
	city.city,
	(case when customer.active = 0 then 'no' else 'yes' end)::varchar(100) as "active_desc",
	customer.create_date::timestamp,
	customer.last_update::timestamp
from
	stg.customer as customer

	left join stg.address on 1=1
	and customer.address_id =address.address_id

	left join stg.city on 1=1
	and address.city_id = city.city_id
  );
2022-01-15 16:27:57.172574 (Thread-1): SQL status: SELECT 599 in 0.08 seconds
2022-01-15 16:27:57.176079 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-15 16:27:57.176309 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
alter table "sakila_wh"."dwh"."hello_world" rename to "hello_world__dbt_backup"
2022-01-15 16:27:57.233536 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-15 16:27:57.236924 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-15 16:27:57.237172 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
alter table "sakila_wh"."dwh"."hello_world__dbt_tmp" rename to "hello_world"
2022-01-15 16:27:57.294279 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-15 16:27:57.296623 (Thread-1): On model.sakila_dbt_project.hello_world: COMMIT
2022-01-15 16:27:57.296872 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-15 16:27:57.297076 (Thread-1): On model.sakila_dbt_project.hello_world: COMMIT
2022-01-15 16:27:57.356936 (Thread-1): SQL status: COMMIT in 0.06 seconds
2022-01-15 16:27:57.360425 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-15 16:27:57.360681 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
drop table if exists "sakila_wh"."dwh"."hello_world__dbt_backup" cascade
2022-01-15 16:27:57.421106 (Thread-1): SQL status: DROP TABLE in 0.06 seconds
2022-01-15 16:27:57.422691 (Thread-1): finished collecting timing info
2022-01-15 16:27:57.422968 (Thread-1): On model.sakila_dbt_project.hello_world: Close
2022-01-15 16:27:57.423534 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '291477e8-d627-4b4f-806c-4375696da087', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1112c90a0>]}
2022-01-15 16:27:57.424027 (Thread-1): 21:57:57 | 3 of 7 OK created table model dwh.hello_world........................ [SELECT 599 in 0.68s]
2022-01-15 16:27:57.424335 (Thread-1): Finished running node model.sakila_dbt_project.hello_world
2022-01-15 16:27:57.424604 (Thread-1): Began running node model.sakila_dbt_project.my_first_dbt_model
2022-01-15 16:27:57.425149 (Thread-1): 21:57:57 | 4 of 7 START table model dwh.my_first_dbt_model...................... [RUN]
2022-01-15 16:27:57.425638 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-15 16:27:57.425881 (Thread-1): Compiling model.sakila_dbt_project.my_first_dbt_model
2022-01-15 16:27:57.428734 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.my_first_dbt_model"
2022-01-15 16:27:57.429367 (Thread-1): finished collecting timing info
2022-01-15 16:27:57.432081 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.my_first_dbt_model"
2022-01-15 16:27:57.432685 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-15 16:27:57.432935 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: BEGIN
2022-01-15 16:27:57.433115 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 16:27:57.796589 (Thread-1): SQL status: BEGIN in 0.36 seconds
2022-01-15 16:27:57.797158 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-15 16:27:57.797455 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */


  create  table "sakila_wh"."dwh"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    --union all
    --select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-15 16:27:57.860940 (Thread-1): SQL status: SELECT 1 in 0.06 seconds
2022-01-15 16:27:57.866432 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-15 16:27:57.866663 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
alter table "sakila_wh"."dwh"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2022-01-15 16:27:57.925087 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-15 16:27:57.928480 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-15 16:27:57.928723 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
alter table "sakila_wh"."dwh"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-15 16:27:57.987615 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-15 16:27:57.989657 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: COMMIT
2022-01-15 16:27:57.989911 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-15 16:27:57.990112 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: COMMIT
2022-01-15 16:27:58.048098 (Thread-1): SQL status: COMMIT in 0.06 seconds
2022-01-15 16:27:58.051342 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-15 16:27:58.051584 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
drop table if exists "sakila_wh"."dwh"."my_first_dbt_model__dbt_backup" cascade
2022-01-15 16:27:58.110792 (Thread-1): SQL status: DROP TABLE in 0.06 seconds
2022-01-15 16:27:58.112699 (Thread-1): finished collecting timing info
2022-01-15 16:27:58.112973 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: Close
2022-01-15 16:27:58.113541 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '291477e8-d627-4b4f-806c-4375696da087', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111312af0>]}
2022-01-15 16:27:58.113985 (Thread-1): 21:57:58 | 4 of 7 OK created table model dwh.my_first_dbt_model................. [SELECT 1 in 0.69s]
2022-01-15 16:27:58.114256 (Thread-1): Finished running node model.sakila_dbt_project.my_first_dbt_model
2022-01-15 16:27:58.114509 (Thread-1): Began running node model.sakila_dbt_project.payment_inc
2022-01-15 16:27:58.114828 (Thread-1): 21:57:58 | 5 of 7 START incremental model dwh.payment_inc....................... [RUN]
2022-01-15 16:27:58.115246 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-15 16:27:58.115476 (Thread-1): Compiling model.sakila_dbt_project.payment_inc
2022-01-15 16:27:58.122206 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.payment_inc"
2022-01-15 16:27:58.122858 (Thread-1): finished collecting timing info
2022-01-15 16:27:58.162407 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-15 16:27:58.162638 (Thread-1): On model.sakila_dbt_project.payment_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.payment_inc"} */

    

  create temporary table "payment_inc__dbt_tmp215758155944"
  as (
    

select
*,
'2022-01-15 16:27:51' as dbt_tran_time
from
stg.payment
where 1=1


and payment_date::timestamp > (select max(payment_date) from "sakila_wh"."dwh"."payment_inc")



-- - INTERVAL '3 DAY'
-- unique_key='payment_id'
  );
  
2022-01-15 16:27:58.162808 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 16:27:58.538274 (Thread-1): SQL status: SELECT 0 in 0.38 seconds
2022-01-15 16:27:58.547205 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-15 16:27:58.547432 (Thread-1): On model.sakila_dbt_project.payment_inc: BEGIN
2022-01-15 16:27:58.605174 (Thread-1): SQL status: BEGIN in 0.06 seconds
2022-01-15 16:27:58.605577 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-15 16:27:58.605835 (Thread-1): On model.sakila_dbt_project.payment_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.payment_inc"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'payment_inc__dbt_tmp215758155944'
        
      order by ordinal_position

  
2022-01-15 16:27:58.677255 (Thread-1): SQL status: SELECT 7 in 0.07 seconds
2022-01-15 16:27:58.684218 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-15 16:27:58.684440 (Thread-1): On model.sakila_dbt_project.payment_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.payment_inc"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "sakila_wh".INFORMATION_SCHEMA.columns
      where table_name = 'payment_inc'
        
        and table_schema = 'dwh'
        
      order by ordinal_position

  
2022-01-15 16:27:58.747363 (Thread-1): SQL status: SELECT 7 in 0.06 seconds
2022-01-15 16:27:58.760414 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-15 16:27:58.760652 (Thread-1): On model.sakila_dbt_project.payment_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.payment_inc"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "sakila_wh".INFORMATION_SCHEMA.columns
      where table_name = 'payment_inc'
        
        and table_schema = 'dwh'
        
      order by ordinal_position

  
2022-01-15 16:27:58.825072 (Thread-1): SQL status: SELECT 7 in 0.06 seconds
2022-01-15 16:27:58.828237 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.payment_inc"
2022-01-15 16:27:58.829070 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-15 16:27:58.829289 (Thread-1): On model.sakila_dbt_project.payment_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.payment_inc"} */

      delete
    from "sakila_wh"."dwh"."payment_inc"
    where (payment_id) in (
        select (payment_id)
        from "payment_inc__dbt_tmp215758155944"
    );

    insert into "sakila_wh"."dwh"."payment_inc" ("payment_id", "customer_id", "staff_id", "rental_id", "amount", "payment_date", "dbt_tran_time")
    (
       select "payment_id", "customer_id", "staff_id", "rental_id", "amount", "payment_date", "dbt_tran_time"
       from "payment_inc__dbt_tmp215758155944"
    );
  
2022-01-15 16:27:58.887377 (Thread-1): SQL status: INSERT 0 0 in 0.06 seconds
2022-01-15 16:27:58.889213 (Thread-1): On model.sakila_dbt_project.payment_inc: COMMIT
2022-01-15 16:27:58.889473 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-15 16:27:58.889695 (Thread-1): On model.sakila_dbt_project.payment_inc: COMMIT
2022-01-15 16:27:58.947938 (Thread-1): SQL status: COMMIT in 0.06 seconds
2022-01-15 16:27:58.949187 (Thread-1): finished collecting timing info
2022-01-15 16:27:58.949537 (Thread-1): On model.sakila_dbt_project.payment_inc: Close
2022-01-15 16:27:58.950370 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '291477e8-d627-4b4f-806c-4375696da087', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1111dad30>]}
2022-01-15 16:27:58.950895 (Thread-1): 21:57:58 | 5 of 7 OK created incremental model dwh.payment_inc.................. [INSERT 0 0 in 0.84s]
2022-01-15 16:27:58.951167 (Thread-1): Finished running node model.sakila_dbt_project.payment_inc
2022-01-15 16:27:58.951431 (Thread-1): Began running node model.sakila_dbt_project.customer_test
2022-01-15 16:27:58.951758 (Thread-1): 21:57:58 | 6 of 7 START table model dwh.customer_alias.......................... [RUN]
2022-01-15 16:27:58.952306 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.customer_test".
2022-01-15 16:27:58.952578 (Thread-1): Compiling model.sakila_dbt_project.customer_test
2022-01-15 16:27:58.957338 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.customer_test"
2022-01-15 16:27:58.957940 (Thread-1): finished collecting timing info
2022-01-15 16:27:58.988920 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.customer_test"
2022-01-15 16:27:58.989684 (Thread-1): Using postgres connection "model.sakila_dbt_project.customer_test".
2022-01-15 16:27:58.989877 (Thread-1): On model.sakila_dbt_project.customer_test: BEGIN
2022-01-15 16:27:58.990056 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 16:27:59.342247 (Thread-1): SQL status: BEGIN in 0.35 seconds
2022-01-15 16:27:59.342628 (Thread-1): Using postgres connection "model.sakila_dbt_project.customer_test".
2022-01-15 16:27:59.342890 (Thread-1): On model.sakila_dbt_project.customer_test: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.customer_test"} */


  create  table "sakila_wh"."dwh"."customer_test__dbt_tmp"
  as (
    

select * from 
"sakila_wh"."dwh"."hello_world"
where customer_id < 10
  );
2022-01-15 16:27:59.409073 (Thread-1): SQL status: SELECT 9 in 0.07 seconds
2022-01-15 16:27:59.412594 (Thread-1): Using postgres connection "model.sakila_dbt_project.customer_test".
2022-01-15 16:27:59.412816 (Thread-1): On model.sakila_dbt_project.customer_test: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.customer_test"} */
alter table "sakila_wh"."dwh"."customer_alias" rename to "customer_test__dbt_backup"
2022-01-15 16:27:59.470982 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-15 16:27:59.474480 (Thread-1): Using postgres connection "model.sakila_dbt_project.customer_test".
2022-01-15 16:27:59.474711 (Thread-1): On model.sakila_dbt_project.customer_test: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.customer_test"} */
alter table "sakila_wh"."dwh"."customer_test__dbt_tmp" rename to "customer_alias"
2022-01-15 16:27:59.534458 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-15 16:27:59.536765 (Thread-1): On model.sakila_dbt_project.customer_test: COMMIT
2022-01-15 16:27:59.537027 (Thread-1): Using postgres connection "model.sakila_dbt_project.customer_test".
2022-01-15 16:27:59.537297 (Thread-1): On model.sakila_dbt_project.customer_test: COMMIT
2022-01-15 16:27:59.597044 (Thread-1): SQL status: COMMIT in 0.06 seconds
2022-01-15 16:27:59.600048 (Thread-1): Using postgres connection "model.sakila_dbt_project.customer_test".
2022-01-15 16:27:59.600294 (Thread-1): On model.sakila_dbt_project.customer_test: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.customer_test"} */
drop table if exists "sakila_wh"."dwh"."customer_test__dbt_backup" cascade
2022-01-15 16:27:59.663835 (Thread-1): SQL status: DROP TABLE in 0.06 seconds
2022-01-15 16:27:59.665800 (Thread-1): finished collecting timing info
2022-01-15 16:27:59.666108 (Thread-1): On model.sakila_dbt_project.customer_test: Close
2022-01-15 16:27:59.666698 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '291477e8-d627-4b4f-806c-4375696da087', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11134fc40>]}
2022-01-15 16:27:59.667147 (Thread-1): 21:57:59 | 6 of 7 OK created table model dwh.customer_alias..................... [SELECT 9 in 0.71s]
2022-01-15 16:27:59.667419 (Thread-1): Finished running node model.sakila_dbt_project.customer_test
2022-01-15 16:27:59.667683 (Thread-1): Began running node model.sakila_dbt_project.my_second_dbt_model
2022-01-15 16:27:59.668134 (Thread-1): 21:57:59 | 7 of 7 START table model dwh.my_second_dbt_model..................... [RUN]
2022-01-15 16:27:59.668602 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-15 16:27:59.668889 (Thread-1): Compiling model.sakila_dbt_project.my_second_dbt_model
2022-01-15 16:27:59.671602 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.my_second_dbt_model"
2022-01-15 16:27:59.672238 (Thread-1): finished collecting timing info
2022-01-15 16:27:59.674932 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.my_second_dbt_model"
2022-01-15 16:27:59.675514 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-15 16:27:59.675692 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: BEGIN
2022-01-15 16:27:59.675862 (Thread-1): Opening a new connection, currently in state closed
2022-01-15 16:28:00.028538 (Thread-1): SQL status: BEGIN in 0.35 seconds
2022-01-15 16:28:00.028894 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-15 16:28:00.029099 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */


  create  table "sakila_wh"."dwh"."my_second_dbt_model__dbt_tmp"
  as (
    -- Use the `ref` function to select from other models

select *
from "sakila_wh"."dwh"."my_first_dbt_model"
where id = 1
  );
2022-01-15 16:28:00.097074 (Thread-1): SQL status: SELECT 1 in 0.07 seconds
2022-01-15 16:28:00.101282 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-15 16:28:00.101529 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
alter table "sakila_wh"."dwh"."my_second_dbt_model" rename to "my_second_dbt_model__dbt_backup"
2022-01-15 16:28:00.159409 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-15 16:28:00.163288 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-15 16:28:00.163507 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
alter table "sakila_wh"."dwh"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-15 16:28:00.224711 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-15 16:28:00.226473 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: COMMIT
2022-01-15 16:28:00.226672 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-15 16:28:00.226834 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: COMMIT
2022-01-15 16:28:00.285875 (Thread-1): SQL status: COMMIT in 0.06 seconds
2022-01-15 16:28:00.288541 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-15 16:28:00.288817 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
drop table if exists "sakila_wh"."dwh"."my_second_dbt_model__dbt_backup" cascade
2022-01-15 16:28:00.349950 (Thread-1): SQL status: DROP TABLE in 0.06 seconds
2022-01-15 16:28:00.351818 (Thread-1): finished collecting timing info
2022-01-15 16:28:00.352096 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: Close
2022-01-15 16:28:00.352717 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '291477e8-d627-4b4f-806c-4375696da087', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11133a670>]}
2022-01-15 16:28:00.353202 (Thread-1): 21:58:00 | 7 of 7 OK created table model dwh.my_second_dbt_model................ [SELECT 1 in 0.68s]
2022-01-15 16:28:00.353471 (Thread-1): Finished running node model.sakila_dbt_project.my_second_dbt_model
2022-01-15 16:28:00.354845 (MainThread): Acquiring new postgres connection "master".
2022-01-15 16:28:00.355122 (MainThread): Using postgres connection "master".
2022-01-15 16:28:00.355332 (MainThread): On master: BEGIN
2022-01-15 16:28:00.355541 (MainThread): Opening a new connection, currently in state closed
2022-01-15 16:28:00.802809 (MainThread): SQL status: BEGIN in 0.45 seconds
2022-01-15 16:28:00.803222 (MainThread): On master: COMMIT
2022-01-15 16:28:00.803566 (MainThread): Using postgres connection "master".
2022-01-15 16:28:00.803767 (MainThread): On master: COMMIT
2022-01-15 16:28:00.866464 (MainThread): SQL status: COMMIT in 0.06 seconds
2022-01-15 16:28:00.867111 (MainThread): On master: Close
2022-01-15 16:28:00.867942 (MainThread): 21:58:00 | 
2022-01-15 16:28:00.868308 (MainThread): 21:58:00 | Finished running 6 table models, 1 incremental model in 8.18s.
2022-01-15 16:28:00.868618 (MainThread): Connection 'master' was properly closed.
2022-01-15 16:28:00.868806 (MainThread): Connection 'model.sakila_dbt_project.my_second_dbt_model' was properly closed.
2022-01-15 16:28:00.879817 (MainThread): 
2022-01-15 16:28:00.880066 (MainThread): Completed successfully
2022-01-15 16:28:00.880282 (MainThread): 
Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
2022-01-15 16:28:00.880539 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11105b940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11105b9a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11105b2e0>]}
2022-01-15 16:28:00.880801 (MainThread): Flushing usage events
2022-01-18 15:25:55.639193 (MainThread): Running with dbt=0.21.1
2022-01-18 15:25:55.786904 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2022-01-18 15:25:55.790222 (MainThread): Tracking: tracking
2022-01-18 15:25:55.828503 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a63b640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac44e20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac44340>]}
2022-01-18 15:25:55.854594 (MainThread): Partial parsing not enabled
2022-01-18 15:25:55.916666 (MainThread): Parsing macros/catalog.sql
2022-01-18 15:25:55.921273 (MainThread): Parsing macros/relations.sql
2022-01-18 15:25:55.922770 (MainThread): Parsing macros/adapters.sql
2022-01-18 15:25:55.944355 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2022-01-18 15:25:55.945987 (MainThread): Parsing macros/core.sql
2022-01-18 15:25:55.949448 (MainThread): Parsing macros/materializations/test.sql
2022-01-18 15:25:55.956150 (MainThread): Parsing macros/materializations/helpers.sql
2022-01-18 15:25:55.965247 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2022-01-18 15:25:55.966795 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2022-01-18 15:25:55.983123 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2022-01-18 15:25:56.013537 (MainThread): Parsing macros/materializations/seed/seed.sql
2022-01-18 15:25:56.035233 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2022-01-18 15:25:56.037253 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2022-01-18 15:25:56.046705 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2022-01-18 15:25:56.065460 (MainThread): Parsing macros/materializations/common/merge.sql
2022-01-18 15:25:56.078959 (MainThread): Parsing macros/materializations/table/table.sql
2022-01-18 15:25:56.086744 (MainThread): Parsing macros/materializations/view/view.sql
2022-01-18 15:25:56.093549 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2022-01-18 15:25:56.097208 (MainThread): Parsing macros/etc/get_custom_alias.sql
2022-01-18 15:25:56.098577 (MainThread): Parsing macros/etc/query.sql
2022-01-18 15:25:56.099466 (MainThread): Parsing macros/etc/is_incremental.sql
2022-01-18 15:25:56.100856 (MainThread): Parsing macros/etc/datetime.sql
2022-01-18 15:25:56.109175 (MainThread): Parsing macros/etc/where_subquery.sql
2022-01-18 15:25:56.110922 (MainThread): Parsing macros/etc/get_custom_schema.sql
2022-01-18 15:25:56.113223 (MainThread): Parsing macros/etc/get_custom_database.sql
2022-01-18 15:25:56.114687 (MainThread): Parsing macros/adapters/common.sql
2022-01-18 15:25:56.166662 (MainThread): Parsing macros/schema_tests/relationships.sql
2022-01-18 15:25:56.168268 (MainThread): Parsing macros/schema_tests/not_null.sql
2022-01-18 15:25:56.169700 (MainThread): Parsing macros/schema_tests/unique.sql
2022-01-18 15:25:56.171149 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2022-01-18 15:25:56.173213 (MainThread): Parsing macros/cross_db_utils/except.sql
2022-01-18 15:25:56.174202 (MainThread): Parsing macros/cross_db_utils/replace.sql
2022-01-18 15:25:56.175371 (MainThread): Parsing macros/cross_db_utils/concat.sql
2022-01-18 15:25:56.176295 (MainThread): Parsing macros/cross_db_utils/datatypes.sql
2022-01-18 15:25:56.181721 (MainThread): Parsing macros/cross_db_utils/_is_relation.sql
2022-01-18 15:25:56.182776 (MainThread): Parsing macros/cross_db_utils/length.sql
2022-01-18 15:25:56.183976 (MainThread): Parsing macros/cross_db_utils/dateadd.sql
2022-01-18 15:25:56.187069 (MainThread): Parsing macros/cross_db_utils/intersect.sql
2022-01-18 15:25:56.188152 (MainThread): Parsing macros/cross_db_utils/right.sql
2022-01-18 15:25:56.190271 (MainThread): Parsing macros/cross_db_utils/datediff.sql
2022-01-18 15:25:56.199631 (MainThread): Parsing macros/cross_db_utils/safe_cast.sql
2022-01-18 15:25:56.201669 (MainThread): Parsing macros/cross_db_utils/hash.sql
2022-01-18 15:25:56.203194 (MainThread): Parsing macros/cross_db_utils/cast_bool_to_text.sql
2022-01-18 15:25:56.204606 (MainThread): Parsing macros/cross_db_utils/identifier.sql
2022-01-18 15:25:56.206290 (MainThread): Parsing macros/cross_db_utils/position.sql
2022-01-18 15:25:56.207719 (MainThread): Parsing macros/cross_db_utils/literal.sql
2022-01-18 15:25:56.208606 (MainThread): Parsing macros/cross_db_utils/current_timestamp.sql
2022-01-18 15:25:56.211880 (MainThread): Parsing macros/cross_db_utils/width_bucket.sql
2022-01-18 15:25:56.216646 (MainThread): Parsing macros/cross_db_utils/last_day.sql
2022-01-18 15:25:56.220331 (MainThread): Parsing macros/cross_db_utils/split_part.sql
2022-01-18 15:25:56.222112 (MainThread): Parsing macros/cross_db_utils/date_trunc.sql
2022-01-18 15:25:56.223634 (MainThread): Parsing macros/cross_db_utils/_is_ephemeral.sql
2022-01-18 15:25:56.225383 (MainThread): Parsing macros/materializations/insert_by_period_materialization.sql
2022-01-18 15:25:56.249100 (MainThread): Parsing macros/web/get_url_host.sql
2022-01-18 15:25:56.250900 (MainThread): Parsing macros/web/get_url_path.sql
2022-01-18 15:25:56.253591 (MainThread): Parsing macros/web/get_url_parameter.sql
2022-01-18 15:25:56.255144 (MainThread): Parsing macros/jinja_helpers/pretty_log_format.sql
2022-01-18 15:25:56.256197 (MainThread): Parsing macros/jinja_helpers/pretty_time.sql
2022-01-18 15:25:56.257361 (MainThread): Parsing macros/jinja_helpers/log_info.sql
2022-01-18 15:25:56.258429 (MainThread): Parsing macros/jinja_helpers/slugify.sql
2022-01-18 15:25:56.259541 (MainThread): Parsing macros/schema_tests/fewer_rows_than.sql
2022-01-18 15:25:56.261109 (MainThread): Parsing macros/schema_tests/equal_rowcount.sql
2022-01-18 15:25:56.262728 (MainThread): Parsing macros/schema_tests/relationships_where.sql
2022-01-18 15:25:56.264895 (MainThread): Parsing macros/schema_tests/recency.sql
2022-01-18 15:25:56.266523 (MainThread): Parsing macros/schema_tests/not_constant.sql
2022-01-18 15:25:56.267679 (MainThread): Parsing macros/schema_tests/accepted_range.sql
2022-01-18 15:25:56.270407 (MainThread): Parsing macros/schema_tests/not_accepted_values.sql
2022-01-18 15:25:56.272474 (MainThread): Parsing macros/schema_tests/test_unique_where.sql
2022-01-18 15:25:56.273819 (MainThread): Parsing macros/schema_tests/at_least_one.sql
2022-01-18 15:25:56.274989 (MainThread): Parsing macros/schema_tests/unique_combination_of_columns.sql
2022-01-18 15:25:56.277610 (MainThread): Parsing macros/schema_tests/cardinality_equality.sql
2022-01-18 15:25:56.279466 (MainThread): Parsing macros/schema_tests/expression_is_true.sql
2022-01-18 15:25:56.281142 (MainThread): Parsing macros/schema_tests/sequential_values.sql
2022-01-18 15:25:56.283952 (MainThread): Parsing macros/schema_tests/test_not_null_where.sql
2022-01-18 15:25:56.285671 (MainThread): Parsing macros/schema_tests/equality.sql
2022-01-18 15:25:56.289138 (MainThread): Parsing macros/schema_tests/mutually_exclusive_ranges.sql
2022-01-18 15:25:56.297396 (MainThread): Parsing macros/sql/date_spine.sql
2022-01-18 15:25:56.301770 (MainThread): Parsing macros/sql/nullcheck_table.sql
2022-01-18 15:25:56.303680 (MainThread): Parsing macros/sql/get_relations_by_pattern.sql
2022-01-18 15:25:56.306924 (MainThread): Parsing macros/sql/generate_series.sql
2022-01-18 15:25:56.337218 (MainThread): Parsing macros/sql/get_relations_by_prefix.sql
2022-01-18 15:25:56.341612 (MainThread): Parsing macros/sql/get_tables_by_prefix_sql.sql
2022-01-18 15:25:56.343745 (MainThread): Parsing macros/sql/star.sql
2022-01-18 15:25:56.347912 (MainThread): Parsing macros/sql/unpivot.sql
2022-01-18 15:25:56.357799 (MainThread): Parsing macros/sql/union.sql
2022-01-18 15:25:56.367102 (MainThread): Parsing macros/sql/groupby.sql
2022-01-18 15:25:56.368870 (MainThread): Parsing macros/sql/surrogate_key.sql
2022-01-18 15:25:56.373010 (MainThread): Parsing macros/sql/safe_add.sql
2022-01-18 15:25:56.374838 (MainThread): Parsing macros/sql/nullcheck.sql
2022-01-18 15:25:56.376632 (MainThread): Parsing macros/sql/get_tables_by_pattern_sql.sql
2022-01-18 15:25:56.383536 (MainThread): Parsing macros/sql/get_column_values.sql
2022-01-18 15:25:56.389222 (MainThread): Parsing macros/sql/pivot.sql
2022-01-18 15:25:56.393706 (MainThread): Parsing macros/sql/get_query_results_as_dict.sql
2022-01-18 15:25:56.396205 (MainThread): Parsing macros/sql/haversine_distance.sql
2022-01-18 15:25:56.701575 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-18 15:25:56.713619 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.customer_test".
2022-01-18 15:25:56.716813 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-18 15:25:56.718065 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-18 15:25:56.722633 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.film_test".
2022-01-18 15:25:56.726156 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-18 15:25:56.734470 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-18 15:25:56.738269 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-18 15:25:56.751079 (MainThread): Acquiring new postgres connection "test.sakila_dbt_project.film_replacementcost_30".
2022-01-18 15:25:56.753344 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-18 15:25:56.790894 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-18 15:25:56.792873 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-18 15:25:56.794876 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-18 15:25:56.796721 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-18 15:25:56.798588 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-18 15:25:56.800643 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-18 15:25:56.814379 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-18 15:25:56.818725 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-18 15:25:56.834255 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-18 15:25:56.836207 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-18 15:25:56.864466 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '437fc8ad-a2a5-4e27-a17d-f7b7a3dd8bf7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ad7bc10>]}
2022-01-18 15:25:56.873973 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-01-18 15:25:56.874587 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '437fc8ad-a2a5-4e27-a17d-f7b7a3dd8bf7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10adcdf40>]}
2022-01-18 15:25:56.874876 (MainThread): Found 7 models, 11 tests, 0 snapshots, 0 analyses, 347 macros, 0 operations, 0 seed files, 12 sources, 0 exposures
2022-01-18 15:25:56.876698 (MainThread): 
2022-01-18 15:25:56.877060 (MainThread): Acquiring new postgres connection "master".
2022-01-18 15:25:56.878130 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_sakila_wh".
2022-01-18 15:25:56.888101 (ThreadPoolExecutor-0_0): Using postgres connection "list_sakila_wh".
2022-01-18 15:25:56.888317 (ThreadPoolExecutor-0_0): On list_sakila_wh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh"} */

    select distinct nspname from pg_namespace
  
2022-01-18 15:25:56.888476 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2022-01-18 15:25:56.969843 (ThreadPoolExecutor-0_0): Got an error when attempting to open a postgres connection: 'could not translate host name "invrl7ips02.informatica.com" to address: nodename nor servname provided, or not known
'
2022-01-18 15:25:56.970144 (ThreadPoolExecutor-0_0): Error running SQL: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh"} */

    select distinct nspname from pg_namespace
  
2022-01-18 15:25:56.970331 (ThreadPoolExecutor-0_0): Rolling back transaction.
2022-01-18 15:25:56.970567 (ThreadPoolExecutor-0_0): Error running SQL: macro list_schemas
2022-01-18 15:25:56.970718 (ThreadPoolExecutor-0_0): Rolling back transaction.
2022-01-18 15:25:56.970904 (ThreadPoolExecutor-0_0): On list_sakila_wh: No close available on handle
2022-01-18 15:25:56.971548 (MainThread): Connection 'master' was properly closed.
2022-01-18 15:25:56.971738 (MainThread): Connection 'list_sakila_wh' was properly closed.
2022-01-18 15:25:56.971928 (MainThread): ERROR: Database Error
  could not translate host name "invrl7ips02.informatica.com" to address: nodename nor servname provided, or not known
  
2022-01-18 15:25:56.972197 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac28250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac31280>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ae7fbe0>]}
2022-01-18 15:25:56.972463 (MainThread): Flushing usage events
2022-01-18 15:38:05.609922 (MainThread): Running with dbt=0.21.1
2022-01-18 15:38:05.758964 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2022-01-18 15:38:05.760748 (MainThread): Tracking: tracking
2022-01-18 15:38:05.789017 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1080225b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108619ca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108619310>]}
2022-01-18 15:38:05.814410 (MainThread): Partial parsing not enabled
2022-01-18 15:38:05.877587 (MainThread): Parsing macros/catalog.sql
2022-01-18 15:38:05.881665 (MainThread): Parsing macros/relations.sql
2022-01-18 15:38:05.883153 (MainThread): Parsing macros/adapters.sql
2022-01-18 15:38:05.910489 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2022-01-18 15:38:05.912379 (MainThread): Parsing macros/core.sql
2022-01-18 15:38:05.916402 (MainThread): Parsing macros/materializations/test.sql
2022-01-18 15:38:05.924319 (MainThread): Parsing macros/materializations/helpers.sql
2022-01-18 15:38:05.935657 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2022-01-18 15:38:05.937593 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2022-01-18 15:38:05.957015 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2022-01-18 15:38:05.991257 (MainThread): Parsing macros/materializations/seed/seed.sql
2022-01-18 15:38:06.015451 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2022-01-18 15:38:06.017131 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2022-01-18 15:38:06.027650 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2022-01-18 15:38:06.050155 (MainThread): Parsing macros/materializations/common/merge.sql
2022-01-18 15:38:06.068169 (MainThread): Parsing macros/materializations/table/table.sql
2022-01-18 15:38:06.079072 (MainThread): Parsing macros/materializations/view/view.sql
2022-01-18 15:38:06.089560 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2022-01-18 15:38:06.096721 (MainThread): Parsing macros/etc/get_custom_alias.sql
2022-01-18 15:38:06.098686 (MainThread): Parsing macros/etc/query.sql
2022-01-18 15:38:06.099917 (MainThread): Parsing macros/etc/is_incremental.sql
2022-01-18 15:38:06.102731 (MainThread): Parsing macros/etc/datetime.sql
2022-01-18 15:38:06.113627 (MainThread): Parsing macros/etc/where_subquery.sql
2022-01-18 15:38:06.115977 (MainThread): Parsing macros/etc/get_custom_schema.sql
2022-01-18 15:38:06.119121 (MainThread): Parsing macros/etc/get_custom_database.sql
2022-01-18 15:38:06.121723 (MainThread): Parsing macros/adapters/common.sql
2022-01-18 15:38:06.187199 (MainThread): Parsing macros/schema_tests/relationships.sql
2022-01-18 15:38:06.189150 (MainThread): Parsing macros/schema_tests/not_null.sql
2022-01-18 15:38:06.190477 (MainThread): Parsing macros/schema_tests/unique.sql
2022-01-18 15:38:06.191957 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2022-01-18 15:38:06.194394 (MainThread): Parsing macros/cross_db_utils/except.sql
2022-01-18 15:38:06.195582 (MainThread): Parsing macros/cross_db_utils/replace.sql
2022-01-18 15:38:06.196979 (MainThread): Parsing macros/cross_db_utils/concat.sql
2022-01-18 15:38:06.198090 (MainThread): Parsing macros/cross_db_utils/datatypes.sql
2022-01-18 15:38:06.204938 (MainThread): Parsing macros/cross_db_utils/_is_relation.sql
2022-01-18 15:38:06.206292 (MainThread): Parsing macros/cross_db_utils/length.sql
2022-01-18 15:38:06.207742 (MainThread): Parsing macros/cross_db_utils/dateadd.sql
2022-01-18 15:38:06.210982 (MainThread): Parsing macros/cross_db_utils/intersect.sql
2022-01-18 15:38:06.212135 (MainThread): Parsing macros/cross_db_utils/right.sql
2022-01-18 15:38:06.214614 (MainThread): Parsing macros/cross_db_utils/datediff.sql
2022-01-18 15:38:06.225918 (MainThread): Parsing macros/cross_db_utils/safe_cast.sql
2022-01-18 15:38:06.228041 (MainThread): Parsing macros/cross_db_utils/hash.sql
2022-01-18 15:38:06.229614 (MainThread): Parsing macros/cross_db_utils/cast_bool_to_text.sql
2022-01-18 15:38:06.231139 (MainThread): Parsing macros/cross_db_utils/identifier.sql
2022-01-18 15:38:06.232902 (MainThread): Parsing macros/cross_db_utils/position.sql
2022-01-18 15:38:06.234669 (MainThread): Parsing macros/cross_db_utils/literal.sql
2022-01-18 15:38:06.235981 (MainThread): Parsing macros/cross_db_utils/current_timestamp.sql
2022-01-18 15:38:06.240236 (MainThread): Parsing macros/cross_db_utils/width_bucket.sql
2022-01-18 15:38:06.245951 (MainThread): Parsing macros/cross_db_utils/last_day.sql
2022-01-18 15:38:06.249751 (MainThread): Parsing macros/cross_db_utils/split_part.sql
2022-01-18 15:38:06.251742 (MainThread): Parsing macros/cross_db_utils/date_trunc.sql
2022-01-18 15:38:06.253857 (MainThread): Parsing macros/cross_db_utils/_is_ephemeral.sql
2022-01-18 15:38:06.256023 (MainThread): Parsing macros/materializations/insert_by_period_materialization.sql
2022-01-18 15:38:06.284492 (MainThread): Parsing macros/web/get_url_host.sql
2022-01-18 15:38:06.286901 (MainThread): Parsing macros/web/get_url_path.sql
2022-01-18 15:38:06.289932 (MainThread): Parsing macros/web/get_url_parameter.sql
2022-01-18 15:38:06.291967 (MainThread): Parsing macros/jinja_helpers/pretty_log_format.sql
2022-01-18 15:38:06.293468 (MainThread): Parsing macros/jinja_helpers/pretty_time.sql
2022-01-18 15:38:06.294906 (MainThread): Parsing macros/jinja_helpers/log_info.sql
2022-01-18 15:38:06.296197 (MainThread): Parsing macros/jinja_helpers/slugify.sql
2022-01-18 15:38:06.297512 (MainThread): Parsing macros/schema_tests/fewer_rows_than.sql
2022-01-18 15:38:06.299358 (MainThread): Parsing macros/schema_tests/equal_rowcount.sql
2022-01-18 15:38:06.301310 (MainThread): Parsing macros/schema_tests/relationships_where.sql
2022-01-18 15:38:06.304372 (MainThread): Parsing macros/schema_tests/recency.sql
2022-01-18 15:38:06.306364 (MainThread): Parsing macros/schema_tests/not_constant.sql
2022-01-18 15:38:06.307753 (MainThread): Parsing macros/schema_tests/accepted_range.sql
2022-01-18 15:38:06.310661 (MainThread): Parsing macros/schema_tests/not_accepted_values.sql
2022-01-18 15:38:06.313004 (MainThread): Parsing macros/schema_tests/test_unique_where.sql
2022-01-18 15:38:06.314588 (MainThread): Parsing macros/schema_tests/at_least_one.sql
2022-01-18 15:38:06.315977 (MainThread): Parsing macros/schema_tests/unique_combination_of_columns.sql
2022-01-18 15:38:06.319296 (MainThread): Parsing macros/schema_tests/cardinality_equality.sql
2022-01-18 15:38:06.321788 (MainThread): Parsing macros/schema_tests/expression_is_true.sql
2022-01-18 15:38:06.323822 (MainThread): Parsing macros/schema_tests/sequential_values.sql
2022-01-18 15:38:06.327139 (MainThread): Parsing macros/schema_tests/test_not_null_where.sql
2022-01-18 15:38:06.328729 (MainThread): Parsing macros/schema_tests/equality.sql
2022-01-18 15:38:06.332460 (MainThread): Parsing macros/schema_tests/mutually_exclusive_ranges.sql
2022-01-18 15:38:06.342443 (MainThread): Parsing macros/sql/date_spine.sql
2022-01-18 15:38:06.347768 (MainThread): Parsing macros/sql/nullcheck_table.sql
2022-01-18 15:38:06.349605 (MainThread): Parsing macros/sql/get_relations_by_pattern.sql
2022-01-18 15:38:06.353822 (MainThread): Parsing macros/sql/generate_series.sql
2022-01-18 15:38:06.389126 (MainThread): Parsing macros/sql/get_relations_by_prefix.sql
2022-01-18 15:38:06.393708 (MainThread): Parsing macros/sql/get_tables_by_prefix_sql.sql
2022-01-18 15:38:06.395892 (MainThread): Parsing macros/sql/star.sql
2022-01-18 15:38:06.400053 (MainThread): Parsing macros/sql/unpivot.sql
2022-01-18 15:38:06.410655 (MainThread): Parsing macros/sql/union.sql
2022-01-18 15:38:06.421123 (MainThread): Parsing macros/sql/groupby.sql
2022-01-18 15:38:06.422965 (MainThread): Parsing macros/sql/surrogate_key.sql
2022-01-18 15:38:06.427180 (MainThread): Parsing macros/sql/safe_add.sql
2022-01-18 15:38:06.429114 (MainThread): Parsing macros/sql/nullcheck.sql
2022-01-18 15:38:06.431007 (MainThread): Parsing macros/sql/get_tables_by_pattern_sql.sql
2022-01-18 15:38:06.438962 (MainThread): Parsing macros/sql/get_column_values.sql
2022-01-18 15:38:06.444461 (MainThread): Parsing macros/sql/pivot.sql
2022-01-18 15:38:06.448938 (MainThread): Parsing macros/sql/get_query_results_as_dict.sql
2022-01-18 15:38:06.451802 (MainThread): Parsing macros/sql/haversine_distance.sql
2022-01-18 15:38:06.795166 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-18 15:38:06.807692 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.customer_test".
2022-01-18 15:38:06.810942 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-18 15:38:06.811874 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-18 15:38:06.815288 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.film_test".
2022-01-18 15:38:06.818697 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-18 15:38:06.826882 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-18 15:38:06.829655 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-18 15:38:06.841221 (MainThread): Acquiring new postgres connection "test.sakila_dbt_project.film_replacementcost_30".
2022-01-18 15:38:06.843147 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-18 15:38:06.875794 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-18 15:38:06.877515 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-18 15:38:06.879282 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-18 15:38:06.880927 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-18 15:38:06.882573 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-18 15:38:06.884377 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-18 15:38:06.898935 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-18 15:38:06.903925 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-18 15:38:06.920768 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-18 15:38:06.922746 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-18 15:38:06.950119 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8d624d67-3718-4438-8327-016b649e31db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10878b070>]}
2022-01-18 15:38:06.960714 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-01-18 15:38:06.961312 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8d624d67-3718-4438-8327-016b649e31db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1087b2df0>]}
2022-01-18 15:38:06.961600 (MainThread): Found 7 models, 11 tests, 0 snapshots, 0 analyses, 347 macros, 0 operations, 0 seed files, 12 sources, 0 exposures
2022-01-18 15:38:06.963586 (MainThread): 
2022-01-18 15:38:06.964005 (MainThread): Acquiring new postgres connection "master".
2022-01-18 15:38:06.965091 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_sakila_wh".
2022-01-18 15:38:06.975559 (ThreadPoolExecutor-0_0): Using postgres connection "list_sakila_wh".
2022-01-18 15:38:06.975796 (ThreadPoolExecutor-0_0): On list_sakila_wh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh"} */

    select distinct nspname from pg_namespace
  
2022-01-18 15:38:06.975963 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2022-01-18 15:38:07.546498 (ThreadPoolExecutor-0_0): SQL status: SELECT 14 in 0.57 seconds
2022-01-18 15:38:07.547913 (ThreadPoolExecutor-0_0): On list_sakila_wh: Close
2022-01-18 15:38:07.549221 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_dwh".
2022-01-18 15:38:07.555647 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-18 15:38:07.555869 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: BEGIN
2022-01-18 15:38:07.556024 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2022-01-18 15:38:08.014785 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.46 seconds
2022-01-18 15:38:08.015055 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-18 15:38:08.015206 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_dwh"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dwh'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dwh'
  
2022-01-18 15:38:08.096634 (ThreadPoolExecutor-1_0): SQL status: SELECT 8 in 0.08 seconds
2022-01-18 15:38:08.098007 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: ROLLBACK
2022-01-18 15:38:08.173949 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: Close
2022-01-18 15:38:08.178653 (MainThread): Using postgres connection "master".
2022-01-18 15:38:08.178833 (MainThread): On master: BEGIN
2022-01-18 15:38:08.178984 (MainThread): Opening a new connection, currently in state init
2022-01-18 15:38:08.634580 (MainThread): SQL status: BEGIN in 0.46 seconds
2022-01-18 15:38:08.634868 (MainThread): Using postgres connection "master".
2022-01-18 15:38:08.635031 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-18 15:38:08.726236 (MainThread): SQL status: SELECT 47 in 0.09 seconds
2022-01-18 15:38:08.728286 (MainThread): On master: ROLLBACK
2022-01-18 15:38:08.805230 (MainThread): Using postgres connection "master".
2022-01-18 15:38:08.805484 (MainThread): On master: BEGIN
2022-01-18 15:38:08.955033 (MainThread): SQL status: BEGIN in 0.15 seconds
2022-01-18 15:38:08.955302 (MainThread): On master: COMMIT
2022-01-18 15:38:08.955457 (MainThread): Using postgres connection "master".
2022-01-18 15:38:08.955596 (MainThread): On master: COMMIT
2022-01-18 15:38:09.030966 (MainThread): SQL status: COMMIT in 0.08 seconds
2022-01-18 15:38:09.031244 (MainThread): On master: Close
2022-01-18 15:38:09.031662 (MainThread): 21:08:09 | Concurrency: 1 threads (target='dev')
2022-01-18 15:38:09.031877 (MainThread): 21:08:09 | 
2022-01-18 15:38:09.034346 (Thread-1): Began running node model.sakila_dbt_project.dim_date
2022-01-18 15:38:09.034665 (Thread-1): 21:08:09 | 1 of 7 START table model dwh.dim_date................................ [RUN]
2022-01-18 15:38:09.035215 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-18 15:38:09.035468 (Thread-1): Compiling model.sakila_dbt_project.dim_date
2022-01-18 15:38:09.038457 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_date"
2022-01-18 15:38:09.040143 (Thread-1): finished collecting timing info
2022-01-18 15:38:09.065601 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_date"
2022-01-18 15:38:09.066313 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-18 15:38:09.066493 (Thread-1): On model.sakila_dbt_project.dim_date: BEGIN
2022-01-18 15:38:09.066654 (Thread-1): Opening a new connection, currently in state closed
2022-01-18 15:38:09.524548 (Thread-1): SQL status: BEGIN in 0.46 seconds
2022-01-18 15:38:09.524823 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-18 15:38:09.524974 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */


  create  table "sakila_wh"."dwh"."dim_date__dbt_tmp"
  as (
    with dates as (
SELECT
       TO_CHAR(datum, 'yyyymmdd')::INT AS date_dim_id,
       datum AS date_key,
       EXTRACT(EPOCH FROM datum) AS epoch,
       TO_CHAR(datum, 'TMDay') AS day_name,
       EXTRACT(ISODOW FROM datum) AS day_of_week,
       EXTRACT(DAY FROM datum) AS day_of_month,
       datum - DATE_TRUNC('quarter', datum)::DATE + 1 AS day_of_quarter,
       EXTRACT(DOY FROM datum) AS day_of_year,
       TO_CHAR(datum, 'W')::INT AS week_of_month,
       EXTRACT(WEEK FROM datum) AS week_of_year,
       EXTRACT(MONTH FROM datum) AS month_actual,
       TO_CHAR(datum, 'TMMonth') AS month_name,
       TO_CHAR(datum, 'Mon') AS month_name_abbreviated,
       EXTRACT(QUARTER FROM datum) AS quarter_actual,
       CASE
           WHEN EXTRACT(QUARTER FROM datum) = 1 THEN 'First'
           WHEN EXTRACT(QUARTER FROM datum) = 2 THEN 'Second'
           WHEN EXTRACT(QUARTER FROM datum) = 3 THEN 'Third'
           WHEN EXTRACT(QUARTER FROM datum) = 4 THEN 'Fourth'
           END AS quarter_name,
       EXTRACT(YEAR FROM datum) AS year_actual,
       datum + (1 - EXTRACT(ISODOW FROM datum))::INT AS first_day_of_week,
       datum + (7 - EXTRACT(ISODOW FROM datum))::INT AS last_day_of_week,
       datum + (1 - EXTRACT(DAY FROM datum))::INT AS first_day_of_month,
       (DATE_TRUNC('MONTH', datum) + INTERVAL '1 MONTH - 1 day')::DATE AS last_day_of_month,
       DATE_TRUNC('quarter', datum)::DATE AS first_day_of_quarter,
       (DATE_TRUNC('quarter', datum) + INTERVAL '3 MONTH - 1 day')::DATE AS last_day_of_quarter,
       TO_DATE(EXTRACT(YEAR FROM datum) || '-01-01', 'YYYY-MM-DD') AS first_day_of_year,
       TO_DATE(EXTRACT(YEAR FROM datum) || '-12-31', 'YYYY-MM-DD') AS last_day_of_year,
       TO_CHAR(datum, 'yyyymm') AS yyyymm,
       CASE
           WHEN EXTRACT(ISODOW FROM datum) IN (6, 7) THEN TRUE
           ELSE FALSE
           END AS weekend_indr
FROM (SELECT '2000-01-01'::DATE + SEQUENCE.DAY AS datum
      FROM GENERATE_SERIES(0, 29219) AS SEQUENCE (DAY)
      GROUP BY SEQUENCE.DAY) DQ
)
select
*
from
dates
where
date_key <= CURRENT_DATE
order by date_dim_id asc
  );
2022-01-18 15:38:10.431394 (Thread-1): SQL status: SELECT 8054 in 0.91 seconds
2022-01-18 15:38:10.438358 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-18 15:38:10.438598 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
alter table "sakila_wh"."dwh"."dim_date" rename to "dim_date__dbt_backup"
2022-01-18 15:38:10.515030 (Thread-1): SQL status: ALTER TABLE in 0.08 seconds
2022-01-18 15:38:10.517569 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-18 15:38:10.517758 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
alter table "sakila_wh"."dwh"."dim_date__dbt_tmp" rename to "dim_date"
2022-01-18 15:38:10.593124 (Thread-1): SQL status: ALTER TABLE in 0.08 seconds
2022-01-18 15:38:10.604255 (Thread-1): On model.sakila_dbt_project.dim_date: COMMIT
2022-01-18 15:38:10.604624 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-18 15:38:10.604855 (Thread-1): On model.sakila_dbt_project.dim_date: COMMIT
2022-01-18 15:38:10.681076 (Thread-1): SQL status: COMMIT in 0.08 seconds
2022-01-18 15:38:10.686262 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-18 15:38:10.686535 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
drop table if exists "sakila_wh"."dwh"."dim_date__dbt_backup" cascade
2022-01-18 15:38:10.768128 (Thread-1): SQL status: DROP TABLE in 0.08 seconds
2022-01-18 15:38:10.769468 (Thread-1): finished collecting timing info
2022-01-18 15:38:10.769751 (Thread-1): On model.sakila_dbt_project.dim_date: Close
2022-01-18 15:38:10.770570 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8d624d67-3718-4438-8327-016b649e31db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10878b880>]}
2022-01-18 15:38:10.771031 (Thread-1): 21:08:10 | 1 of 7 OK created table model dwh.dim_date........................... [SELECT 8054 in 1.74s]
2022-01-18 15:38:10.771330 (Thread-1): Finished running node model.sakila_dbt_project.dim_date
2022-01-18 15:38:10.771572 (Thread-1): Began running node model.sakila_dbt_project.film_test
2022-01-18 15:38:10.771850 (Thread-1): 21:08:10 | 2 of 7 START table model dwh.film_test............................... [RUN]
2022-01-18 15:38:10.772268 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.film_test".
2022-01-18 15:38:10.772443 (Thread-1): Compiling model.sakila_dbt_project.film_test
2022-01-18 15:38:10.773981 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.film_test"
2022-01-18 15:38:10.774644 (Thread-1): finished collecting timing info
2022-01-18 15:38:10.777017 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.film_test"
2022-01-18 15:38:10.777569 (Thread-1): Using postgres connection "model.sakila_dbt_project.film_test".
2022-01-18 15:38:10.777724 (Thread-1): On model.sakila_dbt_project.film_test: BEGIN
2022-01-18 15:38:10.777881 (Thread-1): Opening a new connection, currently in state closed
2022-01-18 15:38:11.231519 (Thread-1): SQL status: BEGIN in 0.45 seconds
2022-01-18 15:38:11.231774 (Thread-1): Using postgres connection "model.sakila_dbt_project.film_test".
2022-01-18 15:38:11.231922 (Thread-1): On model.sakila_dbt_project.film_test: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.film_test"} */


  create  table "sakila_wh"."dwh"."film_test__dbt_tmp"
  as (
    select * from 
stg.film
  );
2022-01-18 15:38:11.320747 (Thread-1): SQL status: SELECT 1000 in 0.09 seconds
2022-01-18 15:38:11.323976 (Thread-1): Using postgres connection "model.sakila_dbt_project.film_test".
2022-01-18 15:38:11.324207 (Thread-1): On model.sakila_dbt_project.film_test: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.film_test"} */
alter table "sakila_wh"."dwh"."film_test" rename to "film_test__dbt_backup"
2022-01-18 15:38:11.400534 (Thread-1): SQL status: ALTER TABLE in 0.08 seconds
2022-01-18 15:38:11.404755 (Thread-1): Using postgres connection "model.sakila_dbt_project.film_test".
2022-01-18 15:38:11.405040 (Thread-1): On model.sakila_dbt_project.film_test: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.film_test"} */
alter table "sakila_wh"."dwh"."film_test__dbt_tmp" rename to "film_test"
2022-01-18 15:38:11.481234 (Thread-1): SQL status: ALTER TABLE in 0.08 seconds
2022-01-18 15:38:11.482676 (Thread-1): On model.sakila_dbt_project.film_test: COMMIT
2022-01-18 15:38:11.482851 (Thread-1): Using postgres connection "model.sakila_dbt_project.film_test".
2022-01-18 15:38:11.482995 (Thread-1): On model.sakila_dbt_project.film_test: COMMIT
2022-01-18 15:38:11.558266 (Thread-1): SQL status: COMMIT in 0.08 seconds
2022-01-18 15:38:11.560169 (Thread-1): Using postgres connection "model.sakila_dbt_project.film_test".
2022-01-18 15:38:11.560345 (Thread-1): On model.sakila_dbt_project.film_test: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.film_test"} */
drop table if exists "sakila_wh"."dwh"."film_test__dbt_backup" cascade
2022-01-18 15:38:11.639622 (Thread-1): SQL status: DROP TABLE in 0.08 seconds
2022-01-18 15:38:11.640863 (Thread-1): finished collecting timing info
2022-01-18 15:38:11.641088 (Thread-1): On model.sakila_dbt_project.film_test: Close
2022-01-18 15:38:11.641548 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8d624d67-3718-4438-8327-016b649e31db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108905c40>]}
2022-01-18 15:38:11.641901 (Thread-1): 21:08:11 | 2 of 7 OK created table model dwh.film_test.......................... [SELECT 1000 in 0.87s]
2022-01-18 15:38:11.642112 (Thread-1): Finished running node model.sakila_dbt_project.film_test
2022-01-18 15:38:11.642319 (Thread-1): Began running node model.sakila_dbt_project.hello_world
2022-01-18 15:38:11.642661 (Thread-1): 21:08:11 | 3 of 7 START table model dwh.hello_world............................. [RUN]
2022-01-18 15:38:11.643016 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-18 15:38:11.643200 (Thread-1): Compiling model.sakila_dbt_project.hello_world
2022-01-18 15:38:11.644787 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.hello_world"
2022-01-18 15:38:11.645399 (Thread-1): finished collecting timing info
2022-01-18 15:38:11.647807 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.hello_world"
2022-01-18 15:38:11.648413 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-18 15:38:11.648578 (Thread-1): On model.sakila_dbt_project.hello_world: BEGIN
2022-01-18 15:38:11.648735 (Thread-1): Opening a new connection, currently in state closed
2022-01-18 15:38:12.104827 (Thread-1): SQL status: BEGIN in 0.46 seconds
2022-01-18 15:38:12.105101 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-18 15:38:12.105254 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */


  create  table "sakila_wh"."dwh"."hello_world__dbt_tmp"
  as (
    select
	customer.customer_id::int,
	customer.store_id::int,
	customer.first_name,
	customer.last_name,
	concat(customer.first_name,' ',customer.last_name) as full_name,
	substring(email from POSITION('@' in email)+1 for char_length(email)-POSITION('@' in email)) as domain,
	customer.email,
	customer.active::int,
	customer.address_id::int,
	address.address,
	city.city_id::int,
	city.city,
	(case when customer.active = 0 then 'no' else 'yes' end)::varchar(100) as "active_desc",
	customer.create_date::timestamp,
	customer.last_update::timestamp
from
	stg.customer as customer

	left join stg.address on 1=1
	and customer.address_id =address.address_id

	left join stg.city on 1=1
	and address.city_id = city.city_id
  );
2022-01-18 15:38:12.196737 (Thread-1): SQL status: SELECT 599 in 0.09 seconds
2022-01-18 15:38:12.199282 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-18 15:38:12.199459 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
alter table "sakila_wh"."dwh"."hello_world" rename to "hello_world__dbt_backup"
2022-01-18 15:38:12.274445 (Thread-1): SQL status: ALTER TABLE in 0.07 seconds
2022-01-18 15:38:12.276842 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-18 15:38:12.277015 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
alter table "sakila_wh"."dwh"."hello_world__dbt_tmp" rename to "hello_world"
2022-01-18 15:38:12.352507 (Thread-1): SQL status: ALTER TABLE in 0.08 seconds
2022-01-18 15:38:12.354316 (Thread-1): On model.sakila_dbt_project.hello_world: COMMIT
2022-01-18 15:38:12.354627 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-18 15:38:12.354794 (Thread-1): On model.sakila_dbt_project.hello_world: COMMIT
2022-01-18 15:38:12.430642 (Thread-1): SQL status: COMMIT in 0.08 seconds
2022-01-18 15:38:12.432630 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-18 15:38:12.432804 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
drop table if exists "sakila_wh"."dwh"."hello_world__dbt_backup" cascade
2022-01-18 15:38:12.511964 (Thread-1): SQL status: DROP TABLE in 0.08 seconds
2022-01-18 15:38:12.513189 (Thread-1): finished collecting timing info
2022-01-18 15:38:12.513398 (Thread-1): On model.sakila_dbt_project.hello_world: Close
2022-01-18 15:38:12.513824 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8d624d67-3718-4438-8327-016b649e31db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1089f8100>]}
2022-01-18 15:38:12.514160 (Thread-1): 21:08:12 | 3 of 7 OK created table model dwh.hello_world........................ [SELECT 599 in 0.87s]
2022-01-18 15:38:12.514355 (Thread-1): Finished running node model.sakila_dbt_project.hello_world
2022-01-18 15:38:12.514541 (Thread-1): Began running node model.sakila_dbt_project.my_first_dbt_model
2022-01-18 15:38:12.514941 (Thread-1): 21:08:12 | 4 of 7 START table model dwh.my_first_dbt_model...................... [RUN]
2022-01-18 15:38:12.515280 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-18 15:38:12.515449 (Thread-1): Compiling model.sakila_dbt_project.my_first_dbt_model
2022-01-18 15:38:12.517792 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.my_first_dbt_model"
2022-01-18 15:38:12.518364 (Thread-1): finished collecting timing info
2022-01-18 15:38:12.521370 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.my_first_dbt_model"
2022-01-18 15:38:12.522149 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-18 15:38:12.522319 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: BEGIN
2022-01-18 15:38:12.522470 (Thread-1): Opening a new connection, currently in state closed
2022-01-18 15:38:12.978156 (Thread-1): SQL status: BEGIN in 0.46 seconds
2022-01-18 15:38:12.978396 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-18 15:38:12.978542 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */


  create  table "sakila_wh"."dwh"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    --union all
    --select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-18 15:38:13.057974 (Thread-1): SQL status: SELECT 1 in 0.08 seconds
2022-01-18 15:38:13.061916 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-18 15:38:13.062088 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
alter table "sakila_wh"."dwh"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2022-01-18 15:38:13.137604 (Thread-1): SQL status: ALTER TABLE in 0.08 seconds
2022-01-18 15:38:13.140593 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-18 15:38:13.140824 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
alter table "sakila_wh"."dwh"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-18 15:38:13.216359 (Thread-1): SQL status: ALTER TABLE in 0.08 seconds
2022-01-18 15:38:13.217723 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: COMMIT
2022-01-18 15:38:13.217891 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-18 15:38:13.218032 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: COMMIT
2022-01-18 15:38:13.295883 (Thread-1): SQL status: COMMIT in 0.08 seconds
2022-01-18 15:38:13.297770 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-18 15:38:13.297936 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
drop table if exists "sakila_wh"."dwh"."my_first_dbt_model__dbt_backup" cascade
2022-01-18 15:38:13.375644 (Thread-1): SQL status: DROP TABLE in 0.08 seconds
2022-01-18 15:38:13.376834 (Thread-1): finished collecting timing info
2022-01-18 15:38:13.377042 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: Close
2022-01-18 15:38:13.377461 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8d624d67-3718-4438-8327-016b649e31db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108a40af0>]}
2022-01-18 15:38:13.377794 (Thread-1): 21:08:13 | 4 of 7 OK created table model dwh.my_first_dbt_model................. [SELECT 1 in 0.86s]
2022-01-18 15:38:13.377994 (Thread-1): Finished running node model.sakila_dbt_project.my_first_dbt_model
2022-01-18 15:38:13.378179 (Thread-1): Began running node model.sakila_dbt_project.payment_inc
2022-01-18 15:38:13.378414 (Thread-1): 21:08:13 | 5 of 7 START incremental model dwh.payment_inc....................... [RUN]
2022-01-18 15:38:13.378853 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-18 15:38:13.379030 (Thread-1): Compiling model.sakila_dbt_project.payment_inc
2022-01-18 15:38:13.384445 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.payment_inc"
2022-01-18 15:38:13.385757 (Thread-1): finished collecting timing info
2022-01-18 15:38:13.418327 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-18 15:38:13.418663 (Thread-1): On model.sakila_dbt_project.payment_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.payment_inc"} */

    

  create temporary table "payment_inc__dbt_tmp210813412946"
  as (
    

select
*,
'2022-01-18 15:38:05' as dbt_tran_time
from
stg.payment
where 1=1


and payment_date::timestamp > (select max(payment_date) from "sakila_wh"."dwh"."payment_inc")



-- - INTERVAL '3 DAY'
-- unique_key='payment_id'
  );
  
2022-01-18 15:38:13.418831 (Thread-1): Opening a new connection, currently in state closed
2022-01-18 15:38:13.894157 (Thread-1): SQL status: SELECT 0 in 0.48 seconds
2022-01-18 15:38:13.901316 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-18 15:38:13.901492 (Thread-1): On model.sakila_dbt_project.payment_inc: BEGIN
2022-01-18 15:38:13.976154 (Thread-1): SQL status: BEGIN in 0.07 seconds
2022-01-18 15:38:13.976394 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-18 15:38:13.976545 (Thread-1): On model.sakila_dbt_project.payment_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.payment_inc"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'payment_inc__dbt_tmp210813412946'
        
      order by ordinal_position

  
2022-01-18 15:38:14.066895 (Thread-1): SQL status: SELECT 7 in 0.09 seconds
2022-01-18 15:38:14.072639 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-18 15:38:14.072900 (Thread-1): On model.sakila_dbt_project.payment_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.payment_inc"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "sakila_wh".INFORMATION_SCHEMA.columns
      where table_name = 'payment_inc'
        
        and table_schema = 'dwh'
        
      order by ordinal_position

  
2022-01-18 15:38:14.153679 (Thread-1): SQL status: SELECT 7 in 0.08 seconds
2022-01-18 15:38:14.164840 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-18 15:38:14.165064 (Thread-1): On model.sakila_dbt_project.payment_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.payment_inc"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "sakila_wh".INFORMATION_SCHEMA.columns
      where table_name = 'payment_inc'
        
        and table_schema = 'dwh'
        
      order by ordinal_position

  
2022-01-18 15:38:14.244988 (Thread-1): SQL status: SELECT 7 in 0.08 seconds
2022-01-18 15:38:14.246742 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.payment_inc"
2022-01-18 15:38:14.247417 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-18 15:38:14.247576 (Thread-1): On model.sakila_dbt_project.payment_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.payment_inc"} */

      delete
    from "sakila_wh"."dwh"."payment_inc"
    where (payment_id) in (
        select (payment_id)
        from "payment_inc__dbt_tmp210813412946"
    );

    insert into "sakila_wh"."dwh"."payment_inc" ("payment_id", "customer_id", "staff_id", "rental_id", "amount", "payment_date", "dbt_tran_time")
    (
       select "payment_id", "customer_id", "staff_id", "rental_id", "amount", "payment_date", "dbt_tran_time"
       from "payment_inc__dbt_tmp210813412946"
    );
  
2022-01-18 15:38:14.323279 (Thread-1): SQL status: INSERT 0 0 in 0.08 seconds
2022-01-18 15:38:14.324485 (Thread-1): On model.sakila_dbt_project.payment_inc: COMMIT
2022-01-18 15:38:14.324645 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-18 15:38:14.324771 (Thread-1): On model.sakila_dbt_project.payment_inc: COMMIT
2022-01-18 15:38:14.400056 (Thread-1): SQL status: COMMIT in 0.08 seconds
2022-01-18 15:38:14.400649 (Thread-1): finished collecting timing info
2022-01-18 15:38:14.400858 (Thread-1): On model.sakila_dbt_project.payment_inc: Close
2022-01-18 15:38:14.401370 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8d624d67-3718-4438-8327-016b649e31db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1089b2c10>]}
2022-01-18 15:38:14.401763 (Thread-1): 21:08:14 | 5 of 7 OK created incremental model dwh.payment_inc.................. [INSERT 0 0 in 1.02s]
2022-01-18 15:38:14.401983 (Thread-1): Finished running node model.sakila_dbt_project.payment_inc
2022-01-18 15:38:14.402202 (Thread-1): Began running node model.sakila_dbt_project.customer_test
2022-01-18 15:38:14.402548 (Thread-1): 21:08:14 | 6 of 7 START table model dwh.customer_alias.......................... [RUN]
2022-01-18 15:38:14.402949 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.customer_test".
2022-01-18 15:38:14.403153 (Thread-1): Compiling model.sakila_dbt_project.customer_test
2022-01-18 15:38:14.408309 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.customer_test"
2022-01-18 15:38:14.408986 (Thread-1): finished collecting timing info
2022-01-18 15:38:14.442181 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.customer_test"
2022-01-18 15:38:14.442939 (Thread-1): Using postgres connection "model.sakila_dbt_project.customer_test".
2022-01-18 15:38:14.443130 (Thread-1): On model.sakila_dbt_project.customer_test: BEGIN
2022-01-18 15:38:14.443306 (Thread-1): Opening a new connection, currently in state closed
2022-01-18 15:38:14.902674 (Thread-1): SQL status: BEGIN in 0.46 seconds
2022-01-18 15:38:14.903263 (Thread-1): Using postgres connection "model.sakila_dbt_project.customer_test".
2022-01-18 15:38:14.903705 (Thread-1): On model.sakila_dbt_project.customer_test: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.customer_test"} */


  create  table "sakila_wh"."dwh"."customer_test__dbt_tmp"
  as (
    

select * from 
"sakila_wh"."dwh"."hello_world"
where customer_id < 10
  );
2022-01-18 15:38:14.988717 (Thread-1): SQL status: SELECT 9 in 0.08 seconds
2022-01-18 15:38:14.992403 (Thread-1): Using postgres connection "model.sakila_dbt_project.customer_test".
2022-01-18 15:38:14.992686 (Thread-1): On model.sakila_dbt_project.customer_test: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.customer_test"} */
alter table "sakila_wh"."dwh"."customer_alias" rename to "customer_test__dbt_backup"
2022-01-18 15:38:15.068632 (Thread-1): SQL status: ALTER TABLE in 0.08 seconds
2022-01-18 15:38:15.073207 (Thread-1): Using postgres connection "model.sakila_dbt_project.customer_test".
2022-01-18 15:38:15.073533 (Thread-1): On model.sakila_dbt_project.customer_test: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.customer_test"} */
alter table "sakila_wh"."dwh"."customer_test__dbt_tmp" rename to "customer_alias"
2022-01-18 15:38:15.149837 (Thread-1): SQL status: ALTER TABLE in 0.08 seconds
2022-01-18 15:38:15.152332 (Thread-1): On model.sakila_dbt_project.customer_test: COMMIT
2022-01-18 15:38:15.152626 (Thread-1): Using postgres connection "model.sakila_dbt_project.customer_test".
2022-01-18 15:38:15.152887 (Thread-1): On model.sakila_dbt_project.customer_test: COMMIT
2022-01-18 15:38:15.228672 (Thread-1): SQL status: COMMIT in 0.08 seconds
2022-01-18 15:38:15.231521 (Thread-1): Using postgres connection "model.sakila_dbt_project.customer_test".
2022-01-18 15:38:15.231846 (Thread-1): On model.sakila_dbt_project.customer_test: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.customer_test"} */
drop table if exists "sakila_wh"."dwh"."customer_test__dbt_backup" cascade
2022-01-18 15:38:15.330180 (Thread-1): SQL status: DROP TABLE in 0.08 seconds
2022-01-18 15:38:15.332158 (Thread-1): finished collecting timing info
2022-01-18 15:38:15.332513 (Thread-1): On model.sakila_dbt_project.customer_test: Close
2022-01-18 15:38:15.333192 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8d624d67-3718-4438-8327-016b649e31db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108a79370>]}
2022-01-18 15:38:15.333662 (Thread-1): 21:08:15 | 6 of 7 OK created table model dwh.customer_alias..................... [SELECT 9 in 0.93s]
2022-01-18 15:38:15.333931 (Thread-1): Finished running node model.sakila_dbt_project.customer_test
2022-01-18 15:38:15.334145 (Thread-1): Began running node model.sakila_dbt_project.my_second_dbt_model
2022-01-18 15:38:15.334512 (Thread-1): 21:08:15 | 7 of 7 START table model dwh.my_second_dbt_model..................... [RUN]
2022-01-18 15:38:15.334906 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-18 15:38:15.335106 (Thread-1): Compiling model.sakila_dbt_project.my_second_dbt_model
2022-01-18 15:38:15.337831 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.my_second_dbt_model"
2022-01-18 15:38:15.338718 (Thread-1): finished collecting timing info
2022-01-18 15:38:15.341796 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.my_second_dbt_model"
2022-01-18 15:38:15.342513 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-18 15:38:15.342703 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: BEGIN
2022-01-18 15:38:15.342878 (Thread-1): Opening a new connection, currently in state closed
2022-01-18 15:38:15.824666 (Thread-1): SQL status: BEGIN in 0.48 seconds
2022-01-18 15:38:15.825037 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-18 15:38:15.825262 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */


  create  table "sakila_wh"."dwh"."my_second_dbt_model__dbt_tmp"
  as (
    -- Use the `ref` function to select from other models

select *
from "sakila_wh"."dwh"."my_first_dbt_model"
where id = 1
  );
2022-01-18 15:38:15.908245 (Thread-1): SQL status: SELECT 1 in 0.08 seconds
2022-01-18 15:38:15.911169 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-18 15:38:15.911382 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
alter table "sakila_wh"."dwh"."my_second_dbt_model" rename to "my_second_dbt_model__dbt_backup"
2022-01-18 15:38:15.986778 (Thread-1): SQL status: ALTER TABLE in 0.08 seconds
2022-01-18 15:38:15.990537 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-18 15:38:15.990852 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
alter table "sakila_wh"."dwh"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-18 15:38:16.066558 (Thread-1): SQL status: ALTER TABLE in 0.08 seconds
2022-01-18 15:38:16.068131 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: COMMIT
2022-01-18 15:38:16.068325 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-18 15:38:16.068492 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: COMMIT
2022-01-18 15:38:16.144312 (Thread-1): SQL status: COMMIT in 0.08 seconds
2022-01-18 15:38:16.146980 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-18 15:38:16.147216 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
drop table if exists "sakila_wh"."dwh"."my_second_dbt_model__dbt_backup" cascade
2022-01-18 15:38:16.224820 (Thread-1): SQL status: DROP TABLE in 0.08 seconds
2022-01-18 15:38:16.226393 (Thread-1): finished collecting timing info
2022-01-18 15:38:16.226674 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: Close
2022-01-18 15:38:16.227256 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8d624d67-3718-4438-8327-016b649e31db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108a69f70>]}
2022-01-18 15:38:16.227684 (Thread-1): 21:08:16 | 7 of 7 OK created table model dwh.my_second_dbt_model................ [SELECT 1 in 0.89s]
2022-01-18 15:38:16.227910 (Thread-1): Finished running node model.sakila_dbt_project.my_second_dbt_model
2022-01-18 15:38:16.229022 (MainThread): Acquiring new postgres connection "master".
2022-01-18 15:38:16.229249 (MainThread): Using postgres connection "master".
2022-01-18 15:38:16.229417 (MainThread): On master: BEGIN
2022-01-18 15:38:16.229586 (MainThread): Opening a new connection, currently in state closed
2022-01-18 15:38:16.686658 (MainThread): SQL status: BEGIN in 0.46 seconds
2022-01-18 15:38:16.687282 (MainThread): On master: COMMIT
2022-01-18 15:38:16.687716 (MainThread): Using postgres connection "master".
2022-01-18 15:38:16.688089 (MainThread): On master: COMMIT
2022-01-18 15:38:16.763520 (MainThread): SQL status: COMMIT in 0.08 seconds
2022-01-18 15:38:16.763833 (MainThread): On master: Close
2022-01-18 15:38:16.764338 (MainThread): 21:08:16 | 
2022-01-18 15:38:16.764571 (MainThread): 21:08:16 | Finished running 6 table models, 1 incremental model in 9.80s.
2022-01-18 15:38:16.764765 (MainThread): Connection 'master' was properly closed.
2022-01-18 15:38:16.764922 (MainThread): Connection 'model.sakila_dbt_project.my_second_dbt_model' was properly closed.
2022-01-18 15:38:16.775982 (MainThread): 
2022-01-18 15:38:16.776240 (MainThread): Completed successfully
2022-01-18 15:38:16.776455 (MainThread): 
Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
2022-01-18 15:38:16.776713 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1088ed0d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1088ed2e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1088eda90>]}
2022-01-18 15:38:16.776971 (MainThread): Flushing usage events
2022-01-18 15:39:20.174634 (MainThread): Running with dbt=0.21.1
2022-01-18 15:39:20.261968 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, defer=None, state=None, cls=<class 'dbt.task.clean.CleanTask'>, which='clean', rpc_method=None)
2022-01-18 15:39:20.262542 (MainThread): Tracking: tracking
2022-01-18 15:39:20.285779 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ec1f4f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ec1fb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ebfcc10>]}
2022-01-18 15:39:20.287678 (MainThread): Checking target/*
2022-01-18 15:39:20.296116 (MainThread):  Cleaned target/*
2022-01-18 15:39:20.296403 (MainThread): Checking dbt_modules/*
2022-01-18 15:39:20.341769 (MainThread):  Cleaned dbt_modules/*
2022-01-18 15:39:20.342011 (MainThread): Finished cleaning all paths.
2022-01-18 15:39:20.342428 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ec1fb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ec1f4f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ebfc340>]}
2022-01-18 15:39:20.342721 (MainThread): Flushing usage events
2022-01-18 15:39:29.937650 (MainThread): Running with dbt=0.21.1
2022-01-18 15:39:30.026433 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, defer=None, state=None, cls=<class 'dbt.task.deps.DepsTask'>, which='deps', rpc_method='deps')
2022-01-18 15:39:30.027101 (MainThread): Tracking: tracking
2022-01-18 15:39:30.050935 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103a06f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103a063a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1039e2c70>]}
2022-01-18 15:39:30.054106 (MainThread): Set downloads directory='/var/folders/ht/55m1kf9529v8n85gyrn0hzcc0000gp/T/dbt-downloads-o77s1wy5'
2022-01-18 15:39:30.054961 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/index.json
2022-01-18 15:39:30.817867 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/index.json 200
2022-01-18 15:39:30.818286 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils.json
2022-01-18 15:39:31.292682 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils.json 200
2022-01-18 15:39:31.293631 (MainThread): * Deprecation Warning: The `fishtown-analytics/dbt_utils` package is deprecated
in favor of `dbt-labs/dbt_utils`. Please update your `packages.yml`
configuration to use `dbt-labs/dbt_utils` instead.
2022-01-18 15:39:31.293990 (MainThread): Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '8e356055-d980-4195-a9eb-e7a9d07c3d10', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1039e2940>]}
2022-01-18 15:39:31.314369 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils/0.1.22.json
2022-01-18 15:39:32.209686 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils/0.1.22.json 200
2022-01-18 15:39:32.210143 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils.json
2022-01-18 15:39:32.763710 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils.json 200
2022-01-18 15:39:32.782901 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils/0.1.22.json
2022-01-18 15:39:33.635611 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils/0.1.22.json 200
2022-01-18 15:39:33.636091 (MainThread): Installing fishtown-analytics/dbt_utils@0.1.22
2022-01-18 15:39:34.915440 (MainThread):   Installed from version 0.1.22
2022-01-18 15:39:34.915864 (MainThread):   Updated version available: 0.7.0
2022-01-18 15:39:34.916280 (MainThread): Sending event: {'category': 'dbt', 'action': 'package', 'label': '8e356055-d980-4195-a9eb-e7a9d07c3d10', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1039e2430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1039e2d60>]}
2022-01-18 15:39:34.916700 (MainThread): 
Updates available for packages: ['fishtown-analytics/dbt_utils']                 
Update your versions in packages.yml, then run dbt deps
2022-01-18 15:39:34.918474 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1039e2850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1039e2910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1039e2e20>]}
2022-01-18 15:39:34.918914 (MainThread): Flushing usage events
2022-01-18 15:40:28.253952 (MainThread): Running with dbt=0.21.1
2022-01-18 15:40:28.350940 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, defer=None, state=None, cls=<class 'dbt.task.clean.CleanTask'>, which='clean', rpc_method=None)
2022-01-18 15:40:28.352011 (MainThread): Tracking: tracking
2022-01-18 15:40:28.378061 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109bc7970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109bc73a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109ba2c40>]}
2022-01-18 15:40:28.380301 (MainThread): Checking target/*
2022-01-18 15:40:28.381372 (MainThread):  Cleaned target/*
2022-01-18 15:40:28.381591 (MainThread): Checking dbt_modules/*
2022-01-18 15:40:28.411370 (MainThread):  Cleaned dbt_modules/*
2022-01-18 15:40:28.411758 (MainThread): Finished cleaning all paths.
2022-01-18 15:40:28.412260 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109bc73a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109bc76d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109ba2d90>]}
2022-01-18 15:40:28.412549 (MainThread): Flushing usage events
2022-01-18 15:40:53.011847 (MainThread): Running with dbt=0.21.1
2022-01-18 15:40:53.105406 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, defer=None, state=None, cls=<class 'dbt.task.deps.DepsTask'>, which='deps', rpc_method='deps')
2022-01-18 15:40:53.106007 (MainThread): Tracking: tracking
2022-01-18 15:40:53.129503 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f8170d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f817340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f7f4c40>]}
2022-01-18 15:40:53.133042 (MainThread): Set downloads directory='/var/folders/ht/55m1kf9529v8n85gyrn0hzcc0000gp/T/dbt-downloads-1vwa31z1'
2022-01-18 15:40:53.133989 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/index.json
2022-01-18 15:40:53.803570 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/index.json 200
2022-01-18 15:40:53.803957 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
2022-01-18 15:40:54.280050 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
2022-01-18 15:40:54.301925 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils/0.1.22.json
2022-01-18 15:40:55.147650 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils/0.1.22.json 200
2022-01-18 15:40:55.148106 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
2022-01-18 15:40:55.629288 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
2022-01-18 15:40:55.646301 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils/0.1.22.json
2022-01-18 15:40:56.398989 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils/0.1.22.json 200
2022-01-18 15:40:56.399427 (MainThread): Installing dbt-labs/dbt_utils@0.1.22
2022-01-18 15:40:57.538697 (MainThread):   Installed from version 0.1.22
2022-01-18 15:40:57.538936 (MainThread):   Updated version available: 0.8.0
2022-01-18 15:40:57.539183 (MainThread): Sending event: {'category': 'dbt', 'action': 'package', 'label': '17a96f9f-e4da-4d0c-8a49-67c4f002d151', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f7f4f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f7f4970>]}
2022-01-18 15:40:57.539428 (MainThread): 
Updates available for packages: ['dbt-labs/dbt_utils']                 
Update your versions in packages.yml, then run dbt deps
2022-01-18 15:40:57.540442 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f7f4910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f7f49a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f7f4a60>]}
2022-01-18 15:40:57.540681 (MainThread): Flushing usage events
2022-01-18 15:41:38.905121 (MainThread): Running with dbt=0.21.1
2022-01-18 15:41:39.003436 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2022-01-18 15:41:39.005267 (MainThread): Tracking: tracking
2022-01-18 15:41:39.028274 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105f554f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10654ce50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10654c370>]}
2022-01-18 15:41:39.044372 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065cbbb0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065cba00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1065cb4f0>]}
2022-01-18 15:41:39.044689 (MainThread): Flushing usage events
2022-01-18 15:41:40.512491 (MainThread): Encountered an error:
2022-01-18 15:41:40.512899 (MainThread): Runtime Error
  Failed to read package: Runtime Error
    Invalid config version: 1, expected 2
  
  Error encountered in /Users/nijoshi/Desktop/dbt_proj/dbt_modules/dbt_utils/dbt_project.yml

Error encountered in /Users/nijoshi/Desktop/dbt_proj/dbt_modules/dbt_utils
2022-01-18 15:41:40.519665 (MainThread): Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/dbt/config/runtime.py", line 367, in load_projects
    project = self.new_project(str(path))
  File "/usr/local/lib/python3.9/site-packages/dbt/config/runtime.py", line 144, in new_project
    project = Project.from_project_root(
  File "/usr/local/lib/python3.9/site-packages/dbt/config/project.py", line 642, in from_project_root
    partial = cls.partial_load(project_root, verify_version=verify_version)
  File "/usr/local/lib/python3.9/site-packages/dbt/config/project.py", line 609, in partial_load
    return PartialProject.from_project_root(
  File "/usr/local/lib/python3.9/site-packages/dbt/config/project.py", line 458, in from_project_root
    raise DbtProjectError(
dbt.exceptions.DbtProjectError: Runtime Error
  Invalid config version: 1, expected 2

Error encountered in /Users/nijoshi/Desktop/dbt_proj/dbt_modules/dbt_utils/dbt_project.yml

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/dbt/main.py", line 127, in main
    results, succeeded = handle_and_check(args)
  File "/usr/local/lib/python3.9/site-packages/dbt/main.py", line 205, in handle_and_check
    task, res = run_from_args(parsed)
  File "/usr/local/lib/python3.9/site-packages/dbt/main.py", line 258, in run_from_args
    results = task.run()
  File "/usr/local/lib/python3.9/site-packages/dbt/task/runnable.py", line 438, in run
    self._runtime_initialize()
  File "/usr/local/lib/python3.9/site-packages/dbt/task/runnable.py", line 154, in _runtime_initialize
    super()._runtime_initialize()
  File "/usr/local/lib/python3.9/site-packages/dbt/task/runnable.py", line 92, in _runtime_initialize
    self.load_manifest()
  File "/usr/local/lib/python3.9/site-packages/dbt/task/runnable.py", line 79, in load_manifest
    self.manifest = ManifestLoader.get_full_manifest(self.config)
  File "/usr/local/lib/python3.9/site-packages/dbt/parser/manifest.py", line 179, in get_full_manifest
    projects = config.load_dependencies()
  File "/usr/local/lib/python3.9/site-packages/dbt/config/runtime.py", line 347, in load_dependencies
    for project_name, project in self.load_projects(project_paths):
  File "/usr/local/lib/python3.9/site-packages/dbt/config/runtime.py", line 369, in load_projects
    raise DbtProjectError(
dbt.exceptions.DbtProjectError: Runtime Error
  Failed to read package: Runtime Error
    Invalid config version: 1, expected 2
  
  Error encountered in /Users/nijoshi/Desktop/dbt_proj/dbt_modules/dbt_utils/dbt_project.yml

Error encountered in /Users/nijoshi/Desktop/dbt_proj/dbt_modules/dbt_utils

2022-01-18 15:42:31.355036 (MainThread): Running with dbt=0.21.1
2022-01-18 15:42:31.445872 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2022-01-18 15:42:31.448018 (MainThread): Tracking: tracking
2022-01-18 15:42:31.469146 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111b104f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112106e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112106370>]}
2022-01-18 15:42:31.484775 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112186a00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112186490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1121864f0>]}
2022-01-18 15:42:31.485109 (MainThread): Flushing usage events
2022-01-18 15:42:33.059379 (MainThread): Encountered an error:
2022-01-18 15:42:33.059733 (MainThread): Runtime Error
  Failed to read package: Runtime Error
    Invalid config version: 1, expected 2
  
  Error encountered in /Users/nijoshi/Desktop/dbt_proj/dbt_modules/dbt_utils/dbt_project.yml

Error encountered in /Users/nijoshi/Desktop/dbt_proj/dbt_modules/dbt_utils
2022-01-18 15:42:33.061909 (MainThread): Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/dbt/config/runtime.py", line 367, in load_projects
    project = self.new_project(str(path))
  File "/usr/local/lib/python3.9/site-packages/dbt/config/runtime.py", line 144, in new_project
    project = Project.from_project_root(
  File "/usr/local/lib/python3.9/site-packages/dbt/config/project.py", line 642, in from_project_root
    partial = cls.partial_load(project_root, verify_version=verify_version)
  File "/usr/local/lib/python3.9/site-packages/dbt/config/project.py", line 609, in partial_load
    return PartialProject.from_project_root(
  File "/usr/local/lib/python3.9/site-packages/dbt/config/project.py", line 458, in from_project_root
    raise DbtProjectError(
dbt.exceptions.DbtProjectError: Runtime Error
  Invalid config version: 1, expected 2

Error encountered in /Users/nijoshi/Desktop/dbt_proj/dbt_modules/dbt_utils/dbt_project.yml

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/dbt/main.py", line 127, in main
    results, succeeded = handle_and_check(args)
  File "/usr/local/lib/python3.9/site-packages/dbt/main.py", line 205, in handle_and_check
    task, res = run_from_args(parsed)
  File "/usr/local/lib/python3.9/site-packages/dbt/main.py", line 258, in run_from_args
    results = task.run()
  File "/usr/local/lib/python3.9/site-packages/dbt/task/runnable.py", line 438, in run
    self._runtime_initialize()
  File "/usr/local/lib/python3.9/site-packages/dbt/task/runnable.py", line 154, in _runtime_initialize
    super()._runtime_initialize()
  File "/usr/local/lib/python3.9/site-packages/dbt/task/runnable.py", line 92, in _runtime_initialize
    self.load_manifest()
  File "/usr/local/lib/python3.9/site-packages/dbt/task/runnable.py", line 79, in load_manifest
    self.manifest = ManifestLoader.get_full_manifest(self.config)
  File "/usr/local/lib/python3.9/site-packages/dbt/parser/manifest.py", line 179, in get_full_manifest
    projects = config.load_dependencies()
  File "/usr/local/lib/python3.9/site-packages/dbt/config/runtime.py", line 347, in load_dependencies
    for project_name, project in self.load_projects(project_paths):
  File "/usr/local/lib/python3.9/site-packages/dbt/config/runtime.py", line 369, in load_projects
    raise DbtProjectError(
dbt.exceptions.DbtProjectError: Runtime Error
  Failed to read package: Runtime Error
    Invalid config version: 1, expected 2
  
  Error encountered in /Users/nijoshi/Desktop/dbt_proj/dbt_modules/dbt_utils/dbt_project.yml

Error encountered in /Users/nijoshi/Desktop/dbt_proj/dbt_modules/dbt_utils

2022-01-18 15:43:24.521497 (MainThread): Running with dbt=0.21.1
2022-01-18 15:43:24.607660 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, defer=None, state=None, cls=<class 'dbt.task.clean.CleanTask'>, which='clean', rpc_method=None)
2022-01-18 15:43:24.608289 (MainThread): Tracking: tracking
2022-01-18 15:43:24.631952 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104578970>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104578340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104559c10>]}
2022-01-18 15:43:24.633981 (MainThread): Checking target/*
2022-01-18 15:43:24.635006 (MainThread):  Cleaned target/*
2022-01-18 15:43:24.635226 (MainThread): Checking dbt_modules/*
2022-01-18 15:43:24.664155 (MainThread):  Cleaned dbt_modules/*
2022-01-18 15:43:24.664479 (MainThread): Finished cleaning all paths.
2022-01-18 15:43:24.664963 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104578340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104578d00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104559400>]}
2022-01-18 15:43:24.665264 (MainThread): Flushing usage events
2022-01-18 15:43:50.364537 (MainThread): Running with dbt=0.21.1
2022-01-18 15:43:50.461585 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, defer=None, state=None, cls=<class 'dbt.task.deps.DepsTask'>, which='deps', rpc_method='deps')
2022-01-18 15:43:50.462731 (MainThread): Tracking: tracking
2022-01-18 15:43:50.484723 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059b94f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1059b9b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10599ac10>]}
2022-01-18 15:43:50.487920 (MainThread): Set downloads directory='/var/folders/ht/55m1kf9529v8n85gyrn0hzcc0000gp/T/dbt-downloads-k9c3ngkp'
2022-01-18 15:43:50.488935 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/index.json
2022-01-18 15:43:51.116707 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/index.json 200
2022-01-18 15:43:51.117210 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
2022-01-18 15:43:51.602845 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
2022-01-18 15:43:51.625384 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils/0.7.1.json
2022-01-18 15:43:52.112874 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils/0.7.1.json 200
2022-01-18 15:43:52.113328 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
2022-01-18 15:43:52.676497 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
2022-01-18 15:43:52.699258 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils/0.7.1.json
2022-01-18 15:43:53.257078 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils/0.7.1.json 200
2022-01-18 15:43:53.257625 (MainThread): Installing dbt-labs/dbt_utils@0.7.1
2022-01-18 15:43:54.377167 (MainThread):   Installed from version 0.7.1
2022-01-18 15:43:54.377545 (MainThread):   Updated version available: 0.8.0
2022-01-18 15:43:54.377897 (MainThread): Sending event: {'category': 'dbt', 'action': 'package', 'label': 'b95e6be5-d063-4fb8-b65d-da3dd246c7ae', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10599a2e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10599a940>]}
2022-01-18 15:43:54.378172 (MainThread): 
Updates available for packages: ['dbt-labs/dbt_utils']                 
Update your versions in packages.yml, then run dbt deps
2022-01-18 15:43:54.379333 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10599a8b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10599afa0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10599ae50>]}
2022-01-18 15:43:54.379586 (MainThread): Flushing usage events
2022-01-18 15:44:04.744045 (MainThread): Running with dbt=0.21.1
2022-01-18 15:44:04.846338 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2022-01-18 15:44:04.869994 (MainThread): Tracking: tracking
2022-01-18 15:44:04.893345 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11182a5b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111e2fca0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111e2f310>]}
2022-01-18 15:44:04.920192 (MainThread): Partial parsing not enabled
2022-01-18 15:44:04.975870 (MainThread): Parsing macros/catalog.sql
2022-01-18 15:44:04.979838 (MainThread): Parsing macros/relations.sql
2022-01-18 15:44:04.981366 (MainThread): Parsing macros/adapters.sql
2022-01-18 15:44:05.008237 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2022-01-18 15:44:05.021588 (MainThread): Parsing macros/core.sql
2022-01-18 15:44:05.026269 (MainThread): Parsing macros/materializations/test.sql
2022-01-18 15:44:05.034737 (MainThread): Parsing macros/materializations/helpers.sql
2022-01-18 15:44:05.045811 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2022-01-18 15:44:05.047921 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2022-01-18 15:44:05.073052 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2022-01-18 15:44:05.112537 (MainThread): Parsing macros/materializations/seed/seed.sql
2022-01-18 15:44:05.138906 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2022-01-18 15:44:05.140949 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2022-01-18 15:44:05.152874 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2022-01-18 15:44:05.175657 (MainThread): Parsing macros/materializations/common/merge.sql
2022-01-18 15:44:05.191495 (MainThread): Parsing macros/materializations/table/table.sql
2022-01-18 15:44:05.201487 (MainThread): Parsing macros/materializations/view/view.sql
2022-01-18 15:44:05.209614 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2022-01-18 15:44:05.213747 (MainThread): Parsing macros/etc/get_custom_alias.sql
2022-01-18 15:44:05.215682 (MainThread): Parsing macros/etc/query.sql
2022-01-18 15:44:05.217033 (MainThread): Parsing macros/etc/is_incremental.sql
2022-01-18 15:44:05.218794 (MainThread): Parsing macros/etc/datetime.sql
2022-01-18 15:44:05.228054 (MainThread): Parsing macros/etc/where_subquery.sql
2022-01-18 15:44:05.230035 (MainThread): Parsing macros/etc/get_custom_schema.sql
2022-01-18 15:44:05.234482 (MainThread): Parsing macros/etc/get_custom_database.sql
2022-01-18 15:44:05.236403 (MainThread): Parsing macros/adapters/common.sql
2022-01-18 15:44:05.301899 (MainThread): Parsing macros/schema_tests/relationships.sql
2022-01-18 15:44:05.303959 (MainThread): Parsing macros/schema_tests/not_null.sql
2022-01-18 15:44:05.305389 (MainThread): Parsing macros/schema_tests/unique.sql
2022-01-18 15:44:05.306958 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2022-01-18 15:44:05.309541 (MainThread): Parsing macros/cross_db_utils/except.sql
2022-01-18 15:44:05.310829 (MainThread): Parsing macros/cross_db_utils/replace.sql
2022-01-18 15:44:05.312323 (MainThread): Parsing macros/cross_db_utils/concat.sql
2022-01-18 15:44:05.313519 (MainThread): Parsing macros/cross_db_utils/datatypes.sql
2022-01-18 15:44:05.321794 (MainThread): Parsing macros/cross_db_utils/_is_relation.sql
2022-01-18 15:44:05.323287 (MainThread): Parsing macros/cross_db_utils/length.sql
2022-01-18 15:44:05.324856 (MainThread): Parsing macros/cross_db_utils/dateadd.sql
2022-01-18 15:44:05.328414 (MainThread): Parsing macros/cross_db_utils/intersect.sql
2022-01-18 15:44:05.329744 (MainThread): Parsing macros/cross_db_utils/right.sql
2022-01-18 15:44:05.332870 (MainThread): Parsing macros/cross_db_utils/datediff.sql
2022-01-18 15:44:05.344436 (MainThread): Parsing macros/cross_db_utils/safe_cast.sql
2022-01-18 15:44:05.346623 (MainThread): Parsing macros/cross_db_utils/hash.sql
2022-01-18 15:44:05.348415 (MainThread): Parsing macros/cross_db_utils/cast_bool_to_text.sql
2022-01-18 15:44:05.350709 (MainThread): Parsing macros/cross_db_utils/identifier.sql
2022-01-18 15:44:05.352678 (MainThread): Parsing macros/cross_db_utils/position.sql
2022-01-18 15:44:05.354471 (MainThread): Parsing macros/cross_db_utils/literal.sql
2022-01-18 15:44:05.355594 (MainThread): Parsing macros/cross_db_utils/current_timestamp.sql
2022-01-18 15:44:05.359623 (MainThread): Parsing macros/cross_db_utils/width_bucket.sql
2022-01-18 15:44:05.366064 (MainThread): Parsing macros/cross_db_utils/last_day.sql
2022-01-18 15:44:05.370400 (MainThread): Parsing macros/cross_db_utils/split_part.sql
2022-01-18 15:44:05.372570 (MainThread): Parsing macros/cross_db_utils/date_trunc.sql
2022-01-18 15:44:05.374461 (MainThread): Parsing macros/cross_db_utils/_is_ephemeral.sql
2022-01-18 15:44:05.376612 (MainThread): Parsing macros/materializations/insert_by_period_materialization.sql
2022-01-18 15:44:05.405818 (MainThread): Parsing macros/web/get_url_host.sql
2022-01-18 15:44:05.408091 (MainThread): Parsing macros/web/get_url_path.sql
2022-01-18 15:44:05.411289 (MainThread): Parsing macros/web/get_url_parameter.sql
2022-01-18 15:44:05.413129 (MainThread): Parsing macros/jinja_helpers/pretty_log_format.sql
2022-01-18 15:44:05.414604 (MainThread): Parsing macros/jinja_helpers/pretty_time.sql
2022-01-18 15:44:05.416827 (MainThread): Parsing macros/jinja_helpers/log_info.sql
2022-01-18 15:44:05.418361 (MainThread): Parsing macros/jinja_helpers/slugify.sql
2022-01-18 15:44:05.419767 (MainThread): Parsing macros/schema_tests/fewer_rows_than.sql
2022-01-18 15:44:05.421678 (MainThread): Parsing macros/schema_tests/equal_rowcount.sql
2022-01-18 15:44:05.423536 (MainThread): Parsing macros/schema_tests/relationships_where.sql
2022-01-18 15:44:05.426142 (MainThread): Parsing macros/schema_tests/recency.sql
2022-01-18 15:44:05.428139 (MainThread): Parsing macros/schema_tests/not_constant.sql
2022-01-18 15:44:05.429561 (MainThread): Parsing macros/schema_tests/accepted_range.sql
2022-01-18 15:44:05.433265 (MainThread): Parsing macros/schema_tests/not_accepted_values.sql
2022-01-18 15:44:05.436124 (MainThread): Parsing macros/schema_tests/test_unique_where.sql
2022-01-18 15:44:05.437816 (MainThread): Parsing macros/schema_tests/at_least_one.sql
2022-01-18 15:44:05.439291 (MainThread): Parsing macros/schema_tests/unique_combination_of_columns.sql
2022-01-18 15:44:05.442495 (MainThread): Parsing macros/schema_tests/cardinality_equality.sql
2022-01-18 15:44:05.444766 (MainThread): Parsing macros/schema_tests/expression_is_true.sql
2022-01-18 15:44:05.446818 (MainThread): Parsing macros/schema_tests/sequential_values.sql
2022-01-18 15:44:05.451000 (MainThread): Parsing macros/schema_tests/test_not_null_where.sql
2022-01-18 15:44:05.452755 (MainThread): Parsing macros/schema_tests/equality.sql
2022-01-18 15:44:05.456665 (MainThread): Parsing macros/schema_tests/mutually_exclusive_ranges.sql
2022-01-18 15:44:05.467967 (MainThread): Parsing macros/sql/date_spine.sql
2022-01-18 15:44:05.473311 (MainThread): Parsing macros/sql/nullcheck_table.sql
2022-01-18 15:44:05.475330 (MainThread): Parsing macros/sql/get_relations_by_pattern.sql
2022-01-18 15:44:05.479396 (MainThread): Parsing macros/sql/generate_series.sql
2022-01-18 15:44:05.516547 (MainThread): Parsing macros/sql/get_relations_by_prefix.sql
2022-01-18 15:44:05.521391 (MainThread): Parsing macros/sql/get_tables_by_prefix_sql.sql
2022-01-18 15:44:05.523622 (MainThread): Parsing macros/sql/star.sql
2022-01-18 15:44:05.527915 (MainThread): Parsing macros/sql/unpivot.sql
2022-01-18 15:44:05.539070 (MainThread): Parsing macros/sql/union.sql
2022-01-18 15:44:05.550928 (MainThread): Parsing macros/sql/groupby.sql
2022-01-18 15:44:05.552817 (MainThread): Parsing macros/sql/surrogate_key.sql
2022-01-18 15:44:05.557034 (MainThread): Parsing macros/sql/safe_add.sql
2022-01-18 15:44:05.559034 (MainThread): Parsing macros/sql/nullcheck.sql
2022-01-18 15:44:05.560976 (MainThread): Parsing macros/sql/get_tables_by_pattern_sql.sql
2022-01-18 15:44:05.569135 (MainThread): Parsing macros/sql/get_column_values.sql
2022-01-18 15:44:05.574905 (MainThread): Parsing macros/sql/pivot.sql
2022-01-18 15:44:05.579570 (MainThread): Parsing macros/sql/get_query_results_as_dict.sql
2022-01-18 15:44:05.582789 (MainThread): Parsing macros/sql/haversine_distance.sql
2022-01-18 15:44:05.924545 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-18 15:44:05.936781 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.customer_test".
2022-01-18 15:44:05.940306 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-18 15:44:05.941446 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-18 15:44:05.945390 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.film_test".
2022-01-18 15:44:05.949254 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-18 15:44:05.958322 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-18 15:44:05.961455 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-18 15:44:05.977454 (MainThread): Acquiring new postgres connection "test.sakila_dbt_project.film_replacementcost_30".
2022-01-18 15:44:05.980127 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-18 15:44:06.019584 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-18 15:44:06.021788 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-18 15:44:06.024003 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-18 15:44:06.026120 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-18 15:44:06.028256 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-18 15:44:06.030506 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-18 15:44:06.046053 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-18 15:44:06.052458 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-18 15:44:06.071938 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-18 15:44:06.074256 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-18 15:44:06.108813 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5de8d131-3035-488c-bfba-189e8138af90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111f93070>]}
2022-01-18 15:44:06.121267 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-01-18 15:44:06.121929 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5de8d131-3035-488c-bfba-189e8138af90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111fbadf0>]}
2022-01-18 15:44:06.122273 (MainThread): Found 7 models, 11 tests, 0 snapshots, 0 analyses, 347 macros, 0 operations, 0 seed files, 12 sources, 0 exposures
2022-01-18 15:44:06.124482 (MainThread): 
2022-01-18 15:44:06.124939 (MainThread): Acquiring new postgres connection "master".
2022-01-18 15:44:06.126177 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_sakila_wh".
2022-01-18 15:44:06.138649 (ThreadPoolExecutor-0_0): Using postgres connection "list_sakila_wh".
2022-01-18 15:44:06.138897 (ThreadPoolExecutor-0_0): On list_sakila_wh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh"} */

    select distinct nspname from pg_namespace
  
2022-01-18 15:44:06.139085 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2022-01-18 15:44:06.631952 (ThreadPoolExecutor-0_0): SQL status: SELECT 16 in 0.49 seconds
2022-01-18 15:44:06.634441 (ThreadPoolExecutor-0_0): On list_sakila_wh: Close
2022-01-18 15:44:06.636376 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_dwh".
2022-01-18 15:44:06.642913 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-18 15:44:06.643124 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: BEGIN
2022-01-18 15:44:06.643302 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2022-01-18 15:44:07.101208 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.46 seconds
2022-01-18 15:44:07.101543 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-18 15:44:07.101858 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_dwh"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dwh'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dwh'
  
2022-01-18 15:44:07.182574 (ThreadPoolExecutor-1_0): SQL status: SELECT 8 in 0.08 seconds
2022-01-18 15:44:07.185111 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: ROLLBACK
2022-01-18 15:44:07.260311 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: Close
2022-01-18 15:44:07.268049 (MainThread): Using postgres connection "master".
2022-01-18 15:44:07.268358 (MainThread): On master: BEGIN
2022-01-18 15:44:07.268572 (MainThread): Opening a new connection, currently in state init
2022-01-18 15:44:07.732171 (MainThread): SQL status: BEGIN in 0.46 seconds
2022-01-18 15:44:07.732708 (MainThread): Using postgres connection "master".
2022-01-18 15:44:07.733126 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-18 15:44:07.823953 (MainThread): SQL status: SELECT 47 in 0.09 seconds
2022-01-18 15:44:07.826789 (MainThread): On master: ROLLBACK
2022-01-18 15:44:07.903254 (MainThread): Using postgres connection "master".
2022-01-18 15:44:07.903580 (MainThread): On master: BEGIN
2022-01-18 15:44:08.055604 (MainThread): SQL status: BEGIN in 0.15 seconds
2022-01-18 15:44:08.056216 (MainThread): On master: COMMIT
2022-01-18 15:44:08.056496 (MainThread): Using postgres connection "master".
2022-01-18 15:44:08.056743 (MainThread): On master: COMMIT
2022-01-18 15:44:08.132055 (MainThread): SQL status: COMMIT in 0.08 seconds
2022-01-18 15:44:08.132437 (MainThread): On master: Close
2022-01-18 15:44:08.133129 (MainThread): 21:14:08 | Concurrency: 1 threads (target='dev')
2022-01-18 15:44:08.133523 (MainThread): 21:14:08 | 
2022-01-18 15:44:08.136477 (Thread-1): Began running node model.sakila_dbt_project.dim_date
2022-01-18 15:44:08.136840 (Thread-1): 21:14:08 | 1 of 7 START table model dwh.dim_date................................ [RUN]
2022-01-18 15:44:08.137247 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-18 15:44:08.137466 (Thread-1): Compiling model.sakila_dbt_project.dim_date
2022-01-18 15:44:08.140177 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_date"
2022-01-18 15:44:08.141339 (Thread-1): finished collecting timing info
2022-01-18 15:44:08.167088 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_date"
2022-01-18 15:44:08.168252 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-18 15:44:08.168433 (Thread-1): On model.sakila_dbt_project.dim_date: BEGIN
2022-01-18 15:44:08.168596 (Thread-1): Opening a new connection, currently in state closed
2022-01-18 15:44:08.626922 (Thread-1): SQL status: BEGIN in 0.46 seconds
2022-01-18 15:44:08.627184 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-18 15:44:08.627352 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */


  create  table "sakila_wh"."dwh"."dim_date__dbt_tmp"
  as (
    with dates as (
SELECT
       TO_CHAR(datum, 'yyyymmdd')::INT AS date_dim_id,
       datum AS date_key,
       EXTRACT(EPOCH FROM datum) AS epoch,
       TO_CHAR(datum, 'TMDay') AS day_name,
       EXTRACT(ISODOW FROM datum) AS day_of_week,
       EXTRACT(DAY FROM datum) AS day_of_month,
       datum - DATE_TRUNC('quarter', datum)::DATE + 1 AS day_of_quarter,
       EXTRACT(DOY FROM datum) AS day_of_year,
       TO_CHAR(datum, 'W')::INT AS week_of_month,
       EXTRACT(WEEK FROM datum) AS week_of_year,
       EXTRACT(MONTH FROM datum) AS month_actual,
       TO_CHAR(datum, 'TMMonth') AS month_name,
       TO_CHAR(datum, 'Mon') AS month_name_abbreviated,
       EXTRACT(QUARTER FROM datum) AS quarter_actual,
       CASE
           WHEN EXTRACT(QUARTER FROM datum) = 1 THEN 'First'
           WHEN EXTRACT(QUARTER FROM datum) = 2 THEN 'Second'
           WHEN EXTRACT(QUARTER FROM datum) = 3 THEN 'Third'
           WHEN EXTRACT(QUARTER FROM datum) = 4 THEN 'Fourth'
           END AS quarter_name,
       EXTRACT(YEAR FROM datum) AS year_actual,
       datum + (1 - EXTRACT(ISODOW FROM datum))::INT AS first_day_of_week,
       datum + (7 - EXTRACT(ISODOW FROM datum))::INT AS last_day_of_week,
       datum + (1 - EXTRACT(DAY FROM datum))::INT AS first_day_of_month,
       (DATE_TRUNC('MONTH', datum) + INTERVAL '1 MONTH - 1 day')::DATE AS last_day_of_month,
       DATE_TRUNC('quarter', datum)::DATE AS first_day_of_quarter,
       (DATE_TRUNC('quarter', datum) + INTERVAL '3 MONTH - 1 day')::DATE AS last_day_of_quarter,
       TO_DATE(EXTRACT(YEAR FROM datum) || '-01-01', 'YYYY-MM-DD') AS first_day_of_year,
       TO_DATE(EXTRACT(YEAR FROM datum) || '-12-31', 'YYYY-MM-DD') AS last_day_of_year,
       TO_CHAR(datum, 'yyyymm') AS yyyymm,
       CASE
           WHEN EXTRACT(ISODOW FROM datum) IN (6, 7) THEN TRUE
           ELSE FALSE
           END AS weekend_indr
FROM (SELECT '2000-01-01'::DATE + SEQUENCE.DAY AS datum
      FROM GENERATE_SERIES(0, 29219) AS SEQUENCE (DAY)
      GROUP BY SEQUENCE.DAY) DQ
)
select
*
from
dates
where
date_key <= CURRENT_DATE
order by date_dim_id asc
  );
2022-01-18 15:44:09.604779 (Thread-1): SQL status: SELECT 8054 in 0.98 seconds
2022-01-18 15:44:09.611270 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-18 15:44:09.611489 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
alter table "sakila_wh"."dwh"."dim_date" rename to "dim_date__dbt_backup"
2022-01-18 15:44:09.688843 (Thread-1): SQL status: ALTER TABLE in 0.08 seconds
2022-01-18 15:44:09.691363 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-18 15:44:09.691545 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
alter table "sakila_wh"."dwh"."dim_date__dbt_tmp" rename to "dim_date"
2022-01-18 15:44:09.766793 (Thread-1): SQL status: ALTER TABLE in 0.08 seconds
2022-01-18 15:44:09.778079 (Thread-1): On model.sakila_dbt_project.dim_date: COMMIT
2022-01-18 15:44:09.778347 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-18 15:44:09.778542 (Thread-1): On model.sakila_dbt_project.dim_date: COMMIT
2022-01-18 15:44:09.854259 (Thread-1): SQL status: COMMIT in 0.08 seconds
2022-01-18 15:44:09.859825 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-18 15:44:09.860044 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
drop table if exists "sakila_wh"."dwh"."dim_date__dbt_backup" cascade
2022-01-18 15:44:09.944971 (Thread-1): SQL status: DROP TABLE in 0.08 seconds
2022-01-18 15:44:09.946171 (Thread-1): finished collecting timing info
2022-01-18 15:44:09.946379 (Thread-1): On model.sakila_dbt_project.dim_date: Close
2022-01-18 15:44:09.946813 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5de8d131-3035-488c-bfba-189e8138af90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11205a7f0>]}
2022-01-18 15:44:09.947176 (Thread-1): 21:14:09 | 1 of 7 OK created table model dwh.dim_date........................... [SELECT 8054 in 1.81s]
2022-01-18 15:44:09.947433 (Thread-1): Finished running node model.sakila_dbt_project.dim_date
2022-01-18 15:44:09.947633 (Thread-1): Began running node model.sakila_dbt_project.film_test
2022-01-18 15:44:09.948003 (Thread-1): 21:14:09 | 2 of 7 START table model dwh.film_test............................... [RUN]
2022-01-18 15:44:09.948541 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.film_test".
2022-01-18 15:44:09.948834 (Thread-1): Compiling model.sakila_dbt_project.film_test
2022-01-18 15:44:09.951268 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.film_test"
2022-01-18 15:44:09.952009 (Thread-1): finished collecting timing info
2022-01-18 15:44:09.954673 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.film_test"
2022-01-18 15:44:09.955340 (Thread-1): Using postgres connection "model.sakila_dbt_project.film_test".
2022-01-18 15:44:09.955594 (Thread-1): On model.sakila_dbt_project.film_test: BEGIN
2022-01-18 15:44:09.955779 (Thread-1): Opening a new connection, currently in state closed
2022-01-18 15:44:10.420280 (Thread-1): SQL status: BEGIN in 0.46 seconds
2022-01-18 15:44:10.420685 (Thread-1): Using postgres connection "model.sakila_dbt_project.film_test".
2022-01-18 15:44:10.420946 (Thread-1): On model.sakila_dbt_project.film_test: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.film_test"} */


  create  table "sakila_wh"."dwh"."film_test__dbt_tmp"
  as (
    select * from 
stg.film
  );
2022-01-18 15:44:10.508525 (Thread-1): SQL status: SELECT 1000 in 0.09 seconds
2022-01-18 15:44:10.512939 (Thread-1): Using postgres connection "model.sakila_dbt_project.film_test".
2022-01-18 15:44:10.513180 (Thread-1): On model.sakila_dbt_project.film_test: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.film_test"} */
alter table "sakila_wh"."dwh"."film_test" rename to "film_test__dbt_backup"
2022-01-18 15:44:10.589909 (Thread-1): SQL status: ALTER TABLE in 0.08 seconds
2022-01-18 15:44:10.595463 (Thread-1): Using postgres connection "model.sakila_dbt_project.film_test".
2022-01-18 15:44:10.595700 (Thread-1): On model.sakila_dbt_project.film_test: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.film_test"} */
alter table "sakila_wh"."dwh"."film_test__dbt_tmp" rename to "film_test"
2022-01-18 15:44:10.670912 (Thread-1): SQL status: ALTER TABLE in 0.07 seconds
2022-01-18 15:44:10.672827 (Thread-1): On model.sakila_dbt_project.film_test: COMMIT
2022-01-18 15:44:10.673071 (Thread-1): Using postgres connection "model.sakila_dbt_project.film_test".
2022-01-18 15:44:10.673277 (Thread-1): On model.sakila_dbt_project.film_test: COMMIT
2022-01-18 15:44:10.751606 (Thread-1): SQL status: COMMIT in 0.08 seconds
2022-01-18 15:44:10.754366 (Thread-1): Using postgres connection "model.sakila_dbt_project.film_test".
2022-01-18 15:44:10.754630 (Thread-1): On model.sakila_dbt_project.film_test: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.film_test"} */
drop table if exists "sakila_wh"."dwh"."film_test__dbt_backup" cascade
2022-01-18 15:44:10.833682 (Thread-1): SQL status: DROP TABLE in 0.08 seconds
2022-01-18 15:44:10.835097 (Thread-1): finished collecting timing info
2022-01-18 15:44:10.835349 (Thread-1): On model.sakila_dbt_project.film_test: Close
2022-01-18 15:44:10.835864 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5de8d131-3035-488c-bfba-189e8138af90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1121fca60>]}
2022-01-18 15:44:10.836263 (Thread-1): 21:14:10 | 2 of 7 OK created table model dwh.film_test.......................... [SELECT 1000 in 0.89s]
2022-01-18 15:44:10.836501 (Thread-1): Finished running node model.sakila_dbt_project.film_test
2022-01-18 15:44:10.836729 (Thread-1): Began running node model.sakila_dbt_project.hello_world
2022-01-18 15:44:10.837116 (Thread-1): 21:14:10 | 3 of 7 START table model dwh.hello_world............................. [RUN]
2022-01-18 15:44:10.837548 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-18 15:44:10.837759 (Thread-1): Compiling model.sakila_dbt_project.hello_world
2022-01-18 15:44:10.839640 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.hello_world"
2022-01-18 15:44:10.840286 (Thread-1): finished collecting timing info
2022-01-18 15:44:10.843216 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.hello_world"
2022-01-18 15:44:10.844083 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-18 15:44:10.844295 (Thread-1): On model.sakila_dbt_project.hello_world: BEGIN
2022-01-18 15:44:10.844481 (Thread-1): Opening a new connection, currently in state closed
2022-01-18 15:44:11.301467 (Thread-1): SQL status: BEGIN in 0.46 seconds
2022-01-18 15:44:11.301707 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-18 15:44:11.301841 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */


  create  table "sakila_wh"."dwh"."hello_world__dbt_tmp"
  as (
    select
	customer.customer_id::int,
	customer.store_id::int,
	customer.first_name,
	customer.last_name,
	concat(customer.first_name,' ',customer.last_name) as full_name,
	substring(email from POSITION('@' in email)+1 for char_length(email)-POSITION('@' in email)) as domain,
	customer.email,
	customer.active::int,
	customer.address_id::int,
	address.address,
	city.city_id::int,
	city.city,
	(case when customer.active = 0 then 'no' else 'yes' end)::varchar(100) as "active_desc",
	customer.create_date::timestamp,
	customer.last_update::timestamp
from
	stg.customer as customer

	left join stg.address on 1=1
	and customer.address_id =address.address_id

	left join stg.city on 1=1
	and address.city_id = city.city_id
  );
2022-01-18 15:44:11.392790 (Thread-1): SQL status: SELECT 599 in 0.09 seconds
2022-01-18 15:44:11.395025 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-18 15:44:11.395174 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
alter table "sakila_wh"."dwh"."hello_world" rename to "hello_world__dbt_backup"
2022-01-18 15:44:11.470672 (Thread-1): SQL status: ALTER TABLE in 0.08 seconds
2022-01-18 15:44:11.472894 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-18 15:44:11.473057 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
alter table "sakila_wh"."dwh"."hello_world__dbt_tmp" rename to "hello_world"
2022-01-18 15:44:11.547997 (Thread-1): SQL status: ALTER TABLE in 0.07 seconds
2022-01-18 15:44:11.549405 (Thread-1): On model.sakila_dbt_project.hello_world: COMMIT
2022-01-18 15:44:11.549604 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-18 15:44:11.549738 (Thread-1): On model.sakila_dbt_project.hello_world: COMMIT
2022-01-18 15:44:11.626007 (Thread-1): SQL status: COMMIT in 0.08 seconds
2022-01-18 15:44:11.629384 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-18 15:44:11.629609 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
drop table if exists "sakila_wh"."dwh"."hello_world__dbt_backup" cascade
2022-01-18 15:44:11.708074 (Thread-1): SQL status: DROP TABLE in 0.08 seconds
2022-01-18 15:44:11.710248 (Thread-1): finished collecting timing info
2022-01-18 15:44:11.710600 (Thread-1): On model.sakila_dbt_project.hello_world: Close
2022-01-18 15:44:11.711299 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5de8d131-3035-488c-bfba-189e8138af90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1122000a0>]}
2022-01-18 15:44:11.711761 (Thread-1): 21:14:11 | 3 of 7 OK created table model dwh.hello_world........................ [SELECT 599 in 0.87s]
2022-01-18 15:44:11.712031 (Thread-1): Finished running node model.sakila_dbt_project.hello_world
2022-01-18 15:44:11.712292 (Thread-1): Began running node model.sakila_dbt_project.my_first_dbt_model
2022-01-18 15:44:11.712830 (Thread-1): 21:14:11 | 4 of 7 START table model dwh.my_first_dbt_model...................... [RUN]
2022-01-18 15:44:11.713280 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-18 15:44:11.713517 (Thread-1): Compiling model.sakila_dbt_project.my_first_dbt_model
2022-01-18 15:44:11.716610 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.my_first_dbt_model"
2022-01-18 15:44:11.717458 (Thread-1): finished collecting timing info
2022-01-18 15:44:11.720443 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.my_first_dbt_model"
2022-01-18 15:44:11.721046 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-18 15:44:11.721228 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: BEGIN
2022-01-18 15:44:11.721404 (Thread-1): Opening a new connection, currently in state closed
2022-01-18 15:44:12.185464 (Thread-1): SQL status: BEGIN in 0.46 seconds
2022-01-18 15:44:12.185802 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-18 15:44:12.186014 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */


  create  table "sakila_wh"."dwh"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    --union all
    --select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-18 15:44:12.265929 (Thread-1): SQL status: SELECT 1 in 0.08 seconds
2022-01-18 15:44:12.271908 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-18 15:44:12.272167 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
alter table "sakila_wh"."dwh"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2022-01-18 15:44:12.348007 (Thread-1): SQL status: ALTER TABLE in 0.08 seconds
2022-01-18 15:44:12.352163 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-18 15:44:12.352456 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
alter table "sakila_wh"."dwh"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-18 15:44:12.427883 (Thread-1): SQL status: ALTER TABLE in 0.08 seconds
2022-01-18 15:44:12.430378 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: COMMIT
2022-01-18 15:44:12.430665 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-18 15:44:12.430928 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: COMMIT
2022-01-18 15:44:12.505811 (Thread-1): SQL status: COMMIT in 0.07 seconds
2022-01-18 15:44:12.507888 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-18 15:44:12.508076 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
drop table if exists "sakila_wh"."dwh"."my_first_dbt_model__dbt_backup" cascade
2022-01-18 15:44:12.585107 (Thread-1): SQL status: DROP TABLE in 0.08 seconds
2022-01-18 15:44:12.586569 (Thread-1): finished collecting timing info
2022-01-18 15:44:12.586812 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: Close
2022-01-18 15:44:12.587295 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5de8d131-3035-488c-bfba-189e8138af90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112248af0>]}
2022-01-18 15:44:12.587681 (Thread-1): 21:14:12 | 4 of 7 OK created table model dwh.my_first_dbt_model................. [SELECT 1 in 0.87s]
2022-01-18 15:44:12.587901 (Thread-1): Finished running node model.sakila_dbt_project.my_first_dbt_model
2022-01-18 15:44:12.588110 (Thread-1): Began running node model.sakila_dbt_project.payment_inc
2022-01-18 15:44:12.588573 (Thread-1): 21:14:12 | 5 of 7 START incremental model dwh.payment_inc....................... [RUN]
2022-01-18 15:44:12.588939 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-18 15:44:12.589131 (Thread-1): Compiling model.sakila_dbt_project.payment_inc
2022-01-18 15:44:12.595353 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.payment_inc"
2022-01-18 15:44:12.595972 (Thread-1): finished collecting timing info
2022-01-18 15:44:12.634172 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-18 15:44:12.634847 (Thread-1): On model.sakila_dbt_project.payment_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.payment_inc"} */

    

  create temporary table "payment_inc__dbt_tmp211412626904"
  as (
    

select
*,
'2022-01-18 15:44:04' as dbt_tran_time
from
stg.payment
where 1=1


and payment_date::timestamp > (select max(payment_date) from "sakila_wh"."dwh"."payment_inc")



-- - INTERVAL '3 DAY'
-- unique_key='payment_id'
  );
  
2022-01-18 15:44:12.635238 (Thread-1): Opening a new connection, currently in state closed
2022-01-18 15:44:13.109825 (Thread-1): SQL status: SELECT 0 in 0.47 seconds
2022-01-18 15:44:13.119951 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-18 15:44:13.120240 (Thread-1): On model.sakila_dbt_project.payment_inc: BEGIN
2022-01-18 15:44:13.196810 (Thread-1): SQL status: BEGIN in 0.08 seconds
2022-01-18 15:44:13.200727 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-18 15:44:13.201179 (Thread-1): On model.sakila_dbt_project.payment_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.payment_inc"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from INFORMATION_SCHEMA.columns
      where table_name = 'payment_inc__dbt_tmp211412626904'
        
      order by ordinal_position

  
2022-01-18 15:44:13.289817 (Thread-1): SQL status: SELECT 7 in 0.09 seconds
2022-01-18 15:44:13.297443 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-18 15:44:13.297660 (Thread-1): On model.sakila_dbt_project.payment_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.payment_inc"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "sakila_wh".INFORMATION_SCHEMA.columns
      where table_name = 'payment_inc'
        
        and table_schema = 'dwh'
        
      order by ordinal_position

  
2022-01-18 15:44:13.378816 (Thread-1): SQL status: SELECT 7 in 0.08 seconds
2022-01-18 15:44:13.392387 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-18 15:44:13.392648 (Thread-1): On model.sakila_dbt_project.payment_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.payment_inc"} */

      select
          column_name,
          data_type,
          character_maximum_length,
          numeric_precision,
          numeric_scale

      from "sakila_wh".INFORMATION_SCHEMA.columns
      where table_name = 'payment_inc'
        
        and table_schema = 'dwh'
        
      order by ordinal_position

  
2022-01-18 15:44:13.473685 (Thread-1): SQL status: SELECT 7 in 0.08 seconds
2022-01-18 15:44:13.476354 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.payment_inc"
2022-01-18 15:44:13.477117 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-18 15:44:13.477332 (Thread-1): On model.sakila_dbt_project.payment_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.payment_inc"} */

      delete
    from "sakila_wh"."dwh"."payment_inc"
    where (payment_id) in (
        select (payment_id)
        from "payment_inc__dbt_tmp211412626904"
    );

    insert into "sakila_wh"."dwh"."payment_inc" ("payment_id", "customer_id", "staff_id", "rental_id", "amount", "payment_date", "dbt_tran_time")
    (
       select "payment_id", "customer_id", "staff_id", "rental_id", "amount", "payment_date", "dbt_tran_time"
       from "payment_inc__dbt_tmp211412626904"
    );
  
2022-01-18 15:44:13.553065 (Thread-1): SQL status: INSERT 0 0 in 0.08 seconds
2022-01-18 15:44:13.554857 (Thread-1): On model.sakila_dbt_project.payment_inc: COMMIT
2022-01-18 15:44:13.555102 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-18 15:44:13.555313 (Thread-1): On model.sakila_dbt_project.payment_inc: COMMIT
2022-01-18 15:44:13.631232 (Thread-1): SQL status: COMMIT in 0.08 seconds
2022-01-18 15:44:13.632277 (Thread-1): finished collecting timing info
2022-01-18 15:44:13.632656 (Thread-1): On model.sakila_dbt_project.payment_inc: Close
2022-01-18 15:44:13.633705 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5de8d131-3035-488c-bfba-189e8138af90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11210cf70>]}
2022-01-18 15:44:13.634296 (Thread-1): 21:14:13 | 5 of 7 OK created incremental model dwh.payment_inc.................. [INSERT 0 0 in 1.04s]
2022-01-18 15:44:13.634592 (Thread-1): Finished running node model.sakila_dbt_project.payment_inc
2022-01-18 15:44:13.634881 (Thread-1): Began running node model.sakila_dbt_project.customer_test
2022-01-18 15:44:13.635330 (Thread-1): 21:14:13 | 6 of 7 START table model dwh.customer_alias.......................... [RUN]
2022-01-18 15:44:13.635809 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.customer_test".
2022-01-18 15:44:13.636099 (Thread-1): Compiling model.sakila_dbt_project.customer_test
2022-01-18 15:44:13.641191 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.customer_test"
2022-01-18 15:44:13.641881 (Thread-1): finished collecting timing info
2022-01-18 15:44:13.672893 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.customer_test"
2022-01-18 15:44:13.673673 (Thread-1): Using postgres connection "model.sakila_dbt_project.customer_test".
2022-01-18 15:44:13.673871 (Thread-1): On model.sakila_dbt_project.customer_test: BEGIN
2022-01-18 15:44:13.674054 (Thread-1): Opening a new connection, currently in state closed
2022-01-18 15:44:14.135937 (Thread-1): SQL status: BEGIN in 0.46 seconds
2022-01-18 15:44:14.136268 (Thread-1): Using postgres connection "model.sakila_dbt_project.customer_test".
2022-01-18 15:44:14.136481 (Thread-1): On model.sakila_dbt_project.customer_test: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.customer_test"} */


  create  table "sakila_wh"."dwh"."customer_test__dbt_tmp"
  as (
    

select * from 
"sakila_wh"."dwh"."hello_world"
where customer_id < 10
  );
2022-01-18 15:44:14.220453 (Thread-1): SQL status: SELECT 9 in 0.08 seconds
2022-01-18 15:44:14.223635 (Thread-1): Using postgres connection "model.sakila_dbt_project.customer_test".
2022-01-18 15:44:14.223864 (Thread-1): On model.sakila_dbt_project.customer_test: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.customer_test"} */
alter table "sakila_wh"."dwh"."customer_alias" rename to "customer_test__dbt_backup"
2022-01-18 15:44:14.299713 (Thread-1): SQL status: ALTER TABLE in 0.08 seconds
2022-01-18 15:44:14.303498 (Thread-1): Using postgres connection "model.sakila_dbt_project.customer_test".
2022-01-18 15:44:14.303830 (Thread-1): On model.sakila_dbt_project.customer_test: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.customer_test"} */
alter table "sakila_wh"."dwh"."customer_test__dbt_tmp" rename to "customer_alias"
2022-01-18 15:44:14.380449 (Thread-1): SQL status: ALTER TABLE in 0.08 seconds
2022-01-18 15:44:14.383135 (Thread-1): On model.sakila_dbt_project.customer_test: COMMIT
2022-01-18 15:44:14.383513 (Thread-1): Using postgres connection "model.sakila_dbt_project.customer_test".
2022-01-18 15:44:14.383751 (Thread-1): On model.sakila_dbt_project.customer_test: COMMIT
2022-01-18 15:44:14.459582 (Thread-1): SQL status: COMMIT in 0.08 seconds
2022-01-18 15:44:14.462880 (Thread-1): Using postgres connection "model.sakila_dbt_project.customer_test".
2022-01-18 15:44:14.463112 (Thread-1): On model.sakila_dbt_project.customer_test: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.customer_test"} */
drop table if exists "sakila_wh"."dwh"."customer_test__dbt_backup" cascade
2022-01-18 15:44:14.543561 (Thread-1): SQL status: DROP TABLE in 0.08 seconds
2022-01-18 15:44:14.545790 (Thread-1): finished collecting timing info
2022-01-18 15:44:14.546153 (Thread-1): On model.sakila_dbt_project.customer_test: Close
2022-01-18 15:44:14.546887 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5de8d131-3035-488c-bfba-189e8138af90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11227d370>]}
2022-01-18 15:44:14.547492 (Thread-1): 21:14:14 | 6 of 7 OK created table model dwh.customer_alias..................... [SELECT 9 in 0.91s]
2022-01-18 15:44:14.547795 (Thread-1): Finished running node model.sakila_dbt_project.customer_test
2022-01-18 15:44:14.548058 (Thread-1): Began running node model.sakila_dbt_project.my_second_dbt_model
2022-01-18 15:44:14.548551 (Thread-1): 21:14:14 | 7 of 7 START table model dwh.my_second_dbt_model..................... [RUN]
2022-01-18 15:44:14.549272 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-18 15:44:14.549623 (Thread-1): Compiling model.sakila_dbt_project.my_second_dbt_model
2022-01-18 15:44:14.552845 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.my_second_dbt_model"
2022-01-18 15:44:14.554134 (Thread-1): finished collecting timing info
2022-01-18 15:44:14.561602 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.my_second_dbt_model"
2022-01-18 15:44:14.562605 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-18 15:44:14.562972 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: BEGIN
2022-01-18 15:44:14.563187 (Thread-1): Opening a new connection, currently in state closed
2022-01-18 15:44:15.029992 (Thread-1): SQL status: BEGIN in 0.47 seconds
2022-01-18 15:44:15.030630 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-18 15:44:15.030899 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */


  create  table "sakila_wh"."dwh"."my_second_dbt_model__dbt_tmp"
  as (
    -- Use the `ref` function to select from other models

select *
from "sakila_wh"."dwh"."my_first_dbt_model"
where id = 1
  );
2022-01-18 15:44:15.111234 (Thread-1): SQL status: SELECT 1 in 0.08 seconds
2022-01-18 15:44:15.115293 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-18 15:44:15.115630 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
alter table "sakila_wh"."dwh"."my_second_dbt_model" rename to "my_second_dbt_model__dbt_backup"
2022-01-18 15:44:15.191512 (Thread-1): SQL status: ALTER TABLE in 0.08 seconds
2022-01-18 15:44:15.195101 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-18 15:44:15.195376 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
alter table "sakila_wh"."dwh"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-18 15:44:15.270993 (Thread-1): SQL status: ALTER TABLE in 0.08 seconds
2022-01-18 15:44:15.272851 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: COMMIT
2022-01-18 15:44:15.273051 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-18 15:44:15.273219 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: COMMIT
2022-01-18 15:44:15.348845 (Thread-1): SQL status: COMMIT in 0.08 seconds
2022-01-18 15:44:15.351797 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-18 15:44:15.352104 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
drop table if exists "sakila_wh"."dwh"."my_second_dbt_model__dbt_backup" cascade
2022-01-18 15:44:15.429567 (Thread-1): SQL status: DROP TABLE in 0.08 seconds
2022-01-18 15:44:15.431843 (Thread-1): finished collecting timing info
2022-01-18 15:44:15.432722 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: Close
2022-01-18 15:44:15.433840 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5de8d131-3035-488c-bfba-189e8138af90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11226f4c0>]}
2022-01-18 15:44:15.434478 (Thread-1): 21:14:15 | 7 of 7 OK created table model dwh.my_second_dbt_model................ [SELECT 1 in 0.88s]
2022-01-18 15:44:15.434902 (Thread-1): Finished running node model.sakila_dbt_project.my_second_dbt_model
2022-01-18 15:44:15.436515 (MainThread): Acquiring new postgres connection "master".
2022-01-18 15:44:15.436765 (MainThread): Using postgres connection "master".
2022-01-18 15:44:15.436936 (MainThread): On master: BEGIN
2022-01-18 15:44:15.437107 (MainThread): Opening a new connection, currently in state closed
2022-01-18 15:44:15.895157 (MainThread): SQL status: BEGIN in 0.46 seconds
2022-01-18 15:44:15.895802 (MainThread): On master: COMMIT
2022-01-18 15:44:15.896075 (MainThread): Using postgres connection "master".
2022-01-18 15:44:15.896339 (MainThread): On master: COMMIT
2022-01-18 15:44:15.971422 (MainThread): SQL status: COMMIT in 0.07 seconds
2022-01-18 15:44:15.986669 (MainThread): On master: Close
2022-01-18 15:44:15.987538 (MainThread): 21:14:15 | 
2022-01-18 15:44:15.987834 (MainThread): 21:14:15 | Finished running 6 table models, 1 incremental model in 9.86s.
2022-01-18 15:44:15.988076 (MainThread): Connection 'master' was properly closed.
2022-01-18 15:44:15.988271 (MainThread): Connection 'model.sakila_dbt_project.my_second_dbt_model' was properly closed.
2022-01-18 15:44:15.999758 (MainThread): 
2022-01-18 15:44:16.000045 (MainThread): Completed successfully
2022-01-18 15:44:16.000311 (MainThread): 
Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
2022-01-18 15:44:16.000621 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11222af10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11222a400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11222a5e0>]}
2022-01-18 15:44:16.000904 (MainThread): Flushing usage events
2022-01-21 06:44:04.615074 (MainThread): Running with dbt=0.21.1
2022-01-21 06:44:04.716963 (MainThread): running dbt with arguments Namespace(record_timing_info=None, debug=False, log_format='default', write_json=True, use_colors=None, strict=False, warn_error=False, partial_parse=None, single_threaded=False, test_new_parser=False, use_experimental_parser=False, project_dir=None, profiles_dir='/Users/nijoshi/.dbt', profile=None, target=None, vars='{}', log_cache_events=False, use_cache=True, fail_fast=False, threads=None, version_check=True, select=None, exclude=None, selector_name=None, state=None, defer=None, full_refresh=False, cls=<class 'dbt.task.run.RunTask'>, which='run', rpc_method='run')
2022-01-21 06:44:04.719521 (MainThread): Tracking: tracking
2022-01-21 06:44:04.743827 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111a5a490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112060e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112060430>]}
2022-01-21 06:44:04.768787 (MainThread): Partial parsing not enabled
2022-01-21 06:44:04.832003 (MainThread): Parsing macros/catalog.sql
2022-01-21 06:44:04.837060 (MainThread): Parsing macros/relations.sql
2022-01-21 06:44:04.838954 (MainThread): Parsing macros/adapters.sql
2022-01-21 06:44:04.867525 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2022-01-21 06:44:04.869578 (MainThread): Parsing macros/core.sql
2022-01-21 06:44:04.873878 (MainThread): Parsing macros/materializations/test.sql
2022-01-21 06:44:04.881493 (MainThread): Parsing macros/materializations/helpers.sql
2022-01-21 06:44:04.892542 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2022-01-21 06:44:04.894520 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2022-01-21 06:44:04.914620 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2022-01-21 06:44:04.953195 (MainThread): Parsing macros/materializations/seed/seed.sql
2022-01-21 06:44:04.978678 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2022-01-21 06:44:04.980702 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2022-01-21 06:44:04.991874 (MainThread): Parsing macros/materializations/incremental/on_schema_change.sql
2022-01-21 06:44:05.015574 (MainThread): Parsing macros/materializations/common/merge.sql
2022-01-21 06:44:05.031784 (MainThread): Parsing macros/materializations/table/table.sql
2022-01-21 06:44:05.040768 (MainThread): Parsing macros/materializations/view/view.sql
2022-01-21 06:44:05.048847 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2022-01-21 06:44:05.053114 (MainThread): Parsing macros/etc/get_custom_alias.sql
2022-01-21 06:44:05.054862 (MainThread): Parsing macros/etc/query.sql
2022-01-21 06:44:05.055939 (MainThread): Parsing macros/etc/is_incremental.sql
2022-01-21 06:44:05.057590 (MainThread): Parsing macros/etc/datetime.sql
2022-01-21 06:44:05.067424 (MainThread): Parsing macros/etc/where_subquery.sql
2022-01-21 06:44:05.069518 (MainThread): Parsing macros/etc/get_custom_schema.sql
2022-01-21 06:44:05.072192 (MainThread): Parsing macros/etc/get_custom_database.sql
2022-01-21 06:44:05.073924 (MainThread): Parsing macros/adapters/common.sql
2022-01-21 06:44:05.137656 (MainThread): Parsing macros/schema_tests/relationships.sql
2022-01-21 06:44:05.139810 (MainThread): Parsing macros/schema_tests/not_null.sql
2022-01-21 06:44:05.141342 (MainThread): Parsing macros/schema_tests/unique.sql
2022-01-21 06:44:05.143086 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2022-01-21 06:44:05.145891 (MainThread): Parsing macros/cross_db_utils/except.sql
2022-01-21 06:44:05.147424 (MainThread): Parsing macros/cross_db_utils/replace.sql
2022-01-21 06:44:05.148986 (MainThread): Parsing macros/cross_db_utils/concat.sql
2022-01-21 06:44:05.150178 (MainThread): Parsing macros/cross_db_utils/datatypes.sql
2022-01-21 06:44:05.157010 (MainThread): Parsing macros/cross_db_utils/_is_relation.sql
2022-01-21 06:44:05.158459 (MainThread): Parsing macros/cross_db_utils/length.sql
2022-01-21 06:44:05.159957 (MainThread): Parsing macros/cross_db_utils/dateadd.sql
2022-01-21 06:44:05.163384 (MainThread): Parsing macros/cross_db_utils/intersect.sql
2022-01-21 06:44:05.164584 (MainThread): Parsing macros/cross_db_utils/right.sql
2022-01-21 06:44:05.167084 (MainThread): Parsing macros/cross_db_utils/datediff.sql
2022-01-21 06:44:05.178134 (MainThread): Parsing macros/cross_db_utils/safe_cast.sql
2022-01-21 06:44:05.180250 (MainThread): Parsing macros/cross_db_utils/hash.sql
2022-01-21 06:44:05.181826 (MainThread): Parsing macros/cross_db_utils/cast_bool_to_text.sql
2022-01-21 06:44:05.183436 (MainThread): Parsing macros/cross_db_utils/identifier.sql
2022-01-21 06:44:05.185297 (MainThread): Parsing macros/cross_db_utils/position.sql
2022-01-21 06:44:05.187018 (MainThread): Parsing macros/cross_db_utils/literal.sql
2022-01-21 06:44:05.188100 (MainThread): Parsing macros/cross_db_utils/current_timestamp.sql
2022-01-21 06:44:05.192253 (MainThread): Parsing macros/cross_db_utils/width_bucket.sql
2022-01-21 06:44:05.200282 (MainThread): Parsing macros/cross_db_utils/last_day.sql
2022-01-21 06:44:05.206215 (MainThread): Parsing macros/cross_db_utils/split_part.sql
2022-01-21 06:44:05.208570 (MainThread): Parsing macros/cross_db_utils/date_trunc.sql
2022-01-21 06:44:05.210675 (MainThread): Parsing macros/cross_db_utils/_is_ephemeral.sql
2022-01-21 06:44:05.213231 (MainThread): Parsing macros/materializations/insert_by_period_materialization.sql
2022-01-21 06:44:05.242718 (MainThread): Parsing macros/web/get_url_host.sql
2022-01-21 06:44:05.244996 (MainThread): Parsing macros/web/get_url_path.sql
2022-01-21 06:44:05.247861 (MainThread): Parsing macros/web/get_url_parameter.sql
2022-01-21 06:44:05.249616 (MainThread): Parsing macros/jinja_helpers/pretty_log_format.sql
2022-01-21 06:44:05.250853 (MainThread): Parsing macros/jinja_helpers/pretty_time.sql
2022-01-21 06:44:05.252185 (MainThread): Parsing macros/jinja_helpers/log_info.sql
2022-01-21 06:44:05.253437 (MainThread): Parsing macros/jinja_helpers/slugify.sql
2022-01-21 06:44:05.254766 (MainThread): Parsing macros/schema_tests/fewer_rows_than.sql
2022-01-21 06:44:05.256630 (MainThread): Parsing macros/schema_tests/equal_rowcount.sql
2022-01-21 06:44:05.258429 (MainThread): Parsing macros/schema_tests/relationships_where.sql
2022-01-21 06:44:05.261009 (MainThread): Parsing macros/schema_tests/recency.sql
2022-01-21 06:44:05.263147 (MainThread): Parsing macros/schema_tests/not_constant.sql
2022-01-21 06:44:05.264579 (MainThread): Parsing macros/schema_tests/accepted_range.sql
2022-01-21 06:44:05.267396 (MainThread): Parsing macros/schema_tests/not_accepted_values.sql
2022-01-21 06:44:05.269734 (MainThread): Parsing macros/schema_tests/test_unique_where.sql
2022-01-21 06:44:05.271336 (MainThread): Parsing macros/schema_tests/at_least_one.sql
2022-01-21 06:44:05.272780 (MainThread): Parsing macros/schema_tests/unique_combination_of_columns.sql
2022-01-21 06:44:05.276295 (MainThread): Parsing macros/schema_tests/cardinality_equality.sql
2022-01-21 06:44:05.278821 (MainThread): Parsing macros/schema_tests/expression_is_true.sql
2022-01-21 06:44:05.280945 (MainThread): Parsing macros/schema_tests/sequential_values.sql
2022-01-21 06:44:05.284389 (MainThread): Parsing macros/schema_tests/test_not_null_where.sql
2022-01-21 06:44:05.286024 (MainThread): Parsing macros/schema_tests/equality.sql
2022-01-21 06:44:05.290054 (MainThread): Parsing macros/schema_tests/mutually_exclusive_ranges.sql
2022-01-21 06:44:05.301422 (MainThread): Parsing macros/sql/date_spine.sql
2022-01-21 06:44:05.307624 (MainThread): Parsing macros/sql/nullcheck_table.sql
2022-01-21 06:44:05.309772 (MainThread): Parsing macros/sql/get_relations_by_pattern.sql
2022-01-21 06:44:05.313960 (MainThread): Parsing macros/sql/generate_series.sql
2022-01-21 06:44:05.349949 (MainThread): Parsing macros/sql/get_relations_by_prefix.sql
2022-01-21 06:44:05.354320 (MainThread): Parsing macros/sql/get_tables_by_prefix_sql.sql
2022-01-21 06:44:05.356597 (MainThread): Parsing macros/sql/star.sql
2022-01-21 06:44:05.360824 (MainThread): Parsing macros/sql/unpivot.sql
2022-01-21 06:44:05.370953 (MainThread): Parsing macros/sql/union.sql
2022-01-21 06:44:05.380928 (MainThread): Parsing macros/sql/groupby.sql
2022-01-21 06:44:05.382597 (MainThread): Parsing macros/sql/surrogate_key.sql
2022-01-21 06:44:05.386811 (MainThread): Parsing macros/sql/safe_add.sql
2022-01-21 06:44:05.388713 (MainThread): Parsing macros/sql/nullcheck.sql
2022-01-21 06:44:05.390673 (MainThread): Parsing macros/sql/get_tables_by_pattern_sql.sql
2022-01-21 06:44:05.400814 (MainThread): Parsing macros/sql/get_column_values.sql
2022-01-21 06:44:05.408411 (MainThread): Parsing macros/sql/pivot.sql
2022-01-21 06:44:05.413949 (MainThread): Parsing macros/sql/get_query_results_as_dict.sql
2022-01-21 06:44:05.417146 (MainThread): Parsing macros/sql/haversine_distance.sql
2022-01-21 06:44:05.797018 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-21 06:44:05.812736 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.customer_test".
2022-01-21 06:44:05.817351 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-21 06:44:05.818670 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-21 06:44:05.823298 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.film_test".
2022-01-21 06:44:05.827671 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-21 06:44:05.836492 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-21 06:44:05.839742 (MainThread): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-21 06:44:05.852974 (MainThread): Acquiring new postgres connection "test.sakila_dbt_project.film_replacementcost_30".
2022-01-21 06:44:05.855015 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-21 06:44:05.898225 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-21 06:44:05.900374 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-21 06:44:05.902532 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-21 06:44:05.904560 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-21 06:44:05.906562 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-21 06:44:05.908715 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-21 06:44:05.922901 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-21 06:44:05.927257 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-21 06:44:05.943435 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-21 06:44:05.945390 (MainThread): 'soft_unicode' has been renamed to 'soft_str'. The old name will be removed in MarkupSafe 2.1.
2022-01-21 06:44:05.974291 (MainThread): Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '77ec5de1-6dab-491f-9005-070565bd2747', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1121f2dc0>]}
2022-01-21 06:44:05.984088 (MainThread): write_gpickle is deprecated and will be removed in 3.0.Use ``pickle.dump(G, path, protocol)``
2022-01-21 06:44:05.984648 (MainThread): Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '77ec5de1-6dab-491f-9005-070565bd2747', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1121cfdf0>]}
2022-01-21 06:44:05.984928 (MainThread): Found 7 models, 11 tests, 0 snapshots, 0 analyses, 347 macros, 0 operations, 0 seed files, 12 sources, 0 exposures
2022-01-21 06:44:05.986713 (MainThread): 
2022-01-21 06:44:05.987072 (MainThread): Acquiring new postgres connection "master".
2022-01-21 06:44:05.988078 (ThreadPoolExecutor-0_0): Acquiring new postgres connection "list_sakila_wh".
2022-01-21 06:44:05.997204 (ThreadPoolExecutor-0_0): Using postgres connection "list_sakila_wh".
2022-01-21 06:44:05.997390 (ThreadPoolExecutor-0_0): On list_sakila_wh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh"} */

    select distinct nspname from pg_namespace
  
2022-01-21 06:44:05.997547 (ThreadPoolExecutor-0_0): Opening a new connection, currently in state init
2022-01-21 06:44:06.411531 (ThreadPoolExecutor-0_0): SQL status: SELECT 16 in 0.41 seconds
2022-01-21 06:44:06.413377 (ThreadPoolExecutor-0_0): On list_sakila_wh: Close
2022-01-21 06:44:06.415136 (ThreadPoolExecutor-1_0): Acquiring new postgres connection "list_sakila_wh_dwh".
2022-01-21 06:44:06.421865 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-21 06:44:06.422134 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: BEGIN
2022-01-21 06:44:06.422327 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state closed
2022-01-21 06:44:06.745192 (ThreadPoolExecutor-1_0): SQL status: BEGIN in 0.32 seconds
2022-01-21 06:44:06.745478 (ThreadPoolExecutor-1_0): Using postgres connection "list_sakila_wh_dwh".
2022-01-21 06:44:06.745647 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "list_sakila_wh_dwh"} */
select
      'sakila_wh' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'dwh'
    union all
    select
      'sakila_wh' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'dwh'
  
2022-01-21 06:44:06.805058 (ThreadPoolExecutor-1_0): SQL status: SELECT 0 in 0.06 seconds
2022-01-21 06:44:06.807907 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: ROLLBACK
2022-01-21 06:44:06.863936 (ThreadPoolExecutor-1_0): On list_sakila_wh_dwh: Close
2022-01-21 06:44:06.868630 (MainThread): Using postgres connection "master".
2022-01-21 06:44:06.868824 (MainThread): On master: BEGIN
2022-01-21 06:44:06.868985 (MainThread): Opening a new connection, currently in state init
2022-01-21 06:44:07.196006 (MainThread): SQL status: BEGIN in 0.33 seconds
2022-01-21 06:44:07.196691 (MainThread): Using postgres connection "master".
2022-01-21 06:44:07.196971 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2022-01-21 06:44:07.267013 (MainThread): SQL status: SELECT 47 in 0.07 seconds
2022-01-21 06:44:07.269510 (MainThread): On master: ROLLBACK
2022-01-21 06:44:07.323289 (MainThread): Using postgres connection "master".
2022-01-21 06:44:07.323638 (MainThread): On master: BEGIN
2022-01-21 06:44:07.434250 (MainThread): SQL status: BEGIN in 0.11 seconds
2022-01-21 06:44:07.434871 (MainThread): On master: COMMIT
2022-01-21 06:44:07.435234 (MainThread): Using postgres connection "master".
2022-01-21 06:44:07.435474 (MainThread): On master: COMMIT
2022-01-21 06:44:07.489523 (MainThread): SQL status: COMMIT in 0.05 seconds
2022-01-21 06:44:07.489975 (MainThread): On master: Close
2022-01-21 06:44:07.490616 (MainThread): 12:14:07 | Concurrency: 1 threads (target='dev')
2022-01-21 06:44:07.490959 (MainThread): 12:14:07 | 
2022-01-21 06:44:07.493802 (Thread-1): Began running node model.sakila_dbt_project.dim_date
2022-01-21 06:44:07.494192 (Thread-1): 12:14:07 | 1 of 7 START view model dwh.dim_date................................. [RUN]
2022-01-21 06:44:07.494626 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.dim_date".
2022-01-21 06:44:07.494879 (Thread-1): Compiling model.sakila_dbt_project.dim_date
2022-01-21 06:44:07.496818 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.dim_date"
2022-01-21 06:44:07.497396 (Thread-1): finished collecting timing info
2022-01-21 06:44:07.525197 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.dim_date"
2022-01-21 06:44:07.526094 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-21 06:44:07.526287 (Thread-1): On model.sakila_dbt_project.dim_date: BEGIN
2022-01-21 06:44:07.526458 (Thread-1): Opening a new connection, currently in state closed
2022-01-21 06:44:07.862005 (Thread-1): SQL status: BEGIN in 0.34 seconds
2022-01-21 06:44:07.862368 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-21 06:44:07.862603 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */

  create view "sakila_wh"."dwh"."dim_date__dbt_tmp" as (
    with dates as (
SELECT
       TO_CHAR(datum, 'yyyymmdd')::INT AS date_dim_id,
       datum AS date_key,
       EXTRACT(EPOCH FROM datum) AS epoch,
       TO_CHAR(datum, 'TMDay') AS day_name,
       EXTRACT(ISODOW FROM datum) AS day_of_week,
       EXTRACT(DAY FROM datum) AS day_of_month,
       datum - DATE_TRUNC('quarter', datum)::DATE + 1 AS day_of_quarter,
       EXTRACT(DOY FROM datum) AS day_of_year,
       TO_CHAR(datum, 'W')::INT AS week_of_month,
       EXTRACT(WEEK FROM datum) AS week_of_year,
       EXTRACT(MONTH FROM datum) AS month_actual,
       TO_CHAR(datum, 'TMMonth') AS month_name,
       TO_CHAR(datum, 'Mon') AS month_name_abbreviated,
       EXTRACT(QUARTER FROM datum) AS quarter_actual,
       CASE
           WHEN EXTRACT(QUARTER FROM datum) = 1 THEN 'First'
           WHEN EXTRACT(QUARTER FROM datum) = 2 THEN 'Second'
           WHEN EXTRACT(QUARTER FROM datum) = 3 THEN 'Third'
           WHEN EXTRACT(QUARTER FROM datum) = 4 THEN 'Fourth'
           END AS quarter_name,
       EXTRACT(YEAR FROM datum) AS year_actual,
       datum + (1 - EXTRACT(ISODOW FROM datum))::INT AS first_day_of_week,
       datum + (7 - EXTRACT(ISODOW FROM datum))::INT AS last_day_of_week,
       datum + (1 - EXTRACT(DAY FROM datum))::INT AS first_day_of_month,
       (DATE_TRUNC('MONTH', datum) + INTERVAL '1 MONTH - 1 day')::DATE AS last_day_of_month,
       DATE_TRUNC('quarter', datum)::DATE AS first_day_of_quarter,
       (DATE_TRUNC('quarter', datum) + INTERVAL '3 MONTH - 1 day')::DATE AS last_day_of_quarter,
       TO_DATE(EXTRACT(YEAR FROM datum) || '-01-01', 'YYYY-MM-DD') AS first_day_of_year,
       TO_DATE(EXTRACT(YEAR FROM datum) || '-12-31', 'YYYY-MM-DD') AS last_day_of_year,
       TO_CHAR(datum, 'yyyymm') AS yyyymm,
       CASE
           WHEN EXTRACT(ISODOW FROM datum) IN (6, 7) THEN TRUE
           ELSE FALSE
           END AS weekend_indr
FROM (SELECT '2000-01-01'::DATE + SEQUENCE.DAY AS datum
      FROM GENERATE_SERIES(0, 29219) AS SEQUENCE (DAY)
      GROUP BY SEQUENCE.DAY) DQ
)
select
*
from
dates
where
date_key <= CURRENT_DATE
order by date_dim_id asc
  );

2022-01-21 06:44:07.938405 (Thread-1): SQL status: CREATE VIEW in 0.08 seconds
2022-01-21 06:44:07.945651 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-21 06:44:07.945907 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
alter table "sakila_wh"."dwh"."dim_date__dbt_tmp" rename to "dim_date"
2022-01-21 06:44:08.000070 (Thread-1): SQL status: ALTER TABLE in 0.05 seconds
2022-01-21 06:44:08.007810 (Thread-1): On model.sakila_dbt_project.dim_date: COMMIT
2022-01-21 06:44:08.008069 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-21 06:44:08.008249 (Thread-1): On model.sakila_dbt_project.dim_date: COMMIT
2022-01-21 06:44:08.062469 (Thread-1): SQL status: COMMIT in 0.05 seconds
2022-01-21 06:44:08.068177 (Thread-1): Using postgres connection "model.sakila_dbt_project.dim_date".
2022-01-21 06:44:08.068401 (Thread-1): On model.sakila_dbt_project.dim_date: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.dim_date"} */
drop view if exists "sakila_wh"."dwh"."dim_date__dbt_backup" cascade
2022-01-21 06:44:08.123088 (Thread-1): SQL status: DROP VIEW in 0.05 seconds
2022-01-21 06:44:08.124830 (Thread-1): finished collecting timing info
2022-01-21 06:44:08.125133 (Thread-1): On model.sakila_dbt_project.dim_date: Close
2022-01-21 06:44:08.125718 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '77ec5de1-6dab-491f-9005-070565bd2747', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112050a30>]}
2022-01-21 06:44:08.126146 (Thread-1): 12:14:08 | 1 of 7 OK created view model dwh.dim_date............................ [CREATE VIEW in 0.63s]
2022-01-21 06:44:08.126372 (Thread-1): Finished running node model.sakila_dbt_project.dim_date
2022-01-21 06:44:08.126634 (Thread-1): Began running node model.sakila_dbt_project.film_test
2022-01-21 06:44:08.126911 (Thread-1): 12:14:08 | 2 of 7 START table model dwh.film_test............................... [RUN]
2022-01-21 06:44:08.127381 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.film_test".
2022-01-21 06:44:08.127604 (Thread-1): Compiling model.sakila_dbt_project.film_test
2022-01-21 06:44:08.129420 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.film_test"
2022-01-21 06:44:08.130089 (Thread-1): finished collecting timing info
2022-01-21 06:44:08.151010 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.film_test"
2022-01-21 06:44:08.151779 (Thread-1): Using postgres connection "model.sakila_dbt_project.film_test".
2022-01-21 06:44:08.151969 (Thread-1): On model.sakila_dbt_project.film_test: BEGIN
2022-01-21 06:44:08.152142 (Thread-1): Opening a new connection, currently in state closed
2022-01-21 06:44:08.477264 (Thread-1): SQL status: BEGIN in 0.33 seconds
2022-01-21 06:44:08.477530 (Thread-1): Using postgres connection "model.sakila_dbt_project.film_test".
2022-01-21 06:44:08.477686 (Thread-1): On model.sakila_dbt_project.film_test: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.film_test"} */


  create  table "sakila_wh"."dwh"."film_test__dbt_tmp"
  as (
    select * from 
stg.film
  );
2022-01-21 06:44:08.544431 (Thread-1): SQL status: SELECT 1000 in 0.07 seconds
2022-01-21 06:44:08.547788 (Thread-1): Using postgres connection "model.sakila_dbt_project.film_test".
2022-01-21 06:44:08.548025 (Thread-1): On model.sakila_dbt_project.film_test: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.film_test"} */
alter table "sakila_wh"."dwh"."film_test__dbt_tmp" rename to "film_test"
2022-01-21 06:44:08.605744 (Thread-1): SQL status: ALTER TABLE in 0.06 seconds
2022-01-21 06:44:08.611696 (Thread-1): On model.sakila_dbt_project.film_test: COMMIT
2022-01-21 06:44:08.611955 (Thread-1): Using postgres connection "model.sakila_dbt_project.film_test".
2022-01-21 06:44:08.612125 (Thread-1): On model.sakila_dbt_project.film_test: COMMIT
2022-01-21 06:44:08.665551 (Thread-1): SQL status: COMMIT in 0.05 seconds
2022-01-21 06:44:08.667693 (Thread-1): Using postgres connection "model.sakila_dbt_project.film_test".
2022-01-21 06:44:08.667895 (Thread-1): On model.sakila_dbt_project.film_test: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.film_test"} */
drop table if exists "sakila_wh"."dwh"."film_test__dbt_backup" cascade
2022-01-21 06:44:08.721690 (Thread-1): SQL status: DROP TABLE in 0.05 seconds
2022-01-21 06:44:08.723789 (Thread-1): finished collecting timing info
2022-01-21 06:44:08.724226 (Thread-1): On model.sakila_dbt_project.film_test: Close
2022-01-21 06:44:08.725493 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '77ec5de1-6dab-491f-9005-070565bd2747', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112401fd0>]}
2022-01-21 06:44:08.726292 (Thread-1): 12:14:08 | 2 of 7 OK created table model dwh.film_test.......................... [SELECT 1000 in 0.60s]
2022-01-21 06:44:08.726637 (Thread-1): Finished running node model.sakila_dbt_project.film_test
2022-01-21 06:44:08.727023 (Thread-1): Began running node model.sakila_dbt_project.hello_world
2022-01-21 06:44:08.727562 (Thread-1): 12:14:08 | 3 of 7 START table model dwh.hello_world............................. [RUN]
2022-01-21 06:44:08.728146 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.hello_world".
2022-01-21 06:44:08.728398 (Thread-1): Compiling model.sakila_dbt_project.hello_world
2022-01-21 06:44:08.732282 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.hello_world"
2022-01-21 06:44:08.733068 (Thread-1): finished collecting timing info
2022-01-21 06:44:08.736560 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.hello_world"
2022-01-21 06:44:08.737318 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-21 06:44:08.737529 (Thread-1): On model.sakila_dbt_project.hello_world: BEGIN
2022-01-21 06:44:08.737712 (Thread-1): Opening a new connection, currently in state closed
2022-01-21 06:44:09.072548 (Thread-1): SQL status: BEGIN in 0.33 seconds
2022-01-21 06:44:09.072830 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-21 06:44:09.073004 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */


  create  table "sakila_wh"."dwh"."hello_world__dbt_tmp"
  as (
    select
	customer.customer_id::int,
	customer.store_id::int,
	customer.first_name,
	customer.last_name,
	concat(customer.first_name,' ',customer.last_name) as full_name,
	substring(email from POSITION('@' in email)+1 for char_length(email)-POSITION('@' in email)) as domain,
	customer.email,
	customer.active::int,
	customer.address_id::int,
	address.address,
	city.city_id::int,
	city.city,
	(case when customer.active = 0 then 'no' else 'yes' end)::varchar(100) as "active_desc",
	customer.create_date::timestamp,
	customer.last_update::timestamp
from
	stg.customer as customer

	left join stg.address on 1=1
	and customer.address_id =address.address_id

	left join stg.city on 1=1
	and address.city_id = city.city_id
  );
2022-01-21 06:44:09.143060 (Thread-1): SQL status: SELECT 599 in 0.07 seconds
2022-01-21 06:44:09.145834 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-21 06:44:09.146048 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
alter table "sakila_wh"."dwh"."hello_world__dbt_tmp" rename to "hello_world"
2022-01-21 06:44:09.199862 (Thread-1): SQL status: ALTER TABLE in 0.05 seconds
2022-01-21 06:44:09.201502 (Thread-1): On model.sakila_dbt_project.hello_world: COMMIT
2022-01-21 06:44:09.201767 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-21 06:44:09.201969 (Thread-1): On model.sakila_dbt_project.hello_world: COMMIT
2022-01-21 06:44:09.255686 (Thread-1): SQL status: COMMIT in 0.05 seconds
2022-01-21 06:44:09.257907 (Thread-1): Using postgres connection "model.sakila_dbt_project.hello_world".
2022-01-21 06:44:09.258114 (Thread-1): On model.sakila_dbt_project.hello_world: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.hello_world"} */
drop table if exists "sakila_wh"."dwh"."hello_world__dbt_backup" cascade
2022-01-21 06:44:09.311949 (Thread-1): SQL status: DROP TABLE in 0.05 seconds
2022-01-21 06:44:09.314029 (Thread-1): finished collecting timing info
2022-01-21 06:44:09.314292 (Thread-1): On model.sakila_dbt_project.hello_world: Close
2022-01-21 06:44:09.315046 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '77ec5de1-6dab-491f-9005-070565bd2747', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1123eb550>]}
2022-01-21 06:44:09.315698 (Thread-1): 12:14:09 | 3 of 7 OK created table model dwh.hello_world........................ [SELECT 599 in 0.59s]
2022-01-21 06:44:09.316116 (Thread-1): Finished running node model.sakila_dbt_project.hello_world
2022-01-21 06:44:09.316524 (Thread-1): Began running node model.sakila_dbt_project.my_first_dbt_model
2022-01-21 06:44:09.317344 (Thread-1): 12:14:09 | 4 of 7 START table model dwh.my_first_dbt_model...................... [RUN]
2022-01-21 06:44:09.318609 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-21 06:44:09.319419 (Thread-1): Compiling model.sakila_dbt_project.my_first_dbt_model
2022-01-21 06:44:09.323344 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.my_first_dbt_model"
2022-01-21 06:44:09.324147 (Thread-1): finished collecting timing info
2022-01-21 06:44:09.327453 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.my_first_dbt_model"
2022-01-21 06:44:09.328214 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-21 06:44:09.328445 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: BEGIN
2022-01-21 06:44:09.328732 (Thread-1): Opening a new connection, currently in state closed
2022-01-21 06:44:09.653777 (Thread-1): SQL status: BEGIN in 0.33 seconds
2022-01-21 06:44:09.654158 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-21 06:44:09.654413 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */


  create  table "sakila_wh"."dwh"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    --union all
    --select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2022-01-21 06:44:09.713464 (Thread-1): SQL status: SELECT 1 in 0.06 seconds
2022-01-21 06:44:09.716768 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-21 06:44:09.717109 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
alter table "sakila_wh"."dwh"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2022-01-21 06:44:09.770512 (Thread-1): SQL status: ALTER TABLE in 0.05 seconds
2022-01-21 06:44:09.772115 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: COMMIT
2022-01-21 06:44:09.772309 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-21 06:44:09.772473 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: COMMIT
2022-01-21 06:44:09.826192 (Thread-1): SQL status: COMMIT in 0.05 seconds
2022-01-21 06:44:09.829018 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_first_dbt_model".
2022-01-21 06:44:09.829502 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_first_dbt_model"} */
drop table if exists "sakila_wh"."dwh"."my_first_dbt_model__dbt_backup" cascade
2022-01-21 06:44:09.883425 (Thread-1): SQL status: DROP TABLE in 0.05 seconds
2022-01-21 06:44:09.884896 (Thread-1): finished collecting timing info
2022-01-21 06:44:09.885167 (Thread-1): On model.sakila_dbt_project.my_first_dbt_model: Close
2022-01-21 06:44:09.885710 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '77ec5de1-6dab-491f-9005-070565bd2747', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11232c220>]}
2022-01-21 06:44:09.886105 (Thread-1): 12:14:09 | 4 of 7 OK created table model dwh.my_first_dbt_model................. [SELECT 1 in 0.57s]
2022-01-21 06:44:09.886342 (Thread-1): Finished running node model.sakila_dbt_project.my_first_dbt_model
2022-01-21 06:44:09.886574 (Thread-1): Began running node model.sakila_dbt_project.payment_inc
2022-01-21 06:44:09.886952 (Thread-1): 12:14:09 | 5 of 7 START incremental model dwh.payment_inc....................... [RUN]
2022-01-21 06:44:09.887459 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-21 06:44:09.887667 (Thread-1): Compiling model.sakila_dbt_project.payment_inc
2022-01-21 06:44:09.891367 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.payment_inc"
2022-01-21 06:44:09.891976 (Thread-1): finished collecting timing info
2022-01-21 06:44:09.933748 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.payment_inc"
2022-01-21 06:44:09.934447 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-21 06:44:09.934630 (Thread-1): On model.sakila_dbt_project.payment_inc: BEGIN
2022-01-21 06:44:09.934792 (Thread-1): Opening a new connection, currently in state closed
2022-01-21 06:44:10.261422 (Thread-1): SQL status: BEGIN in 0.33 seconds
2022-01-21 06:44:10.261776 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-21 06:44:10.261964 (Thread-1): On model.sakila_dbt_project.payment_inc: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.payment_inc"} */

      

  create  table "sakila_wh"."dwh"."payment_inc"
  as (
    

select
*,
'2022-01-21 06:44:04' as dbt_tran_time
from
stg.payment
where 1=1




-- - INTERVAL '3 DAY'
-- unique_key='payment_id'
  );
  
2022-01-21 06:44:10.353252 (Thread-1): SQL status: SELECT 16052 in 0.09 seconds
2022-01-21 06:44:10.354911 (Thread-1): On model.sakila_dbt_project.payment_inc: COMMIT
2022-01-21 06:44:10.355209 (Thread-1): Using postgres connection "model.sakila_dbt_project.payment_inc".
2022-01-21 06:44:10.355402 (Thread-1): On model.sakila_dbt_project.payment_inc: COMMIT
2022-01-21 06:44:10.409426 (Thread-1): SQL status: COMMIT in 0.05 seconds
2022-01-21 06:44:10.410123 (Thread-1): finished collecting timing info
2022-01-21 06:44:10.410381 (Thread-1): On model.sakila_dbt_project.payment_inc: Close
2022-01-21 06:44:10.410924 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '77ec5de1-6dab-491f-9005-070565bd2747', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1124377c0>]}
2022-01-21 06:44:10.411332 (Thread-1): 12:14:10 | 5 of 7 OK created incremental model dwh.payment_inc.................. [SELECT 16052 in 0.52s]
2022-01-21 06:44:10.411562 (Thread-1): Finished running node model.sakila_dbt_project.payment_inc
2022-01-21 06:44:10.411781 (Thread-1): Began running node model.sakila_dbt_project.customer_test
2022-01-21 06:44:10.412051 (Thread-1): 12:14:10 | 6 of 7 START table model dwh.customer_alias.......................... [RUN]
2022-01-21 06:44:10.412421 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.customer_test".
2022-01-21 06:44:10.412623 (Thread-1): Compiling model.sakila_dbt_project.customer_test
2022-01-21 06:44:10.416130 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.customer_test"
2022-01-21 06:44:10.416874 (Thread-1): finished collecting timing info
2022-01-21 06:44:10.419549 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.customer_test"
2022-01-21 06:44:10.420167 (Thread-1): Using postgres connection "model.sakila_dbt_project.customer_test".
2022-01-21 06:44:10.420351 (Thread-1): On model.sakila_dbt_project.customer_test: BEGIN
2022-01-21 06:44:10.420523 (Thread-1): Opening a new connection, currently in state closed
2022-01-21 06:44:10.759501 (Thread-1): SQL status: BEGIN in 0.34 seconds
2022-01-21 06:44:10.759781 (Thread-1): Using postgres connection "model.sakila_dbt_project.customer_test".
2022-01-21 06:44:10.759952 (Thread-1): On model.sakila_dbt_project.customer_test: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.customer_test"} */


  create  table "sakila_wh"."dwh"."customer_test__dbt_tmp"
  as (
    

select * from 
"sakila_wh"."dwh"."hello_world"
where customer_id < 10
  );
2022-01-21 06:44:10.821211 (Thread-1): SQL status: SELECT 9 in 0.06 seconds
2022-01-21 06:44:10.825271 (Thread-1): Using postgres connection "model.sakila_dbt_project.customer_test".
2022-01-21 06:44:10.825587 (Thread-1): On model.sakila_dbt_project.customer_test: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.customer_test"} */
alter table "sakila_wh"."dwh"."customer_test__dbt_tmp" rename to "customer_alias"
2022-01-21 06:44:10.879382 (Thread-1): SQL status: ALTER TABLE in 0.05 seconds
2022-01-21 06:44:10.880996 (Thread-1): On model.sakila_dbt_project.customer_test: COMMIT
2022-01-21 06:44:10.881201 (Thread-1): Using postgres connection "model.sakila_dbt_project.customer_test".
2022-01-21 06:44:10.881366 (Thread-1): On model.sakila_dbt_project.customer_test: COMMIT
2022-01-21 06:44:10.935337 (Thread-1): SQL status: COMMIT in 0.05 seconds
2022-01-21 06:44:10.937571 (Thread-1): Using postgres connection "model.sakila_dbt_project.customer_test".
2022-01-21 06:44:10.937772 (Thread-1): On model.sakila_dbt_project.customer_test: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.customer_test"} */
drop table if exists "sakila_wh"."dwh"."customer_test__dbt_backup" cascade
2022-01-21 06:44:10.992313 (Thread-1): SQL status: DROP TABLE in 0.05 seconds
2022-01-21 06:44:10.993848 (Thread-1): finished collecting timing info
2022-01-21 06:44:10.994129 (Thread-1): On model.sakila_dbt_project.customer_test: Close
2022-01-21 06:44:10.994687 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '77ec5de1-6dab-491f-9005-070565bd2747', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1123d2820>]}
2022-01-21 06:44:10.995073 (Thread-1): 12:14:10 | 6 of 7 OK created table model dwh.customer_alias..................... [SELECT 9 in 0.58s]
2022-01-21 06:44:10.995302 (Thread-1): Finished running node model.sakila_dbt_project.customer_test
2022-01-21 06:44:10.995642 (Thread-1): Began running node model.sakila_dbt_project.my_second_dbt_model
2022-01-21 06:44:10.996111 (Thread-1): 12:14:10 | 7 of 7 START table model dwh.my_second_dbt_model..................... [RUN]
2022-01-21 06:44:10.996858 (Thread-1): Acquiring new postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-21 06:44:10.997360 (Thread-1): Compiling model.sakila_dbt_project.my_second_dbt_model
2022-01-21 06:44:11.001250 (Thread-1): Writing injected SQL for node "model.sakila_dbt_project.my_second_dbt_model"
2022-01-21 06:44:11.002093 (Thread-1): finished collecting timing info
2022-01-21 06:44:11.007017 (Thread-1): Writing runtime SQL for node "model.sakila_dbt_project.my_second_dbt_model"
2022-01-21 06:44:11.007978 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-21 06:44:11.008218 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: BEGIN
2022-01-21 06:44:11.008439 (Thread-1): Opening a new connection, currently in state closed
2022-01-21 06:44:11.337059 (Thread-1): SQL status: BEGIN in 0.33 seconds
2022-01-21 06:44:11.337644 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-21 06:44:11.338018 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */


  create  table "sakila_wh"."dwh"."my_second_dbt_model__dbt_tmp"
  as (
    -- Use the `ref` function to select from other models

select *
from "sakila_wh"."dwh"."my_first_dbt_model"
where id = 1
  );
2022-01-21 06:44:11.397308 (Thread-1): SQL status: SELECT 1 in 0.06 seconds
2022-01-21 06:44:11.400232 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-21 06:44:11.400436 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
alter table "sakila_wh"."dwh"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2022-01-21 06:44:11.454447 (Thread-1): SQL status: ALTER TABLE in 0.05 seconds
2022-01-21 06:44:11.456181 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: COMMIT
2022-01-21 06:44:11.456383 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-21 06:44:11.456548 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: COMMIT
2022-01-21 06:44:11.512069 (Thread-1): SQL status: COMMIT in 0.06 seconds
2022-01-21 06:44:11.516096 (Thread-1): Using postgres connection "model.sakila_dbt_project.my_second_dbt_model".
2022-01-21 06:44:11.516304 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.21.1", "profile_name": "sakila_conn", "target_name": "dev", "node_id": "model.sakila_dbt_project.my_second_dbt_model"} */
drop table if exists "sakila_wh"."dwh"."my_second_dbt_model__dbt_backup" cascade
2022-01-21 06:44:11.570460 (Thread-1): SQL status: DROP TABLE in 0.05 seconds
2022-01-21 06:44:11.571830 (Thread-1): finished collecting timing info
2022-01-21 06:44:11.572070 (Thread-1): On model.sakila_dbt_project.my_second_dbt_model: Close
2022-01-21 06:44:11.572546 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '77ec5de1-6dab-491f-9005-070565bd2747', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112456ca0>]}
2022-01-21 06:44:11.572932 (Thread-1): 12:14:11 | 7 of 7 OK created table model dwh.my_second_dbt_model................ [SELECT 1 in 0.58s]
2022-01-21 06:44:11.573157 (Thread-1): Finished running node model.sakila_dbt_project.my_second_dbt_model
2022-01-21 06:44:11.574221 (MainThread): Acquiring new postgres connection "master".
2022-01-21 06:44:11.574451 (MainThread): Using postgres connection "master".
2022-01-21 06:44:11.574620 (MainThread): On master: BEGIN
2022-01-21 06:44:11.574789 (MainThread): Opening a new connection, currently in state closed
2022-01-21 06:44:11.901520 (MainThread): SQL status: BEGIN in 0.33 seconds
2022-01-21 06:44:11.901818 (MainThread): On master: COMMIT
2022-01-21 06:44:11.902004 (MainThread): Using postgres connection "master".
2022-01-21 06:44:11.902171 (MainThread): On master: COMMIT
2022-01-21 06:44:11.954782 (MainThread): SQL status: COMMIT in 0.05 seconds
2022-01-21 06:44:11.955272 (MainThread): On master: Close
2022-01-21 06:44:11.955987 (MainThread): 12:14:11 | 
2022-01-21 06:44:11.956224 (MainThread): 12:14:11 | Finished running 1 view model, 5 table models, 1 incremental model in 5.97s.
2022-01-21 06:44:11.956530 (MainThread): Connection 'master' was properly closed.
2022-01-21 06:44:11.956702 (MainThread): Connection 'model.sakila_dbt_project.my_second_dbt_model' was properly closed.
2022-01-21 06:44:11.969711 (MainThread): 
2022-01-21 06:44:11.969983 (MainThread): Completed successfully
2022-01-21 06:44:11.970266 (MainThread): 
Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
2022-01-21 06:44:11.970538 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1123efe20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1123ef820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112473190>]}
2022-01-21 06:44:11.970812 (MainThread): Flushing usage events
